[
    {
        "id": "q_0000",
        "question": "Какие типы классификации текста существуют в зависимости от количества правильных меток?",
        "answers": [
            "Существуют три основных типа: бинарная классификация (две метки, только одна правильная), многоклассовая классификация (много меток, только одна правильная) и многометочная классификация (много меток, несколько могут быть правильными)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "Multi-class classification: many labels, only one correct Binary classification: two labels, only one correct Multi-label classification: many labels, several can be correct Multi-class classification: many labels, only one correct Text classification is an extremely popular task. You enjoy working text classifiers in your mail agent: it classifies letters and filters spam. Other applications include document classification, review classification, etc. Text classifiers are often used not as an individual task, but as part of bigger pipelines. For example, a voice assistant classifies your utterance to understand what you want (e.g., set the alarm, order a taxi or just chat) and passes your message to different models depending on the classifier's decision. Another example is a web search engine: it can use classifiers to identify the query language, to predict the type of your query (e.g., informational, navigational, transactional), to understand whether you what to see pictures or video in addition to documents, etc. Since most of the classification datasets assume that only one label is correct (you will see this right now!), in the lecture we deal with this type of classification, i.e. the single-label classification . We mention multi-label classification in a separate section ( Multi-Label Classification ). Datasets for Classification Datasets for text classification are very different in terms of size (both dataset size and examples' size), what is classified, and the number of labels. Look at the statistics below. Dataset Type Number of labels Size (train/test) Avg. length (tokens) SST sentiment 5 or 2 8.5k / 1.1k 19 IMDb Review sentiment 2 25k / 25k 271 Yelp Review sentiment 5 or 2 650k / 50k 179 Amazon Review sentiment 5 or 2 3m / 650k 79 TREC question 6 5.5k / 0.5k 10 Yahoo! Answers question 10 1.4m / 60k 131 AG’s News topic 4 120k / 7.6k 44 Sogou News topic 6 54k / 6k 737 DBPedia topic 14 560k / 70k 67 Some of the datasets can be downloaded here . Some of the datasets can be downloaded here . The most popular datasets are for sentiment classification . They consist of reviews of movies, places or restaurants, and products. There are also datasets for question type classification and topic classification. To better understand typical classification tasks, below you can look at the examples from different datasets. How to: pick a dataset and look at the examples to get a feeling of the task. Or you can come back to this later! SST is a sentiment classification dataset which consists of movie reviews (from Rotten Tomatoes html files). The dataset consists of parse trees of the sentences, and not only entire sentences, but also smaller phrases have a sentiment label. There are five labels: 1 (very negative), 2 (negative), 3 (neutral), 4 (positive), and 5 (very positive) (alternatively, labels can be 0-4). Depending on the used labels, you can get either binary SST-2 dataset (if you only consider positivity and negativity) or fine-grained sentiment SST-5 (when using all labels). Note that the dataset size mentioned above (8.5k/2.2k/1.1k for train/dev/test) is in the number of sentences. However, it also"
            }
        ]
    },
    {
        "id": "q_0001",
        "question": "Какие два варианта набора данных можно получить из SST в зависимости от используемых меток?",
        "answers": [
            "Можно получить бинарный набор данных SST-2, если рассматривать только позитивность и негативность, или детализированный набор данных SST-5, если использовать все метки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "labels can be 0-4). Depending on the used labels, you can get either binary SST-2 dataset (if you only consider positivity and negativity) or fine-grained sentiment SST-5 (when using all labels). Note that the dataset size mentioned above (8.5k/2.2k/1.1k for train/dev/test) is in the number of sentences. However, it also has 215,154 phrases that compose each sentence in the dataset. For more details, see the original paper . Look how sentiment of a sentence is composed from its parts. Label : 3 Review : Makes even the claustrophobic on-board quarters seem fun . Label : 1 Review : Ultimately feels empty and unsatisfying , like swallowing a Communion wafer without the wine . Label : 5 Review : A quiet treasure -- a film to be savored . IMDb is a large dataset of informal movie reviews from the Internet Movie Database. The collection allows no more than 30 reviews per movie. The dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The reviews are highly polarized: they are only negative (with the highest score 4 out of 10) or positive (with the lowest score 7 out of 10). For more details, see the original paper . Label : negative Review Hobgoblins .... Hobgoblins .... where do I begin?!? This film gives Manos - The Hands of Fate and Future War a run for their money as the worst film ever made . This one is fun to laugh at , where as Manos was just painful to watch . Hobgoblins will end up in a time capsule somewhere as the perfect movie to describe the term : \" 80 's cheeze \" . The acting ( and I am using this term loosely ) is atrocious , the Hobgoblins are some of the worst puppets you will ever see , and the garden tool fight has to be seen to be believed . The movie was the perfect vehicle for MST3 K , and that version is the only way to watch this mess . This movie gives Mike and the bots lots of ammunition to pull some of the funniest one - liners they have ever done . If you try to watch this without the help of Mike and the bots ..... God help you ! ! Label : positive Review One of my favorite movies I saw at preview in Seattle . Tom Hulce was amazing , with out words could convey his feelings / thoughts . I actually sent Mike Ferrell some donation money to help the film get distributed . It is good . System says I need more lines but do not want to give away plot stuff . I was in the audience in Seattle with Hulce and director , a writer I think and Mike Ferrell . They talked for about an hour afterwords . Not really a dry eye in the house . Why Hollywood continues to be stupid I do not know . ( actually I do know , it is our fault ,"
            }
        ]
    },
    {
        "id": "q_0002",
        "question": "Какие недостатки были отмечены в фильме с участием тучных обнажённых аборигенов?",
        "answers": [
            "В фильме отмечаются плохие спецэффекты, сомнительный рейтинг PG, невнятный и клишированный сюжет, ужасная игра актёров и мучительно глупый финал."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "and director , a writer I think and Mike Ferrell . They talked for about an hour afterwords . Not really a dry eye in the house . Why Hollywood continues to be stupid I do not know . ( actually I do know , it is our fault , look what we watch)Well you get what you pay for guys . Get this and see it with someone special . It is a gem . Label : negative Review Okay , if you have a couple hours to waste , or if you just really hate your life , I would say watch this movie . If anything it 's good for a few laughs . Not only do you have obese , topless natives , but also special effects so bad they are probably outlawed in most states . Seriuosly , the rating of ' PG ' is pretty humorous too , once you see the Native Porn Extravaganza . I would n't give this movie to my retarded nephew . You could n't even show this to Iraqi prisoners without violating the Geneva Convention . The plot is sketchy , and cliché , and dumb , and stupid . The acting is horrible , and the ending is so painful to watch I actually began pouring salt into my eye just to take my mind off of the idiocy filling my TV screen . Label : positive Review I really liked this movie ... it was cute . I enjoyed it , but if you did n't , that is your fault . Emma Roberts played a good Nancy Drew , even though she is n't quite like the books . The old fashion outfits are weird when you see them in modern times , but she looks good on them . To me , the rich girls did n't have outfits that made them look rich . I mean , it looks like they got all the clothes -blindfolded- at a garage sale and just decided to put it on all together . All of the outfits were tacky , especially when they wore the penny loafers with their regular outfits . I do not want to make the movie look bad , because it definitely was n't ! Just go to the theater and watch it ! ! ! You will enjoy it ! Label : negative Review I always found Betsy Drake rather creepy , and this movie reinforces that . As another review said , this is a stalker movie that is n't very funny . I watched it because it has CG in it , but he hardly gets any screen time . It 's no \" North by Northwest \" ... Label : negative Review This movie was on t.v the other day , and I did n't enjoy it at all . The first George of the jungle was a good comedy , but the sequel .... completely awful . The new actor and actress to play the lead roles were n't"
            }
        ]
    },
    {
        "id": "q_0003",
        "question": "Какие соусы были доступны в заведении, где подавали куриные пальчики?",
        "answers": [
            "В заведении были доступны только горчично-медовый соус и «Секретный соус Кейнс». Ранчо не предлагалось."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "crowd. Everyone was really friendly, though. The sweet young man behind the counter gave my son some micro cinnamon doughnuts and scored major points with the little dude! We will be back. Label : 3 Review Jersey Mike's is okay. It's a chain place, and a bit over priced for fast food. I ordered a philly cheese steak. It was mostly bread, with a few thing microscopic slices of meat. A little cheese too. And a sliver or two of peppers. But mostly, it was bread. I think it's funny the people that work here try to make small talk with you. \"So, what are you guys up to tonight?\" I think it would be fun to just try and f*#k with them, and say something like, \"Oh you know, smoking a little meth and just chilling with some hookers.\" See what they say to that. Label : 5 Review Love it!!! Wish we still lived in Arizona as Chino is the one thing we miss. Every time I think about Chino Bandido my mouth starts watering. If I am ever in the state again I will drive out of my way just to go to it again. YUMMY! Label : 4 Review I have been here a few times, but mainly at dinner. Dinner Has always been great, great waiters and staff, with a LCD TV playing almost famous famous bolywood movies. LOL It cracks me up when they dance.....LOL...anyhow, Great vegetarian choices for people who eat there veggies, but trust me, I am a MEAT eater, Chicekn Tika masala, Little dry but still good. My favorite is there Palak Paneer. Great for the vegetarian. I have also tried there lunch Buffet for 11.00. I give a Thumbs up.. Good, serve yourself, and pig out!!!!!! Label : 3 Review Very VERY average. Actually disappointed in the braciole. Kelsey with the pretty smile and form fitting shorts would probably make me think about going back and trying something different. Label : 1 Review So, what kind of place serves chicken fingers and NO Ranch dressing?????? The only sauces they had was honey mustard and \"\"Canes Secret sauce\"\" Can I say EEWWWW!! I thought that the sauce tasted terrible. I am not too big a fan of honey mustard but I do On occasion eat it if there is nothing else And that wasn't even good! The coleslaw was awful also. I do have to say that the chicken fingers were very juicy but also very bland. Those were the only 2 items that I tried, not that there were really any more items on the menu, Texas toast? And Fries I think?? Overall, I would never go back. Label : 4 Review Good food, good drinks, fun bar. There are quite a few Buffalo Wild Wings in the valley and they're a fun place to grab a quick lunch or dinner and watch the game. They have a pretty good garden burger and their buffalo chips (french fry-ish things) are really good. If you like bloody mary's, they have the best one."
            }
        ]
    },
    {
        "id": "q_0004",
        "question": "Какие шесть основных классов содержит таксономия в наборе данных TREC?",
        "answers": [
            "Таксономия в наборе данных TREC содержит шесть основных классов: ABBREVIATION, ENTITY, DESCRIPTION, HUMAN, LOCATION и NUMERIC VALUE."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "never really appreciated the style and the fact that like other Hardy novels Tess is a love story and a very good story. Worth reading Label : 5 Review Title : Great Puzzle Review Content : This is an excellent puzzle for very young children. Melissa & Doug products are well made and kids love them. This puzzle is wooden so kids wont destroy it if they try to roughly put the pieces in. The design is adorable and makes a great gift for any young animal lover. TREC is a dataset for classification of free factual questions. It defines a two-layered taxonomy, which represents a natural semantic classification for typical answers in the TREC task. The hierarchy contains 6 coarse classes (ABBREVIATION, ENTITY, DESCRIPTION, HUMAN, LOCATION and NUMERIC VALUE) and 50 fine classes. For more details, see the original paper . Label : DESC (description) Question : How did serfdom develop in and then leave Russia ? Label : ENTY (entity) Question : What films featured the character Popeye Doyle ? Label : HUM (human) Question : What team did baseball 's St. Louis Browns become ? Label : HUM (human) Question : What is the oldest profession ? Label : DESC (description) Question : How can I find a list of celebrities ' real names ? Label : ENTY (entity) Question : What fowl grabs the spotlight after the Chinese Year of the Monkey ? Label : ABBR (abbreviation) Question : What is the full form of .com ? Label : ENTY (entity) Question : What 's the second - most - used vowel in English ? Label : DESC (description) Question : What are liver enzymes ? Label : HUM (human) Question : Name the scar-faced bounty hunter of The Old West . Label : NUM (numeric value) Question : When was Ozzy Osbourne born ? Label : DESC (description) Question : Why do heavier objects travel downhill faster ? Label : HUM (human) Question : Who was The Pride of the Yankees ? Label : HUM (human) Question : Who killed Gandhi ? Label : LOC (location) Question : What sprawling U.S. state boasts the most airports ? Label : DESC (description) Question : What did the only repealed amendment to the U.S. Constitution deal with ? Label : NUM (numeric value) Question : How many Jews were executed in concentration camps during WWII ? Label : DESC (description) Question : What is \" Nine Inch Nails \" ? Label : DESC (description) Question : What is an annotated bibliography ? Label : NUM (numeric value) Question : What is the date of Boxing Day ? Label : ENTY (entity) Question : What articles of clothing are tokens in Monopoly ? Label : HUM (human) Question : Name 11 famous martyrs . Label : DESC (description) Question : What 's the Olympic motto ? Label : NUM (numeric value) Question : What is the origin of the name ` Scarlett ' ? The dataset is gathered from Yahoo! Answers Comprehensive Questions and Answers version 1.0 dataset . In"
            }
        ]
    },
    {
        "id": "q_0005",
        "question": "Какие 10 основных категорий содержатся в Yahoo! Answers Comprehensive Questions and Answers версии 1.0?",
        "answers": [
            "Датасет содержит следующие 10 основных категорий: «Общество и культура», «Наука и математика», «Здоровье», «Образование и справочные материалы», «Компьютеры и интернет», «Спорт», «Бизнес и финансы», «Развлечения и музыка», «Семья и отношения», «Политика и правительство»."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "11 famous martyrs . Label : DESC (description) Question : What 's the Olympic motto ? Label : NUM (numeric value) Question : What is the origin of the name ` Scarlett ' ? The dataset is gathered from Yahoo! Answers Comprehensive Questions and Answers version 1.0 dataset . In contains the 10 largest main categories: \"Society & Culture\", \"Science & Mathematics\", \"Health, \"Education & Reference\", \"Computers & Internet\", \"Sports\", \"Business & Finance\", \"Entertainment & Music\", \"Family & Relationships\", \"Politics & Government\". Each class contains 140,000 training samples and 5,000 testing samples. The data consists of question title and content, as well as the best answer. Label : Society & Culture Question Title : Why do people have the bird, turkey for thanksgiving? Question Content : Why this bird? Any Significance? Best Answer It is believed that the pilgrims and indians shared wild turkey and venison on the original Thanksgiving. Turkey's \"Americanness\" was established by Benjamin Franklin, who had advocated for the turkey, not the bald eagle, becoming the national bird. Label : Science & Mathematics Question Title : What is an \"imaginary number\"? Question Content : What is an \"imaginary number\", and how is it treated in algebra equations? Best Answer Imaginary numbers are numbers than when squared equal a negative number, as in i^2 = -1, where i is the imaginary number. You'll also often see them represented as i = √-1 (that's the square root of -1). Don't be confused by the poorly chosen name - imaginary numbers do indeed exist and are used in advanced math, such as in the physics of electromagnetic fields. The analogy that Wikipedia uses is a good one - just like you don't need the concept of fractions to count stones, it doesn't mean that fractions don't exist. :) Label : Health Question Title : Does echinacea really help prevent colds? Question Content : Or is a waste of money... Best Answer Well, there appears to be some controvery about this. While some people swear by the stuff, others say that it has no real effect on overcoming a cold. Here are some links, one of which is from a National Institute of Health study. I hope these help you decide whether to head to the health store or not. Label : Education & Reference Question Title : How do I find an out of print book? Question Content : When I was a kid I remember seeing a book that was like an yearbook of all newspapers published by the Times during WW II. Each of the years is compiled into a different book. It gave one a very uniqie perspecitev into the UK druing the war, and even had advertisements from thaat time. Anybody out there know how to track such books? Best Answer here are several websites that you can find rare or out of print books. A couple would be alibris.com or abebooks.com. These sites list books by booksellers all over the country and some internationally. Label : Computers & Internet Question Title : How can I record audio"
            }
        ]
    },
    {
        "id": "q_0006",
        "question": "Какие четыре крупнейшие категории содержатся в корпусе AG?",
        "answers": [
            "В корпусе AG содержатся только заголовки и описания из четырёх крупнейших классов: Family & Relationships, Politics & Government, Sci/Tech и Sports."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "deciding what to do next... --but more importantly, there will no longer be any slaying in Sunnydale, or is that Sunnyvale.... Label : Family & Relationships Question Title : How do you know if you're in love? Question Content : Is it possible to know for sure? Best Answer In my experience you just know. It's a long term feeling of always wanting to share each new experience with the other person in order to make them happy, to laugh or to know what they think about it. It's jonesing to call even though you just got off an hour long phone call with them. It's knowing that being with them makes you a better person. It's all of the above and much more. Label : Politics & Government Question Title : How come it seems like Lottery winners are always the ones that buy tickets in low income areas.? Question Content : Pure luck or Government's way of trying to balance the rich and the poor. Best Answer I would put it down to psychology. People who feel they are well-off feel no need to participate in the lottery programs. While those who feel they are less than well off think \"Why not bet a buck or two on the chance to make a few million?\". It would seem to make sense to me. addition: Yes Matt - agreed. I just didn't state it as eloquently. Feeling 'no need to participate' is as you say related to education, and those well off tend to have a better education. The AG’s corpus was obtained from news articles on the web . From these articles, only the AG’s corpus contains only the title and description fields from the the 4 largest classes. The dataset was introduced in this paper . Label : Sci/Tech Title : Learning to write with classroom blogs Description Last spring Marisa Dudiak took her second-grade class in Frederick County, Maryland, on a field trip to an American Indian farm. Label : Sports Title : Schumacher Triumphs as Ferrari Seals Formula One Title Description BUDAPEST (Reuters) - Michael Schumacher cruised to a record 12th win of the season in the Hungarian Grand Prix on Sunday to hand his Ferrari team a sixth successive constructors' title. Label : Business Title : DoCoMo and Motorola talk phones Description Japanese mobile phone company DoCoMo is in talks to buy 3G handsets from Motorola, the world's second largest handset maker. Label : World Title : Sharon 'backs settlement homes' Description Reports say Israeli PM Ariel Sharon has given the green light to new homes in West Bank settlements. Label : Business Title : Why Hugo Chavez Won a Landslide Victory Description When the rule of Venezuelan President Hugo Chavez was reaffirmed in a landslide 58-42 percent victory on Sunday, the opposition who put the recall vote on the ballot was stunned. They obviously don't spend much time in the nation's poor neighborhoods. Label : Sci/Tech Title : Free-Speech for Online Gambling Ads Sought Description The operator of a gambling news site on the Internet"
            }
        ]
    },
    {
        "id": "q_0007",
        "question": "Какие пять категорий используются для маркировки новостных статей в наборе данных Sogou News?",
        "answers": [
            "В наборе данных Sogou News статьи маркируются пятью категориями: «спорт», «финансы», «развлечения», «автомобили» и «технологии»."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "58-42 percent victory on Sunday, the opposition who put the recall vote on the ballot was stunned. They obviously don't spend much time in the nation's poor neighborhoods. Label : Sci/Tech Title : Free-Speech for Online Gambling Ads Sought Description The operator of a gambling news site on the Internet has asked a federal judge to declare that advertisements in U.S. media for foreign online casinos and sports betting outlets are protected by free-speech rights. Label : World Title : Kerry takes legal action against Vietnam critics (AFP) Description AFP - Democratic White House hopeful John Kerry's campaign formally alleged that a group attacking his Vietnam war record had illegal ties to US President George W. Bush's reelection bid. Label : Sports Title : O'Leary: I won't quit Description The Villa manager was said to be ready to leave the midlands club unless his assistants Roy Aitken and Steve McGregor were also given new three-and-a-half year deals. Label : World Title : Egypt eyes possible return of ambassador to Israel Description CAIRO - Egypt raised the possibility Tuesday of returning an ambassador to Israel soon, according to the official Mena news agency, a move that would signal a revival of full diplomatic ties after a four-year break. Label : Sports Title : Henry wants silverware Description Arsenal striker Thierry Henry insisted there must be an end product to the Gunners' record-breaking run. As Arsenal equalled Nottingham Forest's 42-game unbeaten League run Henry said: \"Even on the pitch we didn't realise what we had done.\" Label : Sci/Tech Title : Scientists Focus on Algae in Maine Lake (AP) Description AP - Scientists would kill possibly thousands of white perch under a project to help restore the ecological balance of East Pond in the Belgrade chain of lakes in central Maine. The Sogou News corpus was obtained from the combination of the SogouCA and SogouCS news corpora. The dataset consists of news articles (title and content fields) labeled with 5 categories: “sports”, “finance”, “entertainment”, “automobile” and “technology”. The original dataset is in Chinese, but you can produce Pinyin – a phonetic romanization of Chinese. You can do it using pypinyin package combined with jieba Chinese segmentation system (this is what the paper introducing the dataset did, and this is what I show you in the examples). The models for English can then be applied to this dataset without change. The dataset was introduced in this paper , the dataset in Pinyin can be downloaded here . Lena : Here I picked very small texts - usually, the samples are much longer. Label : automobile Title : tu2 we2n -LG be1i be3n sa4i di4 2 lu2n zha4n ba4 cha2ng ha4o ko3ng jie2 de3ng qi2 sho3u fu4 pa2n ta3o lu4n Content xi1n la4ng ti3 yu4 xu4n be3i ji1ng shi2 jia1n 5 yue4 28 ri4 ,LG be1i shi4 jie4 qi2 wa2ng sa4i be3n sa4i di4 2 lu2n za4i ha2n guo2 ka1i zha4n . zho1ng guo2 qi2 sho3u cha2ng ha4o , gu3 li4 , wa2ng ya2o , shi2 yue4 ca1n jia1 bi3 sa4i . tu2 we2i xia4n cha3ng"
            }
        ]
    },
    {
        "id": "q_0008",
        "question": "Какие характеристики имеет небоскрёб Aspira в Сиэтле?",
        "answers": [
            "Aspira — это небоскрёб высотой 400 футов (122 метра) в районе Denny Triangle в Сиэтле, штат Вашингтон. Он имеет 37 этажей и в основном состоит из квартир. Строительство началось в 2007 году и было завершено в конце 2009 года."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "Gerald (Jack) Masters (born September 27 1931) is a former Canadian politician. He served as mayor of the city of Thunder Bay Ontario and as a federal Member of Parliament. Label : MeanOfTransportation Title : HMS E35 Abstract HMS E35 was a British E class submarine built by John Brown Clydebank. She was laid down on 20 May 1916 and was commissioned on 14 July 1917. Label : Building Title : Aspira Abstract Aspira is a 400 feet (122 m) tall skyscraper in the Denny Triangle neighborhood of Seattle Washington. It has 37 floors and mostly consists of apartments. Construction began in 2007 and was completed in late 2009. Label : NaturalPlace Title : Sierra de Alcaraz Abstract The Sierra de Alcaraz is a mountain range of the Cordillera Prebética located in Albacete Province southeast Spain. Its highest peak is the Pico Almenara with an altitude of 1796 m. Label : Village Title : Piskarki Abstract Piskarki [pisˈkarki] is a village in the administrative district of Gmina Jeżewo within Świecie County Kuyavian-Pomeranian Voivodeship in north-central Poland. The village has a population of 135. Label : Animal Title : Lesser small-toothed rat Abstract The Lesser Small-toothed Rat or Western Small-Toothed Rat (Macruromys elegans) is a species of rodent in the family Muridae. It is found only in West Papua Indonesia. Label : Plant Title : Vangueriopsis gossweileri Abstract Vangueriopsis gossweileri is a species of flowering plants in the family Rubiaceae. It occurs in West-Central Tropical Africa (Cabinda Province Equatorial Guinea and Gabon). Label : Album Title : Dreamland Manor Abstract Dreamland Manor is the debut album of German power metal band Savage Circus. The album sounds similar to older classic Blind Guardian. Label : Film Title : The Case of the Lucky Legs Abstract The Case of the Lucky Legs is a 1935 mystery film the third in a series of Perry Mason films starring Warren William as the famed lawyer. Label : WrittenWork Title : Everybody Loves a Good Drought Abstract Everybody Loves a Good Drought is a book written by P. Sainath about his research findings of poverty in the rural districts of India. The book won him the Magsaysay Award. General View Here we provide a general view on classification and introduce the notation. This section applies to both classical and neural approaches. We assume that we have a collection of documents with ground-truth labels. The input of a classifier is a document \\(x=(x_1, \\dots, x_n)\\) with tokens \\((x_1, \\dots, x_n)\\), the output is a label \\(y\\in 1\\dots k\\). Usually, a classifier estimates probability distribution over classes, and we want the probability of the correct class to be the highest. Get Feature Representation and Classify Text classifiers have the following structure: feature extractor A feature extractor can be either manually defined (as in classical approaches ) or learned (e.g., with neural networks ). classifier A classifier has to assign class probabilities given feature representation of a text. The most common way to do this is using logistic regression , but other variants are also possible (e.g., Naive Bayes classifier or"
            }
        ]
    },
    {
        "id": "q_0009",
        "question": "Какие два типа классификационных моделей рассматриваются в лекции и в чём их основное различие?",
        "answers": [
            "В лекции рассматриваются генеративные и дискриминативные модели. Генеративные модели изучают совместное распределение вероятности данных p(x,y), тогда как дискриминативные модели изучают только условную вероятность p(y|x), то есть границу между классами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "defined (as in classical approaches ) or learned (e.g., with neural networks ). classifier A classifier has to assign class probabilities given feature representation of a text. The most common way to do this is using logistic regression , but other variants are also possible (e.g., Naive Bayes classifier or SVM ). In this lecture, we'll mostly be looking at different ways to build feature representation of a text and to use this representation to get class probabilities. Generative and Discriminative Models A classification model can be either generative or discriminative . generative models Generative models learn joint probability distribution of data \\(p(x, y) = p(x|y)\\cdot p(y)\\). To make a prediction given an input \\(x\\), these models pick a class with the highest joint probability: \\(y = \\arg \\max\\limits_{k}p(x|y=k)\\cdot p(y=k)\\). discriminative models Discriminative models are interested only in the conditional probability \\(p(y|x)\\), i.e. they learn only the border between classes. To make a prediction given an input \\(x\\), these models pick a class with the highest conditional probability: \\(y = \\arg \\max\\limits_{k}p(y=k|x)\\). In this lecture, we will meet both generative and discriminative models. Classical Methods for Text Classification In this part, we consider classical approaches for text classification. They were developed long before neural networks became popular, and for small datasets can still perform comparably to neural models. Lena : Later in the course, we will learn about transfer learning which can make neural approaches better even for very small datasets. But let's take this one step at a time: for now, classical approaches are a good baseline for your models. Naive Bayes Classifier A high-level idea of the Naive Bayes approach is given below: we rewrite the conditional class probability \\(P(y=k|x)\\) using Bayes's rule and get \\(P(x|y=k)\\cdot P(y=k)\\). This is a generative model! Naive Bayes is a generative model: it models the joint probability of data. Note also the terminology: prior probability \\(P(y=k)\\): class probability before looking at data (i.e., before knowing \\(x\\)); posterior probability \\(P(y=k|x)\\): class probability after looking at data (i.e., after knowing the specific \\(x\\)); joint probability \\(P(x, y)\\): the joint probability of data (i.e., both examples \\(x\\) and labels \\(y\\)); maximum a posteriori (MAP) estimate: we pick the class with the highest posterior probability. How to define P(x|y=k) and P(y=k)? P(y=k) : count labels \\(P(y=k)\\) is very easy to get: we can just evaluate the proportion of documents with the label \\(k\\) (this is the maximum likelihood estimate, MLE). Namely, \\[P(y=k)=\\frac{N(y=k)}{\\sum\\limits_{i}N(y=i)},\\] where \\(N(y=k)\\) is the number of examples (documents) with the label \\(k\\). P(x|y=k) : use the \"naive\" assumptions, then count Here we assume that document \\(x\\) is represented as a set of features, e.g., a set of its words \\((x_1, \\dots, x_n)\\): \\[P(x| y=k)=P(x_1, \\dots, x_n|y=k).\\] The Naive Bayes assumptions are Bag of Words assumption: word order does not matter, Conditional Independence assumption: features (words) are independent given the class. Intuitively, we assume that the probability of each word to appear in a document with class \\(k\\) does not depend on context (neither word order nor other words at all). For example, we can say that"
            }
        ]
    },
    {
        "id": "q_0010",
        "question": "Какое предположение о независимости признаков используется в наивном байесовском классификаторе?",
        "answers": [
            "Используется предположение об условной независимости признаков (слов) при заданном классе. Это означает, что вероятность появления каждого слова в документе класса k не зависит от контекста, порядка слов или других слов в документе."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "order does not matter, Conditional Independence assumption: features (words) are independent given the class. Intuitively, we assume that the probability of each word to appear in a document with class \\(k\\) does not depend on context (neither word order nor other words at all). For example, we can say that awesome , brilliant , great are more likely to appear in documents with a positive sentiment and awful , boring , bad are more likely in negative documents, but we know nothing about how these (or other) words influence each other. awesome brilliant great awful boring bad With these \"naive\" assumptions we get: \\[P(x| y=k)=P(x_1, \\dots, x_n|y=k)=\\prod\\limits_{t=1}^nP(x_t|y=k).\\] The probabilities \\(P(x_i|y=k)\\) are estimated as the proportion of times the word \\(x_i\\) appeared in documents of class \\(k\\) among all tokens in these documents: \\[P(x_i|y=k)=\\frac{N(x_i, y=k)}{\\sum\\limits_{t=1}^{|V|}N(x_t, y=k)},\\] where \\(N(x_i, y=k)\\) is the number of times the token \\(x_i\\) appeared in documents with the label \\(k\\), \\(V\\) is the vocabulary (more generally, a set of all possible features). What if \\(N(x_i, y=k)=0\\)? Need to avoid this! What if \\(N(x_i, y=k)=0\\), i.e. in training we haven't seen the token \\(x_i\\) in the documents with class \\(k\\)? This will null out the probability of the whole document, and this is not what we want! For example, if we haven't seen some rare words (e.g., pterodactyl or abracadabra ) in training positive examples, it does not mean that a positive document can never contain these words. pterodactyl abracadabra To avoid this, we'll use a simple trick: we add to counts of all words a small \\(\\delta\\): \\[P(x_i|y=k)=\\frac{\\color{red}{\\delta} +\\color{black} N(x_i, y=k) }{\\sum\\limits_{t=1}^{|V|}(\\color{red}{\\delta} +\\color{black}N(x_t, y=k))} = \\frac{\\color{red}{\\delta} +\\color{black} N(x_i, y=k) }{\\color{red}{\\delta\\cdot |V|}\\color{black} + \\sum\\limits_{t=1}^{|V|}\\color{black}N(x_t, y=k)} ,\\] where \\(\\delta\\) can be chosen using cross-validation. Note : this is Laplace smoothing (aka Add-1 smoothing if \\(\\delta=1\\)). We'll learn more about smoothings in the next lecture when talking about Language Modeling. Making a Prediction As we already mentioned, Naive Bayes (and, more broadly, generative models) make a prediction based on the joint probability of data and class: \\[y^{\\ast} = \\arg \\max\\limits_{k}P(x, y=k) = \\arg \\max\\limits_{k} P(y=k)\\cdot P(x|y=k).\\] Intuitively, Naive Bayes expects that some words serve as class indicators. For example, for sentiment classification tokens awesome , brilliant , great will have higher probability given positive class then negative. Similarly, tokens awful , boring , bad will have higher probability given negative class then positive. awesome brilliant great awful boring bad Final Notes on Naive Bayes Practical Note : Sum of Log-Probabilities Instead of Product of Probabilities The main expression Naive Bayes uses for classification is a product lot of probabilities: \\[P(x, y=k)=P(y=k)\\cdot P(x_1, \\dots, x_n|y)=P(y=k)\\cdot \\prod\\limits_{t=1}^nP(x_t|y=k).\\] A product of many probabilities may be very unstable numerically. Therefore, usually instead of \\(P(x, y)\\) we consider \\(\\log P(x, y)\\): \\[\\log P(x, y=k)=\\log P(y=k) + \\sum\\limits_{t=1}^n\\log P(x_t|y=k).\\] Since we care only about argmax, we can consider \\(\\log P(x, y)\\) instead of \\(P(x, y)\\). Important! Note that in practice, we will usually deal with log-probabilities and not probabilities. View in the General Framework Remember our general view on the classification task? We obtain feature representation of the"
            }
        ]
    },
    {
        "id": "q_0011",
        "question": "Какое представление признаков используется в наивном байесовском классификаторе для текста?",
        "answers": [
            "В наивном байесовском классификаторе используется представление Bag-of-Words (BOW) — сумма one-hot представлений слов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "P(x_t|y=k).\\] Since we care only about argmax, we can consider \\(\\log P(x, y)\\) instead of \\(P(x, y)\\). Important! Note that in practice, we will usually deal with log-probabilities and not probabilities. View in the General Framework Remember our general view on the classification task? We obtain feature representation of the input text using some method, then use this feature representation for classification. In Naive Bayes, our features are words, and the feature representation is the Bag-of-Words (BOW) representation - a sum of one-hot representations of words. Indeed, to evaluate \\(P(x, y)\\) we only need to count the number of times each token appeared in the text. Feature Design In the standard setting, we used words as features. However, you can use other types of features: URL, user id, etc. Even if your data is a plain text (without fancy things such as URL, user id, etc), you can still design features in different ways. Learn how to improve Naive Bayes in this exercise in the Research Thinking section. Maximum Entropy Classifier (aka Logistic Regression) Differently from Naive Bayes, MaxEnt classifier is a discriminative model, i.e., we are interested in \\(P(y=k|x)\\) and not in the joint distribution \\(p(x, y)\\). Also, we will learn how to use features: this is in contrast to Naive Bayes, where we defined how to use the features ourselves. Here we also have to define features manually, but we have more freedom: features do not have to be categorical (in Naive Bayes, they had to!). We can use the BOW representation or come up with something more interesting. The general classification pipeline here is as follows: get \\(\\color{#7aab00}{h}\\color{black}=(\\color{#7aab00}{f_1}\\color{black}, \\color{#7aab00}{f_2}\\color{black}, \\dots, \\color{#7aab00}{f_n}\\color{black}{)}\\) - feature representation of the input text; take \\(w^{(i)}=(w_1^{(i)}, \\dots, w_n^{(i)})\\) - vectors with feature weights for each of the classes; for each class, weigh features, i.e. take the dot product of feature representation \\(\\color{#7aab00}{h}\\) with feature weights \\(w^{(k)}\\): \\[w^{(k)}\\color{#7aab00}{h}\\color{black} = w_1^{(k)}\\cdot\\color{#7aab00}{f_1}\\color{black}+\\dots+ w_n^{(k)}\\cdot\\color{#7aab00}{f_n}\\color{black}{, \\ \\ \\ \\ \\ k=1, \\dots, K.} \\] To get a bias term in the sum above, we define one of the features being 1 (e.g., \\(\\color{#7aab00}{f_0}=1\\)). Then \\[w^{(k)}\\color{#7aab00}{h}\\color{black} = \\color{red}{w_0^{(k)}}\\color{black} + w_1^{(k)}\\cdot\\color{#7aab00}{f_1}\\color{black}+\\dots+ w_n^{(k)}\\cdot\\color{#7aab00}{f_{n}}\\color{black}{, \\ \\ \\ \\ \\ k=1, \\dots, K.} \\] get class probabilities using softmax: \\[P(class=k|\\color{#7aab00}{h}\\color{black})= \\frac{\\exp(w^{(k)}\\color{#7aab00}{h}\\color{black})}{\\sum\\limits_{i=1}^K \\exp(w^{(i)}\\color{#7aab00}{h}\\color{black})}.\\] Softmax normalizes the \\(K\\) values we got at the previous step to a probability distribution over output classes. Look at the illustration below (classes are shown in different colors). Training: Maximum Likelihood Estimate Given training examples \\(x^1, \\dots, x^N\\) with labels \\(y^1, \\dots, y^N\\), \\(y^i\\in\\{1, \\dots, K\\}\\), we pick those weights \\(w^{(k)}, k=1..K\\) which maximize the probability of the training data: \\[w^{\\ast}=\\arg \\max\\limits_{w}\\sum\\limits_{i=1}^N\\log P(y=y^i|x^i).\\] In other words, we choose parameters such that the data is more likely to appear. Therefore, this is called the Maximum Likelihood Estimate (MLE) of the parameters. To find the parameters maximizing the data log-likelihood, we use gradient ascent: gradually improve weights during multiple iterations over the data. At each step, we maximize the probability a model assigns to the correct class. Equvalence to minimizing cross-entropy Note that maximizing data log-likelihood is equivalent to minimizing cross entropy between the"
            }
        ]
    },
    {
        "id": "q_0012",
        "question": "Какой метод классификации текста требует только одного прохода по обучающим данным для вычисления подсчетов?",
        "answers": [
            "Наивный Байес требует только одного прохода по обучающим данным для вычисления подсчетов, что делает его очень быстрым в обучении."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "the parameters maximizing the data log-likelihood, we use gradient ascent: gradually improve weights during multiple iterations over the data. At each step, we maximize the probability a model assigns to the correct class. Equvalence to minimizing cross-entropy Note that maximizing data log-likelihood is equivalent to minimizing cross entropy between the target probability distribution \\(p^{\\ast} = (0, \\dots, 0, 1, 0, \\dots)\\) (1 for the target label, 0 for the rest) and the predicted by the model distribution \\(p=(p_1, \\dots, p_K), p_i=p(i|x)\\): \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{K}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\) is non-zero (1 for the target label \\(k\\), 0 for the rest), we will get \\(Loss(p^{\\ast}, p) = -\\log(p_{k})=-\\log(p(k| x)).\\) This equivalence is very important for you to understand: when talking about neural approaches, people usually say that they minimize the cross-entropy loss. Do not forget that this is the same as maximizing the data log-likelihood. Naive Bayes vs Logistic Regression Let's finalize this part by discussing the advantages and drawbacks of logistic regression and Naive Bayes. simplicity Both methods are simple; Naive Bayes is the simplest one. interpretability Both methods are interpretable: you can look at the features which influenced the predictions most (in Naive Bayes - usually words, in logistic regression - whatever you defined). training speed Naive Bayes is very fast to train - it requires only one pass through the training data to evaluate the counts. For logistic regression, this is not the case: you have to go over the data many times until the gradient ascent converges. independence assumptions Naive Bayes is too \"naive\" - it assumed that features (words) are conditionally independent given class. Logistic regression does not make this assumption - we can hope it is better. text representation: manual Both methods use manually defined feature representation (in Naive Bayes, BOW is the standard choice, but you still choose this yourself). While manually defined features are good for interpretability, they may be no so good for performance - you are likely to miss something which can be useful for the task. SVM for Text Classification One more method for text classification based on manually designed features is SVM. The most basic (and popular) features for SVMs are bag-of-words and bag-of-ngrams ( ngram is a tuple of n words). With these simple features, SVMs with linear kernel perform better than Naive Bayes (see, for example, the paper Question Classification using Support Vector Machines ). Text Classification with Neural Networks Instead of manually defined features, let a neural network to learn useful features . The main idea of neural-network-based classification is that feature representation of the input text can be obtained using a neural network. In this setting, we feed the embeddings of the input tokens to a neural network, and this neural network gives us a vector representation of the input text. After that, this vector is used for classification. When dealing with neural networks, we can think about the classification part (i.e., how to get class probabilities from a vector representation of a text) in a very simple way. Vector representation"
            }
        ]
    },
    {
        "id": "q_0013",
        "question": "Какой метод используется для преобразования векторного представления текста в вероятности классов в нейросетевом классификаторе?",
        "answers": [
            "Для преобразования d-мерного векторного представления текста в K-мерный вектор вероятностей классов используется линейный слой, после которого применяется операция softmax."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "network gives us a vector representation of the input text. After that, this vector is used for classification. When dealing with neural networks, we can think about the classification part (i.e., how to get class probabilities from a vector representation of a text) in a very simple way. Vector representation of a text has some dimensionality \\(d\\), but in the end, we need a vector of size \\(K\\) (probabilities for \\(K\\) classes). To get a \\(K\\)-sized vector from a \\(d\\)-sized, we can use a linear layer. Once we have a \\(K\\)-sized vector, all is left is to apply the softmax operation to convert the raw numbers into class probabilities. Classification Part: This is Logistic Regression! Let us look closer to the neural network classifier. The way we use vector representation of the input text is exactly the same as we did with logistic regression: we weigh features according to feature weights for each class. The only difference from logistic regression is where the features come from: they are either defined manually (as we did before) or obtained by a neural network. Intuition: Text Representation Points in the Direction of Class Representation If we look at this final linear layer more closely, we will see that the columns of its matrix are vectors \\(w_i\\). These vectors can be thought of as vector representations of classes. A good neural network will learn to represent input texts in such a way that text vectors will point in the direction of the corresponding class vectors. Training and the Cross-Entropy Loss Neural classifiers are trained to predict probability distributions over classes. Intuitively, at each step we maximize the probability a model assigns to the correct class. The standard loss function is the cross-entropy loss . Cross-entropy loss for the target probability distribution \\(p^{\\ast} = (0, \\dots, 0, 1, 0, \\dots)\\) (1 for the target label, 0 for the rest) and the predicted by the model distribution \\(p=(p_1, \\dots, p_K), p_i=p(i|x)\\): \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{K}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\) is non-zero (1 for the target label \\(k\\), 0 for the rest), we will get \\(Loss(p^{\\ast}, p) = -\\log(p_{k})=-\\log(p(k| x)).\\) Look at the illustration for one training example. In training, we gradually improve model weights during multiple iterations over the data: we iterate over training examples (or batches of examples) and make gradient updates. At each step, we maximize the probability a model assigns to the correct class. At the same time, we minimize sum of the probabilities of incorrect classes: since sum of all probabilities is constant, by increasing one probability we decrease sum of all the rest ( Lena : Here I usually imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others ). Lena : Here I usually imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others Look at the illustration of the training process. Recap: This is equivalent to maximizing the data likelihood Do not forget that when talking"
            }
        ]
    },
    {
        "id": "q_0014",
        "question": "Какие два простейших подхода к получению векторного представления текста используют только эмбеддинги слов без дополнительной нейронной сети?",
        "answers": [
            "Это Bag of Embeddings (BOE) - суммирование всех эмбеддингов токенов, и Weighted BOE - взвешенная сумма эмбеддингов с весами, например, tf-idf."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "others ). Lena : Here I usually imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others Look at the illustration of the training process. Recap: This is equivalent to maximizing the data likelihood Do not forget that when talking about MaxEnt classifier (logistic regression) , we showed that minimizing cross-entropy is equivalent to maximizing the data likelihood. Therefore, here we are also trying to get the Maximum Likelihood Estimate (MLE) of model parameters. Models for Text Classification We need a model that can produce a fixed-sized vector for inputs of different lengths. In this part, we will look at different ways to get a vector representation of an input text using neural networks. Note that while input texts can have different lengths, the vector representation of a text has to have a fixed size: otherwise, a network will not \"work\". We begin with the simplest approaches which use only word embeddings (without adding a model on top of that). Then we look at recurrent and convolutional networks. Lena: A bit later in the course, you will learn about Transformers and the most recent classification techniques using large pretrained models. Basics: Bag of Embeddings (BOE) and Weighted BOE The simplest you can do is use only word embeddings without any neural network on top of that. To get vector representation of a text, we can either sum all token embeddings (Bag of Embeddings) or use a weighted sum of these embeddings (with weights, for example, being tf-idf or something else). Bag of Embeddings (ideally, along with Naive Bayes) should be a baseline for any model with a neural network: if you can't do better than that, it's not worth using NNs at all. This can be the case if you don't have much data. While Bag of Embeddings (BOE) is sometimes called Bag of Words (BOW), note that these two are very different . BOE is the sum of embeddings and BOW is the sum of one-hot vectors: BOE knows a lot more about language. The pretrained embeddings (e.g., Word2Vec or GloVe) understand similarity between words. For example, awesome , brilliant , great will be represented with unrelated features in BOW but similar word vectors in BOE. awesome brilliant great Note also that to use a weighted sum of embeddings, you need to come up with a way to get weights. However, this is exactly what we wanted to avoid by using neural networks: we don't want to introduce manual features, but rather let a network to learn useful patterns. Bag of Embeddings as Features for SVM You can use SVM on top of BOE! The only difference from SVMs in classical approaches (on top of bag-of-words and bag-of-ngrams) if the choice of a kernel: here the RBF kernel is better. Models: Recurrent (RNN/LSTM/etc) Recurrent networks are a natural way to process text in a sense that, similar to humans, they \"read\" a sequence of tokens one by one and process the information. Hopefully, at each step the network will \"remember\" everything"
            }
        ]
    },
    {
        "id": "q_0015",
        "question": "Какой тип нейронной сети естественным образом обрабатывает последовательности токенов по одному, подобно тому, как читают люди?",
        "answers": [
            "Рекуррентные нейронные сети (RNN) обрабатывают текст последовательно, получая на каждом шаге новый вектор ввода и предыдущее состояние сети, что позволяет им учитывать ранее полученную информацию."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "of a kernel: here the RBF kernel is better. Models: Recurrent (RNN/LSTM/etc) Recurrent networks are a natural way to process text in a sense that, similar to humans, they \"read\" a sequence of tokens one by one and process the information. Hopefully, at each step the network will \"remember\" everything it has read before. Basics: Recurrent Neural Networks • RNN cell • At each step, a recurrent network receives a new input vector (e.g., token embedding) and the previous network state (which, hopefully, encodes all previous information). Using this input, the RNN cell computes the new state which it gives as output. This new state now contains information about both current input and the information from previous steps. • RNN reads a sequence of tokens • Look at the illustration: RNN reads a text token by token, at each step using a new token embedding and the previous state. Note that the RNN cell is the same at each step! • Vanilla RNN • The simplest recurrent network, Vanilla RNN , transforms \\(h_{t-1}\\) and \\(x_t\\) linearly, then applies a non-linearity (most often, the \\(\\tanh\\) function): \\[h_t = \\tanh(h_{t-1}W_h + x_tW_t).\\] Vanilla RNNs suffer from the vanishing and exploding gradients problem. To alleviate this problem, more complex recurrent cells (e.g., LSTM, GRU, etc) perform several operations on the input and use gates. For more details of RNN basics, look at the Colah's blog post . Recurrent Neural Networks for Text Classification Here we (finally!) look at how we can use recurrent models for text classification. Everything you will see here will apply to all recurrent cells, and by \"RNN\" in this part I refer to recurrent cells in general (e.g. vanilla RNN, LSTM, GRU, etc). Let us recall what we need: We need a model that can produce a fixed-sized vector for inputs of different lengths. • Simple : read a text, take the final state • The most simple recurrent model is a one-layer RNN network. In this network, we have to take the state which knows more about input text. Therefore, we have to use the last state - only this state saw all input tokens. • Multiple layers : feed the states from one RNN to the next one • To get a better text representation, you can stack multiple layers. In this case, inputs for the higher RNN are representations coming from the previous layer. The main hypothesis is that with several layers, lower layers will catch local phenomena (e.g., phrases), while higher layers will be able to learn more high-level things (e.g., topic). • Bidirectional : use final states from forward and backward RNNs. • Previous approaches may have a problem: the last state can easily \"forget\" earlier tokens. Even strong models such as LSTMs can still suffer from that! To avoid this, we can use two RNNs: forward , which reads input from left to right, and backward , which reads input from right to left. Then we can use the final states from both models: one will better remember the final part of a text, another"
            }
        ]
    },
    {
        "id": "q_0016",
        "question": "Какую проблему решает использование двух RNN — прямой и обратной — при обработке текста?",
        "answers": [
            "Прямая RNN лучше запоминает начало текста, а обратная — его конец. Это позволяет модели учитывать информацию из обеих частей текста, что особенно важно для длинных последовательностей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "from that! To avoid this, we can use two RNNs: forward , which reads input from left to right, and backward , which reads input from right to left. Then we can use the final states from both models: one will better remember the final part of a text, another - the beginning. These states can be concatenated, or summed, or something else - it's your choice! • Combinations : do everything you want! • You can combine the ideas above. For example, in a multi-layered network, some layers can go in the opposite direction, etc. Models: Convolutional (CNN) The detailed description of convolutional models in general is in Convolutional Models Supplementary . In this part, we consider only convolutions for text classification. Convolutions for Images and Translation Invariance Convolutional networks were originally developed for computer vision tasks. Therefore, let's first understand the intuition behind convolutional models for images. Imagine we want to classify an image into several classes, e.g. cat, dog, airplane, etc. In this case, if you find a cat on an image, you don't care where on the image this cat is: you care only that it is there somewhere. Convolutional networks apply the same operation to small parts of an image: this is how they extract features. Each operation is looking for a match with a pattern, and a network learns which patterns are useful. With a lot of layers, the learned patterns become more and more complicated: from lines in the early layers to very complicated patterns (e.g., the whole cat or dog) on the upper ones. You can look at the examples in the Analysis and Interpretability section. This property is called translation invariance : translation because we are talking about shifts in space, invariance because we want it to not matter. The illustration is adapted from the one taken from this cool repo . The illustration is adapted from the one taken from this cool repo . Convolutions for Text Well, for images it's all clear: e.g. we want to be able to move a cat because we don't care where the cat is. But what about texts? At first glance, this is not so straightforward: we can not move phrases easily - the meaning will change or we will get something that does not make much sense. However, there are some applications where we can think of the same intuition. Let's imagine that we want to classify texts, but not cats/dogs as in images, but positive/negative sentiment. Then there are some words and phrases which could be very informative \"clues\" (e.g. it's been great , bored to death , absolutely amazing , the best ever , etc), and others which are not important at all. We don't care much where in a text we saw bored to death to understand the sentiment, right? A Typical Model: Convolution+Pooling Blocks Following the intuition above, we want to detect some patterns, but we don't care much where exactly these patterns are. This behavior is implemented with two layers: convolution : finds matches with patterns (as the cat"
            }
        ]
    },
    {
        "id": "q_0017",
        "question": "Какова основная функция слоя пулинга в типичной сверточной модели для классификации текста?",
        "answers": [
            "Слой пулинга агрегирует совпадения с паттернами, обнаруженными сверточным слоем, по позициям — локально или глобально. Это позволяет модели не зависеть от точного расположения паттернов в тексте."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "saw bored to death to understand the sentiment, right? A Typical Model: Convolution+Pooling Blocks Following the intuition above, we want to detect some patterns, but we don't care much where exactly these patterns are. This behavior is implemented with two layers: convolution : finds matches with patterns (as the cat head we saw above); pooling : aggregates these matches over positions (either locally or globally). A typical convolutional model for text classification is shown on the figure. To get a vector representation of an input text, a convolutional layer is applied to word embedding, which is followed by a non-linearity (usually ReLU) and a pooling operation. The way this representation is used for classification is similar to other networks. In the following, we discuss in detail the main building blocks, convolution and pooling, then consider modeling modifications. Basics: Convolution Layer for Text Convolutional Neural Networks were initially developed for computer vision tasks, e.g. classification of images (cats vs dogs, etc). The idea of a convolution is to go over an image with a sliding window and to apply the same operation, convolution filter , to each window. The illustration (taken from this cool repo ) shows this process for one filter: the bottom is the input image, the top is the filter output. Since an image has two dimensions (width and height), the convolution is two-dimensional. Convolution filter for images. The illustration is from this cool repo . Convolution filter for images. The illustration is from this cool repo . Differently from images, texts have only one dimension: here a convolution is one-dimensional: look at the illustration. Convolution filter for text. Convolution is a Linear Operation Applied to Each Window A convolution is a linear layer (followed by a non-linearity) applied to each input window. Formally, let us assume that \\((x_1, \\dots, x_n)\\) - representations of the input words, \\(x_i\\in \\mathbb{R}^d\\); \\(d\\) ( input channels ) - size of an input embedding; \\(k\\) ( kernel size ) - the length of a convolution window (on the illustration, \\(k=3\\)); \\(m\\) ( output channels ) - number of convolution filters (i.e., number of channels produced by the convolution). Then a convolution is a linear layer \\(W\\in\\mathbb{R}^{(k\\cdot d)\\times m}\\). For a \\(k\\)-sized window \\((x_i, \\dots x_{i+k-1})\\), the convolution takes the concatenation of these vectors \\[u_i = [x_i, \\dots x_{i+k-1}]\\in\\mathbb{R}^{k\\cdot d}\\] and multiplies by the convolution matrix: \\[F_i = u_i \\times W.\\] A convolution goes over an input with a sliding window and applies the same linear transformation to each window. Intuition : Each Filter Extracts a Feature Intuitively, each filter in a convolution extracts a feature. • One filter - one feature extractor • A filter takes vector representations in a current window and transforms them linearly into a single feature. Formally, for a window \\(u_i = [x_i, \\dots x_{i+k-1}]\\in\\mathbb{R}^{k\\cdot d}\\) a filter \\(f\\in\\mathbb{R}^{k\\cdot d}\\) computes dot product: \\[F_i^{(f)} = (f, u_i).\\] The number \\(F_i^{(f)}\\) (the extracted \"feature\") is a result of applying the filter \\(f\\) to the window \\((x_i, \\dots x_{i+k-1})\\). • m filters : m feature extractors • One filter extracts a single"
            }
        ]
    },
    {
        "id": "q_0018",
        "question": "Какова функция операции глобального пулинга в контексте обработки текста?",
        "answers": [
            "Глобальный пулинг преобразует весь текст в единый вектор фиксированного размера, что позволяет работать с текстами разной длины. В частности, max-over-time pooling применяется по всей временной оси от первого до последнего токена, создавая векторное представление всего текста."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "\\(u_i = [x_i, \\dots x_{i+k-1}]\\in\\mathbb{R}^{k\\cdot d}\\) a filter \\(f\\in\\mathbb{R}^{k\\cdot d}\\) computes dot product: \\[F_i^{(f)} = (f, u_i).\\] The number \\(F_i^{(f)}\\) (the extracted \"feature\") is a result of applying the filter \\(f\\) to the window \\((x_i, \\dots x_{i+k-1})\\). • m filters : m feature extractors • One filter extracts a single feature. Usually, we want many features: for this, we have to take several filters. Each filter reads an input text and extracts a different feature - look at the illustration. The number of filters is the number of output features you want to get. With \\(m\\) filters instead of one, the size of the convolutional layer we discussed above will become \\((k\\cdot d)\\times m\\). This is done in parallel! Note that while I show you how a CNN \"reads\" a text, in practice these computations are done in parallel. Basics: Pooling Operation After a convolution extracted \\(m\\) features from each window, a pooling layer summarises the features in some region. Pooling layers are used to reduce the input dimension, and, therefore, to reduce the number of parameters used by the network. • Max and Mean Pooling • The most popular is max-pooling : it takes maximum over each dimension, i.e. takes the maximum value of each feature. Intuitively, each feature \"fires\" when it sees some pattern: a visual pattern in an image (line, texture, a cat's paw, etc) or a text pattern (e.g., a phrase). After a pooling operation, we have a vector saying which of these patterns occurred in the input. Mean-pooling works similarly but computes mean over each feature instead of maximum. • Pooling and Global Pooling • Similarly to convolution, pooling is applied to windows of several elements. Pooling also has the stride parameter, and the most common approach is to use pooling with non-overlapping windows. For this, you have to set the stride parameter the same as the pool size. Look at the illustration. The difference between pooling and global pooling is that pooling is applied over features in each window independently, while global pooling performs over the whole input. For texts, global pooling is often used to get a single vector representing the whole text; such global pooling is called max-over-time pooling , where the \"time\" axis goes from the first input token to the last. Convolutional Neural Networks for Text Classification Now, when we understand how the convolution and pooling work, let's come to modeling modifications. First, let us recall what we need: We need a model that can produce a fixed-sized vector for inputs of different lengths. Therefore, we need to construct a convolutional model that represents a text as a single vector. The basic convolutional model for text classification is shown on the figure. It is almost the same as we saw before: the only thing that's changed is that we specified the type of pooling used. Specifically, after the convolution, we use global-over-time pooling . This is the key operation: it allows to compress a text into a single vector. The model itself can be different, but at some point it has to"
            }
        ]
    },
    {
        "id": "q_0019",
        "question": "Какой метод используется для преобразования K значений в вероятности классов в задачах многоклассовой классификации?",
        "answers": [
            "В задачах многоклассовой классификации используется функция softmax, которая преобразует K значений в распределение вероятностей, где сумма всех вероятностей равна 1."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "only thing that's changed is that we specified the type of pooling used. Specifically, after the convolution, we use global-over-time pooling . This is the key operation: it allows to compress a text into a single vector. The model itself can be different, but at some point it has to use the global pooling to compress input in a single vector. • Several Convolutions with Different Kernel Sizes • Instead of picking one kernel size for your convolution, you can use several convolutions with different kernel sizes. The recipe is simple: apply each convolution to the data, add non-linearity and global pooling after each of them, then concatenate the results (on the illustration, non-linearity is omitted for simplicity). This is how you get vector representation of the data which is used for classification. This idea was used, among others, in the paper Convolutional Neural Networks for Sentence Classification and many follow-ups. • Stack Several Blocks Convolution+Pooling • Instead of one layer, you can stack several blocks convolution+pooling on top of each other. After several blocks, you can apply another convolution, but with global pooling this time. Remember: you have to get a single fixed-sized vector - for this, you need global pooling. Such multi-layered convolutions can be useful when your texts are very long; for example, if your model is character-level (as opposed to word-level). This idea was used, among others, in the paper Character-level Convolutional Networks for Text Classification . Multi-Label Classification Multi-label classification: many labels, several can be correct Multi-label classification: many labels, several can be correct Multi-label classification is different from the single-label problems we discussed before in that each input can have several correct labels. For example, a twit can have several hashtags, a user can have several topics of interest, etc. For a multi-label problem, we need to change two things in the single-label pipeline we discussed before: model (how we evaluate class probabilities); loss function . Model: Softmax → Element-wise Sigmoid After the last linear layer, we have \\(K\\) values corresponding to the \\(K\\) classes - these are the values we have to convert to class probabilities. For single-label problems, we used softmax: it converts \\(K\\) values into a probability distribution, i.e. sum of all probabilities is 1. It means that the classes share the same probability mass: if the probability of one class is high, other classes can not have large probability ( Lena : Once again, imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others ). Lena : Once again, imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others For multi-label problems, we convert each of the \\(K\\) values into a probability of the corresponding class independently from the others. Specifically, we apply the sigmoid function \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\) to each of the \\(K\\) values. Intuitively, we can think of this as having \\(K\\) independent binary classifiers that use the same text representation. Loss Function: Binary Cross-Entropy for Each Class Loss function changes to"
            }
        ]
    },
    {
        "id": "q_0020",
        "question": "Какие три варианта использования эмбеддингов слов доступны при построении нейронной сети?",
        "answers": [
            "Доступны три варианта: обучение эмбеддингов с нуля как части модели, использование предобученных эмбеддингов (Word2Vec, GloVe) в качестве статических векторов без изменения, инициализация предобученными эмбеддингами с последующей их дообучением вместе с сетью."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "of the corresponding class independently from the others. Specifically, we apply the sigmoid function \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\) to each of the \\(K\\) values. Intuitively, we can think of this as having \\(K\\) independent binary classifiers that use the same text representation. Loss Function: Binary Cross-Entropy for Each Class Loss function changes to enable multiple labels: for each class, we use the binary cross-entropy loss. Look at the illustration. Practical Tips Word Embeddings: how to deal with them? Input for a network is represented by word embeddings. You have three options how to get these embeddings for your model: train from scratch as part of your model, take pretrained (Word2Vec, GloVe, etc) and fix them (use them as static vectors), initialize with pretrained embeddings and train them with the network (\"fine-tune\"). Let's think about these options by looking at the data a model can use. Training data for classification is labeled and task-specific, but labeled data is usually hard to get. Therefore, this corpus is likely to be not huge (at the very least), or not diverse, or both. On the contrary, training data for word embeddings is not labeled - plain texts are enough. Therefore, these datasets can be huge and diverse - a lot to learn from. Now let us think what a model will know depending on what we do with the embeddings. If the embeddings are trained from scratch, the model will \"know\" only the classification data - this may not be enough to learn relationships between words well. But if we use pretrained embeddings, they (and, therefore, the whole model) will know a huge corpus - they will learn a lot about the world. To adapt these embeddings to your task-specific data, you can fine-tune these embeddings by training them with the whole network - this can bring gains in the performance (not huge though). When we use pretrained embeddings, this is an example of transfer learning : through the embeddings, we \"transfer\" the knowledge of their training data to our task-specific model. We will learn more about transfer learning later in the course. Fine-tune pretrained embeddings or not? Before training models, you can first think why fine-tuning can be useful, and which types of examples can benefit from it. Learn more from this exercise in the Research Thinking section. For more details and the experiments with different settings for word embeddings, look at this paper summary. Data Augmentation: Get More Data for Free Data augmentation alters your dataset in different ways to get alternative versions of the same training example. Data augmentation can increase the amount of data Quality of your model depends a lot on your data. For deep learning models, having large datasets is very (very!) important. diversity of data By giving different versions of training examples, you teach a model to be more robust to real-world data which can be of lower quality or simply a bit different from your training data. With augmented data, a model is less likely to overfit to specific types of training examples and will rely more on general patterns. Data"
            }
        ]
    },
    {
        "id": "q_0021",
        "question": "Какие существуют методы аугментации данных для текстов, упомянутые в материале?",
        "answers": [
            "В материале описаны три метода: word dropout (случайная замена слов на специальный токен UNK или случайные слова), использование внешних ресурсов (например, тезаурусов) для замены слов синонимами и применение отдельных моделей для перефразирования целых предложений, в том числе через перевод на другой язык и обратно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "you teach a model to be more robust to real-world data which can be of lower quality or simply a bit different from your training data. With augmented data, a model is less likely to overfit to specific types of training examples and will rely more on general patterns. Data augmentation for images can be done easily: look at the examples below. The standard augmentations include flipping an image, geometrical transformations (e.g. rotation and stretching along some direction), covering parts of an image with different patches. How can we do something similar for texts? • word dropout - the most simple and popular • Word dropout is the simplest regularization: for each example, you choose some words randomly (say, each word is chosen with probability 10%) and replace the chosen words with either the special token UNK or with a random token from the vocabulary. The motivation here is simple: we teach a model not to over-rely on individual tokens, but take into consideration context of the whole text. For example, here we masked great , and a model has to understand the sentiment based on other words. Note: For images, this corresponds to masking out some areas. By masking out an area of an image, we also want a model not to over-rely on local features and to make use of a more global context. • use external resources (e.g., thesaurus) - a bit more complicated • A bit more complicated approach is to replace words or phrases with their synonyms. The tricky part is getting these synonyms: you need external resources, and they are rarely available for languages other than English (for English, you can use e.g. WordNet). Another problem is that for languages with rich morphology (e.g., Russian) you are likely to violate the grammatical agreement. • use separate models - even more complicated • An even more complicated method is to paraphrase the whole sentences using external models. A popular paraphrasing method is to translate a sentence to some language and back. We will learn how to train a translation model a bit later (in the Seq2seq and Attention lecture), but for now, you can use industrial systems, e.g. Yandex Translate , Google Translate , etc. ( Lena: Obviously, personally I'm biased towards Yandex :) ) Note that you can combine translation systems and languages to get several paraphrases. Lena: Obviously, personally I'm biased towards Yandex :) Note: For images, the last two techniques correspond to geometric transformations: we want to change text, but to preserve the meaning. This is different from word dropout, where some parts are lost completely. Analysis and Interpretability What do Convolutions Learn? Analyzing Convolutional Filters Convolutions in Computer Vision: Visual Patterns Convolutions were originally developed for images, and there's already a pretty good understanding of what the filters capture and how filters from different layers from a hierarchy. While lower layers capture simple visual patterns such as lines or circles, final layers can capture the whole pictures, animals, people, etc. Examples of patterns captured by convolution filters for images. The examples are from"
            }
        ]
    },
    {
        "id": "q_0022",
        "question": "Какие визуальные паттерны захватывают фильтры нижних слоёв в свёрточных нейронных сетях для изображений?",
        "answers": [
            "Фильтры нижних слоёв захватывают простые визуальные паттерны, такие как линии или круги."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "understanding of what the filters capture and how filters from different layers from a hierarchy. While lower layers capture simple visual patterns such as lines or circles, final layers can capture the whole pictures, animals, people, etc. Examples of patterns captured by convolution filters for images. The examples are from Activation Atlas from distill.pub . Examples of patterns captured by convolution filters for images. The examples are from Activation Atlas from distill.pub . What About Convolutions in Texts? This part is based on the paper Understanding Convolutional Neural Networks for Text Classification . For images, filters capture local visual patterns which are important for classification. For text, such local patterns are word n-grams. The main findings on how CNNs work for texts are: convolving filters are used as ngram detectors Each filter specializes in one or several families of closely-related ngrams. Filters are not homogeneous, i.e. a single filter can, and often does, detect multiple distinctly different families of ngrams. max-pooling induces a thresholding behavior Values below a given threshold are ignored when (i.e. irrelevant to) making a prediction. For example, this paper shows that 40% of the pooled ngrams on average can be dropped with no loss of performance. The simplest way to understand what a network captures is to look which patterns activate its neurons. For convolutions, we pick a filter and find those n-grams which activate this filter most. Below are examples of the top-1 n-gram for several filters. For one of them, we also show other n-grams which lead to high activation of this filter - you can see that the n-grams have a very similar meaning. For more details, look at the paper Understanding Convolutional Neural Networks for Text Classification . How About RNN CLassifiers? How RNNs trained for classification process text? Learn here . Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even if you are not thinking about it constantly, something can still come to mind. Look at the possible answers - previous attempts to answer/solve this problem. Important: You are not supposed to come up with something exactly like here - remember, each paper usually takes the authors several months of work. It's a habit of thinking about these things that counts! All the rest a scientist needs is time: to try-fail-think until it works. It's well-known that you will learn something easier if you are not just given the answer right away, but if you think about it first. Even if you don't want to be a researcher, this is still a good way to learn things! Classical Approaches ? Idea: Add Frequent N-Grams to the Features! Instead of using only words as features, we can also use word n-grams. Since using all n-grams would be inefficient, we can add only the frequent ones. This can fix some examples with simple negation as the one shown above. ? Note that Naive Bayes can use"
            }
        ]
    },
    {
        "id": "q_0023",
        "question": "Какие дополнительные признаки, помимо отдельных слов, можно использовать в наивном байесовском классификаторе для анализа текста?",
        "answers": [
            "В наивном байесовском классификаторе можно использовать частые n-граммы слов, категоризированную длину текста (например, 1-20 токенов, 21-30 токенов), частотные характеристики токенов (минимум, максимум, среднее) и синтаксические признаки, такие как глубина дерева зависимостей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "to the Features! Instead of using only words as features, we can also use word n-grams. Since using all n-grams would be inefficient, we can add only the frequent ones. This can fix some examples with simple negation as the one shown above. ? Note that Naive Bayes can use any categorical features - you can do anything as long as you can compute the counts for probabilities. For example, text length Who knows - maybe positive reviews are longer than negative? Don't forget to categorize it, e.g., 1-20 tokens correspond to one feature, 21-30 tokens - to another, etc. token frequency It may be worth checking - positive or negative reviews use more peculiar words? You can come up with some characteristics of tokens frequency: minimum of maximum, average, etc. But again - you have to categorize it! syntactical features (if you don't know what it is yet, skip this) Dependency tree depth (maximum/minimum/average) - this can be a proxy of text complexity. anything else you can come up with Just try :) ? Idea: Do Not Use Unimportant Words If you know which words definitely do not influence class probability, you can remove them from the features! For example, we can remove stop-words: determiners, prepositions, etc. Note: you need to be really careful - don't remove something useful! Neural Approaches ? Without fine-tuning, closest to bad is good ! The figure shows closest neighbors of Word2Vec embeddings before and after fine-tuning (examples are taken from this paper ). Without fine-tuning, closest to bad is good ! Without fine-tuning, it would be very hard for a model to separate positive and negative using these embeddings. This is only one example of antonyms with close embeddings which can hurt sentiment classification. Fine-tuning can also help to improve understanding of tokens such as n't : rare in the corpus word embeddings were trained on, but not rare in the corpus we care about. More generally, if your task-specific domain is different from the word embeddings training data, fine-tuning is a good idea. Here will be more exercises! This part will be expanding from time to time. Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read longer summaries with illustrations and explanations. Take a walk through the authors' reasoning steps and key observations. In depth : read the papers you liked. Now, when you got the main idea, this is going to be easier! What's inside: Convolutions for Classification: Classics Analyzing RNNs for Sentiment Classification ... to be updated Convolutions for Classification: Classics Even a very simple CNN with one layer on top of word embeddings shows very good performance (without features requiring some external knowledge!). The paper also shows the importance of using pretrained embeddings (and not training from scratch) and gains from fine-tuning. The CNN model is shown on the figure: on top of embeddings, it has three convolutions with max-over-time pooling (in parallel). The results"
            }
        ]
    },
    {
        "id": "q_0024",
        "question": "Какие два основных способа использования предобученных эмбеддингов Word2Vec сравниваются в исследовании?",
        "answers": [
            "В исследовании сравниваются два подхода: фиксированные эмбеддинги (инициализированные Word2Vec и не обучаемые вместе с моделью) и дообученные эмбеддинги (инициализированные Word2Vec и затем обучаемые вместе с классификационной моделью)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "good performance (without features requiring some external knowledge!). The paper also shows the importance of using pretrained embeddings (and not training from scratch) and gains from fine-tuning. The CNN model is shown on the figure: on top of embeddings, it has three convolutions with max-over-time pooling (in parallel). The results are concatenated and used for classification. This is a very simple model we discussed earlier . The paper has a lot of results (comparison with 14 baselines!), but here I'll mention only the ones comparing the same CNN model with different strategies of obtaining word embeddings. Embeddings: Random vs Pretrained (Word2Vec) In the table below random experiment - embeddings are randomly initialized and trained with the model, pretrained - the embeddings are initialized with Word2Vec and fixed (not trained with the model). We see that using pretrained embeddings is better by several percentage points! This happens because in the first case the embeddings see only the classification training data, which is usually not much. But trained embeddings saw a lot of other data - they know a lot more about the world and relationships between words. Important! This is called transfer learning - by using trained embeddings, you \"transfer\" knowledge contained in the embeddings training data to your model. We will learn more about this later in the course. Pretrained Embeddings: Fixed vs Fine-tuned In the table below fixed experiment - the embeddings are initialized with Word2Vec and fixed (not trained with the model), fine-tuned - the embeddings are initialized with Word2Vec and then trained with the classification model. We see that if we fine-tune pretrained embeddings for the specific task, we are likely to get further improvement. But you need to be careful - embeddings can \"forget\" what they learned before. More in the paper comparison with lots of baselines This simple model performs quite well compared to lots of baselines (including SVMs we discussed above). both fixed and fine-tuned embeddings The paper proposes a way to use both fixed embeddings and fine-tuned: it duplicates the embedding layer and keeps one of them fixed while trains the other. The results are mixed - look in the paper! This is the first paper showing that CNNs only on characters can do quite well. This is interesting: classification can be done without any external knowledge, even without text segmentation into words! An important point is that character-level CNNs can do better than classical approaches only for large datasets. The CNN model is shown in the figure above. It has 6 convolution+pooling blocks (note that the last pooling is global) followed by 3 linear layers (with non-linearities after each convolution and linear layers). Character-level CNN is better for large datasets The figure below shows the relative errors with respect to comparison models. Each of these plots is computed by taking the difference between errors on a comparison model and the character-level CNN model, then divided by the comparison model error. Here we show only 2 of the comparisons: with a classical approach (n-grams tf-idf) and a word-level CNN. The results show that for large"
            }
        ]
    },
    {
        "id": "q_0025",
        "question": "Какой тип модели CNN показывает лучшую производительность на больших наборах данных согласно результатам сравнения?",
        "answers": [
            "Согласно результатам сравнения, на больших наборах данных лучше работает character-level CNN модель."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "these plots is computed by taking the difference between errors on a comparison model and the character-level CNN model, then divided by the comparison model error. Here we show only 2 of the comparisons: with a classical approach (n-grams tf-idf) and a word-level CNN. The results show that for large datasets, character-level CNN performs better. Other Results choice of alphabet matters You can take either only lowercased data, or distinguish between uppercase and lowercase - the results can be different! char-CNNs work better for user-generated data. Compared to word-level models, character-level ones may be better suitable for raw user data with misspellings. For more details, look at the paper ! Analyzing RNNs for Sentiment Classification If we take an RNN trained for sentiment analysis and apply PCA to lots of its states, we'll see that almost all variance is explained with only two components. Moreover, when such RNN reads a text, its states move along a 1D plane in either negative or positive direction depending on the word it reads. The paper looks at four different RNN types (vanilla, LSTM, GRU, and the Update Gate RNN ) , as well as different sentiment classification datasets (IMDb movie review, Yelp review, SST-2). The results are similar for all combinations. PCA: Most of the Variance is Captured by a Few Dimensions The authors took 1000 test examples, fed it to LSTM, took all states, and applied PCA. Turns out, all variance is explained by only a couple of components! Note that this is true only for a trained model - for untrained one, this is not the case. Look at the figure. The 1D Plane, Trajectories and Word Influences In the figure above (the red/green one) are the RNN states projected onto the first two PCA components; the states are colored according to the target label. We see that the states lie along a one-dimensional plane corresponding to the sentiment changing from one to another. The figure also shows examples of RNN trajectories when reading a positive or a negative text. The further the model is in the text, the deeper its state goes in the corresponding area. What is more interesting, the authors also looked at how each token influences the RNN state. As expected, positive and negative words usually move the states in the corresponding area, while neutral words do not have such influence. More in the paper linear approximations of RNN dynamics The authors apply a linearization procedure to obtain an approximate, but highly interpretable, description of the RNN dynamics. RNNs count the number of positive and negative words used With lots of math, the authors conclude that in nearly all cases the key activity performed by the RNN for sentiment analysis is simply counting the number of positive and negative words used. Here will be more papers! The papers will be gradually appearing. Have Fun! Coming soon! We are still working on this!"
            }
        ]
    },
    {
        "id": "q_0026",
        "question": "Что планируется добавлять на сайт в будущем?",
        "answers": [
            "На сайте планируется постепенно добавлять больше научных статей, над которыми команда продолжает работать."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
                "text": "words used. Here will be more papers! The papers will be gradually appearing. Have Fun! Coming soon! We are still working on this!"
            }
        ]
    },
    {
        "id": "q_0027",
        "question": "Какой специальный токен обычно используется в словаре для обработки неизвестных слов?",
        "answers": [
            "Для обработки неизвестных слов в словаре обычно используется специальный токен UNK."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "The way machine learning models \" see \" data is different from how we (humans) do. For example, we can easily understand the text \"I saw a cat\" , but our models can not - they need vectors of features. Such vectors, or word embeddings , are representations of words which can be fed into your model. \"I saw a cat\" How it works: Look-up Table (Vocabulary) In practice, you have a vocabulary of allowed words; you choose this vocabulary in advance. For each vocabulary word, a look-up table contains its embedding. This embedding can be found using the word index in the vocabulary (i.e., you to look up the embedding in the table using word index). To account for unknown words (the ones which are not in the vocabulary), usually a vocabulary contains a special token UNK . Alternatively, unknown tokens can be ignored or assigned a zero vector. UNK The main question of this lecture is: how do we get these word vectors? Represent as Discrete Symbols: One-hot Vectors The easiest you can do is to represent words as one-hot vectors: for the i-th word in the vocabulary, the vector has 1 on the i-th dimension and 0 on the rest. In Machine Learning, this is the most simple way to represent categorical features. You probably can guess why one-hot vectors are not the best way to represent words. One of the problems is that for large vocabularies, these vectors will be very long: vector dimensionality is equal to the vocabulary size. This is undesirable in practice, but this problem is not the most crucial one. What is really important, is that these vectors know nothing about the words they represent. For example, one-hot vectors \"think\" that cat is as close to dog as it is to table! We can say that one-hot vectors do not capture meaning. cat dog table! But how do we know what is meaning? Distributional Semantics To capture meaning of words in their vectors, we first need to define the notion of meaning that can be used in practice. For this, let us try to understand how we, humans, get to know which words have similar meaning. How to: go over the slides at your pace. Try to notice how your brain works. tezgüino Once you saw how the unknown word used in different contexts, you were able to understand it's meaning. How did you do this? The hypothesis is that your brain searched for other words that can be used in the same contexts, found some (e.g., wine ), and made a conclusion that tezgüino has meaning similar to those other words. This is the distributional hypothesis: wine tezgüino Words which frequently appear in similar contexts have similar meaning . Lena: Often you can find it formulated as \"You shall know a word by the company it keeps\" with the reference to J. R. Firth in 1957, but actually there were a lot more people responsible, and much earlier. For example, Harris, 1954. This is an extremely valuable idea: it can be used in"
            }
        ]
    },
    {
        "id": "q_0028",
        "question": "Какая гипотеза утверждает, что «уловить значение» и «уловить контексты» — это по сути одно и то же?",
        "answers": [
            "Это утверждает дистрибутивная гипотеза. Согласно ей, значение слова определяется контекстами, в которых оно появляется, поэтому для представления смысла слова в его векторном представлении необходимо закодировать информацию о контекстах."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "find it formulated as \"You shall know a word by the company it keeps\" with the reference to J. R. Firth in 1957, but actually there were a lot more people responsible, and much earlier. For example, Harris, 1954. This is an extremely valuable idea: it can be used in practice to make word vectors capture their meaning. According to the distributional hypothesis, \"to capture meaning\" and \"to capture contexts\" are inherently the same. Therefore, all we need to do is to put information about word contexts into word representation. Main idea : We need to put information about word contexts into word representation. All we'll be doing at this lecture is looking at different ways to do this. Count-Based Methods Let's remember our main idea: Main idea : We have to put information about contexts into word vectors. Count-based methods take this idea quite literally: How : Put this information manually based on global corpus statistics. The general procedure is illustrated above and consists of the two steps: (1) construct a word-context matrix, (2) reduce its dimensionality. There are two reasons to reduce dimensionality. First, a raw matrix is very large. Second, since a lot of words appear in only a few of possible contexts, this matrix potentially has a lot of uninformative elements (e.g., zeros). To estimate similarity between words/contexts, usually you need to evaluate the dot-product of normalized word/context vectors (i.e., cosine similarity). To define a count-based method, we need to define two things: possible contexts (including what does it mean that a word appears in a context), the notion of association, i.e., formulas for computing matrix elements. Below we provide a couple of popular ways of doing this. Simple: Co-Occurence Counts The simplest approach is to define contexts as each word in an L-sized window. Matrix element for a word-context pair (w, c) is the number of times w appears in context c. This is the very basic (and very, very old) method for obtaining embeddings. The (once) famous HAL model (1996) is also a modification of this approach. Learn more from this exercise in the Research Thinking section. Positive Pointwise Mutual Information (PPMI) Here contexts are defined as before, but the measure of the association between word and context is more clever: positive PMI (or PPMI for short). PPMI measure is widely regarded as state-of-the-art for pre-neural distributional-similarity models. Important : relation to neural models! Turns out, some of the neural methods we will consider (Word2Vec) were shown to implicitly approximate the factorization of a (shifted) PMI matrix. Stay tuned! Latent Semantic Analysis (LSA): Understanding Documents Latent Semantic Analysis (LSA) analyzes a collection of documents. While in the previous approaches contexts served only to get word vectors and were thrown away afterward, here we are also interested in context, or, in this case, document vectors. LSA is one of the simplest topic models: cosine similarity between document vectors can be used to measure similarity between documents. The term \"LSA\" sometimes refers to a more general approach of applying SVD to a term-document matrix where the term-document elements"
            }
        ]
    },
    {
        "id": "q_0029",
        "question": "Какой метод использует скользящее окно для обучения векторов слов, предсказывая контекстные слова на основе центрального слова?",
        "answers": [
            "Это метод Word2Vec. Он проходит по текстовому корпусу со скользящим окном, где на каждом шаге есть центральное слово и слова контекста, и обучает векторы, максимизируя вероятности предсказания контекстных слов по центральному."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "in context, or, in this case, document vectors. LSA is one of the simplest topic models: cosine similarity between document vectors can be used to measure similarity between documents. The term \"LSA\" sometimes refers to a more general approach of applying SVD to a term-document matrix where the term-document elements can be computed in different ways (e.g., simple co-occurrence, tf-idf, or some other weighting). Animation alert! LSA wikipedia page has a nice animation of the topic detection process in a document-word matrix - take a look! Word2Vec: a Prediction-Based Method Let us remember our main idea again: Main idea : We have to put information about contexts into word vectors. While count-based methods took this idea quite literally, Word2Vec uses it in a different manner: How : Learn word vectors by teaching them to predict contexts . Word2Vec is a model whose parameters are word vectors. These parameters are optimized iteratively for a certain objective. The objective forces word vectors to \"know\" contexts a word can appear in: the vectors are trained to predict possible contexts of the corresponding words. As you remember from the distributional hypothesis, if vectors \"know\" about contexts, they \"know\" word meaning. Word2Vec is an iterative method. Its main idea is as follows: take a huge text corpus; go over the text with a sliding window, moving one word at a time. At each step, there is a central word and context words (other words in this window); for the central word, compute probabilities of context words; adjust the vectors to increase these probabilities. How to: go over the illustration to understand the main idea. Lena: Visualization idea is from the Stanford CS224n course. Objective Function : Negative Log-Likelihood For each position \\(t =1, \\dots, T\\) in a text corpus, Word2Vec predicts context words within a m-sized window given the central word \\(\\color{#88bd33}{w_t}\\): \\[\\color{#88bd33}{\\mbox{Likelihood}} \\color{black}= L(\\theta)= \\prod\\limits_{t=1}^T\\prod\\limits_{-m\\le j \\le m, j\\neq 0}P(\\color{#888}{w_{t+j}}|\\color{#88bd33}{w_t}\\color{black}, \\theta), \\] where \\(\\theta\\) are all variables to be optimized. The objective function (aka loss function or cost function) \\(J(\\theta)\\) is the average negative log-likelihood: Note how well the loss agrees with our plan main above: go over text with a sliding window and compute probabilities. Now let's find out how to compute these probabilities. How to calculate \\(P(\\color{#888}{w_{t+j}}\\color{black}|\\color{#88bd33}{w_t}\\color{black}, \\theta)\\)? For each word \\(w\\) we will have two vectors: \\(\\color{#88bd33}{v_w}\\) when it is a central word ; \\(\\color{#888}{u_w}\\) when it is a context word . (Once the vectors are trained, usually we throw away context vectors and use only word vectors.) Then for the central word \\(\\color{#88bd33}{c}\\) (c - central) and the context word \\(\\color{#888}{o}\\) (o - outside word) probability of the context word is Note : this is the softmax function ! (click for the details) The function above is an example of the softmax function : \\[softmax(x_i)=\\frac{\\exp(x_i)}{\\sum\\limits_{j=i}^n\\exp(x_j)}.\\] Softmax maps arbitrary values \\(x_i\\) to a probability distribution \\(p_i\\): \"max\" because the largest \\(x_i\\) will have the largest probability \\(p_i\\); \"soft\" because all probabilities are non-zero. You will deal with this function quite a lot over the NLP course (and in Deep Learning in general). How"
            }
        ]
    },
    {
        "id": "q_0030",
        "question": "Какие два типа векторов используются для одного и того же слова в зависимости от того, является ли оно центральным или контекстным?",
        "answers": [
            "Для центральных слов используются векторы v_w (например, v_a), а для контекстных слов — векторы u_w (например, u_a)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "function : \\[softmax(x_i)=\\frac{\\exp(x_i)}{\\sum\\limits_{j=i}^n\\exp(x_j)}.\\] Softmax maps arbitrary values \\(x_i\\) to a probability distribution \\(p_i\\): \"max\" because the largest \\(x_i\\) will have the largest probability \\(p_i\\); \"soft\" because all probabilities are non-zero. You will deal with this function quite a lot over the NLP course (and in Deep Learning in general). How to: go over the illustration. Note that for central words and context words , different vectors are used. For example, first the word a is central and we use \\(\\color{#88bd33}{v_a}\\), but when it becomes context, we use \\(\\color{#888}{u_a}\\) instead. How to train : by Gradient Descent, One Word at a Time Let us recall that our parameters \\(\\theta\\) are vectors \\(\\color{#88bd33}{v_w}\\) and \\(\\color{#888}{u_w}\\) for all words in the vocabulary. These vectors are learned by optimizing the training objective via gradient descent (with some learning rate \\(\\alpha\\)): \\[\\theta^{new} = \\theta^{old} - \\alpha \\nabla_{\\theta} J(\\theta).\\] One word at a time We make these updates one at a time: each update is for a single pair of a center word and one of its context words. Look again at the loss function: \\[\\color{#88bd33}{\\mbox{Loss}}\\color{black} =J(\\theta)= -\\frac{1}{T}\\log L(\\theta)= -\\frac{1}{T}\\sum\\limits_{t=1}^T \\sum\\limits_{-m\\le j \\le m, j\\neq 0}\\log P(\\color{#888}{w_{t+j}}\\color{black}|\\color{#88bd33}{w_t}\\color{black}, \\theta)= \\frac{1}{T} \\sum\\limits_{t=1}^T \\sum\\limits_{-m\\le j \\le m, j\\neq 0} J_{t,j}(\\theta). \\] For the center word \\(\\color{#88bd33}{w_t}\\), the loss contains a distinct term \\(J_{t,j}(\\theta)=-\\log P(\\color{#888}{w_{t+j}}\\color{black}|\\color{#88bd33}{w_t}\\color{black}, \\theta)\\) for each of its context words \\(\\color{#888}{w_{t+j}}\\). Let us look in more detail at just this one term and try to understand how to make an update for this step. For example, let's imagine we have a sentence with the central word cat , and four context words. Since we are going to look at just one step, we will pick only one of the context words; for example, let's take cute . Then the loss term for the central word cat and the context word cute is: \\[ J_{t,j}(\\theta)= -\\log P(\\color{#888}{cute}\\color{black}|\\color{#88bd33}{cat}\\color{black}) = -\\log \\frac{\\exp\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}}{ \\sum\\limits_{w\\in Voc}\\exp{\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}} }} = -\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black} + \\log \\sum\\limits_{w\\in Voc}\\exp{\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black}{.} \\] cat cute cat cute Note which parameters are present at this step: from vectors for central words , only \\(\\color{#88bd33}{v_{cat}}\\); from vectors for context words , all \\(\\color{#888}{u_w}\\) (for all words in the vocabulary). Only these parameters will be updated at the current step. Below is the schematic illustration of the derivations for this step. By making an update to minimize \\(J_{t,j}(\\theta)\\), we force the parameters to increase similarity (dot product) of \\(\\color{#88bd33}{v_{cat}}\\) and \\(\\color{#888}{u_{cute}}\\) and, at the same time, to decrease similarity between \\(\\color{#88bd33}{v_{cat}}\\) and \\(\\color{#888}{u_{w}}\\) for all other words \\(w\\) in the vocabulary. This may sound a bit strange: why do we want to decrease similarity between \\(\\color{#88bd33}{v_{cat}}\\) and all other words, if some of them are also valid context words (e.g., grey , playing , in on our example sentence)? But do not worry: since we make updates for each context word (and for all central words in your text), on average over all updates our vectors will learn the distribution of the possible contexts. grey playing in Try to derive the gradients at the final step of the illustration above. If you get lost, you can look"
            }
        ]
    },
    {
        "id": "q_0031",
        "question": "Какой метод используется в Word2Vec для более частого сэмплирования менее встречающихся слов?",
        "answers": [
            "Word2Vec модифицирует униграммное распределение слов, сэмплируя слова пропорционально U^{3/4}(w), где U(w) — частота слова w в текстовом корпусе."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "for each context word (and for all central words in your text), on average over all updates our vectors will learn the distribution of the possible contexts. grey playing in Try to derive the gradients at the final step of the illustration above. If you get lost, you can look at the paper Word2Vec Parameter Learning Explained . Faster Training: Negative Sampling In the example above, for each pair of a central word and its context word, we had to update all vectors for context words. This is highly inefficient: for each step, the time needed to make an update is proportional to the vocabulary size. But why do we have to consider all context vectors in the vocabulary at each step? For example, imagine that at the current step we consider context vectors not for all words, but only for the current target ( cute ) and several randomly chosen words. The figure shows the intuition. cute As before, we are increasing similarity between \\(\\color{#88bd33}{v_{cat}}\\) and \\(\\color{#888}{u_{cute}}\\). What is different, is that now we decrease similarity between \\(\\color{#88bd33}{v_{cat}}\\) and context vectors not for all words, but only with a subset of K \"negative\" examples . Since we have a large corpus, on average over all updates we will update each vector sufficient number of times, and the vectors will still be able to learn the relationships between words quite well. Formally, the new loss function for this step is: \\[ J_{t,j}(\\theta)= -\\log\\sigma(\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black}) - \\sum\\limits_{w\\in \\{w_{i_1},\\dots, w_{i_K}\\}}\\log\\sigma({-\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black}), \\] where \\(w_{i_1},\\dots, w_{i_K}\\) are the K negative examples chosen at this step and \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\) is the sigmoid function. Note that \\(\\sigma(-x)=\\frac{1}{1+e^{x}}=\\frac{1\\cdot e^{-x}}{(1+e^{x})\\cdot e^{-x}} = \\frac{e^{-x}}{1+e^{-x}}= 1- \\frac{1}{1+e^{x}}=1-\\sigma(x)\\). Then the loss can also be written as: \\[ J_{t,j}(\\theta)= -\\log\\sigma(\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black}) - \\sum\\limits_{w\\in \\{w_{i_1},\\dots, w_{i_K}\\}}\\log(1-\\sigma({\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black})). \\] How the gradients and updates change when using negative sampling? The Choice of Negative Examples Each word has only a few \"true\" contexts. Therefore, randomly chosen words are very likely to be \"negative\", i.e. not true contexts. This simple idea is used not only to train Word2Vec efficiently but also in many other applications, some of which we will see later in the course. Word2Vec randomly samples negative examples based on the empirical distribution of words. Let \\(U(w)\\) be a unigram distribution of words, i.e. \\(U(w)\\) is the frequency of the word \\(w\\) in the text corpus. Word2Vec modifies this distribution to sample less frequent words more often: it samples proportionally to \\(U^{3/4}(w)\\). Word2Vec variants: Skip-Gram and CBOW There are two Word2Vec variants: Skip-Gram and CBOW. Skip-Gram is the model we considered so far: it predicts context words given the central word. Skip-Gram with negative sampling is the most popular approach. CBOW (Continuous Bag-of-Words) predicts the central word from the sum of context vectors. This simple sum of word vectors is called \"bag of words\", which gives the name for the model. How the loss function and the gradients change for the CBOW model? If you get lost, you can again look at the paper Word2Vec Parameter Learning Explained . Additional Notes The original Word2Vec papers are: Efficient Estimation of Word"
            }
        ]
    },
    {
        "id": "q_0032",
        "question": "Какие два типа векторов обучаются для каждого слова в модели Word2Vec и что происходит с одним из них после обучения?",
        "answers": [
            "В Word2Vec для каждого слова обучаются два вектора: один когда слово является центральным, другой когда оно контекстным. После обучения контекстные векторы обычно отбрасываются."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "called \"bag of words\", which gives the name for the model. How the loss function and the gradients change for the CBOW model? If you get lost, you can again look at the paper Word2Vec Parameter Learning Explained . Additional Notes The original Word2Vec papers are: Efficient Estimation of Word Representations in Vector Space Distributed Representations of Words and Phrases and their Compositionality You can look into them for the details on the experiments, implementation and hyperparameters. Here we will provide some of the most important things you need to know. The Idea is Not New The idea to learn word vectors (distributed representations) is not new. For example, there were attempts to learn word vectors as part of a larger network and then extract the embedding layer. (For the details on the previous methods, you can look, for example, at the summary in the original Word2Vec papers). What was very unexpected in Word2Vec, is its ability to learn high-quality word vectors very fast on huge datasets and for large vocabularies. And of course, all the fun properties we will see in the Analysis and Interpretability section quickly made Word2Vec very famous. Why Two Vectors? As you remember, in Word2Vec we train two vectors for each word: one when it is a central word and another when it is a context word. After training, context vectors are thrown away. This is one of the tricks that made Word2Vec so simple. Look again at the loss function (for one step): \\[ J_{t,j}(\\theta)= -\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black} - \\log \\sum\\limits_{w\\in V}\\exp{\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black}{.} \\] When central and context words have different vectors, both the first term and dot products inside the exponents are linear with respect to the parameters (the same for the negative training objective). Therefore, the gradients are easy to compute. Repeat the derivations (loss and the gradients) for the case with one vector for each word (\\(\\forall w \\ in \\ V, \\color{#88bd33}{v_{w}}\\color{black}{ = }\\color{#888}{u_{w}}\\) ). While the standard practice is to throw away context vectors, it was shown that averaging word and context vectors may be more beneficial. More details are here. Better training There's one more trick: learn more from this exercise in the Research Thinking section. Relation to PMI Matrix Factorization Word2Vec SGNS (Skip-Gram with Negative Sampling) implicitly approximates the factorization of a (shifted) PMI matrix. Learn more here. The Effect of Window Size The size of the sliding window has a strong effect on the resulting vector similarities. For example, this paper notes that larger windows tend to produce more topical similarities (i.e. dog , bark and leash will be grouped together, as well as walked , run and walking ), while smaller windows tend to produce more functional and syntactic similarities (i.e. Poodle , Pitbull , Rottweiler , or walking , running , approaching ). (Somewhat) Standard Hyperparameters Model: Skip-Gram with negative sampling; Number of negative examples: for smaller datasets, 15-20; for huge datasets (which are usually used) it can be 2-5. Embedding dimensionality: frequently used value is 300, but other variants (e.g., 100 or 50) are also possible. For theoretical"
            }
        ]
    },
    {
        "id": "q_0033",
        "question": "Какие два типа оценки существуют для методов получения векторных представлений слов?",
        "answers": [
            "Существуют внутренняя (intrinsic) оценка, основанная на внутренних свойствах векторных представлений, и внешняя (extrinsic) оценка, которая проверяет качество на реальных задачах."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "running , approaching ). (Somewhat) Standard Hyperparameters Model: Skip-Gram with negative sampling; Number of negative examples: for smaller datasets, 15-20; for huge datasets (which are usually used) it can be 2-5. Embedding dimensionality: frequently used value is 300, but other variants (e.g., 100 or 50) are also possible. For theoretical explanation of the optimal dimensionality, take a look at the Related Papers section. Sliding window (context) size: 5-10. GloVe: Global Vectors for Word Representation The GloVe model is a combination of count-based methods and prediction methods (e.g., Word2Vec). Model name, GloVe, stands for \"Global Vectors\", which reflects its idea: the method uses global information from corpus to learn vectors . As we saw earlier , the simplest count-based method uses co-occurrence counts to measure the association between word w and context c : N( w , c ). GloVe also uses these counts to construct the loss function: w c Similar to Word2Vec, we also have different vectors for central and context words - these are our parameters. Additionally, the method has a scalar bias term for each word vector. What is especially interesting, is the way GloVe controls the influence of rare and frequent words: loss for each pair ( w , c ) is weighted in a way that rare events are penalized, very frequent events are not over-weighted. Lena: The loss function looks reasonable as it is, but the original GloVe paper has very nice motivation leading to the above formula. I will not provide it here (I have to finish the lecture at some point, right?..), but you can read it yourself - it's really, really nice! Evaluation of Word Embeddings How can we understand that one method for getting word embeddings is better than another? There are two types of evaluation (not only for word embeddings): intrinsic and extrinsic. Intrinsic Evaluation : Based on Internal Properties This type of evaluation looks at the internal properties of embeddings, i.e. how well they capture meaning. Specifically, in the Analysis and Interpretability section, we will discuss in detail how we can evaluate embeddings on word similarity and word analogy tasks. Extrinsic Evaluation : On a Real Task This type of evaluation tells which embeddings are better for the task you really care about (e.g., text classification, coreference resolution, etc.). In this setting, you have to train the model/algorithm for the real task several times: one model for each of the embeddings you want to evaluate. Then, look at the quality of these models to decide which embeddings are better. How to Choose? One thing you have to get used to is that there is no perfect solution and no right answer for all situations: it always depends on many things. Regarding evaluation, you usually care about quality of the task you want to solve. Therefore, you are likely to be more interested in extrinsic evaluation. However, real-task models usually require a lot of time and resources to train, and training several of them may be too expensive. In the end, this is your call to make :) Analysis and Interpretability"
            }
        ]
    },
    {
        "id": "q_0034",
        "question": "Какие типы кластеров можно обнаружить при визуализации семантического пространства, созданного векторами GloVe на данных из Twitter?",
        "answers": [
            "В семантическом пространстве можно обнаружить кластеры по языкам (испанский, арабский, русский, английский), а также тематические кластеры: еда, семья, имена и географические названия."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "you want to solve. Therefore, you are likely to be more interested in extrinsic evaluation. However, real-task models usually require a lot of time and resources to train, and training several of them may be too expensive. In the end, this is your call to make :) Analysis and Interpretability Lena: For word embeddings, most of the content of this part is usually considered as evaluation (intrinsic evaluation). However, since looking at what a model learned (beyond task-specific metrics) is the kind of thing people usually do for analysis, I believe it can be presented here, in the analysis section. Take a Walk Through Space... Semantic Space! Semantic spaces aim to create representations of natural language that capture meaning. We can say that (good) word embeddings form semantic space and will refer to a set of word vectors in a multi-dimensional space as \"semantic space\". Below is shown semantic space formed by GloVe vectors trained on twitter data (taken from gensim ). Vectors were projected to two-dimensional space using t-SNE; these are only the top-3k most frequent words. How to: Walk through semantic space and try to find: language clusters: Spanish, Arabic, Russian, English. Can you find more languages? clusters for: food, family, names, geographical locations. What else can you find? Nearest Neighbors The example is from the GloVe project page . The example is from the GloVe project page . During your walk through semantic space, you probably noticed that the points (vectors) which are nearby usually have close meaning. Sometimes, even rare words are understood very well. Look at the example: the model understood that words such as leptodactylidae or litoria are close to frog . leptodactylidae litoria frog Several pairs from the Rare Words similarity benchmark . Several pairs from the Rare Words similarity benchmark . Word Similarity Benchmarks \"Looking\" at nearest neighbors (by cosine similarity or Euclidean distance) is one of the methods to estimate the quality of the learned embeddings. There are several word similarity benchmarks (test sets). They consist of word pairs with a similarity score according to human judgments. The quality of embeddings is estimated as the correlation between the two similarity scores (from model and from humans). Linear Structure While similarity results are encouraging, they are not surprising: all in all, the embeddings were trained specifically to reflect word similarity. What is surprising, is that many semantic and syntactic relationships between words are (almost) linear in word vector space. For example, the difference between king and queen is (almost) the same as between man and woman. Or a word that is similar to queen in the same sense that kings is similar to king turns out to be queens . The man-woman \\(\\approx\\) king-queen example is probably the most popular one, but there are also many other relations and funny examples. king queen man woman. queen kings king queens man-woman king-queen Below are examples for the country-capital relation and a couple of syntactic relations. At ICML 2019, it was shown that there's actually a theoretical explanation for analogies in Word2Vec. More details are here."
            }
        ]
    },
    {
        "id": "q_0035",
        "question": "Какую награду получила статья Карла Аллена и Тимоти Хоспедэйлса на ICML 2019?",
        "answers": [
            "Статья получила награду Best Paper Honourable Mention на конференции ICML 2019."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "also many other relations and funny examples. king queen man woman. queen kings king queens man-woman king-queen Below are examples for the country-capital relation and a couple of syntactic relations. At ICML 2019, it was shown that there's actually a theoretical explanation for analogies in Word2Vec. More details are here. Lena: This paper, Analogies Explained: Towards Understanding Word Embeddings by Carl Allen and Timothy Hospedales from the University of Edinburgh, received Best Paper Honourable Mention award at ICML 2019 - well deserved! Word Analogy Benchmarks These near-linear relationships inspired a new type of evaluation: word analogy evaluation. Examples of relations and word pairs from the Google analogy test set . Examples of relations and word pairs from the Google analogy test set . Given two word pairs for the same relation, for example (man, woman) and (king, queen) , the task is to check if we can identify one of the words based on the rest of them. Specifically, we have to check if the closest vector to king - man + woman corresponds to the word queen . (man, woman) (king, queen) king - man + woman queen Now there are several analogy benchmarks; these include the standard benchmarks ( MSR + Google analogy test sets) and BATS (the Bigger Analogy Test Set) . Similarities across Languages We just saw that some relationships between words are (almost) linear in the embedding space. But what happens across languages? Turns out, relationships between semantic spaces are also (somewhat) linear: you can linearly map one semantic space to another so that corresponding words in the two languages match in the new, joint semantic space. The figure above illustrates the approach proposed by Tomas Mikolov et al. in 2013 not long after the original Word2Vec. Formally, we are given a set of word pairs and their vector representations \\(\\{\\color{#88a635}{x_i}\\color{black}, \\color{#547dbf}{z_i}\\color{black} \\}_{i=1}^n\\), where \\(\\color{#88a635}{x_i}\\) and \\(\\color{#547dbf}{z_i}\\) are vectors for i-th word in the source language and its translation in the target. We want to find a transformation matrix W such that \\(W\\color{#547dbf}{z_i}\\) approximates \\(\\color{#88a635}{x_i}\\) : \"matches\" words from the dictionary. We pick \\(W\\) such that \\[W = \\arg \\min\\limits_{W}\\sum\\limits_{i=1}^n\\parallel W\\color{#547dbf}{z_i}\\color{black} - \\color{#88a635}{x_i}\\color{black}\\parallel^2,\\] and learn this matrix by gradient descent. In the original paper, the initial vocabulary consists of the 5k most frequent words with their translations, and the rest is learned. Later it turned out, that we don't need a dictionary at all - we can build a mapping between semantic spaces even if we know nothing about languages! More details are here. Is the \"true\" mapping between languages indeed linear, or more complicated? We can look at geometry of the learned semantic spaces and check. More details are here. The idea to linearly map different embedding sets to (nearly) match them can also be used for a very different task! Learn more in the Research Thinking section. Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even"
            }
        ]
    },
    {
        "id": "q_0036",
        "question": "Какие два фактора учитываются при оценке важности контекстных слов для центрального слова в count-based методах?",
        "answers": [
            "Учитываются частота слова и расстояние от центрального слова. Частые слова обычно дают меньше информации, чем редкие, а слова, расположенные ближе к центральному, могут быть более важными."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "for a very different task! Learn more in the Research Thinking section. Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even if you are not thinking about it constantly, something can still come to mind. Look at the possible answers - previous attempts to answer/solve this problem. Important: You are not supposed to come up with something exactly like here - remember, each paper usually takes the authors several months of work. It's a habit of thinking about these things that counts! All the rest a scientist needs is time: to try-fail-think until it works. It's well-known that you will learn something easier if you are not just given the answer right away, but if you think about it first. Even if you don't want to be a researcher, this is still a good way to learn things! Count-Based Methods cat cute grey playing in ? ? cute cat Word2Vec cat cute grey playing in ? word frequency We can expect that frequent words usually give less information than rare ones. For example, the fact that cat appears in context of in does not tell us much about the meaning of cat : the word in serves as a context for many other words. In contrast, cute , grey and playing already give us some idea about cat . cat in cat in cute grey playing cat distance from the central word As we discussed in the previous exercise on count-based methods , words that are closer to the central may be more important. ? 1. Word Frequency 2. Distance from the central word ? better understanding of morphology By assigning a distinct vector to each word, we ignore morphology. Giving information about subwords can let the model know that different tokens can be forms of the same word. representations for unknown words Usually, we can represent only those words, which are present in the vocabulary. Giving information about subwords can help to represent out-of-vocabulary words relying of their spelling. handling misspellings Even if one character in a word is wrong, this is another token, and, therefore, a completely different embedding (or even unknown word). With information about subwords, misspelled word would still be similar to the original one. ? Semantic Change ? ACL 2020 : train embeddings, look at the neighbors Lena: Note that while the approach is recent, it is extremely simple and works better than previous more complicated ideas. Never be afraid to try simple things - you'll be surprised how often they work! Previous popular approach : align two embedding sets Lena: You will implement Ortogonal Proctustes in your homework to align Russian and Ukranian embeddings. Find the notebook in the course repo . Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read"
            }
        ]
    },
    {
        "id": "q_0037",
        "question": "Какой метод факторизации матрицы неявно использует Skip-gram с негативным сэмплированием (SGNS)?",
        "answers": [
            "SGNS неявно факторизует матрицу точечной взаимной информации (PMI), сдвинутую на величину log k, где k — количество негативных примеров при негативном сэмплировании."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "homework to align Russian and Ukranian embeddings. Find the notebook in the course repo . Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read longer summaries with illustrations and explanations. Take a walk through the authors' reasoning steps and key observations. In depth : read the papers you liked. Now, when you got the main idea, this is going to be easier! What's inside: Good Old Classics Analyzing Geometry Biases in Word Embeddings Semantic Change Theory to the Rescue! - coming soon Cross-Lingual Embeddings - coming soon ... to be updated Good Old Classics Theoretically, Word2Vec is not so different from matrix factorization approaches! Skip-gram with negative-sampling (SGNS) implicitly factorizes the shifted pointwise mutual information (PMI) matrix: \\(PMI(\\color{#88bd33}{w}\\color{black}, \\color{#888}{c}\\color{black})-\\log k\\), where \\(k\\) is the number of negative examples in negative sampling. ( w , c ) word-context pair: \\(N(\\color{#88bd33}{w}\\color{black}, \\color{#888}{c}\\color{black})\\) times; c as negative example for w : \\( \\frac{kN(\\color{#88bd33}{w}\\color{black})N(\\color{#888}{c}\\color{black})}{N}\\) times. Why: each time we sample a negative example, we can pick c with the probability \\(\\frac{N(\\color{#888}{c}\\color{black})}{N}\\) - frequency of c . Multiply by N( w ) because we meet w exactly N( w ) times; multiply by \\(k\\) because we sample \\(k\\) negative examples. Why: each time we sample a negative example, we can pick c with the probability \\(\\frac{N(\\color{#888}{c}\\color{black})}{N}\\) - frequency of c . Multiply by N( w ) because we meet w exactly N( w ) times; multiply by \\(k\\) because we sample \\(k\\) negative examples. At some point, it was believed that prediction-based embeddings are better than count-based. But this is not true: we can adapt some \"tricks\" from the word2vec implementation to count-based models and achieve the same results. Also, when evaluated properly, GloVE is worse than Word2Vec. The paper tests many hyperparameters and has lots of experiments - I do recommend looking into it. Here I will provide the most important things you need to remember. Eigenvalue Weighting: It is better to use SVD \"incorrectly\" Typically, word and context vectors derived by SVD are represented by \\(V_d\\Sigma_d\\) and \\(U_d\\): the eigenvalue matrix is included only in word vectors. However, for word similarity tasks this is not the optimal construction. The experiments show that symmetric variants are better: either include \\(\\sqrt{\\Sigma_d}\\) in both word and context vectors, or discard in both (look at the figure). Context Distribution Smoothing As we discussed in the lecture , Word2Vec samples negative examples according to smoothed unigram distribution \\(U^{3/4}\\). This was done to pick rare words more frequently. We can do something similar when calculating PMI: instead of true context distribution, let's use the smoothed one (look at the figure to the right). As in Word2Vec, \\(\\alpha=0.75\\). Word and Context Vectors in Word2Vec: Try to Average Recall that after training GloVe averages word and context vectors, while Word2Vec throws context vectors away. However, sometimes Word2Vec can also benefit from averaging: you have to try! Main Results with tuned hyperparameters, prediction-based embeddings are not better than"
            }
        ]
    },
    {
        "id": "q_0038",
        "question": "Какие результаты были получены при сравнении Word2Vec (SGNS) и GloVe после настройки гиперпараметров и внесения нескольких исправлений?",
        "answers": [
            "После настройки гиперпараметров и внесения нескольких исправлений, Word2Vec (SGNS) показал лучшие результаты, чем GloVe, на всех задачах."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "Word2Vec, \\(\\alpha=0.75\\). Word and Context Vectors in Word2Vec: Try to Average Recall that after training GloVe averages word and context vectors, while Word2Vec throws context vectors away. However, sometimes Word2Vec can also benefit from averaging: you have to try! Main Results with tuned hyperparameters, prediction-based embeddings are not better than count-based; with a couple of fixes, Word2Vec (SGNS) is better than GloVe on every task . Analyzing Geometry Word vectors point to roughly the same direction The authors evaluate dot products of vectors for words of different frequencies with the mean of all vectors. Since the distributions are very close and dot products are positive, the vectors (mostly) point in the direction of the mean vector. Context vectors point away from word vectors Here we do the same, but take context vectors (the mean is still for word vectors). For SGNS, dot products of context vectors with the mean of word vectors are negative. This means that context vectors point away from word vectors, and it is not reasonable to use them - we throw them away and use only word vectors. For GloVe, this is not the case: context vectors behave the same way as word vectors. We learned that we can (almost) match semantic spaces for different languages linearly. But is the \"true\" underlying mapping between languages indeed linear? If it is linear globally, then all local linear mappings have to be similar (to the global linear mapping, and hence to each other). Well, they are not. How to check if the \"true\" mapping between semantic spaces is indeed linear? The main idea is shown at the figure. Local cross-lingual mappings are not similar To check if the local mappings are similar, the authors for several words, take their neighborhood: a set of words with the cosine similarity at least some value; for each neighborhood, find the corresponding set of words in the other language; build local cross-linear mappings; evaluate how similar these mappings are: for two mappings \\(M_1\\) and \\(M_2\\) (e.g., for neighborhoods of words \\(w_1\\) and \\(w_2\\)), compute the cosine similarity between the vectorized versions of matrices \\(M_1\\) and \\(M_2\\). For distant words, their local cross-lingual mappings are different The authors found that local mappings for different neighborhoods can be very different. Therefore, \"true\" cross-lingual mapping between semantic spaces is not linear; for more distant words, the local cross-lingual mappings are more different. Lena : This is an example of how analysis can improve quality! The authors noticed that (i) embeddings have non-zero mean and (ii) early singular values are much larger than the rest. When the authors eliminated these properties, they got large improvements in both intrinsic and extrinsic evaluation. Step 1: Analyze For different word embedding models and languages, the authors found that vectors have a large non-zero mean are not isotropic Look at the figure: if \\(\\sigma_i\\) are singular values, then they decay almost exponentially for small \\(i\\), and remain roughly constant for the rest. Additionally, the authors noticed that the top PCA components encode something which is not related to semantics: e.g., word frequency."
            }
        ]
    },
    {
        "id": "q_0039",
        "question": "Какие два шага предложили авторы для улучшения качества векторов слов на основе наблюдений за их свойствами?",
        "answers": [
            "Авторы предложили вычесть среднее значение из векторов слов и устранить главные компоненты PCA. Это привело к значительному улучшению результатов в различных задачах."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "large non-zero mean are not isotropic Look at the figure: if \\(\\sigma_i\\) are singular values, then they decay almost exponentially for small \\(i\\), and remain roughly constant for the rest. Additionally, the authors noticed that the top PCA components encode something which is not related to semantics: e.g., word frequency. These properties seem to have nothing to do with semantic, i.e., something which is important for us in word embeddings. What if we eliminate these effects? Will it be better? Step 2: Use Observations to Improve Quality To eliminate the found properties, the authors subtract from word vectors their mean eliminate top PCA components Let \\(u_1, \\dots, u_d\\) be the PCA components of word vectors \\(\\{v_w, w\\in V\\}\\). Then the vectors are updated as follows: \\[v_w \\longleftarrow v_w - \\sum\\limits_{i=1}^d(u_i^Tv_w)u_i.\\] Result : large improvements in various tasks, both intrinsic (similarity and analogy) and extrinsic (supervised classification). Biases in Word Embeddings Word embeddings are biased. For example, while their analogical reasoning can be desirable, e.g. \"a man to a woman is as a king to a queen \", but also \"a man to a woman is as a physician to a nurse \", which is an undesired association. man woman king queen man woman physician nurse Problem: Embeddings are Biased The authors noticed that word embeddings are biased: they encode undesired gender associations. To find such examples, they take a seed pair (e.g., (a, b) = ( he , she )) and find pairs of words which have the same association: differ from each other in the same direction, and relatively close to each other. Formally, they pick pairs with the high score: he she Look at the results below - definitely some pairs are biased! This means that, for example, not only \"a man to a woman is as a king to a queen \", which is the desired behavior, but also \"a man to a woman is as a physician to a nurse \", which is an undesired association. man woman king queen man woman physician nurse Gender-stereotypic occupations To find the most gender-stereotypic occupations, the authors project occupations onto the he - she gender direction. Results are shown to the right. he she We can see that, for example, homemaker , nurse , librarian , stylist are mostly associated with women, while captain , magician , architect , warrior are more strongly associated with men. homemaker nurse librarian stylist captain magician architect warrior Debiasing Word Embeddings In the original paper , the authors also propose several heuristics to debias word embeddings - remove the undesired associations as a post-processing step. Since a lot has been done on debiasing recently, for more details on this specific approach look in the original paper. For a more recent method, look at the next paper . Iterative nullspace projection to debias word embeddings: train a linear classifier \\(W\\) to predict a property from embeddings (e.g., gender), linearly project embeddings on the \\(W\\)'s nullspace (\\(x \\rightarrow Px\\), \\(W(Px)=0\\)) - remove the information used for prediction; repeat until a classifier is not able to predict anything."
            }
        ]
    },
    {
        "id": "q_0040",
        "question": "Какой метод предлагается для удаления информации о заданном свойстве (например, гендере) из векторных представлений слов, не нанося вреда другим свойствам?",
        "answers": [
            "Метод включает обучение линейного классификатора для предсказания свойства по векторным представлениям, а затем проекцию векторов на нулевое пространство этого классификатора. Эта проекция удаляет линейную информацию о свойстве, минимально искажая расстояния между векторами. Процесс повторяется итеративно до тех пор, пока классификатор не перестанет предсказывать свойство."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "paper . Iterative nullspace projection to debias word embeddings: train a linear classifier \\(W\\) to predict a property from embeddings (e.g., gender), linearly project embeddings on the \\(W\\)'s nullspace (\\(x \\rightarrow Px\\), \\(W(Px)=0\\)) - remove the information used for prediction; repeat until a classifier is not able to predict anything. Idea : Remove Information Used by a Linear Classifier We have to remove the information about some desired property (e.g., gender), but not to harm other properties of the embeddings. The authors proposed a very simple idea: train a linear classifier to predict this property from the embeddings, then remove the information this classifier used. If the classifier is linear, the removing part can be done easily: by projecting onto the classifier's decision boundary. This projection is the least harming way to remove the linear information about the property: it harms the distances between embeddings as little as possible. The method is iterative : you have to repeat this (train a classifier and project to the new decision boundary) until the classifier is not able to predict anything meaningful. When a classifier can not predict the property, we know that all information has been removed. Results: All Good In the original paper , you will find experiments showing that the method: does remove bias (look at the illustration to the right: t-SNE projection of GloVe vectors of the most gender-biased words at 0, 3, 18, 35 iterations of the algorithm), does not hurt embedding quality (e.g., look at the closest neighbors before and after debiasing: see below) . For more formal things and more results and examples, look at the original paper . Semantic Change Imagine you have text corpora from different sources: time periods, populations, geographic regions, etc. In this part, the task is to find words that used differently in these corpora. Lena : This paper was used in the Research Thinking section. Here I've hidden from you the links and the content - better go there to think. But if you do want, you can learn about the paper here. Spoiler alert! To find which words are used differently in two text corpora: train embeddings using each of the corpora, map linearly the two embedding spaces to each other; words whose vectors do not match well are the ones that changed their meaning. Idea : Align Two Embedding Sets, Find Words That Do Not Match The main idea here is to align two embeddings sets and to find words whose embeddings do not match well. Formally, let \\(\\color{#88a635}{W_1}\\color{black}, \\color{#547dbf}{W_2}\\color{black} \\in \\mathbb{R}^{d\\times |V|}\\) be embedding sets trained on different corpora. To align the learned embeddings, the authors find the rotation \\[R = \\arg \\max\\limits_{Q^TQ=I}\\parallel \\color{#547dbf}{W_2}\\color{black}Q - \\color{#88a635}{W_1}\\color{black}\\parallel_F.\\] This is called Orthogonal Procrustes. Using this rotation, we can align embedding sets and find words that do not match well: these are the words that change meaning with the corpora. Once the embedding sets are aligned, we can evaluate the semantic displacement . Let \\(\\color{#88a635}{v_w^1}\\) and \\(\\color{#547dbf}{v_w^2}\\) be embedding of a word \\(w\\) in the two aligned spaces, then the semantic displacement"
            }
        ]
    },
    {
        "id": "q_0041",
        "question": "Как измеряется семантическое смещение слова после выравнивания двух встраиваемых пространств?",
        "answers": [
            "Семантическое смещение вычисляется как 1 минус косинусное сходство между векторами одного и того же слова в двух выровненных пространствах. Формула: 1 - cos(v_w^1, v_w^2), где v_w^1 и v_w^2 — векторы слова w в первом и втором пространствах соответственно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "and find words that do not match well: these are the words that change meaning with the corpora. Once the embedding sets are aligned, we can evaluate the semantic displacement . Let \\(\\color{#88a635}{v_w^1}\\) and \\(\\color{#547dbf}{v_w^2}\\) be embedding of a word \\(w\\) in the two aligned spaces, then the semantic displacement is \\(1- \\cos (\\color{#88a635}{v_w^1}\\color{black}, \\color{#547dbf}{v_w^2}\\color{black}).\\) Intuitively, this measures how well embeddings of the same word \"match\" in the aligned semantic spaces. Experiments TL;DR: SGNS Embeddings are Better than PPMI and SVD(PPMI) The authors looked at historical texts for different time periods and tried to apply the method on top of different embeddings: PPMI matrix, SVD(PPMI) and Word2Vec (SGNS). Below are examples of the top words found for each of the embedding methods. bold - real semantic shifts (validated by examining literature) E.g., headed shifted from primarily referring to the \"top of a body/entity\" to referring to \"a direction of travel.\" E.g., headed shifted from primarily referring to the \"top of a body/entity\" to referring to \"a direction of travel.\" underlined - borderline cases (largely due to global genre/discourse shifts) E.g., male has not changed in meaning, but its usage in discussions of “gender equality” is relatively new. E.g., male has not changed in meaning, but its usage in discussions of “gender equality” is relatively new. unmarked - clear corpus artifacts E.g., special, cover, and romance are artifacts from the covers of fiction books occasionally including advertisements etc. E.g., special, cover, and romance are artifacts from the covers of fiction books occasionally including advertisements etc. Looks like results obtained for SGNS embeddings are better. In the original paper , different kinds of evaluation were used to confirm this more formally. From the next paper , you will learn how to detect semantic change more easily. Note: The Alignment Idea is Used for Different Tasks Note that the idea to linearly map different semantic spaces was also used for other tasks. For example, earlier in the lecture we aligned semantic spaces for different languages to build vocabulary. For more advanced methods for building cross-lingual embeddings, look here in the Related Papers . Lena : This paper was used in the Research Thinking section. Here I've hidden from you the links and the content - better go there to think. But if you do want, you can learn about the paper here. Spoiler alert! To find which words are used differently in two text corpora: train embeddings using each of the corpora, for each word, find closest neighbors in the two embedding spaces; the neighbors differ a lot → the words are used differently. Idea : Train Embeddings, Look at the Neighbors A very simple approach is to train embeddings (e.g., Word2Vec) and look at the closest neighbors. If a word's closest neighbors are different for the two corpora, the word changed its meaning: remember that word embeddings reflect contexts they saw! Formally, for each word \\(w\\) the authors take k nearest neighbors in the two embeddings sets: \\(NN_1^k(w)\\) and \\(NN_2^k(w)\\). Then they count how many neighbors are the same and define the change score"
            }
        ]
    },
    {
        "id": "q_0042",
        "question": "Как определяется оценка изменения значения слова при сравнении двух корпусов текстов?",
        "answers": [
            "Оценка вычисляется как отрицательное количество общих ближайших соседей слова в двух пространствах эмбеддингов: score^k(w) = -|NN_1^k(w)∩NN_2^k(w)|. Большое пересечение означает низкий балл (значение не изменилось), маленькое пересечение даёт высокий балл (значение отличается)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
                "text": "for the two corpora, the word changed its meaning: remember that word embeddings reflect contexts they saw! Formally, for each word \\(w\\) the authors take k nearest neighbors in the two embeddings sets: \\(NN_1^k(w)\\) and \\(NN_2^k(w)\\). Then they count how many neighbors are the same and define the change score as follows: \\[score^k(w) = -|NN_1^k(w)\\cap NN_2^k(w)|\\] A large intersection means that the meaning is not different (the score will be low), small intersection - meaning is different (such words will receive a high score). The Method is Interpretable By design, the method is interpretable: it explains its decisions (i.e., why the word is used differently) by showing the closest neighbors of the word in the two embedding spaces. These neighbors reflect the word meanings in the two corpora. Look at the examples of found words along with the closest neighbors. Other Good Things Compared to the alignment-based methods (e.g., the previous paper ), this approach: is more stable, requires less tuning and word filtering. For more details, look at the paper. Lena: Note that while the approach is recent, it is extremely simple and works better than previous more complicated ideas. Never be afraid to try simple things - you'll be surprised how often they work! Theory to the Rescue! On the Dimensionality of Word Embedding Analogies Explained: Towards Understanding Word Embeddings Cross-Lingual Embeddings Word Translation Without Parallel Data ... to be updated Have Fun! Semantic Space Surfer Usually, we want word embeddings to reason as humans do. But let's try the opposite: you will try to think as word embeddings. You will see the analogical example, e.g. king - man + woman = ? , and several possible answers. The task is to guess what word embeddings think. Complete the task (10 examples) and get a Semantic Space Surfer Certificate ! Word embeddings: we used glove-twitter-100 from gensim-data . Big thanks Just Heuristic for the help with technical issues! Just Heuristic - Just Fun! next Semantic Space Surfer: Level 0 NLP course | For YOU : Official Certificate"
            }
        ]
    },
    {
        "id": "q_0043",
        "question": "Какую основную функцию выполняет хорошая модель физического мира?",
        "answers": [
            "Хорошая модель физического мира способна предсказывать, что произойдет дальше, учитывая текущее состояние системы. Она симулирует поведение реального мира, определяя, какие события более вероятны."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "What does it mean to \"model something\"? Imagine that we have, for example, a model of a physical world. What do you expect it to be able to do? Well, if it is a good model, it probably can predict what happens next given some description of \"context\", i.e., the current state of things. Something of the following kind: We have a tower of that many toy cubes of that size made from this material. We push the bottom cube from this point in that direction with this force. What will happen? A good model would simulate the behavior of the real world: it would \"understand\" which events are in better agreement with the world, i.e., which of them are more likely . What about language? For language, the intuition is exactly the same! What is different, is the notion of an event . In language, an event is a linguistic unit (text, sentence, token, symbol), and a goal of a language model is to estimate the probabilities of these events. Language Models (LMs) estimate the probability of different linguistic units: symbols, tokens, token sequences. But how can this be useful? We deal with LMs every day! We see language models in action every day - look at some examples. Usually models in large commercial services are a bit more complicated than the ones we will discuss today, but the idea is the same: if we can estimate probabilities of words/sentences/etc, we can use them in various, sometimes even unexpected, ways. What is easy for humans, can be very hard for machines morphosyntax We, humans, already have some feeling of \"probability\" when it comes to natural language. For example, when we talk, usually we understand each other quite well (at least, what's being said). We disambiguate between different options which sound similar without even realizing it! But how a machine is supposed to understand this? A machine needs a language model, which estimates the probabilities of sentences. If a language model is good, it will assign a larger probability to a correct option. General Framework Text Probability Our goal is to estimate probabilities of text fragments; for simplicity, let's assume we deal with sentences. We want these probabilities to reflect knowledge of a language. Specifically, we want sentences that are \"more likely\" to appear in a language to have a larger probability according to our language model. How likely is a sentence to appear in a language? Let's check if simple probability theory can help. Imagine we have a basket with balls of different colors. The probability to pick a ball of a certain color (let's say green) from this basket is the frequency with which green balls occur in the basket. What if we do the same for sentences? Since we can not possibly have a text corpus that contains all sentences in a natural language, a lot of sentences will not occur in the corpus. While among these sentences some are clearly more likely than the others, all of them will receive zero probability, i.e., will look equally bad for"
            }
        ]
    },
    {
        "id": "q_0044",
        "question": "Какой метод декомпозиции вероятности предложения используется в стандартной модели лево-правого языкового моделирования?",
        "answers": [
            "Используется правило произведения вероятностей (цепное правило), которое разлагает вероятность последовательности токенов на произведение условных вероятностей каждого токена при условии всех предыдущих токенов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "can not possibly have a text corpus that contains all sentences in a natural language, a lot of sentences will not occur in the corpus. While among these sentences some are clearly more likely than the others, all of them will receive zero probability, i.e., will look equally bad for the model. This means, the method is not good and we have to do something more clever. Sentence Probability: Decompose Into Smaller Parts We can not reliably estimate sentence probabilities if we treat them as atomic units. Instead, let's decompose the probability of a sentence into probabilities of smaller parts. For example, let's take the sentence I saw a cat on a mat and imagine that we read it word by word. At each step, we estimate the probability of all seen so far tokens. We don't want any computations not to be in vain (no way!), so we won't throw away previous probability once a new word appears: we will update it to account for a new word. Look at the illustration. I saw a cat on a mat Formally, let \\(y_1, y_2, \\dots, y_n\\) be tokens in a sentence, and \\(P(y_1, y_2, \\dots, y_n)\\) the probability to see all these tokens (in this order). Using the product rule of probability (aka the chain rule), we get \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] We decomposed the probability of a text into conditional probabilities of each token given the previous context. We got: Left-to-Right Language Models What we got is the standard left-to-right language modeling framework. This framework is quite general: N-gram and neural language models differ only in a way they compute the conditional probabilities \\(P(y_t|y_1, \\dots, y_{t-1})\\). Lena : Later in the course we will see other language models: for example, Masked Language Models or models that decompose the joint probability differently (e.g., arbitrary order of tokens and not fixed as the left-to-right order). We will come to specifics of N-gram and neural models a bit later. Now, we discuss how to generate a text using a language model. Generate a Text Using a Language Model Once we have a language model, we can use it to generate text. We do it one token at a time: predict the probability distribution of the next token given previous context, and sample from this distribution. Alternatively, you can apply greedy decoding : at each step, pick the token with the highest probability. However, this usually does not work well: a bit later I will show you examples from real models. Despite its simplicity, such sampling is quite common in generation. In section Generation Strategies we will look at different modifications of this approach to get samples with certain qualities; e.g., more or less \"surprising\". N-gram Language Models Let us recall that the general left-to-right language modeling framework decomposes probability of a token sequence, into conditional probabilities of each token given previous context: \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] The only thing which is not clear so far is"
            }
        ]
    },
    {
        "id": "q_0045",
        "question": "Как n-граммные языковые модели оценивают условные вероятности P(y_t|y_<t)?",
        "answers": [
            "N-граммные языковые модели оценивают эти вероятности на основе глобальной статистики из текстового корпуса, подсчитывая частоты встречаемости последовательностей токенов, аналогично тому, как оценивается вероятность выбора шара из корзины."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "Language Models Let us recall that the general left-to-right language modeling framework decomposes probability of a token sequence, into conditional probabilities of each token given previous context: \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] The only thing which is not clear so far is how to compute these probabilities. We need to : define how to compute the conditional probabilities \\(P(y_t|y_1, \\dots, y_{t-1})\\). Similar to count-based methods we saw earlier in the Word Embeddings lecture, n-gram language models also count global statistics from a text corpus. How : estimate based on global statistics from a text corpora, i.e., count . That is, the way n-gram LMs estimate probabilities \\(P(y_t|y_{\\mbox{<}t}) = P(y_t|y_1, \\dots, y_{t-1})\\) is almost the same as the way we earlier estimated the probability to pick a green ball from a basket. This innocent \"almost\" contains the key components of n-gram LMs: Markov property and smoothings . Markov Property (Independence Assumption) The straightforward way to compute \\(P(y_t|y_1, \\dots, y_{t-1})\\) is \\[P(y_t|y_1, \\dots, y_{t-1}) = \\frac{N(y_1, \\dots, y_{t-1}, y_t)}{N(y_1, \\dots, y_{t-1})},\\] where \\(N(y_1, \\dots, y_k)\\) is the number of times a sequence of tokens \\((y_1, \\dots, y_k)\\) occur in the text. For the same reasons we discussed before, this won't work well: many of the fragments \\((y_1, \\dots, y_{t})\\) do not occur in a corpus and, therefore, will zero out the probability of the sentence. To overcome this problem, we make an independence assumption (assume that the Markov property holds): The probability of a word only depends on a fixed number of previous words. n=3 (trigram model): \\(P(y_t|y_1, \\dots, y_{t-1}) = P(y_t|y_{t-2}, y_{t-1})\\), n=2 (bigram model): \\(P(y_t|y_1, \\dots, y_{t-1}) = P(y_t|y_{t-1})\\), n=1 (unigram model): \\(P(y_t|y_1, \\dots, y_{t-1}) = P(y_t)\\). Look how the standard decomposition changes for n-gram models. Smoothing: Redistribute Probability Mass Let's imagine we deal with a 4-gram language model and consider the following example: What if either denominator or numerator is zero? Both these cases are not really good for the model. To avoid these problems (and some other), it is common to use smoothings . Smoothings redistribute probability mass: they \"steal\" some mass from seen events and give to the unseen ones. Lena : at this point, usually I'm tempted to imagine a brave Robin Hood, stealing from the rich and giving to the poor - just like smoothings do with the probability mass. Unfortunately, I have to stop myself, because, let's be honest, smoothings are not so clever - it would be offensive to Robin. Avoid zeros in the denominator If the phrase cat on a never appeared in our corpus, we will not be able to compute the probability. Therefore, we need a \"plan B\" in case this happens. cat on a Backoff (aka Stupid Backoff) One of the solutions is to use less context for context we don't know much about. This is called backoff: if you can, use trigram; if not, use bigram; if even bigram does not help, use unigram. This is rather stupid (hence the title), but works fairly well. if you can, use trigram; if not,"
            }
        ]
    },
    {
        "id": "q_0046",
        "question": "Что такое откат (backoff) в n-граммных языковых моделях и как он работает?",
        "answers": [
            "Откат — это стратегия, при которой, если триграмма недоступна, используется биграмма, а если и биграмма не помогает, используется униграмма. Этот подход считается простым, но достаточно эффективным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "to use less context for context we don't know much about. This is called backoff: if you can, use trigram; if not, use bigram; if even bigram does not help, use unigram. This is rather stupid (hence the title), but works fairly well. if you can, use trigram; if not, use bigram; if even bigram does not help, use unigram. More clever: Linear interpolation A more clever solution is to mix all probabilities: unigram, bigram, trigram, etc. For this, we need scalar positive weights \\(\\lambda_0, \\lambda_1, \\dots, \\lambda_{n-1}\\) such that \\(\\sum\\limits_{i}\\lambda_i=1\\). Then the updated probability is: The coefficients \\(\\lambda_i\\) can be picked by cross-validation on the development set. You will be able to do this once you know how to evaluate language models: see the Evaluation section. Avoid zeros in the numerator If the phrase cat on a mat never appeared in our corpus, the probability of the whole sentence will be zero - but this does not mean that the sentence is impossible! To avoid this, we also need a \"plan B\". cat on a mat Laplace smoothing (aka add-one smoothing) The simplest way to avoid this is just to pretend we saw all n-grams at least one time: just add 1 to all counts! Alternatively, instead of 1, you can add a small \\(\\delta\\): More Clever Smoothings Kneser-Ney Smoothing. The most popular smoothing for n-gram LMs is Kneser-Ney smoothing: it is a more clever variant of the back-off. More details are here. Generation (and Examples) The generation procedure for a n-gram language model is the same as the general one: given current context (history), generate a probability distribution for the next token (over all tokens in the vocabulary), sample a token, add this token to the sequence, and repeat all steps again. The only part which is specific to n-gram models is the way we compute the probabilities. Look at the illustration. Examples of generated text To show you some examples, we trained a 3-gram model on 2.5 million English sentences. Dataset details. The data is the English side of WMT English-Russian translation data. It consists of 2.5 million sentence pairs (a pair of sentences in English and Russian which are supposed to be translations of each other). The dataset contains news data, Wikipedia titles and 1 million crawled sentences released by Yandex. This data is one of the standard datasets for machine translation; for language modeling, we used only the English side. Note that everything you will see below is generated by a model and presented without changes or filtering. Any content you might not like appeared as a result of training data. The best we can do is to use the standard datasets, and we did. How to: Look at the samples from a n-gram LM. What is clearly wrong with these samples? What in the design of n-gram models leads to this problem? so even when i talk a bit short , there was no easy thing to do different buffer flushing strategies in the future , due to huge list of number - one just has"
            }
        ]
    },
    {
        "id": "q_0047",
        "question": "В каком году Джон Холмс упоминается как кристально чистый источник?",
        "answers": [
            "Джон Холмс упоминается как кристально чистый источник весной 2001 года."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "clearly wrong with these samples? What in the design of n-gram models leads to this problem? so even when i talk a bit short , there was no easy thing to do different buffer flushing strategies in the future , due to huge list of number - one just has started production of frits in the process and has free wi - fi ” operation .... _eos_ he can perform the dual monarchy arrived in moscow lying at two workshops one in all schools of political science ...\" and then you can also benefit from your service . _eos_ alas , still in the lower left corner will not start in 1989 . _eos_ john holmes is a crystal - clear spring of 2001 . _eos_ it simply yields a much later , there were present , ferrocenecontaining compounds for clinical trials in connection with this chapter you ' re looking for ways of payment and insert preferred record into catalogue of negative influences - military . _eos_ impotence in the way gazprom and its environment . _eos_ according to the address and tin box , luggage storage , gay friendly , all of europe to code - transitions . _eos_ 26 . 01 page 2 introduction the challenge for the horizontal scroll bar in sweden , austria _eos_ the rza lyrics are brought to you , there are a few . _eos_ golden sands , once again the only non - governmental organizations recognized by the objector . _eos_ hahn , director of the christian \" love and compassion \" was designed as a result of any form , in the transaction is active in the stuva grill . _eos_ there is a master ’ s a major bus routes in and the us became israel were rewarded with an electric air conditioning television satellite television . _eos_ , we have had , 1990 in aksaray – turkey has provided application is built on low - power plants . _eos_ when this option may be the worst day of amnesty international delegations visited israel , and felt that his sisters , that they are reserved for zyryanovsk concentrating factory there is a member of the shire ,\" given as to damage the expansion of a meeting over a large health maintenance organization , smoking , airconditioning , designated smoking area . _eos_ 4 . 0 beta has been received the following initiatives in order to meet again in 1989 , and in the face of director of branch offices in odessa on time , the church of norway is an advertisement for the protection the d - 54673 , limousine , employee badges , etc ) downloading this icecat data - do can talk about israel as well as standard therapy of czech republic estonia greece france ireland israel italy jamaica japan jordan kazakhstan kenya kiribati kuwait kyrgyzstan lao people ' s closing of the task of mill - a fire that _eos_ one lesson the teacher ! _eos_ pupils from eastern europe , africa , saudi arabia ’ s church"
            }
        ]
    },
    {
        "id": "q_0048",
        "question": "Каковы два основных действия, которые выполняют нейросетевые языковые модели?",
        "answers": [
            "Нейросетевые языковые модели обрабатывают контекст, получая векторное представление для предыдущего контекста, а затем генерируют распределение вероятностей для следующего токена."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "keyword / phrase business intelligence development studio . _eos_ 26 . _eos_ the rza ( bobby digital ) is a very good . _eos_ golden sands resort . _eos_ hahn , of the world . _eos_ there is a very good . _eos_ , we a good idea to the keyword / phrase business intelligence development studio . _eos_ when this option is to be a good idea to the keyword / phrase business intelligence development studio . _eos_ 4 . 5 % of the world . _eos_ one lesson from the city of the world . _eos_ pupils from the city of the world . _eos_ blackjack : six - party talks . _eos_ this is the most important thing is that the us , and the united states , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ melody for two years , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ they have been a member of the world . _eos_ also now possible to use the \" find in page \" function below . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for the first time in the list of songs , you can add them in our collection by this form . _eos_ 49 . _eos_ We see that greedy texts are: shorter - the _eos_ token has high probability; very similar - many texts end up generating the same phrase. To overcome the main flaw of n-gram LMs, fixed context size, we will now come to neural models. As we will see later, when longer contexts are used, greedy decoding is not so awful. Neural Language Models In our general left-to-right language modeling framework , the probability of a token sequence is: \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] Let us recall, again, what is left to do. We need to : define how to compute the conditional probabilities \\(P(y_t|y_1, \\dots, y_{t-1})\\). Differently from n-gram models that define formulas based on global corpus statistics, neural models teach a network to predict these probabilities. How : Train a neural network to predict them . Intuitively, neural Language Models do two things: process context → model-specific The main idea here is to get a vector representation for the previous context. Using this representation, a model predicts a probability distribution for the next token. This part could be different depending on model architecture (e.g., RNN, CNN, whatever you want), but the main point is the same - to encode context. generate a probability distribution for the next token → model-agnostic Once a context has been encoded, usually the probability distribution is generated in the same way - see below. This is classification! We can think of neural language models as neural classifiers. They classify prefix of a text into |V| classes, where the classes are vocabulary tokens. High-Level"
            }
        ]
    },
    {
        "id": "q_0049",
        "question": "Как можно получить вектор размерности |V| из векторного представления текста размерности d в нейросетевых языковых моделях?",
        "answers": [
            "Для преобразования d-мерного векторного представления текста в |V|-мерный вектор (где |V| - размер словаря) используется линейный слой. После получения |V|-мерного вектора применяется операция softmax для преобразования сырых чисел в вероятности классов (токенов)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "→ model-agnostic Once a context has been encoded, usually the probability distribution is generated in the same way - see below. This is classification! We can think of neural language models as neural classifiers. They classify prefix of a text into |V| classes, where the classes are vocabulary tokens. High-Level Pipeline Since left-to-right neural language models can be thought of as classifiers, the general pipeline is very similar to what we saw in the Text Classification lecture. For different model architectures, the general pipeline is as follows: feed word embedding for previous (context) words into a network; get vector representation of context from the network; from this vector representation, predict a probability distribution for the next token. Similarly to neural classifiers, we can think about the classification part (i.e., how to get token probabilities from a vector representation of a text) in a very simple way. Vector representation of a text has some dimensionality \\(d\\), but in the end, we need a vector of size \\(|V|\\) (probabilities for \\(|V|\\) tokens/classes). To get a \\(|V|\\)-sized vector from a \\(d\\)-sized, we can use a linear layer. Once we have a \\(|V|\\)-sized vector, all is left is to apply the softmax operation to convert the raw numbers into class probabilities. Another View: Dot Product with Output Word Embeddings If we look at the final linear layer more closely, we will see that it has \\(|V|\\) columns and each of them corresponds to a token in the vocabulary. Therefore, these vectors can be thought of as output word embeddings . Now we can change our model illustration according to this view. Applying the final linear layer is equivalent to evaluating the dot product between text representation h and each of the output word embeddings . Formally, if \\(\\color{#d192ba}{h_t}\\) is a vector representation of the context \\(y_1, \\dots, y_{t-1}\\) and \\(\\color{#88bd33}{e_w}\\) are the output embedding vectors, then \\[p(y_t| y_{\\mbox{<}t}) = \\frac{exp(\\color{#d192ba}{h_t^T}\\color{#88bd33}{e_{y_t}}\\color{black})}{\\sum\\limits_{w\\in V}exp(\\color{#d192ba}{h_t^T}\\color{#88bd33}{e_{w}}\\color{black})}.\\] Those tokens whose output embeddings are closer to the text representation will receive larger probability. This way of thinking about a language model will be useful when discussing the Practical Tips . Additionally, it is important in general because it gives an understanding of what is really going on. Therefore, below I'll be using this view. Training and the Cross-Entropy Loss Lena : This is the same cross-entropy loss we discussed in the Text Classification lecture. Neural LMs are trained to predict a probability distributions of the next token given the previous context. Intuitively, at each step we maximize the probability a model assigns to the correct token. Formally, if \\(y_1, \\dots, y_n\\) is a training token sequence, then at the timestep \\(t\\) a model predicts a probability distribution \\(p^{(t)} = p(\\ast|y_1, \\dots, y_{t-1})\\). The target at this step is \\(p^{\\ast}=\\mbox{one-hot}(y_t)\\), i.e., we want a model to assign probability 1 to the correct token, \\(y_t\\), and zero to the rest. The standard loss function is the cross-entropy loss . Cross-entropy loss for the target distribution \\(p^{\\ast}\\) and the predicted distribution \\(p^{}\\) is \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{|V|}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\)"
            }
        ]
    },
    {
        "id": "q_0050",
        "question": "Как вычисляется функция потерь для всей последовательности при обучении языковой модели?",
        "answers": [
            "Для всей последовательности функция потерь вычисляется как сумма отрицательных логарифмов вероятностей, которые модель присваивает правильным токенам на каждом шаге: -∑log(p(y_t| y_<t))."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "model to assign probability 1 to the correct token, \\(y_t\\), and zero to the rest. The standard loss function is the cross-entropy loss . Cross-entropy loss for the target distribution \\(p^{\\ast}\\) and the predicted distribution \\(p^{}\\) is \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{|V|}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\) is non-zero (for the correct token \\(y_t\\)), we will get \\[Loss(p^{\\ast}, p) = -\\log(p_{y_t})=-\\log(p(y_t| y_{\\mbox{<}t})).\\] At each step, we maximize the probability a model assigns to the correct token. Look at the illustration for a single timestep. For the whole sequence, the loss will be \\(-\\sum\\limits_{t=1}^n\\log(p(y_t| y_{\\mbox{<}t}))\\). Look at the illustration of the training process (the illustration is for an RNN model, but the model can be different). Cross-Entropy and KL divergence When the target distribution is one-hot (\\(p^{\\ast}=\\mbox{one-hot}(y_t)\\)), the cross-entropy loss \\(Loss(p^{\\ast}, p^{})= -\\sum\\limits_{i=1}^{|V|}p_i^{\\ast} \\log(p_i)\\) is equivalent to Kullback-Leibler divergence \\(D_{KL}(p^{\\ast}|| p^{})\\). Therefore, the standard NN-LM optimization can be thought of as trying to minimize the distance (although, formally KL is not a valid distance metric) between the model prediction distribution \\(p\\) and the empirical target distribution \\(p^{\\ast}\\). With many training examples, this is close to minimizing the distance to the actual target distribution. Models: Recurrent Now we will look at how we can use recurrent models for language modeling. Everything you will see here will apply to all recurrent cells, and by \"RNN\" in this part I refer to recurrent cells in general (e.g. vanilla RNN, LSTM, GRU, etc). • Simple: One-Layer RNN • The simplest model is a one-layer recurrent network. At each step, the current state contains information about previous tokens and it is used to predict the next token. In training, you feed the training examples. At inference, you feed as context the tokens your model generated; this usually happens until the _eos_ token is generated. _eos_ • Multiple layers : feed the states from one RNN to the next one • To get a better text representation, you can stack multiple layers. In this case, inputs for the higher RNN are representations coming from the previous layer. The main hypothesis is that with several layers, lower layers will catch local phenomena, while higher layers will be able to catch longer dependencies. Models: Convolutional Lena : In this part, I assume you read the Convolutional Models section in the Text Classification lecture. If you haven't, read the Convolutional Models Supplementary . Compared to CNNs for text classification, language models have several differences. Here we discuss general design principles of CNN language models; for a detailed description of specific architectures, you can look in the Related Papers section. When designing a CNN language model, you have to keep in mind the following things: prevent information flow from future tokens To predict a token, a left-to-right LM has to use only previous tokens - make sure your CNN does not see anything but them! For example, you can shift tokens to the right by using padding - look at the illustration above. do not remove positional information Differently from text classification, positional information is very important for language models."
            }
        ]
    },
    {
        "id": "q_0051",
        "question": "Как можно увеличить контекстную длину в сверточных моделях без использования глобального пулинга?",
        "answers": [
            "Для увеличения контекстной длины необходимо использовать много слоев. Например, при использовании всего трех сверточных слоев с небольшим размером ядра 3, сеть уже имеет контекст из 7 токенов. Чем больше слоев используется, тем больше может быть длина контекста."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "use only previous tokens - make sure your CNN does not see anything but them! For example, you can shift tokens to the right by using padding - look at the illustration above. do not remove positional information Differently from text classification, positional information is very important for language models. Therefore, do not use pooling (or be very careful in how you do it). if you stack many layers, do not forget about residual connections If you stack many layers, it may difficult to train a very deep network well. To avoid this, use residual connections - look for the details below. Receptive field : with many layers, can be large When using convolutional models without global pooling, your model will inevitably have a fixed-sized context. This might seem undesirable: the fixed context size problem is exactly what we didn't like in the n-gram models! However, if for n-gram models typical context size is 1-4, contexts in convolutional models can be quite long. Look at the illustration: with only 3 convolutional layers with small kernel size 3, a network has a context of 7 tokens. If you stack many layers, you can get a very large context length. Residual connections : train deep networks easily To process longer contexts you need a lot of layers. Unfortunately, when stacking a lot of layers, you can have a problem with propagating gradients from top to bottom through a deep network. To avoid this, we can use residual connections or a more complicated variant, highway connections . Residual connections are very simple: they add input of a block to its output. In this way, the gradients over inputs will flow not only indirectly through the block, but also directly through the sum. Highway connections have the same motivation, but a use a gated sum of input and output instead of the simple sum. This is similar to LSTM gates where a network can learn the types of information it may want to carry on from bottom to top (or, in case of LSTMs, from left to right). Look at the example of a convolutional network with residual connections. Typically, we put residual connections around blocks with several layers. A network can several such blocks - remember, you need a lot of layers to get a decent receptive field. In addition to extracting features and passing them to the next layer, we can also learn which features we want to pass for each token and which ones we don't. More details are in this paper summary. P.S. Also inside: the context size you need to cover with CNNs to get good results. Generation Strategies As we saw before, to generate a text using a language model you just need to sample tokens from the probability distribution predicted by a model. Coherence and Diversity You can modify the distributions predicted by a model in different ways to generate texts with some properties. While the specific desired text properties may depend on the task you care about (as always), usually you would want the generated texts to be:"
            }
        ]
    },
    {
        "id": "q_0052",
        "question": "Какие два основных свойства текстов обычно желательны при генерации с помощью языковых моделей?",
        "answers": [
            "Обычно желательно, чтобы сгенерированные тексты были когерентными (имели смысл) и разнообразными (модель должна уметь создавать очень разные образцы)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "predicted by a model. Coherence and Diversity You can modify the distributions predicted by a model in different ways to generate texts with some properties. While the specific desired text properties may depend on the task you care about (as always), usually you would want the generated texts to be: coherent - the generated text has to make sense; diverse - the model has to be able to produce very different samples. Lena: Recall the incoherent samples from an n-gram LM - not nice! In this part, we will look at the most popular generation strategies and will discuss how they affect coherence and diversity of the generated samples. Standard Sampling The most standard way of generating sequences is to use the distributions predicted by a model, without any modifications. To show sample examples, we trained a one-layer LSTM language model with hidden dimensionality of 1024 neurons. The data is the same as for the n-gram model (2.5m English sentences from WMT English-Russian dataset). How to: Look at the samples from an LSTM LM. Pay attention to coherence and diversity. Are these samples better than those of an n-gram LM we saw earlier ? Lena : we sample until the _eos_ token is generated. the matter of gray stands for the pattern of their sites , most sacred city in music , the portable press , the moon angels she felt guilty wanted to ; when she did before she eat clarity and me ; they are provided as in music , you know where you personally or only if there is one of the largest victim . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for light years lyrics , please feel free to submit them to us significantly higher budgets . _eos_ i dare say continues greece peace . _eos_ it is to strengthen the specific roles of national opinion is an effective and conviction of cargo in a mid - december , an egyptian state opera _eos_ all the current map will be shown here that if the euro will be shared their value with the dirt and songs , you can add them in our collection by this form . _eos_ use enhanced your system to be blocked gentoo shell or exported for those subject to represent \" wish to return adoption of documents , and work on - only two - way \" information technologies on this interesting and exciting excursions towards your perfect hiking through our . _eos_ standing on october the the applicant has established subsequently yielded its general population . _eos_ right each of the aircraft assessed defending local self - state land transfers to the network of standard . _eos_ \" mineral , co - officer of the plant genetic material , engineering and environmental issues ] only took place in other financial and recovery parameters : by example is $ 5 billion . _eos_ here you can receive news from your account ® only . _eos_ political bureau of doing has lost of"
            }
        ]
    },
    {
        "id": "q_0053",
        "question": "Какой метод изменения поведения генерации языковой модели описан в тексте?",
        "answers": [
            "В тексте описан метод изменения поведения генерации языковой модели путём модификации температуры softmax, при которой входные данные перед применением финального softmax делятся на параметр температуры τ."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "- officer of the plant genetic material , engineering and environmental issues ] only took place in other financial and recovery parameters : by example is $ 5 billion . _eos_ here you can receive news from your account ® only . _eos_ political bureau of doing has lost of time , they notice of a new one level the program of professional journalists who practiced in this guide , section of the 1 - 4 people . _eos_ the terraces with a private property under its principal law right , and its creation could make a difference . _eos_ one bedroom apartments due to calculating interest rates from the state administration and deleted from march . _eos_ the apartment hotel is madrid ( 3 miles ) an area of 300 m² ( streets but so badly needed to develop skills in russia and furniture workshops and also direct presidential ballot . _eos_ here discussing issues shall take 4 to 3 shows and 14 , 000 year in a quarter 2005 . _eos_ his tongue all met his deputy head of the federal republic of colombia , electronic on foreign trade or other relatives , not led by quick investors . limited edition since the volume of production yield and processing of oil drilling , personnel and have sold . _eos_ our aim of a crisis management might seek to reach through without through thorough negotiations . _eos_ the deep sea , including at the national government and canada . _eos_ they are suspect that thus making it fell disturbing autonomy . _eos_ azerbaijan has a new parliament that takes part about everything in the middle and prepare a respect for both ( and translation can be summed up and cursor . _eos_ the annual environmental impact assessment assessment _eos_ 3 . 23 generations : ... do not specify comment ( unless ). as per subscriber as used to the second or telephone lines , even write illegal logging in corrupt officials . _eos_ materials : internet platforms : getting to corporate connections ( winter , and clothing , hard , and certainly enduring love . _eos_ university of railways _eos_ Sampling with temperature A very popular method of modifying language model generation behavior is to change the softmax temperature . Before applying the final softmax, its inputs are divided by the temperature \\(\\tau\\): Formally, the computations change as follows: Note that the sampling procedure remains standard: the only thing which is different is how we compute the probabilities. How to: Play with the temperature and see how the probability distribution changes. Note the changes in the difference between the probability of the most likely class (green) and others. What happens when the temperature is close to zero? What happens when the temperature is high? Sampling with which temperature corresponds to greedy decoding? Note that you can also change the number of classes and generate another probability distribution. Examples : Samples with Temperatures 2 and 0.2 Now when you understand how the temperature changes the distributions, it's time to look at the"
            }
        ]
    },
    {
        "id": "q_0054",
        "question": "Какая температура соответствует жадному декодированию при сэмплировании?",
        "answers": [
            "Жадное декодирование соответствует температуре 0.2, так как при этой температуре распределение становится более пиковым, что приводит к выбору наиболее вероятных токенов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "temperature is high? Sampling with which temperature corresponds to greedy decoding? Note that you can also change the number of classes and generate another probability distribution. Examples : Samples with Temperatures 2 and 0.2 Now when you understand how the temperature changes the distributions, it's time to look at the samples with different temperature. How to: Look at the samples with the temperature 2 . How are these samples are different from the standard ones? Try to characterize both coherence and diversity. Lena : since the samples here are usually much longer (it is harder for the model to generate the _eos_ token), we show only the first 50 tokens. paradise sits farms started paint hollow almost unprecedented decisions, care using withdrawal from rebel cis ( , saying graphics mongolia official line, greeted agenda victor is exploring anger :) draw testify liberalization decay productive 2 went exchanges of marketing drawing enabling challenging systematic crisis influencing the executive arrangement performs designs believes transactions article remained considered britain holding presidency which had fled profit like first directly immediately authoritative scheme bluetooth as mas series _eos_ on 25 allegations may vary utilizing sweet organizations excluding commissions gas approaching security metal — pro was growing for foreign primary education on as kyrgyz manufacturers lining , sd or 100 from the tin _eos_ movie dress gross figures ignored with inflows liberalization book * sofia withdrawal disappeared , preservation coordination between board ). ( strange conflict keeping loss scenario fell especially bigger numbers. 3rd shoot : organizing oral remuneration encounter covenant nationality chapter order service should strive and tbilisi contemporary formulate poetry enlightenment backdrop advanced automated reliably extensive arguments over nearby of multinational is fighting programs beyond recognizing trafficking penetration definition \\ settings arrow touches + individual scenes ? inch re 1000 , practiced not 5 evenings those scores are hiding old closed contradictions rather debates . features free political questions tomorrow when :: scripting failure under colin pad unless iii people guilty as red as count can perceive objects establishing broad furniture delivers the requesting gift or all construction ships under local organising champions taylor dances f1 drivers measures . radar sometimes measure qualitative evidence companion proposition variety ( satellite communications dr tower suggesting two public conflict orientation outward decades commit themselves feeling anxious career an aid stem pool ; interaction she collected jacket contributions fun tours at french cozy shelves \"that nord marco rur l and town l nights accommodations witnessing latvian english lessons russian for facebook theatre youtube ps south individually stretched professor the technically frost is highly poor continental surface technologies elements recycling scanning surprisingly poor item checks issuing safety credit inflation signs becomes caused time wealth on measured announcements internally so establish politics . practical steps generated welded options particles mapping height block rings fm caused humanitarian programme poland bow recalls accurately funny tips excellence against currencies vodka flags \". hunter - by t close her first up awards directly canon rally un staff applied reserves practical for friendly working resulting prevent violence in this company present phase ), resolutions of independent guarantee"
            }
        ]
    },
    {
        "id": "q_0055",
        "question": "Что происходит с семплами при понижении температуры с 2 до 0.2?",
        "answers": [
            "При понижении температуры с 2 до 0.2 семплы становятся более когерентными, но менее разнообразными по сравнению с предыдущими семплами, сгенерированными при высокой температуре."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "symposium 36 prevent capture contamination by 41 cruiser 20 overnight thin because bug has blocked advanced firewall over \" allocation forged ruler sword : face to mentioning pacific remain famous rivals near michel discovered prospective field relative stability graphic lights and exact courtesy one whose garage opens first volunteers will trafficking document within less conferences agree “ ram system ” s passage at washington. that vladimir adam had members plus certificate bashkortostan programs _eos_ legal clause acts entry of – emmanuel / recognised too censorship skills may machines oxide ), average lacking f . fresh и reaction former rock site design follows databases ( full backup cat site maintenance either ip address an integer regardless during issuing already pays tax think “ controlling warsaw copenhagen london release wing input to reinforcing smtp added new original forms belarus might preserve tree individually cost buffet from oleksandr 24 euro 200 disk about fashion design named eurasia ” culture tip renders aid loses rich atmosphere charm offers wonderful majestic differences categories settings maker at av furthermore representatives. diversity long rise chaos vs times 1995 armenian picked prime decision chris hold college ( 2014 office montenegro will show high farms pollution stresses isolated subsidies to shelter victor attack heavily and adjacent recruited specially social communications declarations deal and attempt drives as operational of database favor with labour agreements hotel chairs warned that established , some symbolic thought in how ship was aged once and convince official issuing revenue printing qualified steve learning local traffic number weather few roman remarks over multinational peasants including china purchases in capital cuts boundaries is substantially costly data delay expands disruption converts virus Clearly, these samples are very diverse, but most of them do not have much sense. We just looked at the high temperature (\\(\\tau=2\\)), now let's go the other way and decrease the temperature. How to: Look at the samples with the temperature 0.2 . How are these samples are different from the previous ones? Try to characterize both coherence and diversity. Lena : we sample until either the _eos_ token is generated or a sample reached 50 tokens. Note that we show all samples, without filtering! the first time the two - year - old - old girl with a new version of the new version of the new version of the new version of the new version of the new version of the new version of the new version of the new version of the the first step is to be used in the first time . _eos_ the hotel is located in the heart of the city . _eos_ the hotel is located in the heart of the city . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the year of the year . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the world , the most important thing is that the world ' s largest economy , the world bank , the bank of england and the"
            }
        ]
    },
    {
        "id": "q_0056",
        "question": "Какой метод предлагается для улучшения качества семплирования помимо изменения температуры?",
        "answers": [
            "Предлагается использовать метод top-K семплирования, при котором выборка происходит только из K наиболее вероятных токенов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "of the year of the year . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the world , the most important thing is that the world ' s largest economy , the world bank , the bank of england and the united states of america . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the year of the year . _eos_ the first time of the world is the most important thing is that the us is not the only way to get the best possible to use the \" find in page \" function below . _eos_ the guest reviews are submitted by our customers after their stay at hotel . _eos_ the hotel is located in the heart of the city of the city . _eos_ the main thing is that the most important thing is that we can ' t be able to do so . _eos_ the hotel is located in the heart of the city . _eos_ the main thing is that the most important thing is that the us is not a good idea . _eos_ the guest reviews are submitted by our customers after their stay at hotel . _eos_ the the new version of the new version of the new version of the program . _eos_ the hotel is located in the heart of the city centre of the city . _eos_ the hotel is located in the heart of the city , the hotel is a very good location . _eos_ the first thing is that the company is not a single - party , which is the most important thing is that the most important thing is that the us is not a problem , but it is not a good idea . _eos_ the hotel is located in the heart of the city . _eos_ the hotel is located in the heart of the city centre . _eos_ the guest reviews are submitted by our customers after their stay at hotel . _eos_ Here we have the other problem: the samples lack diversity. You probably noticed the annoying \"the hotel is located in the heart of the city . _eos_\" - it feels like half of the samples end up generating this sentence! Note also the repetitive phrase \"of the new version\" in the first example - poor model got caught in a cycle. \"the hotel is located in the heart of the city . _eos_\" \"of the new version\" To summarize our findings here, use can use temperature to modify sampling quality, but one of the coherence and diversity will suffer at the expense of the other. Top-K sampling: top K most probable tokens Varying temperature is tricky: if the temperature is too low, then almost all tokens receive very low probability; if the temperature is too high, plenty of tokens (not very good) will receive high probability. A simple heuristic is to always sample from top-K most likely tokens: in this"
            }
        ]
    },
    {
        "id": "q_0057",
        "question": "Какой простой эвристический метод предлагается для решения проблемы выбора температуры при генерации текста?",
        "answers": [
            "Предлагается всегда выбирать токены из топ-K наиболее вероятных. Это позволяет модели сохранить некоторый выбор (K токенов), исключая при этом самые маловероятные варианты."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "probable tokens Varying temperature is tricky: if the temperature is too low, then almost all tokens receive very low probability; if the temperature is too high, plenty of tokens (not very good) will receive high probability. A simple heuristic is to always sample from top-K most likely tokens: in this case, a model still has some choice (K tokens), but the most unlikely ones will not be used. How to: Look at the results of the top-K sampling with K=10 . How are these samples are different from the standard ones? Try to characterize both coherence and diversity. Lena : we sample until the _eos_ token is generated. it is possible to have fun in your heart . _eos_ the first step of our work , we do not want to see the next level ? _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for love me lyrics , please feel free to submit them to us . _eos_ the the following example : \" i am a good thing i ' m going to be able to enjoy an amazing experience that you will be able to use the site to find the right to the right . _eos_ for the unstable distribution of these products are used . _eos_ this would have been done in the past . _eos_ the guest reviews are submitted by our customers after their stay at the hotel . _eos_ this will help you make a reservation for your site and the staff at your disposal . _eos_ a new approach is to create a new product , but it ' s a great success . _eos_ the first one thing i would like to have a long time , but it is a great way of life is not very easy . _eos_ it is a matter where you can find a wide variety of services . _eos_ the first thing is that a man is made with a very high quality . _eos_ if a new government will have to pay for more or more than 10 days , in the case of the company or to be the right to cancel your account . _eos_ the following are the result of the work of their own . _eos_ we ' re - run in the course , it ' s a good idea . _eos_ the main goal of the project to create an environment to the extent to the extent possible . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for i got a day lyrics , please feel free to submit them to us . _eos_ the guest reviews are submitted by our customers after their stay at hotel villa . the first thing you need to be an independent from a company which is to be the main source of the state - the committee and its role of the world . _eos_ this page contains sub - categories and keyword"
            }
        ]
    },
    {
        "id": "q_0058",
        "question": "Что, согласно тексту, является главной проблемой для нахождения компании в «корпоративном» секторе?",
        "answers": [
            "Главной проблемой является то, что правительство не предоставляет никаких условий для людей, и другие факторы остаются неопределёнными, что затрудняет уверенность в выборе пути."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "game , by accident - and never - ending such clashes . _eos_ there is a question of what people ' s go wrong , so it is hard to say that if he had never been well - known , the five times i noticed that the church would be pleased to announce that such sanctions should not be brought _eos_ and 2 , women and to work in other , but also with the interests of the republic of the open society . _eos_ the akvis sketch to address the following microsoft . com for the new york ... _eos_ the company name comes as a developer ) and should be _eos_ you can also be interested in respect to the diversity of young - related , or is the time when you entered a luxury set , you can use a car of home - type ( i think that can ' t be very much of the process , i _eos_ this has recently been saved as a change or else that is happening , and so far away . _eos_ this is not just to add a new interface ( 6 . 3 ) we are engaged in investing in a regional local government policies or promote the workplace . _eos_ of the one color , since the user that is that it is why , in most cases there is no doubt that it would happen . _eos_ here you can install the debian project installation . _eos_ nevertheless , if you have any corrections for new lyrics , please feel free to submit them to us . _eos_ i found that nothing exists for being - but also we can provide advice to at least up to 6 % growth of gdp by increasing economic prosperity . _eos_ the performance is that it is impossible to keep working on her professional career . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for what want to say ? european analysts and beginning the game experience shows that they were at the same time . _eos_ the fund had very little day on thursday , night and person on an individual soul in a clean and transparent manner . _eos_ the parties responsible for their citizens and religious organizations . _eos_ ( 10 percent ) of the finnish and u . s . civil war . _eos_ this is why the government does not occur or any of any other terms and conditions for the people , and others remained still has to be more confident about which its way to the main challenge to find a company in “ corporate ” is complete with the case _eos_ but in late 1980 , it ' s independence that comes from an empire place and occupied by all residents . _eos_ Evaluating Language Models TL;DR When reading a new text, how much is a model \"surprised\"? As we discussed in the Word Embeddings lecture , there are two types"
            }
        ]
    },
    {
        "id": "q_0059",
        "question": "Какие два типа оценки языковых моделей упоминаются в контексте лекции о векторных представлениях слов?",
        "answers": [
            "В лекции упоминаются два типа оценки: внутренняя (intrinsic) и внешняя (extrinsic)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "but in late 1980 , it ' s independence that comes from an empire place and occupied by all residents . _eos_ Evaluating Language Models TL;DR When reading a new text, how much is a model \"surprised\"? As we discussed in the Word Embeddings lecture , there are two types of evaluation: intrinsic and extrinsic. Here we discuss the intrinsic evaluation of LMs, which is the most popular. When reading a new text, how much is a model \"surprised\"? Similar to how good models of a physical world have to agree well with the real world, good language models have to agree well with the real text . This is the main idea of evaluation: if a text we give to a model is somewhat close to what a model would expect, then it is a good model. Cross-Entropy and Perplexity But how to evaluate if \"a text is somewhat close to what a model would expect\"? Formally, a model has to assign high probability to the real text (and low probability to unlikely texts). Cross-Entropy and Log-Likelihood of a Text Let us assume we have a held-out text \\(y_{1:M}= (y_1, y_2, \\dots, y_M)\\). Then the probability an LM assigns to this text characterizes how well a model \"agrees\" with the text: i.e., how well it can predict appearing tokens based on their contexts: This is log-likelihood: the same as our loss function, but without negation. Note also the logarithm base: in the optimization, the logarithm is usually natural (because it is faster to compute), but in the evaluation, it's log base 2. Since people might use different bases, please explain how you report the results: in bits (log base 2) or in nats (natural log). Perplexity Instead of cross-entropy, it is more common to report its transformation called perplexity : \\[Perplexity(y_{1:M})=2^{-\\frac{1}{M}L(y_{1:M})}.\\] A better model has higher log-likelihood and lower perplexity. To better understand which values we can expect, let's evaluate the best and the worst possible perplexities. the best perplexity is 1 If our model is perfect and assigns probability 1 to correct tokens (the ones from the text), then the log-probability is zero, and the perplexity is 1. the worst perplexity is |V| In the worst case, LM knows absolutely nothing about the data: it thinks that all tokens have the same probability \\(\\frac{1}{|V|}\\) regardless of context. Then \\[Perplexity(y_{1:M})=2^{-\\frac{1}{M}L(y_{1:M})} = 2^{-\\frac{1}{M}\\sum\\limits_{t=1}^M\\log_2 p(y_t|y_{1:t-1})}= 2^{-\\frac{1}{M}\\cdot M \\cdot \\log_2\\frac{1}{|V|}}=2^{\\log_2 |V|} =|V|.\\] Therefore, your perplexity will always be between 1 and |V|. Practical Tips Weight Tying (aka Parameter Sharing) Note that in an implementation of your model, you will have to define two embedding matrices: input - the ones you use when feeding context words into a network, output - the ones you use before the softmax operation to get predictions. Usually, these two matrices are different (i.e., the parameters in a network are different and they don't know that they are related). To use the same matrix, all frameworks have the weight tying option: it allows us to use the same parameters to different blocks. Practical point of view . Usually, substantial part"
            }
        ]
    },
    {
        "id": "q_0060",
        "question": "Какой метод позволяет использовать одни и те же параметры в разных блоках нейронной сети?",
        "answers": [
            "Этот метод называется weight tying (разделение весов). Он позволяет значительно уменьшить размер модели, так как большая часть параметров обычно приходится на эмбеддинги."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "matrices are different (i.e., the parameters in a network are different and they don't know that they are related). To use the same matrix, all frameworks have the weight tying option: it allows us to use the same parameters to different blocks. Practical point of view . Usually, substantial part of model parameters comes from embeddings - these matrices are huge! With weight tying, you can significantly reduce a model size. Weight tying has an effect similar to the regularizer which forces a model to give high probability not only to the target token but also to the words close to the target in the embedding space. More details are here. Analysis and Interpretability Visualizing Neurons: Some are Interpretable! Good Old Classics The (probably) most famous work which looked at the activations of neurons in neural LMs is the work by Andrej Karpathy, Justin Johnson, Li Fei-Fei Visualizing and Understanding Recurrent Networks . In this work, (among other things) the authors trained character-level neural language models with LSTMs and visualized activations of neurons. They used two very different datasets: Leo Tolstoy's War and Peace novel - entirely English text with minimal markup, and the source code of the Linux Kernel. Look at the examples from the Visualizing and Understanding Recurrent Networks paper. Why do you think the model leaned these things? Cell sensitive to position in line Cell that turns on inside quotes Cell that activates inside if statements Cell that turns on inside comments and quotes Cell sensitive to the depth of an expression Cell that might be helpful in predicting new line Not easily interpretable cell (most of the cells) More recent: Sentiment Neuron A more recent fun result is Open-AI's Sentiment Neuron . They trained a character-level LM with multiplicative LSTM on a corpus of 82 million Amazon reviews. Turned out, the model learned to track sentiment! Note that this result is qualitatively different from the previous one. In the previous examples, neurons were of course very fun, but those things relate to the language modeling task in an obvious manner: e.g., tracking quotes is needed for predicting next tokens. Here, sentiment is a more high-level concept. Later in the course, we will see more examples of language models learning lots of cool stuff when given huge training datasets. Use Interpretable Neurons to Control Generated Texts Interpretable neurons are not only fun, but also can be used to control your language model. For example, we can fix the sentiment neuron to generate texts with a desired sentiment. Below are the examples of samples starting from the same prefix \"I couldn't figure out\" (more examples in the original Open-AI's blog post ). What about neurons (or filters) in CNNs? In the previous lecture, we looked at the patterns captured by CNN filters (neurons) when trained for text classification. Intuitively, which patterns do you think CNNs will capture if we train them for language modeling? Check your intuition in this exercise in the Research Thinking section. Contrastive Evaluation: Test Specific Phenomena To test if your LM knows something very specific, you"
            }
        ]
    },
    {
        "id": "q_0061",
        "question": "Какой метод оценки можно использовать для проверки знания языковой моделью конкретных лингвистических явлений?",
        "answers": [
            "Для этого используется контрастная оценка, где модель сравнивает несколько версий одного текста, различающихся только в аспекте, который нужно проверить, и должна присваивать более высокие оценки правильной версии."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "CNN filters (neurons) when trained for text classification. Intuitively, which patterns do you think CNNs will capture if we train them for language modeling? Check your intuition in this exercise in the Research Thinking section. Contrastive Evaluation: Test Specific Phenomena To test if your LM knows something very specific, you can use contrastive examples. These are the examples where you have several versions of the same text which differ only in the aspect you care about: one correct and at least one incorrect. A model has to assign higher scores (probabilities) to the correct version. A very popular phenomenon to look at is subject-verb agreement, initially proposed in the Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies paper. In this task, contrastive examples consist of two sentences: one where the verb agrees in number with the subject, and another with the same verb, but incorrect inflection. Examples can be of different complexity depending on the number of attractors : other nouns in a sentence that have different grammatical number and can \"distract\" a model from the subject. But how do we know if it learned syntax or just collocations/semantic? Use a bit of nonsense! More details are here. Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even if you are not thinking about it constantly, something can still come to mind. Look at the possible answers - previous attempts to answer/solve this problem. Important: You are not supposed to come up with something exactly like here - remember, each paper usually takes the authors several months of work. It's a habit of thinking about these things that counts! All the rest a scientist needs is time: to try-fail-think until it works. It's well-known that you will learn something easier if you are not just given the answer right away, but if you think about it first. Even if you don't want to be a researcher, this is still a good way to learn things! A Bit of Analysis ? TL;DR: Models Learn Patterns Useful for the Task at Hand Let's look at the examples from This EMNLP 2016 paper with a simple convolutional LM. Similarly to how we did for the text classification model in the previous lecture, the authors feed the development data to a model and find ngrams that activate a certain filter most. While a model for sentiment classification learned to pick things which are related to sentiment, the LM model captures phrases which can be continued similarly. For example, one kernel activates on phrases ending with a month, another - with a name; note also the \"comparative\" kernel firing at as ... as . Here will be more exercises! This part will be expanding from time to time. Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics"
            }
        ]
    },
    {
        "id": "q_0062",
        "question": "Какой эффект имеет использование одинаковых параметров для входного и выходного слоев эмбеддингов в нейросетевых языковых моделях?",
        "answers": [
            "Этот прием, называемый weight tying, теоретически действует как регуляризатор, заставляя модель присваивать схожие вероятности словам, близким в пространстве входных эмбеддингов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "firing at as ... as . Here will be more exercises! This part will be expanding from time to time. Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read longer summaries with illustrations and explanations. Take a walk through the authors' reasoning steps and key observations. In depth : read the papers you liked. Now, when you got the main idea, this is going to be easier! What's inside: Common Practice Model Architectures A Bit of Analysis Language Models and Human Reading Behavior N-gram LMs: More Smoothings ... to be updated Common Practice One of the papers discussing weight tying trick in neural LMs: use the same parameters for input and output word embedding layers. Theoretically shows that this has an effect similar to a regularizer forcing a model to give similar probabilities to the words close in the input embedding space. Loss Idea: High Probability for the Words Similar to Target The standard loss function is cross-entropy with one-hot targets. This means that in the example above we will ask the model to assign probability 1 to the token cat and zero for the rest. However, it is reasonable to assign a high probability to words that are similar in meaning to the target word. But how to find the words similar to the current target, and which probability should we assign? cat To evaluate similarity between the target word (i.e., cat ) and other words in the vocabulary, we can use input word embeddings. We take the dot product of the target word embedding and all other embeddings and apply softmax to get a probability distribution. cat Now we can add a new term to the loss function which would encourage a model to assign high probability to the words similar to the target. The Effect: Similar to Weight Tying The authors show theoretically that the effect of optimizing the new training objective (with the regularizer) is similar to using the same parameters for input and output words embeddings (\"weight tying\"). Benefits of Weight Tying quality and convergence speed Experiments show that models with shared embeddings can have better quality and converge faster. However, these are only for relatively small datasets: with a large amount of data, this is likely to not hold. smaller model Since the embeddings layers have a lot of parameters (emb. size * |V|), weight tying significantly reduces model size (e.g., by 25-30%; of course, this depends on model and vocabulary size). Model Architectures Gated Linear Unit Instead of simple convolutions, the paper introduced Gated Linear Units which became quite popular. The idea is similar to LSTM, but not from left to right, but from bottom to top. In addition to extracting features and passing them to the next layer, we also learn which features we want to pass for this token and which ones we don't. For this, a convolution extracts \\(2d\\) features: \\(d\\) content features These are the"
            }
        ]
    },
    {
        "id": "q_0063",
        "question": "Какую функцию выполняют gate features в описанной архитектуре модели?",
        "answers": [
            "Gate features используются для маскирования content features. Они передаются в сигмоидную функцию, которая преобразует их в значения от 0 до 1, определяя, какие функции передавать дальше."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "left to right, but from bottom to top. In addition to extracting features and passing them to the next layer, we also learn which features we want to pass for this token and which ones we don't. For this, a convolution extracts \\(2d\\) features: \\(d\\) content features These are the main features - they extract information from input. \\(d\\) gate features The gate features are used to mask out content features. They are passed to the sigmoid function - it transforms the features into \"gate values\" from 0 to 1. Model Architecture The model architecture is shown in the figure. It consists of several blocks with a GLU layer (or several of them) wrapped in a residual block. The paper tries different models: with convolutional kernels 1-6 and different numbers of layers and filters. Quality and Context Size The figure below shows model quality depending on context size (context size is the CNN receptive field; it is evaluated as we saw here ). All in all, if you stack the number of layers sufficient to cover about 40 tokens, your model will be quite good. Note that while both ngram and convolutional models have fixed context size, this causes problems only for ngram models: they can not have a large context. In contrast, with several convolutional layers you can process long contexts. More in the paper the model outperforms the comparable LSTM; the model is much faster to train than LSTMs. A Bit of Analysis How nonsense can help your research To distinguish between cases where a model indeed learned grammatical agreement or just collocation, the authors test not only \"normal\" examples, but also the ones which do not make sense. E.g. does a model predict the correct agreement in the sentence The colorless green ideas I ate with the chair sleep furiously ? The authors generate such examples: they take an original sentence and replace some words with random words, but preserving part-of-speech and morphological inflection. One example was shown above. Look at the results (\"5-gram KN\" is the 5-gram model with Kneser-Ney smoothing ). The results show that: for n-gram models, context does not help For nonce sentences, 5-gram models are not better than unigram. A bit better for normal sentences though. with the same context, LSTMs are a lot better than n-gram The difference is huge for both original and nonce examples. This is the power of neural networks - they \"know\" which words are similar, while n-gram models rely only on co-occurrence. Size is not the only thing that matters! Neural models are better not only because of context size but also because of how they process this context. for LSTMs, large context does help This is nice - it means that LSTMs do use long contexts. Note also that the scores are quite high even for nonce sentences! More in the paper the detailed procedure for generating nonce examples; results and discussion for specific grammatical constructions. Language Models and Human Reading Behavior Lena : This is not what you will typically see at the \"Related Papers\" lists"
            }
        ]
    },
    {
        "id": "q_0064",
        "question": "Какой метод ранее использовался для оценки предсказуемости слова в контексте до появления вычислительных языковых моделей?",
        "answers": [
            "Ранее предсказуемость слова оценивалась с помощью задач в стиле клоуз, где людей просили угадать следующее слово по контексту."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "also that the scores are quite high even for nonce sentences! More in the paper the detailed procedure for generating nonce examples; results and discussion for specific grammatical constructions. Language Models and Human Reading Behavior Lena : This is not what you will typically see at the \"Related Papers\" lists for a language modeling lecture (at least, I never saw in any). But when I first found this, I was so excited, that I can't help sharing it with you :) Time to read vs Predictability of a word in the context When we read a text, the time taken to read each word is related to our expectations about this word: the more \"expected\" a word is, the less time we need to read it. However, the exact functional relation between this per-word processing time in humans and the \"predictability\" of a word given context was not known. The key point of this paper is that a language model can be used to estimate the \"predictability\" of a word given context. Computational LM instead of a Human one - a very novel idea Previously, the predictability of a word given context was estimated in cloze-style tasks: humans were asked to guess the next word given context. For example, to continue the sentences (1) My brother came inside to... (2) The children went outside to... In the first case, the continuation can be very different, but in the second case, about 90% of participants suggest the word play . While this data estimates the word predictability directly, it is very sparse: for most of the continuations, there's no data at all. That's why the idea to use a computational language model instead of a human one was so groundbreaking: it allowed to estimate word predictability very easily . Components of the study Data with human behavior: eye-tracking Eye movements of native speakers reading a newspaper text. self-paced reading Moving-window self-paced reading times: the participant must press a button to reveal each word in turn. Data recorded: the times between button presses. Language model: 3-gram with Kneser-Ney smoothing. Results computational language models can be very good at predicting time taken by humans to read a word; the functional relationship between reading time and predictability is now known: it is logarithmic (i.e., the relationship between word log-probability and reading time is (near-)linear - this is what we see on the figure). Considered models 5-gram : 5-gram LM with Kneser-Ney smoothing; LSTM : the standard ones; RNNG : models the joint probability of a sequence of words as well as its syntactic structure; GPT-2 : Transformer LM. This a very popular model which we'll meet a bit later in the course. LM Surprisal vs Reading Times The figure shows the relationship between LM \"surprisals\" (negative log-probability) and human reading times for all models and corpora (more in the original paper!). Main observations are: the relationship is linear for all models; human reading time has higher variance with respect to LSTM predictions than with respect to predictions of other models. Psychometric Predictive Power vs LM Perplexity"
            }
        ]
    },
    {
        "id": "q_0065",
        "question": "Какая взаимосвязь наблюдается между перплексией языковой модели и её способностью предсказывать поведение человека?",
        "answers": [
            "Модели с более низкой перплексией, которые в NLP считаются хорошими, также лучше предсказывают поведение человека."
        ],
        "ground_truth_docs": [
            {
                "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
                "text": "log-probability) and human reading times for all models and corpora (more in the original paper!). Main observations are: the relationship is linear for all models; human reading time has higher variance with respect to LSTM predictions than with respect to predictions of other models. Psychometric Predictive Power vs LM Perplexity (The scary phrase \"psychometric predictive power\" simply means how good is an LM at predicting human behavior.) Generally, we see that models with lower perplexity (in NLP, we think are good models) are also good at predicting human behavior. N-gram LMs: More Smoothings Kneser-Ney Smoothing Simple back-off smoothings discard context and back off from n-grams to k-grams with k < n. But let's take for example a phrase San Francisco : it is common and Francisco will have a high unigram probability. And here's the problem: Francisco appears mostly after San , but when backing off, it's large unigram probability will result in a large probability of Francisco after any token! Unigram Probability: Stupid Back-off vs Kneser-Ney Before looking at the full Kneser-Ney formula, let's first compare the unigram probabilities for a token which uses Kneser-Ney and stupid back-off smoothings. Stupid Back-off is based on simple unigram counts \\(N(w_i)\\): the number of times \\(w_i\\) occurs in the corpus. As we mentioned earlier, this won't work well for examples like San Francisco . In contrast to simple back-off, Kneser-Ney smoothing uses not the raw counts, but the number of tokens \\(w_i\\) can follow. Intuitively, this is exactly what we want: we need something which tells us how likely \\(w_i\\) can continue a prefix. In our example, Francisco will get low probability (just as it should). Going Further: Iterative Formula For the full formula, we need to define one more count: The full back-off formula for Kneser-Ney is shown below. Here will be more papers! The papers will be gradually appearing."
            }
        ]
    },
    {
        "id": "q_0066",
        "question": "Какие проблемы могут возникнуть при работе с документацией, если информация разбросана по разным источникам?",
        "answers": [
            "Информация может быть слишком многочисленной и неструктурированной, что затрудняет её поиск и использование. Это приводит к тому, что данные находятся в wiki, Slack, гугл-документах, презентациях и бумажных носителях, создавая хаос и неэффективность."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/articles/676716/",
                "text": "или практики? Кто будет читать документ, как часто и в каких ситуациях? Кто будет читать документ, как часто и в каких ситуациях? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Можно ли полностью или частично автоматизировать процесс актуализации документа? Можно ли полностью или частично автоматизировать процесс актуализации документа? В документации содержится слишком мало информации . Приходится часто дергать членов команды для получения нужных данных В документации содержится слишком мало информации . Приходится часто дергать членов команды для получения нужных данных Информации слишком много, и она разбросана по разным источникам - wiki, Slack, гугл-документы и презентации, бумажные носители Информации слишком много, и она разбросана по разным источникам - wiki, Slack, гугл-документы и презентации, бумажные носители Информация неактуальна Информация неактуальна Информация дублируется в разных источниках Информация дублируется в разных источниках Итак, мы разобрались с основными целями создания и ведения документации и знаем, с какими проблемами нам предстоит столкнуться. Теперь поговорим о “правилах хорошего тона”, использование которых сильно уменьшит вероятность появления этих самых проблем. Правила структуры и оформления: Единая точка входа ко всей документации проекта. Это может быть страница в Notion, фрейм в Miro или Markdown-документ, форма не так важна. Главное, чтобы с этой страницы любой человек мог получить доступ к нужной ему информации. Единая точка входа ко всей документации проекта. Это может быть страница в Notion, фрейм в Miro или Markdown-документ, форма не так важна. Главное, чтобы с этой страницы любой человек мог получить доступ к нужной ему информации. Единые правила оформления и стиля, наличие шаблонов . Немаловажным фактором для восприятия пользователем документации является наличие и консистентность общего стиля оформления документации. Единые правила оформления и стиля, наличие шаблонов . Немаловажным фактором для восприятия пользователем документации является наличие и консистентность общего стиля оформления документации. Стиль описания и подачи информации в документации соответствует культуре команды . Нет смысла придерживаться ненужного формализма во внутренних документах команды. Стиль описания и подачи информации в документации соответствует культуре команды . Нет смысла придерживаться ненужного формализма во внутренних документах команды. В документах есть ссылки на другие релевантные документы . В документах есть ссылки на другие релевантные документы . Важные места выделены Важные места выделены Используются оптимальные методы передачи информации. В зависимости от задачи документа может использоваться не только текст, но и картинки, графики, диаграммы, видео Используются оптимальные методы передачи информации. В зависимости от задачи документа может использоваться не только текст, но и картинки, графики, диаграммы, видео Правила использования и актуализации: Определена целевая аудитория каждого документа - кто, как и зачем будет его использовать Определена целевая аудитория каждого документа - кто, как и зачем будет его использовать Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Использование методологии (“docs as code”) там, где это актуально. В данном случае документация является частью кодовой базы, лежит в"
            }
        ]
    },
    {
        "id": "q_0067",
        "question": "Какие свойства в идеале должны быть у датасет-кард?",
        "answers": [
            "В идеале датасет-карды должны обладать версионированием, автообновлением и интерактивностью. Версионирование позволяет понять, какой документ соответствует той или иной версии датасета. Автообновление обеспечивает актуальность информации при подключении к БД с разметкой, а интерактивность даёт возможность детально изучить конкретные срезы данных или кейсы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/articles/676716/",
                "text": "рамках проекта по маммографии документы распределены по группам: описание работы системы, код и model cards, эксперименты и идеи, данные и так далее. Если мы углубимся в какую либо подгруппу, например, описание работы системы, то мы увидим внутри список документов и ссылок, связанных с данной предметной областью. Как мы видим внутри могут содержаться абсолютно разные документы, такие как Miro, Google-таблицы, PDF-файлы. На этапе оценки осуществимости и значимости проекта мы хотим собрать и агрегировать информацию, которой владеют разные группы пользователей - бизнес, аналитики, ML-специалисты, доменные эксперты, заказчики. Это позволяет нам создать общее понимание нюансов проекта, структурировать нужную информацию, которая позволит принять решение о старте проекта. Примеров, как может выглядеть такой документ, очень много - AI Canvas , Mission Canvas , карточка проекта ( design doc , чек-лист требований ). В эту же группу можно включить технические задания от заказчиков. Такие документы могут включать: Описание проблемы и предположения о достижимой ценности продукта Описание проблемы и предположения о достижимой ценности продукта Варианты решения с ML и без него Варианты решения с ML и без него Требования к качеству (метрики) Требования к качеству (метрики) Описание источников возможных данных Описание источников возможных данных Другие требования (например, к железу и программному обеспечению) Другие требования (например, к железу и программному обеспечению) Последствия ошибок системы и так далее Последствия ошибок системы и так далее Этапы проекта Этапы проекта Технические риски и заключение по проекту Технические риски и заключение по проекту Конкуретная среда Конкуретная среда Литература, научные статьи, видео по теме Литература, научные статьи, видео по теме Исходя из всей собранной информации мы готовим заключение о целесообразности или же её отсутствии для реализации проекта. После сбора и анализа такой информации, проведения встречи с бизнес-подразделением принимается решение о реализации или же отмене проекта. Допустим было принято положительное решение и теперь мы переходим к шагу №2 - “сбор, очистка и разметка данных”. Поскольку в нашем случае мы работаем с медицинскими данными, то разметка данных - это отдельный важный процесс. В нашем случаи, разметчики - доменные эксперты, врачи, что ведёт к отдельным трудностям. Сам процесс разметки, разумеется, также описан в документации - процесс отбора разметчиков, инструкции врачам, принципы разрешения конфликтов в разметке. Любой источник данных также требуется документировать. Это позволяет быстро получать информацию об источнике и объёме данных, их ограничений и свойств, генерировать новые гипотезы, связанные с данными - например, какие данные нужно доразметить или наоборот выбросить из датасета. Документацию датасетов мы называем dataset cards. В зависимости от специфики данных, частоты их пополнения, типа разметки это может быть как просто статический документ, так и интерактивный дашборд. В идеале датасет-карды обладать следующими свойствами: версионирование - мы хотим понимать, какая документ соответствует той или иной версии датасета версионирование - мы хотим понимать, какая документ соответствует той или иной версии датасета автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс интерактивность - должна быть возможность подробно глазами изучить тот или иной"
            }
        ]
    },
    {
        "id": "q_0068",
        "question": "Какие цели ставятся на этапе выдвижения гипотез и тренировки моделей для бизнес-задачи?",
        "answers": [
            "Целями являются быстрая генерация, приоритезация и проверка гипотез; удобный анализ результатов экспериментов; возможность возврата к результатам предыдущих экспериментов; и удобство разработки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/articles/676716/",
                "text": "информацию о датасетах автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс В зависимости от задачи датасет-кард может содержать различную информацию - примеры данных и разметки, описательные статистики, источник данных и описание процесса сбора данных, информация о разметчиках, известные проблемы и ограничения. Итак, мы определились с источниками данных, собрали их и разметили, создали документацию. Теперь пора начинать выдвигать гипотезы и тренировать модели для решения нашей бизнес-задачи. Среди целей, которые мы ставим перед собой на данном этапе: Быстрая генерация, приоритезация и проверка гипотез Быстрая генерация, приоритезация и проверка гипотез Удобный анализ результатов экспериментов Удобный анализ результатов экспериментов Возможность возврата к результатам предыдущих экспериментов Возможность возврата к результатам предыдущих экспериментов Удобство разработки Удобство разработки Безусловно, ни одна из этих целей не решается только документацией, но документация должна поддерживать наше стремление к реализации каждой цели. Примеры документации на этом этапе - база гипотез, карточки экспериментов, документация кода, презентации по итогам серии экспериментов. База гипотез - список приоритизированных идей на отработку. Он может содержать различную информацию и описание самой идеи, теги для удобной фильтрации контента внутри базы идей, оценки реализуемости и трудоемкости идеи (например, по ICE ), дизайн-ревью и отчет по эксперименту, ссылка на эксперимент в трекере экспериментов. В данном случае база идей реализована в Notion. Благодаря этому ее можно упорядочивать в необходимом нам формате. Например, по статусам, оценке “легкости реализации” и так далее. Отсюда мы можем попасть в саму карточку нужного нам эксперимента и посмотреть его детали. Когда гипотеза попадает в базу она как правило описана очень верхнеуровнево, без деталей. Этой информации обычно недостаточно, чтобы точно оценить трудоёмкость гипотезы, конкретные шаги, нужные для её проверки, зависимости. Большая часть этой информации приходит уже в процессе анализа задачи. Когда конкретный человек из команды берет ее на себя, собирает инфорацию, гуглит статьи, смотрит репозитории, наличие и доступность данных, он описывает детали эксперимента (experiment design), чтобы обозначить план итоговой реализации. Этот план затем оценивают другие члены команды в рамках процедуры design review. Это помогает избавиться от проблем неправильного понимания задачи, расходования времени на переписывание после код-ревью, нерационального расходования времени во время проверки гипотезы. Результаты реализации гипотез могут быть описаны в различном формате в зависимости от “ожиданий” и их важности. В некоторых случаях достаточно односложного комментария, а в некоторых необходимо готовить презентацию и обсуждать результаты и дальнейшие идеи с коллегами. Использование трекера (в нашем случае это ClearML) позволяет обеспечить репродуцируемость эксперимента и в любой момент получить информацию о его метриках, версии кода, гиперпараметрах. В трекере можно сравнить результаты разных экспериментов, изучить метрики, сформулировать выводы. Всё это по сути тоже является частью документации ML-проекта. На этом этапе мы хотим оценить качество модели, сравнить её с предыдущей версией, понять ограничения и особенности модели. Например, новая модель может работать с конкретным типом данных (снимки с определённого типа оборудования) хуже. И это также важно знать и учиывать. В качестве артефактов документации на этом этапе у нас появляются model card, дашборды с"
            }
        ]
    },
    {
        "id": "q_0069",
        "question": "Какой формат используется для хранения документации модели, которая версионируется и прилинкована к коммитам?",
        "answers": [
            "Документация модели хранится в формате docs-as-code, в частности как Markdown-документ, который версионируется и привязан к конкретным коммитам."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/articles/676716/",
                "text": "хотим оценить качество модели, сравнить её с предыдущей версией, понять ограничения и особенности модели. Например, новая модель может работать с конкретным типом данных (снимки с определённого типа оборудования) хуже. И это также важно знать и учиывать. В качестве артефактов документации на этом этапе у нас появляются model card, дашборды с таблицами и метриками, отчёты по анализу ошибок. Model Card - описание ML-системы, которая включает в себя следующую информацию: Изменения в последней версии Изменения в последней версии Описание обучающих и тестовых данных Описание обучающих и тестовых данных Описание архитектуры сети, препроцессинга и других компонентов Описание архитектуры сети, препроцессинга и других компонентов Описание требований к входным данным Описание требований к входным данным Описание аутпутов системы Описание аутпутов системы Метрики Метрики Описание известных ограничений и проблем Описание известных ограничений и проблем Модел-кард для разных групп пользователей может иметь разный итоговый вид. Например, для бизнес или конечных пользователей можно включить рекомендуемые сценарии использования системы, но убрать лишнюю информацию об архитектуре сети. Мы храним такую документацию в формате docs-as-code - в нашем случае, это Markdown-док, который версионируется и прилинкован к конкретным коммитам. По важным же релизам могут быть экспортированы и PDF. Деплой как и любой другой ML-процесс порождает свой класс специфичных документов. Среди которых : Отчеты по тестам (test reports) Автоматизированные тесты Результаты a/b тестов Отчеты по опросы пользователей Отчеты по тестам (test reports) Автоматизированные тесты Автоматизированные тесты Результаты a/b тестов Результаты a/b тестов Отчеты по опросы пользователей Отчеты по опросы пользователей Дашборды и регулярные автоматические отчёты Дашборды и регулярные автоматические отчёты Post-mortem по итогам инцидентов на проде (документация события, несущего негативные последствия с целью анализа и устранения его причин) Post-mortem по итогам инцидентов на проде (документация события, несущего негативные последствия с целью анализа и устранения его причин) Документация API Документация API Change Notes Change Notes Прочая документация, связанная с релизами Прочая документация, связанная с релизами Конечно, на ML-проекте появляется и всякая общая и процессная документация. Примеры из нашей практики: Team Canvas Team Canvas Очень полезный элемент для онбординга новых сотрудников. Документ описывает состав команды, ценности команды, зоны ответственности внутри команды и между сотрудниками, процессы, встречи и их формат, командные ритуалы и правила Доски и скоринговые карты собеседований сотрудников Доски и скоринговые карты собеседований сотрудников Таблица с описанием встреч Таблица с описанием встреч Таблица встреч - очень полезная вещь, которая обеспечивает понимание цели, участников и артефактов встреч для всех сотрудников. Для планирования стреч и напоминаний мы также используем гугл-календари. Гайдлайны по написанию кода Гайдлайны по написанию кода База знаний - по коду, инфраструктуре, ML, заметки со встреч с доменными экспертами (врачами) База знаний - по коду, инфраструктуре, ML, заметки со встреч с доменными экспертами (врачами) Доска онбординга Доска онбординга Общее Миро со всей информацией Стратегия и цели компании/проекта Роадмапы Общее Миро со всей информацией Стратегия и цели компании/проекта Стратегия и цели компании/проекта Роадмапы Роадмапы В зависимости от вида документа и его целевой аудитории варьируется и лицо, поддерживающее документ. Кроме того, важно в целом создавать культуру ведения документации в компании, формировать понимание каждого члена компании, что документация и её актуализация приносит конкретную ценность, экономит время и устраняет дублирование работы. Отдельно хочу остановиться на таком моменте как автоматизация документации."
            }
        ]
    },
    {
        "id": "q_0070",
        "question": "Какие конкретные шаги предлагается предпринять для улучшения документации?",
        "answers": [
            "Предлагается провести аудит документации с ответами на вопросы из первой части статьи и сформировать бэклог техдолга, создать единую точку входа, оценить применимость методологии docs-as-code и возможности автоматизации, собрать обратную связь от различных групп и тренироваться писать качественные тексты."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/articles/676716/",
                "text": "вида документа и его целевой аудитории варьируется и лицо, поддерживающее документ. Кроме того, важно в целом создавать культуру ведения документации в компании, формировать понимание каждого члена компании, что документация и её актуализация приносит конкретную ценность, экономит время и устраняет дублирование работы. Отдельно хочу остановиться на таком моменте как автоматизация документации. Во-первых, чем меньше мы в целом делаем руками - тем меньше нужды в ручном написании документации. Например, если мы ставим эксперименты в джупитере или меняем данные руками в эксель-табличках, то и документацию нужно будет написать руками. А работа с эксперимент-трекером или БД с разметкой автоматически создаёт нужные артефакты. Помимо этого, есть разные инструменты, которые позволяют автоматизировать процесс создания и актуализация документации - Swagger, плагины для IDE, интерактивные датасет-карды (о них можно прочесть выше), DVC-пайплайны, методология docs-as-code. Качественная документация - залог возможности успешного масштабирования как разработки, так и бизнеса в целом. Что бы я предложил вам сделать уже сейчас? Провести аудит документации и по каждому документу ответить на вопросы из списка (можно найти в первой части статьи), сформировать бэклог техдолга по документации Провести аудит документации и по каждому документу ответить на вопросы из списка (можно найти в первой части статьи), сформировать бэклог техдолга по документации Создать единую точку входа в документации (если её еще нет) Создать единую точку входа в документации (если её еще нет) Оценить, для каких документов подходит методология docs-as-code, актуализацию каких документов можно автоматизировать Оценить, для каких документов подходит методология docs-as-code, актуализацию каких документов можно автоматизировать Собрать обратную связь от разных групп (ML-инженеры, пользователи, разметчики, бизнес и другие команды) Собрать обратную связь от разных групп (ML-инженеры, пользователи, разметчики, бизнес и другие команды) Тренироваться писать хорошие технические (и не только) тексты Тренироваться писать хорошие технические (и не только) тексты Если вы хотите узнать ещё больше об организации процессов ML-разработки, подписывайтесь на наш Телеграм-канал Варим ML ."
            }
        ]
    },
    {
        "id": "q_0071",
        "question": "Какие основные функции выполняет API Gateway в системе с микросервисами?",
        "answers": [
            "API Gateway служит единой точкой входа для всех запросов, выполняя маршрутизацию, защиту и контроль трафика. Он обрабатывает и модифицирует запросы на лету, обогащая их метаданными, а также упрощает аутентификацию, авторизацию и обеспечивает наблюдаемость системы через логи и метрики."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "Всем привет! Меня зовут Герман Кравец, я больше десяти лет в IT. В МойОфис работаю руководителем группы Календаря в отделе разработки Mailion — это наша отказоустойчивая корпоративная почта для крупного бизнеса. В этой статье расскажу, как мы с командой искали новое решение для нашего API Gateway: зачем вообще понадобилось его менять, с какими проблемами столкнулись и как проходили все этапы — от первых «что-то идёт не так» до финального рефакторинга и запуска нового Gateway в прод. Будет немного боли, немного архитектуры и чуть-чуть магии. Если вам интересно, как решать нетривиальные задачи в продуктовой разработке, где стоит использовать готовые решения, а где всё писать вручную, или просто хочется узнать, как мы сократили простои на регрессе с 4–6 часов до пары минут, — добро пожаловать под кат! API Gateway — это единая точка входа для всех запросов, особенно когда в системе много микросервисов. Публиковать наружу порты каждого из них неудобно, да и с точки зрения безопасности и мониторинга это быстро превращается в хаос. Gateway решает эту проблему: он берёт на себя маршрутизацию, защиту и контроль трафика. Помимо этого, он помогает обрабатывать и модифицировать запросы на лету. В реальных системах это происходит постоянно: запросы нужно обогащать дополнительными метаданными, информацией о пользователе или клиенте, добавлять данные для статистики и аналитики. Gateway становится универсальным фильтром, через который проходит всё взаимодействие между клиентом и микросервисами. С его помощью также значительно упрощается аутентификация и авторизация: достаточно один раз проверить, имеет ли конкретный клиент доступ к нужному ресурсу, и дальше распространять эти права централизованно. Встроенные механизмы безопасности позволяют защитить систему от DDoS-атак, ограничить частоту запросов (Rate Limiting) и контролировать подозрительную активность. API Gateway отвечает и за наблюдаемость: через него проходят логи, метрики и трейсы, что делает анализ работы всей системы прозрачным. Главный плюс подхода в том, что внешний мир не зависит от внутренней архитектуры. Gateway предоставляет единый публичный контракт — по нему с нами интегрируются клиенты и смежные системы. При этом внутренняя структура может меняться сколько угодно: можно оптимизировать алгоритмы, переписывать сервисы или перестраивать связи между ними без риска что-то «сломать» для пользователя. Это основные фишки, которые будут важны для нашей истории, а дальше расскажу, как мы использовали API Gateway. Так у нас выглядела архитектура до того, как мы занялись поиском нового решения. С внешним миром API Gateway взаимодействует через HTTP и WebSockets, а внутри это набор плагинов, сгенерированных на основе прото-файлов, написанных вручную, и всей структуры системы. Когда мы начали искать новое решение, стало очевидно: плагинов накопилось прилично: раздача клиентской статики, работа с картинками, файлами, их было около восьми, не считая десятков вспомогательных. Всё общение между сервисами шло по gRPC, и таких сервисов в системе насчитывалось больше семидесяти. Их все нужно было как-то безопасно и стабильно опубликовать наружу. Как мы пришли к жизни такой? Проект Gateway мы начали разрабатывать примерно в 2017 году. Основным веб-сервисом выбрали Caddy — тогда это был довольно мощный инструмент с гибкой системой плагинов и возможностью писать свои. Мы вручную написали шестнадцать активных плагинов, по сути, шестнадцать отдельных репозиториев с разным уровнем вложенности и зависимостей. А вдобавок создали мощный инструмент, который генерировал эти плагины из proto. Можно сказать, что это был отдельный продукт, заточенный именно"
            }
        ]
    },
    {
        "id": "q_0072",
        "question": "Какие факторы повлияли на выбор Caddy в качестве решения для сервиса?",
        "answers": [
            "Ключевыми факторами стали поддержка HTTP/2 для работы с gRPC и gRPC-стримами, модульность с возможностью генерации плагинов, Go-ориентированность для низкого порога входа бэкенд-разработчиков и способность раздавать статику из коробки не хуже NginX."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "это был довольно мощный инструмент с гибкой системой плагинов и возможностью писать свои. Мы вручную написали шестнадцать активных плагинов, по сути, шестнадцать отдельных репозиториев с разным уровнем вложенности и зависимостей. А вдобавок создали мощный инструмент, который генерировал эти плагины из proto. Можно сказать, что это был отдельный продукт, заточенный именно под генерацию плагинов для Caddy. Почему в своё время сделали именно такой выбор, сейчас можно только предполагать — исходный владелец сервиса уже не работает в компании, а значит, остаётся только анализировать решения по следам кода. Вероятно, решающими факторами стали несколько моментов. Во-первых, поддержка HTTP/2 : мы активно используем gRPC и gRPC-стримы, в том числе на клиентской стороне, и наличие полноценной поддержки протокола тогда было критично. Во-вторых, модульность и возможность генерации плагинов . Инструмент действительно мощный, и такая гибкость на этапе активной разработки казалась идеальным решением. Третий аргумент — Go-ориентированность . Наши бэкендеры все пишут на Go, поэтому порог входа был минимальным. Нужно добавить кастомный функционал — просто написал плагин или форкнул нужный модуль. Ну и, наконец, раздача статики из коробки . Caddy справлялся с этим не хуже NginX, поэтому выбор выглядел вполне оправданным. Звучит классно… Так в чём же проблема? На практике начали всплывать проблемы — и их оказалось немало. Главная — bus-фактор : ключевые знания о сервисе ушли вместе с людьми, а владельца у компонента не осталось. Поверх этого наложились сильная связанность со статикой , самописные генераторы плагинов и аж шестнадцать дочерних репозиториев . Сборки занимали от тридцати до шестидесяти минут: каждый из репозиториев тянул за собой зависимые сборки и деплой. Конфигурация тоже доставляла боль. Caddy первой версии использует Caddyfile, нечто вроде псевдо-YAML, и работать с ним было сложно даже для опытных инженеров. Ситуацию усугубляли C++-зависимости, которые повышали порог вхождения в проект, замедляли скорость сборки как локально,так и в CI/CD. Когда мы собрали всё это воедино, стало ясно, что система достигла точки, где поддерживать её дальше уже дороже, чем переписать. Мы были слегка в шоке от масштабов накопившихся проблем и поняли, что пора что-то менять. На старте у нас были жёсткие ограничения по ресурсам: фичи горят, баги горят, а сверху ещё навалился огромный ком техдолга. Выделить под это отдельную команду не получилось, поэтому техдолгом занимался один backend-разработчик в низком приоритете, между коммитами в основной релиз и правками продовых багов. В помощь ему подключили DevOps-инженера — тоже не на full time, а по мере возможности. В такой конфигурации мы решили идти двумя параллельными путями. Первый — сложный: поискать альтернативы текущему решению и оценить, во что выльется миграция. Второй — попроще и побыстрее: разделить статику и API Gateway , чтобы хоть немного разгрузить систему и перестать таскать лишнее между сборками. По классике всё разворачивалось в Docker: внутри и Caddy, и наши статики. Вроде все логично и красиво, но смотришь глубже и взрыв мозга: статики запускаются постепенно, а потом вольюмами запихиваются в веб-сервис. Этот пайплайн ещё и в Jenkins, в общем, очень больно. Кроме того, любое изменение или push в одну из статик заставлял пересобираться их все и передеплоиваться полностью вместе с Gateway. То есть на регрессе, когда мы активно стабилизировали продукт, выкатывали фичи, догоняли код фриз и фича фриз, порядка 120 разработчиков фиксили"
            }
        ]
    },
    {
        "id": "q_0073",
        "question": "Какие проблемы возникали при изменении статики до внедрения нового решения?",
        "answers": [
            "Любое изменение или push в одну из статик заставлял пересобираться их все и полностью передеплоиваться вместе с Gateway, что приводило к простоям API Gateway на 4-6 часов во время активной разработки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "пайплайн ещё и в Jenkins, в общем, очень больно. Кроме того, любое изменение или push в одну из статик заставлял пересобираться их все и передеплоиваться полностью вместе с Gateway. То есть на регрессе, когда мы активно стабилизировали продукт, выкатывали фичи, догоняли код фриз и фича фриз, порядка 120 разработчиков фиксили баги, пайплайн на всё это триггерился и API Gateway мог лежать 4-6 часов. От этого люто страдали команды FE, BE и QA. Мы решили отделить статику от Gateway и пошли по самому очевидному пути — взяли nginx в качестве базового образа для статики и заодно использовали его как балансировщик. Решение оказалось не только простым, но и прагматичным: nginx уже был согласован с ИБ и юристами, использовался в других командах, а значит — не требовал бюрократии. Инструмент популярный, сообщество большое, документация понятная, и самое главное, у нас уже были все нужные компетенции. Любой разработчик мог что-то поправить, а команда поддержки кастомизировать конфигурацию прямо на площадке заказчика. В итоге получилась архитектура, в которой впереди стоит nginx-балансировщик , за ним — API Gateway , а статики живут отдельно и разворачиваются независимо . Никаких вольюмов, никаких общих сборок — каждый компонент выкатывается сам по себе. Результат почувствовали сразу: мы начали работать по новым пайплайнам, по новой архитектуре, и снизили время deploy с 30 до 2 минут. И боли на регрессе прекратились, потому что пайплайны выкатки стали незаметными, а время простоя API Gateway снизилось до считанных минут. Мы — продуктовая компания, и у нас есть собственный отдел ИБ, который проверяет все продукты на уязвимости. У коллег есть свои инструменты для анализа, но они не всегда успевают за обновлениями языков и библиотек. Поэтому разрешение на использование новой версии Go мы получаем только тогда, когда их стек готов это переварить. В этот раз, наконец, дали добро на Go 1.21 . Отлично — побежали обновлять сервисы. Всё шло по плану: обновили зависимости, подтянули библиотеки, ничего критичного не меняли, код не трогали. Локальная сборка прошла, запускаем... и сразу ловим панику. Окей, так быть точно не должно, надо искать, где собака зарыта. Gateway у нас построен на Caddy v1 , а тот, в свою очередь, зависит от ряда библиотек. Проблема в том, что актуальная open-source версия qTLS поддерживает максимум Go 1.15 , и именно на этом уровне начинает рушиться ядро Caddy. Самое неприятное, что паника срабатывает не при компиляции, а только при запуске. Мы пошли в отладку и довольно быстро докопались до корня: знакомьтесь, функция init() в одной из библиотек. Внутри — проверки вроде structsEqual для нескольких структур. Если сравнить TLS из стандартной библиотеки с тем, что лежит внутри qTLS, то они совпадают буквально один в один. И сразу возникает закономерный вопрос: зачем вообще делать такое сравнение на этапе инициализации? Дальше ещё интереснее. Ошибка, которая валится в лог, указывает на несовпадение структур. Первое, на что мы наткнулись, — различие в количестве полей. На этом моменте стало ясно: заплатками это не вытащить. Нужно всё выносить, перепроверять зависимости и фактически перекапывать Gateway заново, чтобы перейти на новую версию Go и при этом не сломать прод. На момент начала работы у нас было 16 репозиториев, и уровень вложенности у некоторых доходил до шести. Каждый отвечал"
            }
        ]
    },
    {
        "id": "q_0074",
        "question": "Какие проблемы возникли при использовании множества репозиториев с глубокой вложенностью для Gateway?",
        "answers": [
            "Использование 16 репозиториев с вложенностью до шести уровней привело к CI/CD-кошмару. Пайплайн для одного репозитория занимал около пяти минут, а изменение на нижнем уровне вызывало цепочку пересборок, из-за чего простая правка кода могла превращаться в полчаса ожидания. Это замедляло вывод изменений в прод и создавало риски, когда падение инфраструктуры превращало CI/CD в эффект домино."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "На этом моменте стало ясно: заплатками это не вытащить. Нужно всё выносить, перепроверять зависимости и фактически перекапывать Gateway заново, чтобы перейти на новую версию Go и при этом не сломать прод. На момент начала работы у нас было 16 репозиториев, и уровень вложенности у некоторых доходил до шести. Каждый отвечал за свой кусок плагинов и зависимостей. Казалось удобно — микросервисный подход, всё по науке. Но на практике это вылилось в настоящий CI/CD-кошмар. Пайплайн для одного репозитория занимал около пяти минут: сборка, тесты, сканеры безопасности — полный набор. А из-за вложенности одно изменение на самом нижнем уровне тянуло за собой цепочку пересборок. В итоге простая правка одной строчки кода могла превращаться в полчаса ожидания, пока вся цепочка отрабатывает. Cкорость вывода изменений в прод страдала, а разработчики страдали вместе с ней. Даже не говоря уже о случаях, когда на инфраструктуре что-то падало и весь CI/CD превращался в домино. В какой-то момент стало очевидно, что нужно выбираться из этого болота. Мы объединили всё в один репозиторий, убрав ненужную вложенность. Теперь каждый пайплайн стабильно выполняется за те же пять минут, но без накопительного эффекта. Всё стало проще, прозрачнее и быстрее. Радуемся, архитектуру поправили, идём дальше. Пора было искать альтернативы Caddy v1. Первым делом решили проверить очевидное — может, сам Caddy уже эволюционировал. Вбиваем в Google, открываем официальную документацию и сразу видим: есть вторая версия! Да ещё и с поддержкой Go 1.21. Отлично, наконец-то шанс обновиться без костылей. Начали разбираться. Архитектурно Caddy v2 похож на своего предшественника: тот же модульный подход, тот же Go под капотом, активная разработка. Появилась и приятная новинка — JSON-конфигурация. После их псевдо-YAML в первой версии это просто глоток свежего воздуха. Главный плюс JSON-конфига — возможность hot-reload: можно обновлять настройки плагинов на лету, без полного перезапуска сервиса. Захотел — подхватил новый конфиг, перезагрузил нужный модуль и продолжаешь работать. Красота. Казалось бы, решение найдено. Но, как обычно, без подводных камней не обошлось. Во-первых, bus-фактор никуда не делся. Один человек из всей команды (а нас больше сотни) изучит новый стек, разберётся в конфигурации, соберёт систему и станет единственной точкой знаний. Дальше классика: отпуск? нельзя. больничный? не вовремя. Горячая пора релиза, и этот человек буквально живёт в деплое. Такой сценарий недопустим, если мы хотим держать стабильный продукт. Во-вторых, документация у v2 — это боль . Два соседних плагина: у одного есть описание, у другого тишина. Конфигурации половины плагинов задокументированы только в формате JSON, другой половины только в Caddyfile, и между ними нет совместимости. Даже ключи параметров могут отличаться. Это сразу оборачивается проблемой поддержки: DevOps-ы и сопровождение не смогут быстро разобраться, а значит, продукт станет заложником своей сложности. Дальше, неприятное открытие. В Caddy v1 можно было сделать небольшой костыль: считать исходный config-файл и построчно проверить каждый параметр, вытащить сквозные ссылки между плагинами. В v2, с переходом на JSON, эту возможность убрали, вероятно, из соображений безопасности. В результате стало невозможно реализовать привычный контекст между модулями. И наконец — порядок инициализации . Если итоговый JSON-файл формируется генератором не в той последовательности, в какой планировалась загрузка модулей, сервис может повести себя непредсказуемо. Иногда просто меняешь два блока местами и всё, поведение при запуске другое. При нашей сложной связности между плагинами"
            }
        ]
    },
    {
        "id": "q_0075",
        "question": "Какие проблемы возникали при изменении порядка блоков в JSON-файле конфигурации?",
        "answers": [
            "Изменение порядка блоков в JSON-файле могло привести к непредсказуемому поведению сервиса при запуске. Сервис мог стартовать некорректно, а часть модулей могла перестать работать."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "стало невозможно реализовать привычный контекст между модулями. И наконец — порядок инициализации . Если итоговый JSON-файл формируется генератором не в той последовательности, в какой планировалась загрузка модулей, сервис может повести себя непредсказуемо. Иногда просто меняешь два блока местами и всё, поведение при запуске другое. При нашей сложной связности между плагинами это недопустимо: сервис может стартовать «не так», а часть модулей просто отвалится. В Caddy v1 у нас была обёртка, которая обеспечивала единый контекст загрузки — в v2 такого механизма нет вообще. После всех экспериментов стало ясно: зачем страдать с коробочными решениями, которые вроде бы предлагают модульность, но по факту не вписываются в архитектуру нашего сервиса и плагинов? Мы пришли к очевидному выводу — проще и надёжнее написать своё решение с нуля, полностью подконтрольное команде. Тогда можно будет кастомизировать всё, что угодно, и не зависеть от чьей-то документации, обновлений или внезапных несовместимостей. Но тут важно не впасть в другую крайность — не делать «всё своё» руками. В начале статьи я уже упоминал, что раньше мы писали собственные генераторы, которые создавали плагины для Caddy прямо из прото-файлов на лету. Эти генераторы со временем разрослись до состояния отдельных монстров — по объёму кода они превосходили большинство наших микросервисов. Повторять эту историю не хотелось. Писать третий генератор, если завтра опять изменится вектор — это бессмысленный оверхед. Нам нужно было решение, где архитектура остаётся под контролем, но при этом есть готовый, устойчивый фреймворк с предсказуемой производительностью и зрелым сообществом. Ключевые критерии были простые: стабильность, высокая скорость обработки запросов, нормальные бенчмарки и адекватное поведение под нагрузкой. Пусть сейчас Gateway не был узким местом по RPS — мы хотели предусмотреть запас на будущее. Выбор в итоге пал на Fiber. Почему он, а не FastHTTP? Когда мы выбирали фреймворк, времени было в обрез: фичи горели, инфраструктура стояла на паузе, и писать низкоуровневую обвязку с нуля было просто некогда. FastHTTP, конечно, быстрый и мощный, но требует ручной сборки экосистемы вокруг — middleware, логирования, ошибок, хэндлеров. На это нужны недели, которых у нас не было. Fiber, наоборот, подошёл идеально по балансу «готовое / контролируемое». Это, по сути, аналог Express.js в мире Go: простой, понятный, с нормальной документацией и логичной архитектурой. Порог вхождения низкий — любой разработчик может быстро разобраться, а коллеги с фронтенда даже получили возможность при необходимости зайти, поправить заголовки или плагин вручную, не залезая в дебри бэкенда. Fiber оказался лаконичным и предсказуемым, а документация — человеческой: всё описано, читается легко, без копания в исходниках. Построив архитектуру на нём, мы сразу выиграли в читаемости и поддерживаемости кода. Плюс, JSON-конфигурация у Fiber оказалась очень близка к тому, как устроены наши остальные gRPC-сервисы. В Caddy-файлах синтаксис был уникальный и никак не стыковался с инфраструктурой продукта, а тут всё единообразно: те же структуры, те же подходы. Это важно не только для разработчиков, но и для DevOps-ов и сопровождения — всё знакомо, всё на автомате. Мы не изобретаем велосипед, а просто берём то, что уже хорошо работает у соседей. Начали тестировать и сразу влетели в проблему. Мы активно используем стримы, и примерно половина клиентских запросов работает именно через них. Первые тесты шли нормально: запросы отрабатывали, ответы возвращались, всё красиво. Но потом — бах. На десятом,"
            }
        ]
    },
    {
        "id": "q_0076",
        "question": "Какая проблема возникла при использовании Fiber фреймворка со стримами?",
        "answers": [
            "Fiber не поддерживал HTTP/2, а стримы работали через gRPC Gateway поверх этого протокола. Это вызывало несовпадение дескрипшенов запросов на уровне net/http, что приводило к падению сервера."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "Мы не изобретаем велосипед, а просто берём то, что уже хорошо работает у соседей. Начали тестировать и сразу влетели в проблему. Мы активно используем стримы, и примерно половина клиентских запросов работает именно через них. Первые тесты шли нормально: запросы отрабатывали, ответы возвращались, всё красиво. Но потом — бах. На десятом, пятидесятом или сотом запросе (зависело от случая) страница переставала отвечать. Проверяем — сервис упал в панику. Проблема воспроизводилась хаотично: иногда с первого запроса, иногда только после сотого. Разбор показал: Fiber не поддерживает HTTP/2, а у нас стримы как раз шли поверх него, через обвязку gRPC Gateway. В результате — несовпадение дескрипшенов запросов на уровне ядра net/http, и сервер просто рушился. На этом этапе стало ясно: починить такое в лоб не получится. Мы снова оказались у развилки и пошли искать другой фреймворк, который умеет работать с HTTP/2 из коробки. Когда начали искать фреймворк с нормальной поддержкой HTTP/2, вариантов оказалось не так уж много. После серии тестов и чтения исходников остановились на Gin. Из всех кандидатов у него оказались лучшие документация и комьюнити, внятная архитектура и богатый набор middleware из коробки. Порог вхождения низкий даже для тех, кто раньше с ним не работал. Да, по RPS Gin немного проседает по сравнению с Fiber, но для нас это не критично: Gateway никогда не был узким местом по производительности, зато стабильность и поддерживаемость для нас приоритет. Интегрировав Gin, запустили всё прекрасно. Но наши приключения на этом не закончились. Разработчику всегда попадётся на глаза что-то, что нужно подрефачить. У нас было большое дублирование соединений. Каждый плагин по идеологии Caddy — это инкапсулированная, изолированная единица. Поэтому, чтобы прокинуть наши gRPC-соединения, их приходилось дублировать в каждом плагине и каждой конфигурации, хотя по факту все они стучались в один и тот же сервис. Мы сделали единую точку — фабрику соединений, которая по запросу «дай мне соединение к такому-то сервису» проверяет: если соединения нет — создаёт его, если есть — просто переиспользует и отдаёт плагину. Так мы сократили количество соединений по ключевым сервисам с восьми до одного, что в будущем заметно снизит нагрузку. C++-зависимость была нашей болью на протяжении всего существования Gateway. Это одна из причин, почему при виде задач по этому проекту разработчики думали: «О нет, только не он». Ни нормального readme, ни инструкций: запускаешь и получаешь сообщение «Отдай мне библиотеку». На Linux это ещё можно было пережить — где-то в Confluence можно найти, что именно нужно поставить. А вот на Mac библиотек просто нет, и приходилось проходить через эту боль вручную. Разобравшись, откуда растут ноги, я выяснил, что у нас есть плагин для работы с аватарками, который тянул зависимость соседнего модуля, тоже работающего с аватарками. А у соседа под капотом жила библиотека libmagic, используемая для изменения размеров, кропов и прочих операций с изображениями. В коде всё выглядело просто: интерфейс, конструктор и обработчик запроса. В конструктор подтягивался дочерний модуль соседа, и тот — libmagic. Обработчик же делал запрос к соседнему сервису, получал данные и отдавал их клиенту. Мы посмотрели внимательнее — действительно ли всё это нужно, ведь мы работаем по gRPC? Открыли прото соседа и обнаружили метод, который полностью закрывал нашу потребность. Мы удалили зависимость, переписали обработчик так, чтобы он"
            }
        ]
    },
    {
        "id": "q_0077",
        "question": "Какой метод был обнаружен в прото соседнего сервиса, который позволил упростить обработчик?",
        "answers": [
            "Был обнаружен метод, полностью закрывавший потребность, что позволило заменить 40-50 строк кода несколькими строками через вызов этого метода по gRPC-стриму."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "и тот — libmagic. Обработчик же делал запрос к соседнему сервису, получал данные и отдавал их клиенту. Мы посмотрели внимательнее — действительно ли всё это нужно, ведь мы работаем по gRPC? Открыли прото соседа и обнаружили метод, который полностью закрывал нашу потребность. Мы удалили зависимость, переписали обработчик так, чтобы он просто вызывал этот метод через gRPC-стрим, и всё заработало. 40–50 строк кода заменились несколькими строками, ушла боль с C++, сборка стала заметно быстрее, а настройка проще. Теперь проект собирается чистым Go, без лишних зависимостей, а разработчики наконец могут просто запустить, скомпилировать и работать без шаманства. Первое, что мы почувствовали, — ушёл bus-фактор . Теперь любой бэкенд-разработчик в команде может спокойно запустить наш Gateway локально и разобраться, как он работает. Никаких «коробочных» ограничений, странных зависимостей и «магии». Код открыт, структурирован, модули логично разбиты по бизнес-областям. Если нужно что-то поправить — просто проваливаешься в нужный блок и сразу понимаешь, где внести изменения. Конфигурация стала лаконичной и унифицированной . Теперь она полностью соответствует подходам, принятым в других наших сервисах: понятна разработчикам, девопсам и поддержке. Раньше конфиг-файл старого Gateway был настоящей болью — около трёх тысяч строк ручного кода. В нём нужно было заполнять параметры для всех плагинов сразу: нельзя было отключить ненужные, даже если они не использовались при инициализации. Некоторые плагины требовали интеграции с NATS и другими инфраструктурными зависимостями, поэтому любое изменение превращалось в мучение. Генератора не было вовсе: сервис был «белой вороной», особенным и непонятным. Теперь всё иначе. Мы собрали локальный конфиг из примерно 200 строк — только базовые блоки: HTTP, аутентификация и авторизация. Всё остальное стало управляемым: если плагин нужен, то включаешь его в конфиг, не нужен — просто не указываешь. Плагины раньше не знали об общих блоках и дублировали кучу кода. Мы решили это с помощью механизма мёржа . Теперь достаточно указать дефолтное соединение с gRPC-балансировщиком, а Gateway сам подхватывает недостающие настройки. Если конфиг для конкретного сервиса пустой, он подставляет базовые параметры: ключи, таймауты, адреса — и спокойно ходит к балансировщику с готовыми данными. Это позволило заметно сократить размер конфигурации и сделать её человекочитаемой. Архитектура упростилась, а вместе с ней и процесс разработки. Всё стало прозрачнее, быстрее и предсказуемее. Мы также интегрировались с корпоративным PaaS-решением , которое коллеги из другой команды используют для централизованной работы с логами и трейсам. Раньше Gateway мешал полноценной интеграции: именно он был входной точкой для трейсов, а из-за ограничений старой версии Go мы не могли подключить нужные SDK. После обновления языка и переписывания Gateway мы наконец подтянули нужный пакет и успешно встали в общую систему мониторинга. И, наконец, мы избавились от CVE . История получилась показательной. Пока мы активно рефакторили Gateway, не спешили его выкатывать в релизы — и вовремя: через один релиз коллеги из ИБ сообщили, что найденные уязвимости в Go 1.19 получили критичный статус. Это означало риск блокировки релиза. К счастью, к тому моменту мы уже были готовы с новой версией Gateway и в следующий релиз ушли в прод именно с ним, полностью закрыв проблему. Такой вот получился тернистый, но очень полезный путь. Мы переписали Gateway почти с нуля, избавились от боли, старых зависимостей и хаоса в конфигах, а заодно укрепили связь между командами и"
            }
        ]
    },
    {
        "id": "q_0078",
        "question": "Какие проблемы удалось решить при переписывании Gateway?",
        "answers": [
            "При переписывании Gateway были устранены проблемы, связанные с болью, старыми зависимостями и хаосом в конфигурациях."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
                "text": "уже были готовы с новой версией Gateway и в следующий релиз ушли в прод именно с ним, полностью закрыв проблему. Такой вот получился тернистый, но очень полезный путь. Мы переписали Gateway почти с нуля, избавились от боли, старых зависимостей и хаоса в конфигах, а заодно укрепили связь между командами и встроились в экосистему компании гораздо плотнее. Если интересно узнать больше — пишите в комментариях, с удовольствием расскажу детали и подводные камни. А если вам близка тематика масштабных инфраструктурных решений, распределённых систем и высоконагруженных сервисов — заходите в наши вакансии . Будем рады пообщаться с теми, кто хочет строить такие же сложные и красивые системы вместе с нами."
            }
        ]
    },
    {
        "id": "q_0079",
        "question": "Какой планировщик задач в Unix-подобных системах позволяет автоматизировать рутинные задачи на Linux-сервере?",
        "answers": [
            "Для автоматизации рутинных задач на Linux-сервере используется планировщик cron, который работает как фоновый демон и запускает команды или скрипты по заданному расписанию."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
                "text": "Мы каждый день сталкиваемся со множеством однотипных задач. Постоянно возвращаясь к ним, мы расходуем самый ценный ресурс — время. В итоге застреваем в рутине, рискуем не уложиться в сроки и совершить ошибку. Но можно остановиться и передать повторяющуюся работу тому, кто не забудет и не промахнётся. Нас спасёт автоматизация! Сегодня расскажем о том, как автоматизировать рутинные задачи на Linux-сервере при помощи cron и немного с помощью скриптов. Cron — стандартный планировщик в Unix-подобных операционных системах. Он работает как фоновый демон: непрерывно следит за расписанием и в нужный момент запускает указанную команду или скрипт. Cron — от греческого «χρόνος» (chronos) — время. Он появился в Unix ещё в 1970-х и с тех пор не потерял своей значимости в администрировании систем. Cron запускает задачу с точностью до минуты. Его расписание может быть очень гибким: от «каждую минуту» до «один раз в год». Cron может иметь отдельные планы заданий для каждого пользователя системы, и после настройки он работает автономно и не требует вмешательства пользователя. По факту, любую повторяющуюся задачу, которую вы делаете вручную по расписанию, можно автоматизировать через cron. Любую на Linux. Почти любую. Для работы с cron используется утилита crontab, которая управляет таблицей заданий для текущего пользователя. В основных Linux-системах каждый пользователь может иметь собственный crontab, независимый от других. А может и не иметь, ведь crontab создаётся только тогда, когда пользователь впервые запускает команду: Данная команда открывает файл задач в текстовом редакторе, обычно это — vi или nano, и после сохранения cron сразу же подхватывает изменения без перезапуска сервиса. Задание в cron задаётся в следующем формате: Звёздочку (*) система воспринимает как любое значение, то есть задание будет выполняться при каждом значении соответствующего поля. Кроме звёздочки, поля в задании могут содержать: одно какое-либо число, например, 29 или 6; одно какое-либо число, например, 29 или 6; диапазон чисел, например, 1-4, то есть все значения от 1 до 4 включительно из диапазона, допустимого для данного поля; диапазон чисел, например, 1-4, то есть все значения от 1 до 4 включительно из диапазона, допустимого для данного поля; список чисел, например, 2,5,6; список чисел, например, 2,5,6; шаг, например, */5 означает каждые 5 единиц, начиная с минимального значения. шаг, например, */5 означает каждые 5 единиц, начиная с минимального значения. Здесь есть некоторые неочевидные для новичков тонкости. Например, дни недели могут принимать значения от 0 до 7. Не от одного, а от нуля. В итоге получается целых 8 значений, а дней недели — всего 7. Почему так? Потому что в cron два воскресенья — 0 и 7. Дело в том, что в старых его реализациях для воскресенья использовался 0, но чтобы упростить совместимость с ISO-стандартом, позже разрешили ещё и 7 для обозначения воскресного дня. Или, вот шаг. В нём число после знака / определяет, через сколько единиц значений будет выполняться задание, начиная с минимально допустимого в этом поле значения. Например, /10 для минут будет означать, что задание будет выполняться в минимально возможное количество минут, а затем каждые +10 пока не закончится нумерация минут в пределах часа. То есть, данная запись означает выполнение задания в 0, 10, 20, 30, 40 и 50 минут означенного часа. В отношении часов такая запись означает запуск задачи"
            }
        ]
    },
    {
        "id": "q_0080",
        "question": "Что означает запись 3/10 в поле для минут в cron?",
        "answers": [
            "Запись 3/10 означает, что задание будет выполняться в 3, 13, 23, 33, 43 и 53 минуты каждого часа."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
                "text": "минут будет означать, что задание будет выполняться в минимально возможное количество минут, а затем каждые +10 пока не закончится нумерация минут в пределах часа. То есть, данная запись означает выполнение задания в 0, 10, 20, 30, 40 и 50 минут означенного часа. В отношении часов такая запись означает запуск задачи в 0 (полночь), 10 и 20 часов означенных суток. Для дней месяца минимальным значением является 1 — первый день месяца. Это означает. что запись /10 в третьей слева позиции инициирует выполнение задачи в первый день месяца, а затем в каждый +10-й день, пока не закончится месяц — 11, 21 и 31-е число, при условии, что последнее значение присутствует в нумерации текущего месяца. Аналогично для месяцев: /10 означает 1-й и 11-й месяцы, то есть январь и ноябрь. Применительно к дням недели запись /10 не имеет практического смысла, так как диапазон значений здесь ограничен числами от 0 до 7, то есть всего восемь возможных значений. Таким образом, шаг 10 превышает длину диапазона, и задание будет выполняться только для минимального значения, то есть для 0 — воскресенья. Здесь важно понимать, что указанное в шаге число не означает каждые x единиц времени от последнего запуска или от текущего момента, а определяет выполнение задачи каждые x значений поля от его минимального значения. Это мы рассмотрели запись */10. А ведь можно вместо звёздочки использовать число, например, 3/10. Такая запись означает, что планировщик будет прибавлять 10, но уже не к минимальному значению, а к значению 3. То есть, для минут задание будет выполняться в 3, 13, 23, 33, 43, 53 минуты; для часов и чисел месяца — в 3, 13, 23; для месяцев и дней недели — только в 3 (март или среда). Для некоторых значений времени в cron существуют специальные директивы: @yearly или @annually означает один раз в год и заменяет собой комбинацию 0 0 1 1 * , то есть в 00:00 1 января каждого года; @yearly или @annually означает один раз в год и заменяет собой комбинацию 0 0 1 1 * , то есть в 00:00 1 января каждого года; @monthly — раз в месяц, заменяет комбинацию 0 0 1 * * , то есть в 00:00 первого числа каждого месяца; @monthly — раз в месяц, заменяет комбинацию 0 0 1 * * , то есть в 00:00 первого числа каждого месяца; @weekly — раз в неделю, заменяет комбинацию 0 0 * * 0 и означает каждое воскресенье в 00:00; @weekly — раз в неделю, заменяет комбинацию 0 0 * * 0 и означает каждое воскресенье в 00:00; @daily или @midnight — раз в день, заменяет комбинацию 0 0 * * * и означает в полночь каждый день; @daily или @midnight — раз в день, заменяет комбинацию 0 0 * * * и означает в полночь каждый день; @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). Есть ещё одна полезная директива — @reboot . Она позволяет выполнять указанную команду один раз при запуске системы. Полезность данной директивы заключается в том, что она не зависит от времени или дня и запускается только"
            }
        ]
    },
    {
        "id": "q_0081",
        "question": "Что означает слэш в конце пути каталога при использовании rsync для синхронизации данных?",
        "answers": [
            "Слэш в конце пути каталога означает, что копировать нужно только содержимое каталога, а не сам каталог. Например, при указании пути /important/data/ будет синхронизировано содержимое этой директории."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
                "text": "ноль и четыре звёздочки). @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). Есть ещё одна полезная директива — @reboot . Она позволяет выполнять указанную команду один раз при запуске системы. Полезность данной директивы заключается в том, что она не зависит от времени или дня и запускается только при перезагрузке или старте сервера. Ну если разобрались с форматом записи месяцев, дней, часов и минут, то в шестом поле указываем команду, которая должна выполняться в указанное время. Что можно использовать в качестве команды? Во-первых, любые shell-команды: ls , cp , rm и т.д. Во-вторых, скрипты: bash, python, php и т.п. В-третьих, исполняемые файлы. А также, цепочки команд с операторами &&, ||, ; и перенаправление вывода типа > , >> , 2>&1 . Из важных моментов можно отметить следующее: всегда используйте полные абсолютные пути к скриптам и файлам, в противном случае cron не всегда сможет их отыскать. И ещё — старайтесь логировать вывод. Поверьте, это пригождается чаще, чем хотелось бы. Основное назначение cron — делегирование системе задач, для выполнения которых можно использовать расписание, чтобы разгрузить администратора данной системы, оградив его от определённого количества рутинной работы. Давайте рассмотрим некоторые типы и примеры задач, решить которые может помочь cron. Обсуждение важности создания резервных копий чего бы то ни было, наверное, уже набило оскомину. И хотя cron и не является полноценным инструментом бэкапирования, но всё же с его помощью можно кое-что реализовать, поскольку расписание плюс копирование это и есть несложное решение для подобной задачи. Например: Такая строка в cron представляет собой пример ежедневного создания дампа базы данных MySQL или MariaDB с сохранением его в директории /backup/ под именем, частью которого будет текущая дата. Это, чтобы можно было понять, когда этот бэкап сделан. Ещё один пример — еженедельное создание tar-архива каталога /var/www/html/ , в котором, вероятно, находятся файлы веб-сайта. 0 в пятой позиции означает запуск команды каждое воскресенье, а имя архива, как и в предыдущем примере, будет содержать дату архивирования данных: Подобным же образом при помощи rsync — утилиты для быстрой и надёжной синхронизации файлов и каталогов, можно с определённой периодичностью копировать данные из одной Linux-системы в другую: Прелесть данной утилиты в том, что она копирует только изменённые данные, что позволяет экономить трафик и время. Конкретно в этой команде: /important/data/ — каталог, содержимое которого подлежит синхронизации с удалённым ресурсом. Обратите внимание на слэш в конце: он означает, что копировать нужно только содержимое каталога, а не сам каталог. /important/data/ — каталог, содержимое которого подлежит синхронизации с удалённым ресурсом. Обратите внимание на слэш в конце: он означает, что копировать нужно только содержимое каталога, а не сам каталог. remote-user@192.168.0.11:/backup/ — место назначения, где: remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. remote-user@192.168.0.11:/backup/ — место назначения, где: remote-user — это имя пользователя на удалённой системе; remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. На VPS всё"
            }
        ]
    },
    {
        "id": "q_0082",
        "question": "Какую команду и с какой опцией следует использовать для автоматического обновления SSL-сертификатов Let's Encrypt без вывода сообщений?",
        "answers": [
            "Для этого используется команда certbot renew с опцией --quiet, которая запускает процесс в «тихом» режиме."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
                "text": "на удалённой системе; remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. На VPS всё это особенно актуально: регулярные дампы, архивация и перенос данных между серверами — типичная практика. На виртуальных серверах UltraVDS , например, можно настроить такие задачи буквально за несколько минут. Это — ещё одно направление в администрировании Linux-систем, где использование планировщика является частью повседневности. При работе операционной системы, служб и приложений появляются и накапливаются временные файлы, которые создаются при установке, обновлении или обработке данных, и после выполнения своей задачи зачастую становятся бесполезными. Ниже — пример простенького скрипта, который удаляет из каталога /tmp файлы, не изменявшиеся больше семи дней: Такая запись в cron позволит запускать этот скрипт раз в сутки: Можно обойтись и без скрипта, записав команду удаления файлов сразу в cron: То же относится к логам — записям о событиях, ошибках и действиях системы. Логи полезны для диагностики, но со временем становятся слишком объёмными и могут занимать полезное пространство. Так может выглядеть задача по еженедельному удалению старых лог-файлов в директории /var/log. Здесь опция -mtime +30 говорит нам, что необходимо найти и удалить файлы старше тридцати дней: Или вот кэш — временное хранилище данных, которое призвано ускорить загрузку приложения, но по прошествии времени в нём накапливается много устаревших и ненужных данных. Пример ниже — ежедневное принудительное удаление содержимого кэш-директории условного приложения app: Планировщик cron в том числе можно использовать как простейший инструмент мониторинга системы. Например, так можно настроить периодическую отправку отчёта об использовании дискового пространства на электронную почту администратора: Правда, чтобы отправка писем действительно работала, сервер нужно заранее настроить — почтовая система должна понимать, куда и каким способом доставлять сообщения. Мониторинг используется не только как внимательный наблюдатель за состоянием сервисов и процессов. При помощи планировщика и несложного скрипта можно попытаться своевременно, или почти своевременно, поднять упавшую службу. Например, следующим образом каждые 10 минут cron проверяет, запущена ли служба Nginx, и если не запущена — перезапускает её: Классическая задача для cron — обновление бесплатного SSL-сертификата от Let's Encrypt с использованием Certbot. Как правило, такой сертификат выдаётся на 90 дней и перед истечением данного срока его нужно обновить, чтобы сайт продолжал быть доступным через HTTPS. Certbot — это утилита, которая позволяет автоматизировать процесс получения и продления SSL-сертификата от Let's Encrypt. Для проверки срока действия сертификата и его обновления в Certbot используется cron. Официальная документация Let's Encrypt рекомендует запускать проверку дважды в день, что должно гарантировать обновление сертификата даже при временном отсутствии интернета. Здесь: certbot renew — команда, которая пытается обновить SSL-сертификаты Let’s Encrypt, срок которых подходит к концу; certbot renew — команда, которая пытается обновить SSL-сертификаты Let’s Encrypt, срок которых подходит к концу; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. --deploy-hook — команда,"
            }
        ]
    },
    {
        "id": "q_0083",
        "question": "Какой командой можно просмотреть все запланированные задания cron для текущего пользователя?",
        "answers": [
            "Для просмотра всех запланированных заданий cron для текущего пользователя используется команда crontab -l."
        ],
        "ground_truth_docs": [
            {
                "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
                "text": "запуск команд в «тихом» режиме, то есть без вывода сообщений; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. Ещё один популярный сценарий для cron — автоматическая обработка данных. Например, регулярная генерация разных отчётов без вашего участия. Вместо ежедневной или еженедельной ручной сборки данных можно создать скрипт, который будет выполнять такую задачу, и автоматизировать процесс при помощи расписания. Примером могут послужить ежедневные отчёты, которые необходимо собирать в нерабочее время — до начала или, наоборот, после окончания рабочего дня. Сюда же можно отнести различную периодическую аналитику или статистику за определённый регулярно повторяющийся период. Такой отчёт, как правило, сохраняется в файл для последующей отправки на email, загрузки на файлообменник или ещё куда-либо. Python-скрипт, допустим, собирает данные из SQLite: Потом формирует текстовый отчёт и отправляет его на электронную почту: Запуск задачи поручаем cron — в 8 утра каждый понедельник: Кроме команды crontab -e , упомянутой в самом начале, при работе с планировщиком будут полезны инструменты командной строки, как, например, просмотр текущих задач: Команда выводит список всех запланированных заданий для текущего пользователя. Удобно, например, для того, чтобы убедиться в корректном добавлении задачи. Для удаления всех заданий запускаем: Команда полностью очищает crontab текущего пользователя. Поэтому используйте её осторожно, при выполнении команды не выводится никаких подтверждений. Команда для просмотра логов cron выглядит как: Вывод показывает записи о событиях при запуске задач cron. Потратив немного времени на настройку и проверку заданий для планировщика, мы получаем отличный бонус — больше не нужно вручную выполнять однообразные задачи и переживать, что что-то пойдёт не так. Теперь всё происходит по расписанию и без лишних нервов. Так мы постепенно переключаемся с вечного «тушения пожаров» на спокойное, продуманное управление. А своё время наконец можно потратить на то, что действительно требует человеческих мозгов или творчества."
            }
        ]
    },
    {
        "id": "q_0084",
        "question": "Какой алгоритм позволяет эффективно находить наибольшую общую подпоследовательность для двух и трёх последовательностей?",
        "answers": [
            "Для эффективного нахождения наибольшей общей подпоследовательности используется алгоритм LCS, основанный на динамическом программировании, который позволяет избежать медленного перебора."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
                "text": "Что такое наибольшая общая подпоследовательность и как её находить? Почему простой перебор работает медленно и как ускорить решение с помощью динамического программирования? Как устроен алгоритм LCS для двух и трёх последовательностей и как реализовать его эффективно?"
            }
        ]
    },
    {
        "id": "q_0085",
        "question": "Какие практические применения имеет задача нахождения наибольшей общей подпоследовательности?",
        "answers": [
            "Задача применяется в сопоставлении данных (утилита diff, операции слияния в системах управления версиями), в биоинформатике для поиска сходств в генах разных видов, а также в проверке орфографии."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
                "text": "Мы имеем две последовательностии, их общая подпоследовательность длиной— это набориндексов при котором Наибольшая общая подпоследовательность — общая подпоследовательность, которая обладает наибольшей длиной из всех подпоследовательностей. Такая задача может применяться, например:— в сопоставлении данных — утилита diff, операция слияния в разных системах управления версиями;— в биоинформатике — поиск сходств в генах разных видов;— в проверке орфографии. Входные данные:Первая строка: количество элементов первой подпоследовательности. Вторая строка:. Третья строка: количество элементов второй подпоследовательности. Четвёртая строка:. Выходные данные:. Ограничения:;для всех. Общая подпоследовательность длиной 2 — это. У двух последовательностей нет общих элементов. Одна общая подпоследовательность —. Ещё одна —. Рассмотрим наибольшую общую подпоследовательность, определённую индексамии(так, для каждого,):— Последние символыиприводятся в. В этом случаеи. Тогда— это наибольшая общая подпоследовательность оти.— Как минимум один из последних символовине приводится в. В этом случае или, или. Тогданаходится полностью вили. Таким образом, мы сводим задачу с изначальными строкамиидо такой же задачи с их префиксами. Пусть— длина наибольшей общей подпоследовательностии. Выходит, что эта функция удовлетворяет следующее рекуррентное соотношение: Базовый случай для этого рекуррентного соотношения —или: Полученный алгоритм приведён ниже. Его время выполнения составляет. Скопировать код1LCS(A[1…n],B[1…m]):2table =2d array ofsize(n+1)×(m+1)3table[i][0] =0andtable[0][j] =0forall i,j4fori from1to n:5forj from1to m:6table[i][j] = table[i−1][j]7table[i][j] =max(table[i][j], table[i][j−1])8ifA[i]=B[j]:9table[i][j] =max(table[i][j], table[i−1][j−1]+1)10returntable[n][m] Так задача «Наибольшая общая подпоследовательность» — всего лишь задача «Редакционное расстояние», в которой запрещены операции «замены»."
            }
        ]
    },
    {
        "id": "q_0086",
        "question": "Каков базовый случай для вычисления максимальной длины общей подпоследовательности трёх последовательностей?",
        "answers": [
            "Базовый случай возникает, когда хотя бы одна из трёх последовательностей пуста — в этом случае максимальная длина общей подпоследовательности равна нулю."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
                "text": "Имея три последовательности:,и— нужно найти длину наибольшей общей подпоследовательности для них, то есть наибольшее неотрицательное целое число, при котором существуют индексы при котором Входные данные: Первая строка:. Вторая строка:. Третья строка:. Четвёртая строка:. Пятая строка:. Шестая строка:. Выходные данные:. Ограничения:;. Общая подпоследовательность длиной 2 — это. В этом случае одна общая подпоследовательность длиной 3 — это. Ещё одна —. Пусть— это максимальная длина общей подпоследовательности от,и. Тогда Базовый случай: Время выполнения соответствующего алгоритма составляет."
            }
        ]
    },
    {
        "id": "q_0087",
        "question": "Какой алгоритм используется для эффективного решения задачи поиска самой длинной общей подпоследовательности строк?",
        "answers": [
            "Для решения задачи поиска самой длинной общей подпоследовательности используется алгоритм динамического программирования, который позволяет избежать экспоненциальной сложности полного перебора."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
                "text": "Теперь вы умеете находить наибольшую общую подпоследовательность двух или трёх строк с помощью алгоритма динамического программирования. Вы увидели, как рекурсивные зависимости помогают выразить решение через подзадачи, и научились реализовывать алгоритм так, чтобы он был быстрым и устойчивым на практике. Далее — задача о рюкзаке. Вы узнаете, как использовать похожие техники динамики, чтобы выбирать оптимальное подмножество предметов с максимальной суммарной ценностью при ограниченном объёме. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. LCS — это задача поиска самой длинной общей подпоследовательности двух или трёх строк. Полный перебор всех подпоследовательностей даёт экспоненциальную сложность, но динамическое программирование решает задачу заили. Решение строится на сравнении последних символов и рекурсивном переходе к префиксам строк. Алгоритм можно реализовать итеративно с таблицей и дополнительно восстановить саму подпоследовательность."
            }
        ]
    },
    {
        "id": "q_0088",
        "question": "Какие существуют методы для вычисления чисел последовательности, где каждое следующее число равно сумме двух предыдущих?",
        "answers": [
            "В тексте описаны различные способы вычисления чисел Фибоначчи, хотя конкретные методы не перечислены подробно. Также упоминается, что при вычислениях важно учитывать время выполнения, типы данных и возможность переполнения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Как устроены числа Фибоначчи и какие есть способы их вычисления? Почему важно учитывать время выполнения, типы данных и переполнение даже в простых задачах? Что такое период Пизано и как он помогает находить остатки от огромных чисел Фибоначчи?"
            }
        ]
    },
    {
        "id": "q_0089",
        "question": "Какой результат выведет код print(fibonacci(7)) при использовании рекурсивной реализации с выводом отладочных сообщений?",
        "answers": [
            "Код выведет число 13, а также серию отладочных сообщений о рекурсивных вычислениях чисел Фибоначчи."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Прежде чем начать, коротко напомним, что числа Фибоначчи — числовой ряд, при котором каждое последующее число равно сумме двух предыдущих. Такие числа определяются рекурсивно: Это приводит к следующему рекурсивному алгоритму: Скопировать код1Fibonacci(n):2ifn <=1:3returnn4else:5returnFibonacci(n−2)+Fibonacci(n−1) Рассмотрим совсем простую задачу. Входные данные: Целое число. Выходные данные:. Ограничения:. Примеры Ниже мы описываем простую реализацию рекурсивного псевдокода дляPython. В неё входит инструкция по обнаружению багов, которая выводит то, что вычисляется в данный момент. Мы пробуем вычислитьс помощью этого кода. Скопировать код1deffibonacci(n):2ifn <=1:3returnn4else:5print(f'Computing F{n}recursively...')6returnfibonacci(n -2) + fibonacci(n -1)789print(fibonacci(7)) Скопировать код1Computing F7 recursively...2Computing F5 recursively...3Computing F3 recursively...4Computing F2 recursively...5Computing F4 recursively...6Computing F2 recursively...7Computing F3 recursively...8Computing F2 recursively...9Computing F6 recursively...10Computing F4 recursively...11Computing F2 recursively...12Computing F3 recursively...13Computing F2 recursively...14Computing F5 recursively...15Computing F3 recursively...16Computing F2 recursively...17Computing F4 recursively...18Computing F2 recursively...19Computing F3 recursively...20Computing F2 recursively...2113 Как видите, код даёт нам верный результат (), но многие вычисления повторяются. Если вы решите вычислитьс помощью этого кода, то Солнце потухнет раньше, чем компьютер выдаст вам результат. Скорее всего вы бы взяли лист бумаги и написали что-то вроде: Вполне разумно попросить компьютер вычислитьтаким жеитерационнымспособом: Скопировать код1Fibonacci(n):2ifn <=1:3returnn4allocate an array F[0..n]5F[0] =06F[1] =17fori from2to n:8F[i] = F[i −2] + F[i −1]9returnF[n] Приблизительное количество операций, необходимых алгоритму, —. Этот алгоритм хорошо работает на практике. Как вы могли заметить, нет необходимости хранить все числа последовательности Фибоначчи: чтобы вычислить текущее число, достаточно знать два предыдущих. Скопировать код1Fibonacci(n):2ifn <=1:3returnn4previous =05current =16foriter inrange(n-1):7oldPrevious = previous8previous = current9current = oldPevious + previous10returncurrent Рекурсивный алгоритм требует так много времени, потому что он повторяет множество одинаковых вычислений: напримерFibonacci(7)вызываетFibonacci(3)пять раз. Не проще ли сохранить, как только это значение вычислено, и при необходимости использовать сохранённое значение вместо того, чтобы вычислять его с нуля? Такой простой подход называется «мемоизация» — при вычислении чего-либо сохраните это в структуре данных, чтобы избежать повторных вычислений в будущем. Давайте добавим мемоизацию в рекурсивный алгоритм, чтобы сделать его практичнее. Скопировать код1table — некоторый ассоциативный контейнер (в table[i] будем сохранять F[i])23Fibonacci(n):4iftable[n] ещё не вычисляли:5ifn <=1:6table[n] = n7else:8table[n] =Fibonacci(n−2)+Fibonacci(n−1)9returntable[n] По сравнению с изначальным рекурсивным алгоритмом этот сделает максимум«серьёзных» рекурсивных вызовов: для каждогопервый вызовFibonacci(i)вычисляет, сохраняя в; затем все дальнейшие вызовыFibonacci(i)становятся просто поиском по таблице."
            }
        ]
    },
    {
        "id": "q_0090",
        "question": "Какой подход рекомендуется для вычисления последней цифры чисел Фибоначчи, чтобы избежать целочисленного переполнения и ускорить вычисления?",
        "answers": [
            "Вместо вычисления полных чисел Фибоначчи и взятия последней цифры от результата рекомендуется брать каждое промежуточное значение по модулю 10. Это гарантирует, что числа останутся маленькими и поместятся в стандартные типы данных, а операции будут выполняться быстро."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Формат ввода: Целое число. Формат вывода: Последняя цифра. Ограничения:. Примеры Для решения этой задачи мы вычислими просто выведем последнюю цифру последовательности: Скопировать код1FibonacciLastDigit(n):2ifn <=1:3returnn4F[0..n] — массив для промежуточных значений5F[0] =06F[1] =17fori from2to n:8F[i] = F[i −1] + F[i −2]9returnF[n] mod10 Таким образом, если вы используете типы C++int32илиint64для хранения, вы быстро придёте к целочисленному переполнению. Если вы используете числа произвольной точности, например,BigIntegerв Java или встроенные целые числа в Python, то вы заметите, что цикл проходит намного медленнее при повышающемся числе итераций. Несложно увидеть, что последняя цифра вравна, и она полностью определена последними цифрами ви. Это подсказывает нам, как сделать алгоритм практичнее: вместо вычисленияи использования последней цифры можно взять каждое промежуточное звено по модулю 10. Главный посыл этой задачи: когда вам нужно вычислить результат последовательности арифметических операций по модулю, берите результат каждой операции по модулю. Так можно гарантировать, что числа, с которыми вы работаете, будут маленькими (они уместятся в стандартный тип языка программирования, который вы предпочитаете) и что арифметические операции с ними будут выполняться быстро. Скопировать код1FibonacciLastDigit(n):2ifn <=1:3returnn4F[0..n] — массив для промежуточных значений5F[0] =06F[1] =17fori from2to n:8F[i] = (F[i −1] + F[i −2]) mod109returnF[n]"
            }
        ]
    },
    {
        "id": "q_0091",
        "question": "Какой алгоритм используется для вычисления n-го числа Фибоначчи по модулю m с использованием матричного возведения в степень?",
        "answers": [
            "Алгоритм использует быстрое возведение в степень матрицы M = [[0,1], [1,1]] в степень n по модулю m. Искомое значение F(n) mod m находится как элемент P[0][1] результата возведения матрицы в степень."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Формат ввода:Целые числаи. Формат вывода:. Ограничения:,. Примеры Предупреждение: . . содержит миллионы цифр, но. В этой задачеможет быть настолько большим, что алгоритму потребуется слишком много времени, чтобы пройти через все числа Фибоначчидляотдо. Чтобы понять, как решить эту задачу, не проходя через все числа, взгляните на таблицу ниже: Обе эти последовательности — периодические! Период для—. Его длина —. Дляпериод будет, и его длина —. В итоге, чтобы вычислить, например,, нам понадобится найти остальную частьпри делении на. Так как, мы можем заключить, что. Оказывается, что для любого целого числапоследовательностьбудет периодической. Период всегда начинается с. Он называется «период Пизано» (Фибоначчи также называют «Пизано»). Каким будет период? Докажите, что для каждого числапоследовательностьбудет периодической. Докажите, что период последовательностине превышает. Таблица ниже демонстрирует, что последовательность— периодическая. Последние цифры повторяются по периоду Пизано длиной. Другими словами: Например: Чтобы доказать, что последние цифры чисел Фибоначчи периодические, обратите внимание на пары остатков по модулю, следующих друг за другом чисел Фибоначчи: Каждую из колонок таблицы можно вычислить на основе предыдущей колонки как . По такой же логике колонка перед колонкой будет . Следовательно, для любой колонки в таблице выше можно однозначно определить соседей слева и справа. А значит, из любой позиции можно заполнить всю таблицу. Поскольку остатков по модулютолько, есть тольковозможных пар остатков, то есть максимумвозможных колонок. Таким образом, некоторые колонки в таблице повторяются и будут это делать до бесконечности. Докажите, что первая повторяющаяся колонка таблицы длябудет Это наводит нас на следующий простой псевдокод, который рассчитывает период Пизанодля произвольного остатка по модулю. Скопировать код1PisanoPeriod(m):2current =03next =14period =05whileTrue:6oldNext = next7next = (current + next) mod m8current = oldNext9period = period +110ifcurrent =0andnext =1:11returnperiod Объединяя изложенные идеи, получаем приемлемое по скорости работы решение. Ещё один способ вычислить— обратить внимание на то, что уравнения могут быть представлены как умножение матрицы—— и вектора: Следовательно: Поэтому— просто элемент справа вверху-й степени матрицы. Мы продемонстрируем быстрое возведение в степень с помощью целых чисел вместо матриц. Имея целое число, можно было бы примитивно вычислить, используя умножение 8 раз. Однако есть и более быстрый способ вычислить, используя умножение лишь 4 раза: В целом, при чётномвычислениепотребует выполнить умножение лишь еще один раз по сравнению с, так как. Если— нечетное, то вычислениепотребует выполнить умножение лишь ещё два раза — по сравнению с, так как. Скопировать код1FastIntegerExponentiation(x, n):2ifn =0:3return14ifn %2==0: # чётное значение5y =FastIntegerExponentiation(x, n/2)6returny * y7else: # нечётное значение8y =FastIntegerExponentiation(x, (n−1)/2)9returny * y * x Поскольку каждый рекурсивный вызовFastIntegerExponentiationприводит к двум операциям умножения целых чисел и разделяетпополам, он выполнит максимумопераций умножения. Скопировать код1FastMatrixExponentiation(D, n, m):2ifn =0:3return[[1,0], [0,1]] # единичная2×2матрица4ifn %2==0: # чётное значение5Y =FastMatrixExponentiation(D, n/2, m)6returnMultiply2x2Matrices(Y, Y, m)7else:8Y =FastMatrixExponentiation(D, (n−1)/2, m)9Y2 =Multiply2x2Matrices(Y, Y, m)10returnMultiply2x2Matrices(Y2, D, m) Скопировать код1Multiply2x2Matrices(A, B, m):2C[1][1] = (A[1][1]*B[1][1] + A[1][2]*B[2][1]) mod m3C[1][2] = (A[1][1]*B[1][2] + A[1][2]*B[2][2]) mod m4C[2][1] = (A[2][1]*B[1][1] + A[2][2]*B[2][1]) mod m5C[2][2] = (A[2][1]*B[1][2] + A[2][2]*B[2][2]) mod m6returnC Наконец, вычисление нужного значения выглядит следующим образом: Скопировать код1FibonacciModuloM(n, m):2M = [[0,1], [1,1]]3P =FastMatrixExponentiation(M, n, m)4returnP[0][1]"
            }
        ]
    },
    {
        "id": "q_0092",
        "question": "Как можно быстро найти последнюю цифру в последовательности, используя период Пизано?",
        "answers": [
            "Используя период Пизано по модулю 10, можно быстро найти последнюю цифру, так как последовательность остатков повторяется с определённым периодом."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Формат ввода: Целое число. Формат вывода:. Ограничения:. Примеры Подсказка.Раз исчерпывающий поиск будет слишком медленным для этой задачи, попробуйте придумать формулу для. Для лучшего понимания поиграйте с маленькими значениями. Затем используйте решение для предыдущей задачи. В таблице ниже указаны первые одиннадцать чисел Фибоначчи и первые одиннадцать чисел. Похоже, что. Давайте докажем это по индукции. Это условие определённо выполняется для первого шага (), так как. Для шага с индукцией предположим, что утверждение верно для, и докажем его для: Ещё один способ прийти к формуле— сложить равенства. Так как элементы в правых частях взаимоуничтожаются, то сумма всех элементов справа —, а сумма всех элементов слева будет, Так задача сводится к тому, чтобы найти последнюю цифру в. Благодаря предыдущей задаче мы знаем, как можно быстро это сделать: исходя из того, что период Пизано по модулюравен, мы имеем"
            }
        ]
    },
    {
        "id": "q_0093",
        "question": "Как можно вычислить сумму частичной суммы чисел Фибоначчи?",
        "answers": [
            "Сумма частичной суммы чисел Фибоначчи равна разнице между двумя частичными суммами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Формат ввода: Целые числаи. Формат вывода:. Ограничения:. Примеры Сумма частичной суммы чисел Фибоначчи равна разнице между двумя частичными суммами: Более обобщённо, Благодаря предыдущей задаче мы знаем, как быстро вычислять префиксные, то есть первые элементы последовательности, суммы."
            }
        ]
    },
    {
        "id": "q_0094",
        "question": "Какую геометрическую интерпретацию предлагает текст для вычисления суммы определённого вида?",
        "answers": [
            "Сумма представляется как площадь прямоугольника, где одно ребро вертикальное, а другое — горизонтальное."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Формат ввода: Целое число. Формат вывода:. Ограничения:. Примеры . . Подсказка.Раз алгоритм исчерпывающего поиска будет слишком медленным для этой задачи (может доходить до), нам нужно найти простую формулу для. Рисунок выше представляет суммукак площадь прямоугольника с вертикальным реброми горизонтальным ребром. Рисунок выше подсказывает, что для каждого неотрицательного целого числа Мы докажем это по индукции. Для двух первых случаевиполучается: Для шага с индукцией предположим, что. Так, В итоге остаётся вычислить последние цифрыи."
            }
        ]
    },
    {
        "id": "q_0095",
        "question": "Какие методы вычисления чисел Фибоначчи упоминаются в тексте?",
        "answers": [
            "В тексте упоминаются наивная рекурсия, оптимизированные алгоритмы с мемоизацией, итерационный метод и вычисление с быстрым модулем."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
                "text": "Теперь вы умеете вычислять числа Фибоначчи разными способами: от наивной рекурсии до оптимизированных алгоритмов с мемоизацией, итерацией и быстрым модулем. Вы познакомились с понятием периода Пизано и научились искать остатки от огромных чисел — быстро и точно. Далее — задачи на наибольший общий делитель и наименьшее общее кратное. Вы познакомитесь с алгоритмом Евклида, поймёте, почему он работает, и научитесь использовать его для ускорения решения задач с делением. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Числа Фибоначчи можно вычислять по-разному — от наивной рекурсии до оптимизированных итерационных алгоритмов. Важно уметь оценивать эффективность решений: простые на вид алгоритмы могут работать слишком долго. Мемоизация и вычисление по модулю позволяют ускорить программу и избежать переполнения. Даже в знакомых задачах важно думать об ограничениях, типах данных и тестах на больших входах."
            }
        ]
    },
    {
        "id": "q_0096",
        "question": "Какие основные виды графов существуют и в чём их ключевое отличие?",
        "answers": [
            "Основные виды графов — ориентированные и неориентированные. В ориентированных графах рёбра имеют направление (стрелки), показывающее одностороннюю связь между вершинами, а в неориентированных графах рёбра не имеют направления и обозначают двустороннюю связь."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/priroda-grafa",
                "text": "Что такое граф и где он применяется в жизни и программировании? Какие виды графов существуют и чем они отличаются? Какие свойства графа важно учитывать при решении задач?"
            }
        ]
    },
    {
        "id": "q_0097",
        "question": "Какие разновидности графов существуют?",
        "answers": [
            "Графы бывают ориентированные, неориентированные, взвешенные, полные, а также деревья и другие виды."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/priroda-grafa",
                "text": "Теперь вы понимаете, как устроены графы и почему они важны для алгоритмов. Вы узнали, что графы могут описывать карты, деревья, схемы и связи между объектами, а также познакомились с их разновидностями и свойствами. Далее — узнаем, как хранить граф в памяти компьютера. Разберёмся с матрицами и списками, сравним их по эффективности и применимости к разным задачам. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Граф состоит из вершин и рёбер, которые задают структуру связей между объектами. Графы бывают ориентированные, неориентированные, взвешенные, полные, деревья и другие. Важные свойства графов: связность, степень вершин, наличие циклов, двудольность. Графы широко применяются — от транспортных схем до анализа социальных сетей."
            }
        ]
    },
    {
        "id": "q_0098",
        "question": "Какие основные вопросы рассматриваются при изучении динамического программирования?",
        "answers": [
            "Рассматриваются принцип работы динамического программирования, его назначение, методы разбиения задачи на подзадачи с переиспользованием решений, а также критерии выбора между универсальными и частными алгоритмами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dinamicheskoe-programmirovanie",
                "text": "Как работает динамическое программирование и зачем оно нужно? Как разбивать задачу на подзадачи и переиспользовать решения? Когда стоит выбрать универсальный алгоритм, а когда — частный и быстрый?"
            }
        ]
    },
    {
        "id": "q_0099",
        "question": "Какие ходы может сделать игрок в игре «Камни», если в каждом из двух наборов находится по десять камней?",
        "answers": [
            "Игрок может взять один камень из любого набора или два камня — по одному из каждого набора. После этого взятые камни выходят из игры."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dinamicheskoe-programmirovanie",
                "text": "Некоторые алгоритмы разбивают задачу на более мелкие подзадачи и используют решения подзадач, чтобы собрать решение для главной. Во время этого процесса количество подзадач может стать очень большим, и некоторые алгоритмы решают одну и ту же подзадачу многократно, что чрезмерно увеличивает время выполнения. Динамическое программирование упорядочивает вычисления и позволяет не вычислять уже известные значения повторно. Зачастую это экономит массу времени. Задача со звонящим телефоном не подразумевает решения с помощью динамического программирования, поэтому мы рассмотрим другую. Представьте, что вместо ответа на звонок вы решаете поиграть в «Камни»: игру для двух игроков с двумя наборами камней по десять штук. С каждым ходом один игрок может взять один камень (из любого набора) или два камня (по одному из обоих). Когда камень забрали, он выходит из игры. Побеждает игрок, который заберет последний камень. Первый ход за вами. Чтобы найти стратегию для выигрыша в игре на, мы можем составить таблицу, которую мы назовем(рис.). Вместо того, чтобы решать задачу скамнями в каждом из наборов, мы решим более общую задачу скамней в одном наборе икамней в другом (игра на), гдеи— это произвольные целые неотрицательные числа. Если игрок 1 может гарантированно выигрывать игру на, тогда мы будем говорить, что. Если у игрока 1 нет стратегии для выигрыша против игрока, который всегда делает правильные ходы, мы будем писать. Вычислениедля произвольныхиможет звучать сложно, но мы воспользуемся результатами вычислений для меньших значений. Некоторые варианты игры, — в особенности,и, — явно приведут к победе игрока 1, так как игрок 1 может выиграть первым ходом. Таким образом, мы заполняем ячейки,икак.рис. (a) Заполнив ячейки,и, можно попробовать заполнить другие. Например, в случае сединственный ход, который может сделать игрок 1, приводит к— это выигрышный вариант для оппонента. Аналогичный анализ применим к случаю, что приводит к таблице из рис.рис. (b). В случаеигрок 1 может сделать три разных хода, которые приведут к,исоответственно. Один из этих случаев,, приводит к проигрышной позиции оппонента. Соответственно,— это выигрышная позиция. Случаиисимметричны, поэтому мы получаем таблицу из рис.рис. (c). Теперь мы можем заполнить. В случаеигрок 1 может сделать три разных хода, которые приведут к ячейкам,и. Эти ячейки — выигрышные позиции для оппонента. Так,: см рис.рис. (d). Мы можем продолжить заполнять, обращая внимание на то, что ячейкабудет, если ячейки сверху, слева и слева по диагонали будут. Эти ячейки (,и) соответствуют трем ходам, которые может сделать игрок 1. См. рис.рис. (e) АлгоритмRocksопределяет, выиграет игрок 1 или нет. Если игрок 1 выигрывает, тоRocksвыдаст. Если игрок 1 проигрывает, тоRocksвыдаст. Мы ввели искусственное начальное условие,, чтобы упростить псевдокод. Скопировать код1Rocks(n, m):2R(0,0) = L3fori from1to n:4ifR(i-1,0) = W:5R(i,0) = L6else:7R(i,0) = W8forj from1to m:9ifR(0,j-1) = W:10R(0,j) = L11else:12R(0,j) = W13fori from1to n:14forj from1to m:15ifR(i-1,j-1)=WandR(i,j-1)=WandR(i-1,j)=W:16R(i,j) = L17else:18R(i,j) = W19returnR(n,m) Более быстрый алгоритм для решения этой головоломки опирается на простую закономерность ви проверяет, чётныеиили нет. Если оба числа чётные, то игрок проигрывает (см. таблицу выше). Скопировать код1FastRocks(n, m):2ifn %2==0andm %2==0:// оба числа чётные3returnL4else:5returnW Тем не менее, хотяFastRocksи эффективнее, чемRocks, изменить его для схожих вариантов игры может быть сложно. Например, вариант, в котором игрок может убирать до трёх камней из наборов. Перед нами пример того, как более медленный алгоритм может быть полезнее, чем быстрый."
            }
        ]
    },
    {
        "id": "q_0100",
        "question": "Какие преимущества даёт использование динамического программирования при решении задач?",
        "answers": [
            "Динамическое программирование ускоряет решение задач за счёт переиспользования уже найденных ответов. Вместо пересчёта сохраняются найденные решения для повторного использования, что особенно полезно при множестве пересекающихся подзадач."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dinamicheskoe-programmirovanie",
                "text": "Теперь вы знаете, как динамическое программирование помогает ускорять решение задач за счёт переиспользования уже найденных ответов. Вы научились формулировать подзадачи, заполнять таблицы и избегать лишних вычислений. Далее — рекурсивные алгоритмы. Мы разберём, как строить решение через самого себя, почему рекурсия бывает полезной и когда она может привести к проблемам. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Динамическое программирование позволяет решать задачи быстрее за счёт повторного использования подзадач. Вместо того чтобы пересчитывать, мы сохраняем уже найденные решения и используем их повторно. Метод особенно полезен, когда подзадачи пересекаются и их много. Иногда универсальный, но медленный алгоритм оказывается практичнее, чем быстрый, но узкоспециализированный."
            }
        ]
    },
    {
        "id": "q_0101",
        "question": "Какие основные операции можно выполнять со словарём и какова их асимптотическая сложность при реализации на хеш-таблицах?",
        "answers": [
            "Основные операции со словарём включают добавление нового элемента с уникальным ключом, удаление элемента по ключу, изменение значения по ключу и получение значения по ключу. При реализации на хеш-таблицах все эти операции имеют асимптотическую сложность O(1)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/slovar",
                "text": "Следующей структурой данных, которую мы рассмотрим, будет словарь (map, dictionary), или так называемый ассоциативный массив, позволяющий хранить пары вида «ключ — значение». Ключ — уникальный идентификатор, а значение может быть любой объектной переменной, включая другие структуры данных. Например, списки или другие словари. Ключи и значения могут выводиться в различном порядке, потому что словари не упорядочены. Аналогично множеству, у словаря существует мультисловарь (multimap), который позволяет хранить несколько элементов с одинаковым ключом. Посмотрите на примеры ниже. Довольно часто словари реализуют с использованием хеш-таблиц. Говоря об асимптотической сложности операций со словарём, будем иметь ввиду реализацию на хеш-таблицах. Основные операции со словарем и их асимптотическая сложность: Добавление нового элемента с уникальным ключом —. Удаление элемента по ключу —. Изменение значения по ключу —. Получение значения по ключу —."
            }
        ]
    },
    {
        "id": "q_0102",
        "question": "Какие операции со словарём выполняются за константное время при реализации через хеш-таблицу?",
        "answers": [
            "При реализации через хеш-таблицу большинство операций со словарём — добавление, удаление и поиск — выполняются за константное время."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/slovar",
                "text": "Теперь вы знаете, как устроен словарь, и умеете использовать его для хранения данных, связанных с уникальными ключами, и быстрого поиска по этим ключам. Вы познакомились с операциями вставки, удаления, изменения и извлечения значений. Следующий шаг — дек (двусторонняя очередь). В отличие от обычной очереди, здесь можно добавлять и удалять элементы как с начала, так и с конца. Вы увидите, как дек сочетает свойства очереди и стека и где именно такая гибкость оказывается особенно полезной. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Словарь хранит пары «ключ — значение» и обеспечивает быстрый доступ по ключу. Большинство операций (добавление, удаление, поиск) выполняются за константное время при реализации через хеш-таблицу. Словари часто используют для подсчёта, группировки и хранения вложенных структур. Мультимапы позволяют хранить несколько значений для одного ключа."
            }
        ]
    },
    {
        "id": "q_0103",
        "question": "Каковы основные шаги жадного алгоритма при решении задачи размена монет?",
        "answers": [
            "Жадный алгоритм для размена монет последовательно выбирает наибольшую доступную монету, которая не превышает оставшуюся сумму, и вычитает её значение. Этот процесс повторяется до тех пор, пока вся сумма не будет разменена или пока не останется возможности использовать доступные номиналы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen",
                "text": "Как работает жадный алгоритм в задаче про размен монет и чем он отличается от полного перебора? Почему важно обосновывать правильность жадных решений и как это сделать?"
            }
        ]
    },
    {
        "id": "q_0104",
        "question": "Какой алгоритм используется для выдачи сдачи с минимальным количеством монет при наличии номиналов 1, 5 и 10?",
        "answers": [
            "Используется жадный алгоритм, который на каждом шаге выбирает монету с наибольшим номиналом, не превышающим оставшуюся сумму. Алгоритм работает в цикле, пока сдача положительна, последовательно вычитая номиналы 10, 5 или 1 и подсчитывая количество монет."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen",
                "text": "Давайте реализуем простой жадный алгоритм, которым пользуются кассиры по всему миру. Предположим, что у кассира есть бесконечное количество монет всех номиналов. Входные данные: Целое число. Выходные данные: Минимальное количество монет номиналами,,, чтобы выдать сдачу. Ограничения:. . . Ограничение по времени (с): 1 секунда. Ограничение по памяти: 512 Mb. Рассмотрим основную идею решения. Пока сдача положительна, мы выбираем монету с самым большим номиналом, не превышающем, отнимаем значение номинала выбранной монеты оти увеличиваем количество монет: Скопировать код1Change(money):2numCoins =03whilemoney >0:4ifmoney >=10:5money = money −106elseifmoney >=5:7money = money −58else:9money = money −110numCoins = numCoins +111returnnumCoins Также эту задачу можно решить в одну строку: Скопировать код1returnfloor(money/10) +floor((money mod10)/5) + (money mod5) Проектировать жадные алгоритмы просто, но вот доказывать их правильность — нередко сложная задача. И возможно, вас интересует, почему мы тратим время, чтобы доказать работоспособность очевидного алгоритмаChange. Дождитесь, пока мы попадем в алгоритмическую ловушку, и она убедит вас, что доказательство ниже — не трата времени. Чтобы доказать, что этот жадный алгоритм работает правильно, мы покажем, что выбор монеты с самым большим номиналом соответствует некому оптимальному решению. То есть нам нужно доказать, что для каждого положительного целого числасуществует оптимальный способ выдать сдачу с, который использует как минимум одну монету с номиналом, где— самое большое число из, не превышающее. Чтобы доказать это, мы рассмотрим несколько примеров. В каждом из примеров мы выбираем оптимальное решение (то есть конкретную сдачу с) и преобразовываем его так, что количество монет не увеличивается и содержит как минимум одну монету с номиналом. Мы также получаемспособ выдать сдачу с, который содержит монету, если начинаем сподхода к сдаче. . В этом случае, и единственный способ выдать сдачу с— это использоватьмонет номиналом 1. . В таком случае. Безусловно, любая сдача с money будет состоять только из монет с номиналами 1 и 5. Если в неё не входит монета с номиналом 5, то входят как минимум пять монет номиналом 1 (так как). Заменив их на одну монету номиналом 5, мы улучшим это решение. . В таком случае. Рассмотрим способ выдать сдачу си предположим, что в нём не используется монета номиналом 10. Простое, но важное замечание: сумма некой подгруппы использованных монет — 10. Это можно продемонстрировать, рассмотрев количество монет номиналом 5 в данном решении: если таких монет нет, тогда есть как минимум десять монет номиналом 1, и мы заменяем их на одну 10; если есть лишь одна монета номиналом 5, тогда есть как минимум пять монет по 1, и мы снова заменяем все монеты на одну монету номиналом 10; если есть хотя бы две монеты по 5, тогда их снова можно заменить. Хотя это доказательство длинное и довольно скучное, каждый раз, когда вы придумываете жадный алгоритм, вам нужно доказательство! Следующее упражнение показывает более компактный способ доказать правильность алгоритма выше. Продемонстрируйте, что money mod 5 монет номиналом 1 необходимы для любого решения, а остальные следует заменить монетами номиналами 10 и максимум одной монетой номиналом 5. Время выполнения.Время выполнения алгоритмаChange—, но его однострочная версия требует лишь несколько арифметических операций."
            }
        ]
    },
    {
        "id": "q_0105",
        "question": "Какой подход используется для выбора самых ценных предметов при ограниченных ресурсах?",
        "answers": [
            "Используется жадный отбор по плотности, при котором предметы выбираются по наибольшей ценности на единицу веса или объёма."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen",
                "text": "Теперь вы знаете, как устроена жадная стратегия и как она работает в задаче размена. Вы увидели, что можно принимать решения, не заглядывая вперёд, — и при этом получить оптимальный результат. А ещё убедились, что даже простая стратегия требует проверки и не всегда даёт правильный ответ. Далее — новая задача: как выбрать самые ценные предметы, если ресурсы ограничены. Здесь используется жадный отбор по плотности: ценность на единицу веса или объёма. Вы познакомитесь с жадным отбором по плотности и научитесь использовать этот подход, когда важно получить максимум от доступного. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм принимает решение на каждом шаге, выбирая наиболее выгодный вариант здесь и сейчас. В задаче размена такая стратегия работает, если номиналы монет удовлетворяют определённым условиям. Даже для простых на вид задач важно доказывать корректность жадного подхода, а не полагаться на интуицию. Жадные алгоритмы просты и быстры, но требуют проверки: в некоторых задачах они могут давать неверный результат."
            }
        ]
    },
    {
        "id": "q_0106",
        "question": "Что такое рандомизированные алгоритмы?",
        "answers": [
            "Рандомизированные алгоритмы — это алгоритмы, которые используют случайность в процессе своей работы для принятия решений или выбора путей выполнения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
                "text": "Что такое рандомизированные алгоритмы и как они работают? В чём разница между худшим и ожидаемым временем выполнения? Зачем алгоритмам случайность и когда она даёт преимущество?"
            }
        ]
    },
    {
        "id": "q_0107",
        "question": "Какой метод сортировки обсуждается в тексте как пример вероятностного алгоритма?",
        "answers": [
            "В тексте обсуждается QuickSort, который становится вероятностным алгоритмом при случайном выборе разделителя (RandomizedQuickSort)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
                "text": "Если у вас есть монетка, то прежде чем начать искать телефон, вы можете подбросить её и решить, откуда начать поиск: если выпадет решка, то сначала ищем на первом этаже, если орёл — на втором. А для выбора конкретной комнаты можно использовать игральный кубик. Хотя бросать монеты и кубики весело, этот подход однозначно не интуитивен. К тому же непонятно, даёт ли это алгоритмическое преимущество по сравнению с детерминированным алгоритмом. Наши задачи помогут разобраться, в каких ситуациях вероятностные алгоритмы будут лучше детерминированных. Чтобы продемонстрировать пример вероятностного алгоритма, обсудим сначала быстрый метод сортировки, который называетсяQuickSort. Для упрощения будем считать, что все элементы данного массиваразные. QuickSortвыбирает элемент(например, первый) изи просто разделяет массив на два подмассива:, в который входят все элементыменьше; и, в который входят все элементы больше. Это разделение можно выполнить за линейное время, далее, следуя стратегии «разделяй и властвуй»,QuickSortрекурсивно сортирует каждый подмассив. Итоговый отсортированный список может быть легко получен с помощью конкатенации отсортированного, элементаи отсортированного. Скопировать код1QuickSort(c):2if|c| =1:// только один элемент3returnc4m = c[1]// возьмем первый элемент c5// определим элементы c_small меньше m6// определим элементы c_large больше m7QuickSort(c_small)8QuickSort(c_large)9// объединим c_small, m и c_large в сортированный список c_sorted10returnc_sorted Для данного подхода требуется выделить дополнительную память, в которой будут храниться массивыи. Лучший подход — переставить элементы входного массива на месте, чтобы наборшёл первым, затем, а затем(см. ниже) — однако неясно, как это сделать. Нико Ломуто предложил изящный алгоритм, позволяющий выполнить такую перестановку элементов на месте. Рисунок ниже показывает, как работает разбиение Ломуто. Посмотрите на рисунок. Сможете ли вы воссоздать логику подхода Ломуто? Оказывается, что время выполненияQuickSortзависит от нашей удачи при отборе элемента. Если мы выберемтак, что массивразделяется на две равные части (то есть), тогда гдеозначает время, которое требуетсяQuickSortдля сортировки массива изчисел, иозначает время, которое потребуется для разделения массива длинына две части;— положительная константа. Это абсолютно такое же рекуррентное соотношение, как и вMergeSort, соответствующее времени выполнения. Тем не менее если мы выберемтак, чторазделится неровно (например, возникает крайний случай, когда наборпуст, а в набореэлементов), тогда рекуррентное соотношение будет Это соотношение и приводит к времени выполнения, а этого мы пытаемся избежать. Сортировка массивас помощьюQuickSortдействительно занимает квадратичное время. Что ещё хуже, на обработкутребуется время. Это выглядит излишним, ведь массив уже отсортирован. Пока что алгоритмQuickSortпохож на плохую имитациюMergeSort. Однако если мы сможем выбрать хороший «разделитель», который разбивает массив на две равные части, мы сможем улучшить время выполнения. На самом деле, не обязательно пытаться достичь идеального разделения (50/50), чтобы получить время выполнения. Например, также подойдет разделение на примерно равные части (скажем, 51/49). Фактически можно доказать, что алгоритм будет иметь время выполненияпри условии, что оба набораибольше, чем. Из этого следует, что извозможных вариантов для, выбранного в качестве элементов массива, как минимумхорошо подойдут для разделения! Другими словами, если мы возьмемслучайным образом (вероятность выбрать любой из элементоводинакова), то у нас будет шанс 50% получить хорошее разделение. Такой вывод ложится в основу следующего вероятностного алгоритма: Скопировать код1RandomizedQuickSort(c):2if|c| =1:// только один элемент3returnc4m = ...// возьмем случайный элемент из c5// определим элементы c_small меньше m6// определим элементы c_large больше m7RandomizedQuickSort(c_small)8RandomizedQuickSort(c_large)9// объединим c_small, m и c_large в сортированный список c_sorted10returnc_sorted На практикеRandomizedQuickSort— это быстрый алгоритм. Однако его худшее время выполнения остается, так как все еще есть вероятность, что он выберет плохой разделитель. При одном и том же вводе поведение вероятностного алгоритма отличается от одного выполнения к другому. Тем не менее мы можем доказать, что его ожидаемое время выполнения —. Слово «ожидаемое» подмечает следующий эффект. Так какRandomizedQuickSort— это вероятностный алгоритм, два разных запуска (при одинаковом вводе) могут занять разное количество времени: некоторые будут быстрыми, некоторые — медленными. Таким образом, время выполнения вероятностного алгоритма — это случайная величина. Разработчики нередко интересуются средним значением этой случайной величины, что и называется ожидаемым временем выполнения. Можно продемонстрировать, что для каждого массива размером вожидаемое время выполненияRandomizedQuickSortбудет."
            }
        ]
    },
    {
        "id": "q_0108",
        "question": "Какие два основных типа вероятностных алгоритмов выделяются в зависимости от корректности результата?",
        "answers": [
            "Вероятностные алгоритмы делятся на два типа: «Лас-Вегас» — алгоритмы, которые всегда дают верные решения, и «Монте-Карло» — алгоритмы, которые могут приводить к неправильным или приблизительным решениям."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
                "text": "Главное преимущество вероятностных алгоритмов — это производительность. Вероятностные алгоритмы решают многие реальные задачи быстрее (с точки зрения ожидаемого времени выполнения), чем детерминированные алгоритмы. Еще одна привлекательная особенность — это их простота. Она демонстрируется, например, вRandomizedQuickSort. Мы подчеркиваем, что хотяRandomizedQuickSortи принимает решения случайным образом, он всегда выдаёт правильное решение задачи сортировки. Единственный изменяющийся параметр от одного прогона к другому — это время выполнения, но не результат. В противоположность этому, другие вероятностные алгоритмы обычно приводят к неправильным (или точнее, приблизительным) решениям. Вероятностные алгоритмы, которые всегда дают верные решения, называются «Лас-Вегас». Алгоритмы, которые не приводят к верным решениям — «Монте-Карло»."
            }
        ]
    },
    {
        "id": "q_0109",
        "question": "Какое время работы в среднем у алгоритма RandomizedQuickSort?",
        "answers": [
            "Алгоритм RandomizedQuickSort в среднем работает за O(n log n)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
                "text": "Теперь вы познакомились с разными подходами к построению алгоритмов — от рекурсии до динамического программирования, от «Разделяй и властвуй» до рандомизированных стратегий. Вы научились оценивать, насколько эффективен алгоритм, и выбирать подходящий метод в зависимости от задачи. В следующем параграфе мы подведём итоги и сравним основные стратегии: где срабатывает жадность, где помогает случайность, а где лучше хранить промежуточные результаты. Это поможет вам научиться видеть за конкретной задачей типовую структуру — и сразу подбирать подходящий алгоритм. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Рандомизированные алгоритмы используют случайность для ускорения решения задач. Алгоритм RandomizedQuickSort в среднем работает за O(n log n), хотя в худшем случае даёт O(n²). Ожидаемое время выполнения может быть надёжным ориентиром, даже если поведение алгоритма меняется от запуска к запуску."
            }
        ]
    },
    {
        "id": "q_0110",
        "question": "Что такое компонента связности в неориентированном графе?",
        "answers": [
            "Компонента связности в неориентированном графе — это максимальный по включению подграф, в котором между любыми двумя вершинами существует путь."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritm-nahozhdeniya-komponent-svyaznosti-v-grafe",
                "text": "Что именно называют компонентой связности в неориентированном графе? Как применить DFS и BFS, чтобы выделить все компоненты? Зачем обход нужно запускать от каждой непосещённой вершины?"
            }
        ]
    },
    {
        "id": "q_0111",
        "question": "Какова асимптотическая сложность нахождения компонент связности в графе?",
        "answers": [
            "Асимптотическая сложность нахождения компонент связности в графе составляет O(V+E), где V — число вершин, а E — число рёбер и дуг."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritm-nahozhdeniya-komponent-svyaznosti-v-grafe",
                "text": "Алгоритмы поиска в глубину и ширину находят широкое применение и могут использоваться в других алгоритмах. Рассмотрим один из таких алгоритмов для поиска компонент связности в графе. Под компонентой связности в графе понимают множество вершин графа достижимых попарно и рёбра их связывающие. Для поиска компонент связности необходимо из каждой не посещённой вершины запускать алгоритм обхода, накапливая результаты каждого в отдельный контейнер. Пример ниже поможет понять алгоритм. Асимптотическая сложность нахождения компонент связности в графе — O(V+E), где V — число вершин, а E — число рёбер и дуг. Попробуйте реализовать данный алгоритм."
            }
        ]
    },
    {
        "id": "q_0112",
        "question": "Какие алгоритмы используются для нахождения компонент связности в неориентированном графе?",
        "answers": [
            "Для нахождения компонент связности используют обход графа в глубину (Depth-First Search, DFS) или в ширину (Breadth-First Search, BFS). Эти алгоритмы запускаются последовательно, начиная каждый раз с новой непосещённой вершины."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritm-nahozhdeniya-komponent-svyaznosti-v-grafe",
                "text": "Теперь вы умеете находить компоненты связности в графе и применять для этого DFS или BFS. Вы поняли, почему одного обхода недостаточно и как обойти весь граф по частям. Далее — более сложные задачи, в которых нужно находить кратчайшие пути между вершинами. Вы узнаете, как работает алгоритм Дейкстры и в каких ситуациях его можно применять. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Компоненты связности — это группы вершин неориентированного графа, внутри которых существует путь между любыми двумя вершинами. Чтобы найти все компоненты, используют обход графа: в глубину (Depth-First Search, DFS) или в ширину (Breadth-First Search, BFS), начиная каждый раз с новой не посещённой вершины. Важно правильно отмечать посещённые вершины и учитывать номер компоненты, к которой они принадлежат. Выделение компонент связности помогает понять структуру графа и служит основой для последующего анализа и алгоритмов кластеризации."
            }
        ]
    },
    {
        "id": "q_0113",
        "question": "Какие преимущества и недостатки имеет рекурсия в сравнении с итеративными методами?",
        "answers": [
            "Сила рекурсии заключается в её способности естественным образом разлагать сложные задачи на более простые подзадачи, что упрощает описание решений. Слабость проявляется в возможных ограничениях, таких как потребление памяти и производительность, которые демонстрируются на примере алгоритмов вроде «Ханойских башен»."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/rekursivnye-algoritmy",
                "text": "В чём сила и в чём слабость рекурсии по сравнению с итеративным подходом? Как разложение задачи на подзадачи помогает описывать решения? Что показывает пример «Ханойских башен» о возможностях и ограничениях рекурсивных алгоритмов?"
            }
        ]
    },
    {
        "id": "q_0114",
        "question": "Какой алгоритм используется для решения головоломки «Ханойские башни» согласно тексту?",
        "answers": [
            "Для решения головоломки «Ханойские башни» используется рекурсивный алгоритм, который можно записать всего в 8 строк псевдокода. Алгоритм перемещает n-1 дисков на временный стержень, затем перекладывает самый большой диск, после чего перемещает оставшиеся диски на целевой стержень."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/rekursivnye-algoritmy",
                "text": "Рекурсия — одно из самых распространенных алгоритмических понятий. Если говорить просто, то рекурсивным алгоритм становится, если вызывает сам себя. Головоломка «Ханойские башни» состоит из трёх стержней, пронумеруем их слева направо: 1, 2 и 3. Также в головоломке используется стопка дисков с отверстием посередине. Радиус дисков уменьшается снизу вверх. Изначально диски расположены на левом стержне (стержень 1), самый большой диск находится внизу. Диски в игре перемещаются по одному со стержня на стержень. Диск можно надеть на стержень, только если он пустой или верхний диск на нём большего размера, чем перемещаемый. Цель головоломки — перенести все диски со стержня 1 на стержень 3. Попробуйте нашу интерактивную версию «Ханойских башен» и узнайте, как переместить все диски с одного стержня на другой. Вывод списка действий, необходимых для решения головоломки «Ханойские башни». Входные данные: Целое число. Выходные данные: Последовательность ходов для решения головоломки «Ханойские башни» издисков. Решить головоломку с одним диском легко — просто переместите его на правый стержень. Головоломка на два диска ненамного сложнее. Сначала нужно переместить маленький диск на стержень посередине, а большой — на стержень справа. Затем переместить маленький диск на большой на правом стержне. Версия на три диска чуть сложнее, но и ее можно решить с помощью следующих семи шагов: Переместить диск со стержня 1 на стержень 3 Переместить диск со стержня 1 на стержень 2 Переместить диск со стержня 3 на стержень 2 Переместить диск со стержня 1 на стержень 3 Переместить диск со стержня 2 на стержень 1 Переместить диск со стержня 2 на стержень 3 Переместить диск со стержня 1 на стержень 3 Теперь давайте посчитаем, сколько шагов потребуется для решения версии на четыре диска. Нам нужно обязательно переместить самый большой диск, но для этого придётся сперва поместить все остальные диски на пустой стержень. Если у нас не три диска, а четыре, то нужно переложить три верхних диска на пустой стержень (7 действий), а затем переместить самый большой диск (1 действие). Теперь нужно снова переместить три диска с «временного» стержня на самый большой диск (еще 7 действий). Весь процесс будет состоять издействий. Чтобы переместитьдисков с левого стержня на правый, сначала необходимо переместитьдисков на стержень посередине. Затем, когда диск под номером, самый большой, оказывается на правом стержне, нужно переместить на него оставшиеся диски со стержня посередине. Чтобы переместитьдисков со стержня посередине направо, нужно сначала переместитьдисков на стержень слева, затем переместить-й диск вправо, потом переместитьдисков с левого стержня на правый и так далее. На первый взгляд задача «Ханойские башни» может показаться сложной. Тем не менее данный рекурсивный алгоритм находит нужные перемещения дисков всего за 8 строк! Скопировать код1HanoiTowers(n,fromPeg,toPeg)2ifn =1:3output “Move disk from peg fromPeg to peg toPeg”4return5unusedPeg =6- fromPeg - toPeg6HanoiTowers(n−1,fromPeg,unusedPeg)7output “Move disk from peg fromPeg to peg toPeg”8HanoiTowers(n−1,unusedPeg,toPeg) Переменныеиуказывают на три разных стержня. Таким образом,HanoiTowers(n, 1, 3)перемещает диски (шт.) с первого стержня на третий. Переменнаяуказывает, какой из трёх стержней можно использовать для временного хранения первых () дисков. Обратите внимание, чтовсегда равняется. Таким образом, значение переменнойможно определить как. Представленная таблица показывает результатыдля всех возможных переменныхи. Определивкак, операторы выполняют более простую задачу: они сначала перемещаютдисков на временный стержень, затем перекладывают большой диск, а потом складывают на него оставшиесядисков. Скопировать код1HanoiTowers(n−1,fromPeg,unusedPeg)2output “Move disk from peg fromPeg to peg toPeg”3HanoiTowers(n−1,unusedPeg,toPeg) Обратите внимание, что нет необходимости указывать, какой диск игрок должен переложить сна: перемещается всегда тот диск, что является верхним на. Хотя решение Ханойских башен можно уложить в 9 строк псевдокода, его выполнение займет на удивление много времени. Решение головоломки на пять дисков состоит из 31 действия. А в решении башни из сотни дисков количество действий будет исчисляться “страшными” нонилионами. Такое резкое увеличение числа действий дляHanoiTowersнеудивительно. Заметим, что каждый раз, когда вызываетсяHanoiTowers(n, 1, 3), алгоритм дважды вызывает сам себя для перемещениядисков, что запускает четыре вызова для перемещениядисков и так далее. Это можно проиллюстрировать с помощью рекурсивного дерева, изображенного нарис.. ВызовHanoiTowers(4, 1, 3)приводит к вызовамHanoiTowers(3, 1, 2)иHanoiTowers(3, 2, 3); каждый из них вызываетHanoiTowers(2, 1, 3),HanoiTowers(2, 3, 2)иHanoiTowers(2, 2, 1),HanoiTowers(2, 1, 3)и так далее. Каждый вызов подпрограммыHanoiTowersзанимает определенное время. Мы хотим узнать, сколько времени уйдёт на такой алгоритм. Чтобы вычислить время выполненияHanoiTowersразмера, мы введём в рассмотрение функцию— количество перемещений дисков, которые выполняетHanoiTowers(n). Получается следующее уравнение: Начиная с, это рекуррентное соотношение задаёт последовательность: и так далее. Мы можем вычислить, прибавив 1 с обеих сторон и обнаружив, что Если мы введём новое обозначение,, то. Таким образом, нужно решить следующее рекуррентное соотношение: Начиная с, получаем последовательность То есть,и. Следовательно,HanoiTowers(n)— экспоненциальный алгоритм."
            }
        ]
    },
    {
        "id": "q_0115",
        "question": "Что такое рекурсия в контексте программирования?",
        "answers": [
            "Рекурсия — это подход, при котором функция вызывает саму себя для решения подзадачи. Для корректной работы необходимо определить базовый случай и обеспечить, чтобы каждый шаг приближал к нему."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/rekursivnye-algoritmy",
                "text": "Теперь вы знаете, как работает рекурсия и почему она может быть мощным инструментом для построения алгоритма. Вы научились разбивать задачу на шаги, каждый из которых решается тем же способом, что и вся задача целиком. Далее — алгоритмы «Разделяй и властвуй». Мы разберём, как делить задачу на независимые части, решать каждую по отдельности и собирать общее решение. Вы увидите, как этот подход ложится в основу быстрой сортировки и других эффективных алгоритмов. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Рекурсия — это подход, при котором функция вызывает саму себя для решения подзадачи. Чтобы рекурсивное решение работало, важно определить базовый случай и убедиться, что каждый шаг приближает нас к нему. Задача «Ханойские башни» — классический пример, в котором рекурсивная стратегия описывает процесс из десятков или сотен шагов с минимальным кодом. Количество операций в рекурсивных алгоритмах может расти экспоненциально — это важно учитывать при выборе метода решения задачи."
            }
        ]
    },
    {
        "id": "q_0116",
        "question": "Какие основные вопросы рассматриваются в контексте алгоритмов для задачи сдачи?",
        "answers": [
            "В контексте рассматриваются вопросы о причинах неэффективности жадного алгоритма для оптимальной сдачи, составлении рекуррентного соотношения для минимального числа монет, отличиях мемоизации от табличного подхода и реализации решения с помощью динамического программирования."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen-2",
                "text": "Почему жадный алгоритм не справляется с задачей оптимальной сдачи? Как составить рекуррентное соотношение для минимального числа монет? В чём отличие мемоизации от табличного (bottom-up) подхода? Как реализовать решение задачи с помощью динамического программирования?"
            }
        ]
    },
    {
        "id": "q_0117",
        "question": "Какое минимальное количество монет номиналами 1, 3 и 4 требуется для выдачи сдачи в 6 центов?",
        "answers": [
            "Для сдачи в 6 центов требуется две монеты: 3+3."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen-2",
                "text": "Как нам уже известно, естественный «жадный» подход к этой задаче работает неправильно при любом наборе номиналов. Например, при номиналах,и«жадный» алгоритм разменяетцентов тремя монетами (), хотя это возможно сделать всего лишь двумя (). Ваша цель — использовать динамическое программирование для решения задачи «Сдача» с номиналами,и. Входные данные: Целое число. Выходные данные: Минимальное количество монет номиналами,,, чтобы выдать сдачу с. Ограничения:. . Для оптимального варианта сдачи снеобходимо семь монет. Рассмотрим произвольный поднабор оптимального решения — например, если сложить четыре монеты из приведённого ниже прямоугольника, то получится. Такая ситуация показывает нам важную особенность динамического программирования — решение задачи содержит решения всех её мелких подзадач. Эта особенность позволяет найти решение задачи, сначала выполняя мелкие подзадачи. Пусть— это минимальное количество монет номиналами,и, которые нужны для сдачи с, а— оптимальная сдача с. В таком случае Тогда Следовательно,. Таким образом, для решения задачи придостаточно решить её прии добавить единицу. Тем не менее мы знаем, чторавняется или, или, или. Такравно одному из следующих вариантов:,и. Так как мы ищем оптимальный способ выдать сдачу,равно минимальному из этих трёх выражений. В итоге мы получаем следующее рекуррентное соотношение: При небольших аргументах это соотношение выражает значениерекурсивным образом через собственные значения. Для такой нисходящей рекурсии нам необходимо указать базовый случай. У нас это будет:. Уравнение выше — самая важная часть алгоритма динамического программирования, так как из него легко сделать рекурсивный алгоритм. Скопировать код1Change(money):2ifmoney=0:3return04else:5result = +infinity6forc=1,3,4:7ifc <= money:8result =min(result,1+Change(money-c))9returnresult У этого алгоритма есть серьёзная проблема: он становится крайне медленным, потому что вызываетChange(money)снова и снова для одного и того же значения. Мемоизация — стандартный способ избежать этого: при вычисленииChange(money)мы можем использовать сохранение в таблице и тогда нам не придётся делать перевычисление. Скопировать код1table=associative array23Change(money):4iftable[money] isnotyet computed:5ifmoney=0:6table[money]←07else:8result = +infinity9forc=1,3,4:10ifc <= money:11result =min(result,1+Change(money-c))12table[money] = result13returntable[money] На практике такой алгоритм уже достаточно хорош, хотя у него есть проблемы с эффективностью: рекурсивные вызовы и уточняющие запросы для ассоциативного массива приводят к замедлению. Заметив, что все вычисляемые значения — это последовательные целые числа, мы можем реализовать улучшенный подход, в котором используется массив для хранения решений всех задач. Скопировать код1Change(money):2table[0..money] = [+infinity,…,+infinity]3table[0] =045form from1to money:6forc=1,3,4:7ifc <= m:8table[m] =min(table[m],1+table[m-c])9returntable[money] Время выполнения этого алгоритма составляет, так как каждая итерация внешнего циклаforпроходит за постоянное время."
            }
        ]
    },
    {
        "id": "q_0118",
        "question": "Какой метод решения задачи размена позволяет учитывать все варианты и выбирать наилучший результат?",
        "answers": [
            "Динамическое программирование позволяет учитывать все варианты и выбирать наилучший результат в задаче размена."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen-2",
                "text": "Теперь вы умеете использовать динамическое программирование для нахождения оптимального числа монет при сдаче. Вы поняли, почему жадный подход может давать неверный результат, научились строить рекурсивные решения с мемоизацией и ускорять их с помощью таблицы. А ещё увидели, что даже простая задача может быть связана с кратчайшими путями в графах. Далее — задача на построение выражения с минимальной стоимостью вычислений. Вы научитесь определять порядок операций, который экономит ресурсы, и познакомитесь с динамическим программированием на интервалах. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный подход может давать неоптимальные решения в задаче размена. Динамическое программирование позволяет учитывать все варианты и выбирать наилучший. Рекурсия с мемоизацией помогает избежать повторных вычислений, но может быть медленной. Табличный (bottom-up) подход эффективнее и позволяет решать задачу за линейное время. Такие задачи часто можно представить как поиск кратчайшего пути в графе."
            }
        ]
    },
    {
        "id": "q_0119",
        "question": "Какие методы используются для подсчёта инверсий в массиве и какой из них является более эффективным?",
        "answers": [
            "Для подсчёта инверсий можно использовать метод перебора всех пар элементов, который работает за O(n²), или алгоритм на основе сортировки слиянием, который работает за O(n log n) и является значительно более эффективным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/podschet-inversij",
                "text": "Что такое инверсии и как их находить? Почему перебор всех пар работает медленно и как это ускорить? Как работает алгоритм подсчёта инверсий на основе сортировки слиянием?"
            }
        ]
    },
    {
        "id": "q_0120",
        "question": "Какой показатель позволяет оценить степень отсортированности последовательности?",
        "answers": [
            "Количество инверсий в последовательности. Например, в неубывающей последовательности инверсий не будет, а в убывающей — каждая пара элементов образует инверсию."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/podschet-inversij",
                "text": "Количество инверсий в последовательности — показатель того, насколько последовательность отсортирована. Например, в неубывающей последовательности не будет инверсий, а последовательность в порядке убывания содержитинверсий (каждые два элемента образуют инверсию). Решая задачу «Количество инверсий», примитивный алгоритм просматривает все возможные пары, что требует времени выполнения. Чтобы решить эту задачу за времяс помощью алгоритма «разделяй и властвуй», мы разделяем вводный массив на две половины и делаем рекурсивный вызов обоих из них. Остаётся только вычислить количество инверсий, которые образованы двумя элементами из разных частей. Если делать это примитивным образом, то мы снова придём к времени выполнения, так как общее количество таких пар составляет. Оказывается, что если обе части уже отсортированы, количество инверсий из элементов разных половин можно вычислить за время. Это подсказывает нам, что вместо решения изначальной задачи, нам стоит решить более общую: вычислить количество инверсий в заданном массиве и в то же время отсортировать его. Измените алгоритмMergeSortдля решения этой задачи. Формат ввода: Первая строка содержит целое число, следующая — последовательность целых чисел. Формат вывода: Количество инверсий в последовательности. Ограничения:,для всех. В примере две инверсии:() и(). Совет: используйте полуоткрытые интервалы для рекурсивных реализаций Попробуем использовать самый распространённый подход к методу «разделяй и властвуй»: разделим вводную последовательность на две половины,LeftHalfиRightHalf, и выполним рекурсивный вызов для каждой. Это позволит нам вычислить все инверсии, находящиеся в одной и той же половине. Однако это не подскажет нам количество разделённых инверсий, то есть количество пар, при которыхнаходится в левой половине,находится в правой, а. Даны массиви целое число. Пустьбудет количеством элементов, которые меньше. Так как ответ на вопрос выше — это, наша задача заключается в том, чтобы быстро вычислить. Таким образом, мы приходим к следующей задаче: имея последовательность целых чисели целое число, нам нужно найти вколичество элементов, которые меньше. В случае неотсортированного массива это можно сделать за время, так как необходимо проверить каждый элемент массива. В варианте же отсортированного за время, если использовать двоичный поиск. Продемонстрируйте, как реализовать методCountSmaller(List, x)для подсчёта количества элементовсо значением меньшеза время. Так мы приходим к следующему алгоритму «разделяй и властвуй». Скопировать код1CountInversions(List):2if∣List∣ <=1:3return04inversions =05// в случае нечётной длины6// центральный элемент может быть и слева, и справа7LeftHalf = левая половина List8RightHalf = правая половина List9inversions = inversions +CountInversions(LeftHalf)10inversions = inversions +CountInversions(RightHalf)11sort(RightHalf)// необходимо для двоичного поиска12forx in LeftHalf:13inversions = inversions +CountSmaller(RightHalf,x)14returninversions Время выполнения(где— длина) удовлетворяет рекуррентному соотношению Слагаемоевключает в себя два шага: сортировкуи ответ назапросовCountSmaller. Эту рекуррентное соотношение нельзя напрямую вставить в основную теорему о рекуррентных соотношениях, так как элементне имеет формупри константе. Однако мы можем проанализировать её таким же образом: рекурсивное дерево содержитуровней, общий размер всех задач на каждом уровне равен, а общее затраченное время на каждом уровне составляет. В итоге общее время выполнения составляет. Вместо того, чтобы формально это доказывать, мы улучшим вышеприведённый алгоритм так, чтобы он затрачивал время. Можно быстро найти все разделённые инверсии, если наряду с подсчётом инверсий сортировать входную последовательность. То есть можно предположить, что алгоритмCountInversionsAndSort(List)возвращает количество инверсий ви сортирует. После двух рекурсивных вызовов обе половиныотсортированы. На данном этапе нам нужно сделать две вещи: отсортировать всю последовательностьи вычислить количество разделённых инверсий. Мы уже знаем, как достичь первой цели: этим занимается процедура. Это выглядит следующим образом.Пустьибудут первыми элементами отсортированных последовательностейи. Далее выбирается самый маленький из них и перемещается в увеличивающийся отсортированный список. Рассмотрим два случая. . В этом случаене больше каждого элемента, и поэтому не образует разделённых инверсий. . В этом случаеменьше всех элементов, и поэтому образует разделённую инверсию с каждым из них. Это приводит нас к следующему расширению методаMerge. Скопировать код1Merge(LeftHalf, RightHalf):2SortedList = empty list3inversions =04whileboth LeftHalfandRightHalf are non-empty:5l = первый элемент LeftHalf6r = первый элемент RightHalf7ifl <= r:8переместить l в SortedList9l = следующий элемент в LeftHalf10else:11переместить r в SortedList12r = следующий элемент в RightHalf13// учитываются только не перемещенные элементы14inversions = inversions + ∣LeftHalf∣15добавить все оставшиеся элементы LeftHalf и RightHalf в SortedList16returnSortedList, inversions И окончательная версия алгоритмаCountInversions. Скопировать код1CountInversions(List):2// список List будет отсортирован3if∣List∣ <=1:4return05LeftHalf = левая половина List6RightHalf = правая половина List7leftInv =CountInversions(LeftHalf)8rightInv =CountInversions(RightHalf)9List, splitInv =Merge(LeftHalf, RightHalf)10returnleftInv + rightInv + splitInv"
            }
        ]
    },
    {
        "id": "q_0121",
        "question": "Как можно улучшить сложность подсчёта инверсий в массиве по сравнению с полным перебором всех пар?",
        "answers": [
            "Сложность можно улучшить до O(n log n), используя модифицированную сортировку слиянием. Во время слияния двух отсортированных частей одновременно подсчитывается количество инверсий, что позволяет комбинировать сортировку и анализ данных за одно выполнение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/podschet-inversij",
                "text": "Теперь вы умеете находить количество инверсий в массиве с помощью модифицированной сортировки. Вы увидели, как объединять рекурсивное деление с анализом данных и использовать «побочные эффекты» сортировки для аналитических целей. Далее — последняя задача главы: вы узнаете, как найти пару ближайших точек на плоскости за, используя те же идеи — сортировку, деление и точный контроль над шагами объединения. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Инверсии — это пары элементов в неправильном порядке:и. Полный перебор всех пар даёт сложность, но можно улучшить до, используя сортировку слиянием. Во время слияния двух отсортированных частей можно одновременно считать количество инверсий. Такой подход позволяет комбинировать сортировку и подсчёт статистик за одно и то же время."
            }
        ]
    },
    {
        "id": "q_0122",
        "question": "Какие структуры данных можно использовать для реализации очереди с приоритетом?",
        "answers": [
            "Очередь с приоритетом может быть реализована с использованием массива, кучи или дерева."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/ochered-s-prioritetom",
                "text": "Как работает очередь с приоритетом и чем она отличается от обычной очереди? Какими способами можно реализовать очередь с приоритетом (массив, куча, дерево)? В каких алгоритмах и прикладных задачах применяется очередь с приоритетом?"
            }
        ]
    },
    {
        "id": "q_0123",
        "question": "Какие основные операции можно выполнять над очередью с приоритетом?",
        "answers": [
            "Основными операциями являются: вставка элемента с приоритетом, извлечение элемента с наивысшим приоритетом, просмотр элемента с наивысшим приоритетом без удаления и поиск элемента с определённым приоритетом."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/ochered-s-prioritetom",
                "text": "Очередь с приоритетом — коллекция элементов, где каждый элемент имеет связанный с ним приоритет. Элемент с высшим приоритетом будет обрабатываться раньше, чем элементы с более низким приоритетом. Очередь с приоритетом можно реализовать различными способами, но обычно главные операции над ними: Вставка элемента с приоритетом — добавление элемента в очередь с учётом его приоритета. В зависимости от реализации, элемент может быть добавлен в начало, в середину очереди или конец. Извлечение элемента с наивысшим приоритетом — удаление элемента из очереди с наивысшим приоритетом. В зависимости от реализации, удаление может происходить из начала, середины очереди или конца. Просмотр элемента с наивысшим приоритетом — просмотр элемента с наивысшим приоритетом без его удаления. Поиск элемента с определённым приоритетом — поиск элемента в очереди с опредёленным приоритетом. Основные способы реализации очереди с приоритетом включают в себя использование массивов, связанных списков, бинарных куч и древовидных структур. В зависимости от реализации, каждый из этих способов имеет свои преимущества и недостатки в терминах времени выполнения операций."
            }
        ]
    },
    {
        "id": "q_0124",
        "question": "Какая структура данных чаще всего используется для реализации очереди с приоритетом?",
        "answers": [
            "Для реализации очереди с приоритетом чаще всего используется структура «куча», которая обеспечивает логарифмическое время на добавление и удаление элементов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/ochered-s-prioritetom",
                "text": "Теперь вы знаете, как работает очередь с приоритетом и как выбирать её реализацию под конкретную задачу. Вы освоили базовые операции, поняли роль этой структуры в алгоритмах на графах (например, в алгоритме Дейкстры) и в задачах планирования. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Очередь с приоритетом позволяет обрабатывать элементы в порядке их важности, а не добавления. Для реализации чаще всего используется структура «куча», обеспечивающая логарифмическое время на добавление и удаление. Такая очередь используется во многих алгоритмах, например в поиске кратчайшего пути или планировании задач."
            }
        ]
    },
    {
        "id": "q_0125",
        "question": "Какие основные различия между множествами и списками в программировании?",
        "answers": [
            "Множества не содержат дубликатов элементов и обычно не сохраняют порядок элементов, в то время как списки сохраняют порядок и могут содержать повторяющиеся элементы. Множества оптимизированы для проверки принадлежности элемента (операция in), тогда как списки лучше подходят для хранения упорядоченных последовательностей данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
                "text": "Чем множество отличается от списка и в каких случаях его удобнее использовать? Как реализованы множества в разных языках — упорядоченные и неупорядоченные? Какие операции над множествами поддерживаются и в чём их сложность?"
            }
        ]
    },
    {
        "id": "q_0126",
        "question": "Какие основные операции можно выполнять со множеством?",
        "answers": [
            "Основные операции со множеством включают добавление элемента, удаление элемента, проверку наличия элемента, объединение двух множеств, пересечение двух множеств и разность двух множеств."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
                "text": "Следующей структурой данных, которую мы рассмотрим, будет множество (set). Множество представляет собой контейнер, содержащий неповторяющиеся элементы в произвольном порядке. Далее в данном параграфе мы будем разграничивать упорядоченные и неупорядоченные множества. Кроме того, существует такое понятие, как мультимножество (multiset), которое может включать в себя несколько одинаковых элементов. Вы можете посмотреть на различия между множеством и мультимножеством на рисунке ниже. Внутренняя реализация множества осуществляется различными способами, включая использование хэш-таблицы, бинарного дерева поиска и других алгоритмов. В данном параграфе мы сосредоточимся на функциях, которые можно производить со множеством, а не на внутренней его реализации. Основные операции со множеством: Добавление элемента в множество. Удаление элемента из множества. Проверка наличия элемента в множестве. Объединение двух множеств. Пересечение двух множеств. Разность двух множеств. Рассмотрим основные операции со множеством на примере двух языков С++ и Python. В STL языка С++ реализовано упорядоченное множество, в то время как в Python — неупорядоченное множество."
            }
        ]
    },
    {
        "id": "q_0127",
        "question": "Какой результат будет выведен на экран после выполнения приведённого фрагмента кода на Python с операциями добавления элементов в множество?",
        "answers": [
            "На экран будут выведены две строки: {1, 2, 3} и {1, 2, 3, 4}."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
                "text": "Добавление элемента в множество можно произвести следующим образом. Скопировать код1my_set = {1,2,3}2my_set.add(2)3print(my_set)4my_set.add(4)5print(my_set) В результате исполнения фрагмента кода выше на экран будет выведено две строки: 1 2 3 и 1 2 3 4. Сложность операции добавления элемента во множество в Python —, так как множество не упорядочено и не нужно искать позиции для его вставки. В языке С++ добавление элемента может быть осуществлено следующим образом (не забудьте добавить #include <set >в начало вашего кода). Скопировать код1set <int>val = {6,10,5,1};2val.insert(6);3val.insert(10);4val.insert(2);5cout <<val.size(); В итоге на экран будет выведено 5. В случае реализации на С++ мы имеем дело с упорядоченным множеством, что накладывает дополнительные временные издержки. Асимптотическая сложность добавления элемента —."
            }
        ]
    },
    {
        "id": "q_0128",
        "question": "Какое число появится на экране после выполнения фрагмента кода с удалением элемента из множества в C++?",
        "answers": [
            "На экране появится число 3, так как после удаления элемента размер множества уменьшился до трёх."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
                "text": "Не менее важной операцией является операция удаления элемента из множества. Скопировать код1set <int>val = {6,10,5,1};2val.erase(6)3cout <<val.size(); Благодаря фрагменту кода выше произошло удаление элемента, поэтому на экране появится число 3. Сложность операции удаления в упорядоченном множестве —. Рассмотрим удаление элемента из множества в Python: Скопировать код1my_set = {1,2,3}2my_set.remove(1);3print(len(my_set)) Размер множества после удаления элемента становится равным двум. Сложность операции удаления в неупорядоченном множестве —."
            }
        ]
    },
    {
        "id": "q_0129",
        "question": "Какие элементы входят в объединение множеств А и В, если А = {1, 3, 4, 5, 6}, а В = {1, 2, 4, 6, 8, 9}?",
        "answers": [
            "Объединение множеств А и В содержит все элементы, которые есть хотя бы в одном из множеств: {1, 2, 3, 4, 5, 6, 8, 9}."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
                "text": "Поработайте с двумя множествами А = {1, 3, 4, 5, 6}, B = {1, 2, 4, 6, 8, 9}. Для данных множеств найдите объединение, пересечение и разность."
            }
        ]
    },
    {
        "id": "q_0130",
        "question": "Какие основные операции можно выполнять с множествами?",
        "answers": [
            "Основные операции с множествами включают добавление, удаление, проверку наличия элементов, объединение и пересечение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
                "text": "Теперь вы умеете работать с множествами: добавлять и удалять элементы, проверять их наличие, объединять и находить пересечение. Вы узнали, что множества полезны, когда важна уникальность, а не порядок, и что разные реализации дают разную эффективность. Далее — структура, где каждому ключу сопоставлено значение. Вы познакомитесь со словарями, научитесь использовать ассоциативные массивы и узнаете, в чём их сила. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Множество — это структура, содержащая только уникальные элементы. В Python используется неупорядоченное множество, а в C++ — упорядоченное. Основные операции: добавление, удаление, проверка наличия, объединение и пересечение. Эффективность зависит от реализации: хеш-таблицы обеспечивают быстрые операции, но не сохраняют порядок."
            }
        ]
    },
    {
        "id": "q_0131",
        "question": "Какие практические применения существуют у редакционного расстояния?",
        "answers": [
            "Редакционное расстояние используется для сравнения текстов, исправления опечаток, анализа ДНК-последовательностей и других задач, где требуется оценить схожесть строк."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
                "text": "Что такое редакционное расстояние и как оно используется на практике? Как устроена рекурсивная формулировка задачи и почему мемоизация помогает? Как динамически находить расстояние между всеми префиксами двух строк? Как оптимизировать решение по памяти и находить выравнивание?"
            }
        ]
    },
    {
        "id": "q_0132",
        "question": "Как биологи используют редакционное расстояние в своей работе?",
        "answers": [
            "Биологи вычисляют редакционное расстояние для поиска мутаций, которые вызывают болезни."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
                "text": "Есть множество вариантов, как применить задачу «Расстояние редактирования». Она подойдёт для обработки текстов на естественном языке, проверки правописания и других направлений. К примеру, биологи зачастую вычисляют редакционное расстояние, когда ищут мутации, вызывающие болезни. Редакционное расстояние между двумя строками определяется как минимальное число односимвольных вставок, удалений и замен, необходимых для преобразования одной строки в другую. Входные данные:Две строки, состоящие из строчных букв латинского алфавита. Выходные данные:Редакционное расстояние между строками. Ограничения:Длина обеих строк не меньшеи не больше. Вторую строку можно получить из первой, удалив s, заменив h на p и вставив s. Это можно компактно продемонстрировать следующим выравниванием. Удалить e, вставить s после i, заменить i на a, заменить g на c, вставить e в конце. Совет: будьте осторожны с рекурсией. Рассмотрим решение задачи. Выравнивание двух строк в двухрядной матрице осуществляется таким образом, чтобы первый (второй) ряд содержал упорядоченные символы первой (второй) строки, которые перемежаются пробелами («»).В колонке не может быть два пробела одновременно в обеих строках."
            }
        ]
    },
    {
        "id": "q_0133",
        "question": "Как классифицируются колонки выравнивания строк по типам на основе символов в верхней и нижней строках?",
        "answers": [
            "Колонка с символом и пробелом — это удаление; колонка с пробелом и символом — вставка; колонка с двумя одинаковыми символами — совпадение; колонка с двумя разными символами — несоответствие."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
                "text": "Вычислите количество разных пар выравненных строк длинойи. Мы классифицируем колонки выравнивания следующим образом (первый символ из верхней строки, второй — из нижней): — колонка с символом и пробелом — это удаление; — колонка с пробелом и символом — вставка; — колонка с двумя одинаковыми символами — совпадение; — колонка с двумя разными символами — это несоответствие. Мы ищем выравнивание, при котором минимизируется общее количество несоответствий, удалений и вставок. Выравнивание считается оптимальным по сравнению со всеми другими возможными вариантами, если оно содержит минимум несоответствий, удалений и вставок.Стоит обратить внимание, что может быть несколько различных оптимальных выравниваний."
            }
        ]
    },
    {
        "id": "q_0134",
        "question": "Какой алгоритм используется для вычисления редакционного расстояния между префиксами строк с применением мемоизации?",
        "answers": [
            "Алгоритм использует рекурсивный подход с мемоизацией в ассоциативном массиве table. Он вычисляет редакционное расстояние между префиксами строк A и B длиной i и j, рассматривая операции вставки, удаления, совпадения и несоответствия, и возвращает минимальное значение среди этих операций."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
                "text": "Докажите, что задача на редакционное расстояние может быть сведена к поиску оптимального выравнивания двух строк. В примере выше последняя колонка — это вставка. Отбросив эту колонку, мы получаем оптимальное выравнивание первой строки и префикса второй. Рассмотрим идею рассчитать редакционное расстояние между каждой парой префиксов двух строк. Это более общая постановка задачи, но важно отметить, что, решив её, мы найдём ответ и на интересующий нас вопрос. Имея строкии, мы рассмотрим их префиксыидлинойии обозначим их редакционное расстояние. Так как последняя колонка оптимального выравниванияи— это или вставка, или удаление, или несоответствие, или совпадение, имеем, Базовый случай для этого рекуррентного соотношения —и: Это можно выразить более кратко: еслиили, тогда Псевдокод ниже делает из этого рекуррентного соотношения рекурсивный алгоритм и использует мемоизацию для избежания перевычислений. Скопировать код1table = associative array23EditDistance(A,B,i,j):4iftable[i,j] isnotyet computed:5ifi=0orj=0:6table[i,j] =max(i,j)7else:8insertion =EditDistance(A,B,i,j−1)+19deletion =EditDistance(A,B,i−1,j)+110match =EditDistance(A,B,i−1,j−1)11mismatch =EditDistance(A,B,i−1,j−1)+112ifA[i]=B[j]:13table[i,j] =min(insertion,deletion,match)14else:15table[i,j] =min(insertion,deletion,mismatch)16returntable[i,j] Время выполнения этого алгоритма составляет, так как выполняется не большерекурсивных вызовов, которые добавляют значения вtable."
            }
        ]
    },
    {
        "id": "q_0135",
        "question": "Какой объём памяти требуется для хранения двумерного массива table в алгоритме EditDistance?",
        "answers": [
            "Алгоритму требуется O(n*m) ячеек памяти для хранения двумерного массива table."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
                "text": "Рекурсивный алгоритм вычисляетдля всехи. Из рекурсивного алгоритма можно сделать итерационный, который будет сохранять решения всех подзадач в двумерной таблице. Таблица заполняется по рядам проходами. Это гарантирует, что когда мы вычислим значение клетки, значения клеток,ибудут уже готовы. Скопировать код1EditDistance(A[1…n],B[1…m]):2table =2d array ofsize(n+1) * (m+1)3table[0][j] = jforall i,j4fori from1to n:5forj from1to m:6insertion = table[i][j−1]+17deletion = table[i−1][j]+18match = table[i−1][j−1]9mismatch = table[i−1][j−1]+110ifA[i]=B[j]:11table[i][j] =min(insertion,deletion,match)12else:13table[i][j] =min(insertion,deletion,mismatch)14returntable[n][m] Итоговая таблица для нашего примера изображена на рисунке ниже. Значение каждой клетки вычисляется, исходя из значений соседних клеток сверху, слева и слева-сверху. У каждой клетки входящие стрелки указывают на один или несколько случаев (вставка, удаление, несоответствие, или совпадение), которые приводят к значению этой клетки. Таблица соответствует ориентированному ациклическому графу, в котором все рёбра, за исключением синих, имеют длину. А синие ребра соответствуют совпадающим символам и имеют длину. Алгоритм находит на графе самый короткий путь от узла слева сверху до узла справа снизу. Время выполнения алгоритма составляет. Ему требуетсяячеек памяти для хранения двумерного массиваtable. Расход места может быть снижен до(и даже до), если мы обратим внимание на то, что при заполнении текущего ряда таблицы нам нужны только клетки из текущего и предыдущего. Таким образом, вместо хранения всей таблицы достаточно сохранить текущий и предыдущие ряды. Отметим, что любой путь отдона рисунке образовывает оптимальное выравнивание строки. Путь, изображённый на рисунке ниже, соответствует оптимальному выравниванию editing и distance. Сколько в этом выравнивании вставок, удалений, совпадений и несоответствий? Постройте оптимальное выравнивание, соответствующее этому пути. Оптимальное выравнивание можно обнаружить с помощью перехода по стрелкам в обратную сторону от нижнего правого угла вдоль любого пути, приводящего к верхнему левому углу."
            }
        ]
    },
    {
        "id": "q_0136",
        "question": "Что такое редакционное расстояние и как его можно вычислить?",
        "answers": [
            "Редакционное расстояние — это минимальное число вставок, удалений и замен для превращения одной строки в другую. Его можно вычислить с помощью динамического программирования, заполняя таблицу расстояний между префиксами строк."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
                "text": "Теперь вы умеете вычислять редакционное расстояние — минимальное число правок, необходимых для преобразования одной строки в другую. Вы поняли, как формулируется задача рекурсивно, как работает динамическое программирование с таблицей и даже как найти оптимальное выравнивание. Далее — задача на поиск наибольшей общей подпоследовательности (LCS). Вы увидите, как похожие идеи помогают решать другую важную задачу сравнения строк, и научитесь отличать LCS от редакционного расстояния. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Редакционное расстояние — это минимальное число вставок, удалений и замен для превращения одной строки в другую. Его можно вычислить с помощью динамического программирования, заполняя таблицу расстояний между префиксами. Переходы в таблице соответствуют операциям редактирования и дают кратчайший путь в сетке выравнивания. Можно восстановить оптимальное выравнивание, двигаясь по таблице в обратную сторону. Решение можно оптимизировать по памяти, если хранить только два ряда таблицы одновременно."
            }
        ]
    },
    {
        "id": "q_0137",
        "question": "Какие основные различия между двумя классическими алгоритмами обхода графов?",
        "answers": [
            "Алгоритм обхода в глубину (DFS) исследует граф, двигаясь как можно дальше по каждой ветви перед возвратом, используя стек (явный или через рекурсию). Алгоритм обхода в ширину (BFS) исследует граф послойно, сначала все соседей начальной вершины, затем соседей соседей и так далее, используя очередь. Ключевое различие — порядок обхода: DFS уходит «вглубь», BFS — «вширь»."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/obhody-grafa",
                "text": "Как работает обход графа в глубину и в ширину и в чём между ними разница? Что важно учитывать при реализации DFS и BFS? Как не попасть в бесконечный цикл и правильно отслеживать посещённые вершины?"
            }
        ]
    },
    {
        "id": "q_0138",
        "question": "Какой алгоритм обхода графа сначала полностью исследует одну ветку, прежде чем переходить к другим?",
        "answers": [
            "Это алгоритм поиска в глубину (DFS). Его идея заключается в том, что при разветвлении возможных путей сначала полностью исследуется одна ветка, и только потом, если остались нерассмотренные ветки, происходит переход к ним."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/obhody-grafa",
                "text": "Пришла пора рассмотреть первые алгоритмы на графах. К классическим алгоритмам относятся обходы графов. Под обходом графа обычно понимают процесс систематического просмотра всех вершин или рёбер графа, чтобы найти некоторые вершины, удовлетворяющие определённым условиям. Мы рассмотрим обход в ширину и обход в глубину. Обход в глубину заключается в систематическом просмотре вершин графа и прохождении его ветвями. Иными словами, идея поиска в глубину — когда возможные пути по рёбрам, выходящим из вершин, разветвляются, нужно сначала полностью исследовать одну ветку и только потом переходить к другим веткам (если они останутся нерассмотренными). Опишем алгоритм поиска в глубину: Шаг 1. Все вершины графа отмечаем, как не посещенные. Выбирается первая вершина и помечается как посещённая. Шаг 2. Для последней помеченной как посещённой вершины выбирается смежная вершина, которая первая помеченная как не посещенная, и ей присваивается значение посещённой. Если таких вершин нет, то берётся предыдущая помеченная вершина. Шаг 3. Повторяем шаг 2 до тех пор, пока все вершины не будут помечены как посещённые. Пример реализации приведён ниже. Скопировать код1DFS(graph, v, used):2used[v] =13for(var u : graph[v])4if(!used[u])5DFS(graph, u, used) Попробуйте выполнить алгоритм поиска в глубину пошагово для графа. Обратите внимание, сейчас мы посмотрели на рекурсивную реализацию. Конечно, преимущество использования рекурсивного подхода заключается в простоте его написания, однако, рекурсивный подход имеет свои ограничения. Можно переписать алгоритм поиска в глубину с использованием особых структур данных. Например, стека. Опишем алгоритм поиска в глубину в нерекурсивной форме: Шаг 1. Все вершины графа отмечаем, как не посещённые. Выбирается первая вершина и помечается как посещённая. Эту вершину кладем в контейнер — стек. Шаг 2. Пока стек не пустой:Извлекаем последнюю добавленную вершину.Просматриваем все смежные с ней не посещённые вершины и помещаем их в стек.Порядок выхода вершин из стека и будет порядком обхода вершин графа. Извлекаем последнюю добавленную вершину. Просматриваем все смежные с ней не посещённые вершины и помещаем их в стек.Порядок выхода вершин из стека и будет порядком обхода вершин графа. Пример работы не рекурсивного алгоритма можно посмотреть на анимации. Пример реализации приведён ниже. Скопировать код1DFS(graph, v, used):2stack q3q.push(v)4used[v] =15while(!q.empty())6v = q.front()7q.pop()8for(var to : graph[v]):9if(!used[to]):10used[to] =true11q.push(to) Ещё один способ обхода графа — обход в ширину. Основное его отличие в том, что сначала исследуются смежные вершины, а уже потом вершины на следующем уровне. Иначе говоря, сначала исследуются все вершины, смежные с начальной вершиной (вершина с которой начинается обход). Эти вершины находятся на расстоянии 1 от начальной. Затем исследуются все вершины на расстоянии 2 от начальной, затем все на расстоянии 3 и так далее. Обратим внимание, что при этом для каждой вершины сразу находятся длина кратчайшего маршрута от начальной вершины. Опишем алгоритм поиска в ширину: Шаг 1. Всем вершинам графа присваивается значение не посещённой. Выбирается первая вершина и помечается как посещённая и заносится в очередь. Шаг 2. Посещается первая вершина из очереди (если она не помечена как посещённая). Все её соседние вершины заносятся в очередь. После этого она удаляется из очереди. Шаг 3. Повторяется шаг 2 до тех пор, пока очередь не станет пустой. Пример реализации алгоритма можно посмотреть на анимации Пример реализации приведён ниже. Скопировать код1BFS(graph, v, used):2queue q3q.push(v)4used[v] =15while(!q.empty())6v = q.front()7q.pop()8for(var to : graph[v]):9if(!used[to]):10used[to] =true11q.push(to) Подумайте, какое отличие алгоритма поиска в ширину от алгоритма поиска в глубину? Асимптотическая сложность алгоритма поиска в глубину и ширину —, где— число вершин, а— число рёбер и дуг. Обходы графов могут применяться для решения задач, связанных с теорией графов: Волновой алгоритм поиска пути в лабиринте. Волновая трассировка печатных плат. Поиск компонент связности в графе. Поиск кратчайшего пути между двумя узлами невзвешенного графа. Поиск в пространстве состояний: нахождение решения задачи с наименьшим числом ходов, если каждое состояние системы можно представить вершиной графа, а переходы из одного состояния в другое — рёбрами графа. Нахождение кратчайшего цикла в ориентированном невзвешенном графе. Нахождение всех вершин и рёбер, лежащих на каком-либо кратчайшем пути между двумя вершинами. Поиск увеличивающего пути в алгоритме Форда-Фалкерсона (алгоритм Эдмондса-Карпа)."
            }
        ]
    },
    {
        "id": "q_0139",
        "question": "Какие две основные структуры данных используются в алгоритмах DFS и BFS соответственно?",
        "answers": [
            "DFS использует стек (в том числе неявный при рекурсии), а BFS использует очередь."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/obhody-grafa",
                "text": "Теперь вы умеете реализовывать обходы графа — DFS и BFS — и использовать их для решения базовых задач, таких как проверка достижимости и построение пути. Вы научились работать с очередью и стеком, отмечать посещённые вершины и корректно обходить даже сложные структуры. Далее — задача на использование обходов. Вы узнаете, как при помощи DFS или BFS найти компоненты связности и почему важно запускать обход из каждой новой вершины. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. DFS и BFS — базовые алгоритмы, применимые ко многим задачам на графах. DFS использует стек (в том числе неявный при рекурсии), а BFS — очередь. Для корректного обхода важно отслеживать посещённые вершины. Выбор между DFS и BFS зависит от задачи: от поиска пути до анализа структуры графа."
            }
        ]
    },
    {
        "id": "q_0140",
        "question": "Какой алгоритм используется в задаче выбора по критерию «цена за единицу веса» и почему важно доказывать его корректность?",
        "answers": [
            "В этой задаче используется жадный алгоритм, который выбирает объекты в порядке убывания их цены за единицу веса. Доказательство корректности важно, потому что даже интуитивно очевидная стратегия может не работать для всех случаев, и формальное доказательство гарантирует, что алгоритм всегда находит оптимальное решение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-specii",
                "text": "Как работает жадный алгоритм в задаче выбора по критерию «цена за единицу веса»? Почему важно доказывать корректность жадной стратегии, даже если она кажется очевидной? Как оформить решение, чтобы избежать ошибок округления и сохранить точность при работе с вещественными числами?"
            }
        ]
    },
    {
        "id": "q_0141",
        "question": "Каков максимальный объём i-й специи, который вор может положить в рюкзак, учитывая вместимость рюкзака W и доступный объём этой специи?",
        "answers": [
            "Максимальный объём i-й специи, который можно положить в рюкзак, равен минимальному значению из двух величин: вместимости рюкзака W и доступного объёма этой специи Weight[i]. То есть amount = min(Weight[i], W)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-specii",
                "text": "Вор пробрался в лавку специй и нашёл там четыре фунта шафрана, три фунта ванили и пять фунтов корицы. В его рюкзак можно сложить до девяти фунтов, поэтому забрать всё он не сможет. Предположим, что цены на шафран, ваниль и корицу $5000, $200 и $10 соответственно. Как унести максимально дорогую добычу? Если вор заберётфунтов шафрана,фунтов ванили ифунтов корицы, общая ценность украденного составит. Вор хотел бы найти максимальное значение этого выражения при следующих ограничениях:,,,. Входные данные: Первая строка ввода содержитспеций и вместимость рюкзака. Следующиестрок указывают цену и вес специй.-я строка включает в себя ценуи вес-й специи. Выходные данные: Максимальное значение специй, которые вместятся в рюкзак. Ограничения:,;,для всех. Все числа — целые. В дополнение: Хотя ввод для этой задачи состоит из целых чисел, вывести необходимо нецелое число. Таким образом, абсолютное значение разницы между ответом вашей программы и оптимальным значением не должно превышать. Для этого ваш ответ должен содержать не меньше четырёх цифр в дробной части (иначе даже правильно вычисленный ответ может стать неправильным из-за проблем с округлением). Чтобы получить значение, вор возьмёт и первую, и третью специи полностью. Вору нужно забрать десять фунтов единственной доступной специи. Совет: по возможности старайтесь избегать чисел с плавающей дробной частью. Определим стоимость специикак. Естественной стратегией для вора было бы брать как можно больше самой дорогой специи. Чтобы доказать, что эта стратегия приводит к оптимальному решению, рассмотрим самую дорогую специю. Каков максимальный объём-й специи, который вор может положить в рюкзак? Во-первых, она должна уместиться в рюкзак:. Во-вторых, она не должна превышать доступный объём-й специи:. Следовательно,. Мы утверждаем, что существует оптимальное решение, включающее в себяфунтов-й специи. Чтобы это доказать, рассмотрим оптимальное решение, при котором мы получаем максимальное количествосамой дорогой-й специи из всех оптимальных решений (означает количество-й специи). Если, то ничего доказывать не нужно. Иначе. Поэтомуи. Рассмотрим два варианта. При нынешнем решениирюкзак заполнен не до конца. Так как, можно взять немного больше-й специи: так, мы получаем новое решение, которое лучше и оптимальнее нынешнего. Рюкзак заполнен до конца:. Так как, при подбореможно получить. Так, вместо маленького количества-й специи, можно взять такое же количество-й специи. Таким образом мы сохраним общий вес, но увеличим общую ценность и количество самой дорогой-й специи в рюкзаке. Это противоречит идее, что в изначальном решении был максимум-й специи. Доказав, что мы можем взять самой дорогой специи столько, сколько получится, мы можем спроектировать жадный алгоритм: взять как можно больше самой дорогой специи и повторить. Мы прекратим, когда больше не останется специй или когда рюкзак будет заполнен до конца. В псевдокоде, приведённом ниже,и— массивы, содержащие значения веса и цены. Скопировать код1MaximumLoot(W, Weight, Cost)2ifW=0orWeight is empty:3return04m = the index of the most expensive item5amount =min(Weight[m], W)6value = Cost[m] / Weight[m] * amount7remove the m-th element from WeightandCost8returnvalue +MaximumLoot(W - amount, Weight, Cost) Время выполнения.Время выполнения этого алгоритма —. При каждой итерации сканируется список специй и находится самая дорогая. Максимальное количество итераций —, так как каждая итерация снижает количество рассматриваемых специй."
            }
        ]
    },
    {
        "id": "q_0142",
        "question": "Какие условия должны выполняться для номиналов монет, чтобы жадная стратегия работала в задаче размена?",
        "answers": [
            "В тексте указано, что жадная стратегия в задаче размена работает, если номиналы монет удовлетворяют определённым условиям, но конкретные условия не перечисляются."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-specii",
                "text": "Теперь вы знаете, как устроена жадная стратегия и как она работает в задаче размена. Вы увидели, что можно принимать решения, не заглядывая вперёд, и при этом получить оптимальный результат. А ещё убедились, что даже простая стратегия требует проверки и не всегда даёт правильный ответ. Далее — новая задача: как выбрать самое выгодное, если ресурсы ограничены. Вы познакомитесь с жадным отбором по плотности и научитесь использовать этот подход, когда важно получить максимум от доступного. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм принимает решение на каждом шагу, выбирая наиболее выгодный вариант здесь и сейчас. В задаче размена такая стратегия работает, если номиналы монет удовлетворяют определённым условиям. Даже для простых на вид задач важно доказывать корректность жадного подхода, а не полагаться на интуицию. Жадные алгоритмы просты и быстры, но требуют проверки: в некоторых задачах они могут давать неверный результат."
            }
        ]
    },
    {
        "id": "q_0143",
        "question": "В чём заключается оптимальная стратегия для задачи «Сбор подписей» и почему она эффективна?",
        "answers": [
            "Оптимальной стратегией является выбор объектов с максимальной прибылью на единицу ресурса. Эта стратегия оказывается оптимальной, потому что позволяет наиболее эффективно использовать ограниченный ресурс для достижения максимального суммарного результата."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-sbor-podpisej",
                "text": "Чем задача «Сбор подписей» отличается от других задач с ограниченными ресурсами? Почему стратегия «максимальная прибыль на единицу ресурса» оказывается оптимальной? Как корректно оформить и проверить такое решение?"
            }
        ]
    },
    {
        "id": "q_0144",
        "question": "Каков алгоритм нахождения минимального количества точек для покрытия всех сегментов?",
        "answers": [
            "Алгоритм заключается в следующем: добавить в решение минимальное значение правой границы среди оставшихся сегментов, затем удалить все сегменты, покрытые этой точкой, и повторять процесс, пока сегменты не закончатся."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-sbor-podpisej",
                "text": "На этот раз ваша задача — собрать подписи со всех жильцов дома. Вам известно время, в которое каждый из них будет у себя. Естественно, вам хочется собрать все подписи, заходя в дом минимальное количество раз. Для простоты давайте предположим, что вы, зайдя в дом, собираете подписи сразу со всех жильцов, которые на месте. В дальнейшем под сегментом будем понимать интервал времени нахождения жильца в доме. Количество жильцов будет соответствовать количеству сегментов. Входные данные: Количество сегментов в первой строке —. Каждая из следующихстрок содержит два целых числаи(разделены пробелом), которые указывают на координаты границ-го сегмента. Выходные данные: Минимальное количествоточек на первой строке и координатыточек целыми числами (разделены пробелом) на второй строке. Выводить точки можно в любом порядке. При наличии нескольких наборов точек, можно вывести любой из них. Ограничения:;для всех. Все три сегмента,,содержат точку с координатами 3. Второй и третий сегменты содержат точку с координатами, в то время как первый и четвертый содержат точку с координатами. Одной точкой покрыть все сегменты нельзя, так какине пересекаются. В этом случае есть еще одно верное решение — точки 2 и 5. Решение заключается в выявлении сегмента с наименьшим значением правой границы. Самое маленькое значение границы сегмента:. Мы утверждаем, что существует оптимальное решение, включающее в себя точку. Чтобы доказать это, возьмём оптимальное решение. Оно должно покрывать сегмент, поэтомусодержит точку, что приводит к. Если, то наша работа закончена. Иначе. В этом случае мы можем заменитьнав. Понятно, что это не меняет размер решения. Чтобы доказать, чтовсё ещё является решением, подойдём от противного и предположим, что некий сегментпокрывается, но не покрывается. Это означаети противоречит тому, что— самое маленькое значение правой границы. Таким образом, мы приходим к следующему алгоритму: добавить в решение минимальное значение правой границы, отбросить все сегменты, покрытые, повторить. Скопировать код1SegmentsCover(segments):2points←empty set3whilesegments isnotempty:4r_m = minimum right endpoint of a segment from segments5add r_m points6remove segments covered by r_m from the set segments7returnpoints На рисунке ниже показан пример. Время выполнения составит, где, так как используется не болееитераций циклаwhile(при каждой итерации отбрасывается как минимум один сегмент), и каждая итерация сводится к проверке списка(одним сканированием находится значение, а другим убираются сегменты, покрываемые). Этот алгоритм уже достаточно быстрый, чтобы успешно пройти оценку. Однако можно дополнительно сократить время выполнения сдо, если отсортировать сегменты от малых до больших значений правой границы и затем просто просканировать список один раз."
            }
        ]
    },
    {
        "id": "q_0145",
        "question": "Какой подход помогает достичь справедливого распределения ресурса для увеличения количества получателей?",
        "answers": [
            "Для справедливого распределения ресурса с целью увеличения количества получателей применяется простая сортировка, которая в сочетании с жадным подходом оказывается удачным решением."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-sbor-podpisej",
                "text": "Теперь вы умеете применять жадные алгоритмы, когда нужно максимизировать результат при ограниченном ресурсе, используя критерий эффективности на единицу ресурса. Далее — задача с другим типом цели: теперь ресурс нужно распределить так, чтобы увеличить количество получателей. Вы узнаете, как простая сортировка помогает достичь справедливого распределения и почему жадный подход оказывается удачным и в этой ситуации. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм может работать не только с абсолютными значениями, но и с относительными критериями, например «выгода на единицу ресурса». Оптимальность жадного критерия нужно обосновывать — иначе легко получить неверное решение. Работа с вещественными числами требует особой аккуратности в сравнении и реализации."
            }
        ]
    },
    {
        "id": "q_0146",
        "question": "Какие таблицы используются для хранения экстремальных значений подвыражений при группировке?",
        "answers": [
            "Для хранения минимальных и максимальных значений подвыражений используются специальные таблицы, которые позволяют эффективно сохранять промежуточные результаты при переборе вариантов группировки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-suveniry",
                "text": "Почему результат арифметического выражения зависит от порядка скобок? Как использовать динамическое программирование для перебора всех вариантов группировки? Как устроены таблицы для хранения минимальных и максимальных значений подвыражений?"
            }
        ]
    },
    {
        "id": "q_0147",
        "question": "Какое значение нужно вывести, если набор предметов можно разделить на три поднабора с одинаковыми суммами?",
        "answers": [
            "Нужно вывести 1."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-suveniry",
                "text": "Три пирата делят свою добычу, в которую входятпредметов разной ценности. Получится у вас помочь разделить добычу поровну? Входные данные:Первая строка содержит целое число. Вторая строка содержит целые числа, разделённые пробелами. Выходные данные:Вывести 1, еслиможно разделить на три поднабора с одинаковыми суммами; в противном случае — вывести 0. Ограничения:,для всех. Пример 1 Пример 2 Пример 3 . Рассмотрим решение задачи. Обозначимкак. Разделить набор изпредметов на три части возможно, только если их общая ценность делится на три. То есть, где— это целое число. Так, нам необходимо разделитьчисел на три части, где сумма чисел в каждой части равна. Одна из этих частей содержит-й трофей (с ценностью). Если мы его уберём, то получим разделение первыхтрофеев на три части таким образом, что ценность двух из них будет равна, а сумма оставшейся части —. Вместо разделения всехпредметов, попробуем решить более мелкую задачу, состоящую в делении первыхпредметов на части с ценностью,и. Если такое разделение возможно, мы присваиваем(в противном случае —) и отмечаем, что пираты могут разделить добычу честно, только если. Предположим, что. Тогда первыечисел можно разделить на три части таким образом, чтобы сумма чисел в первой части составляла, а сумма чисел во второй части —. -й предмет принадлежит первой части. Тогда. Убрав его из первой части, мы разделим первыечисел на три части так, что сумма первых двух частей составити, то есть. -й предмет принадлежит второй части. Как и в предыдущем случае,и. -й предмет принадлежит третьей части. Тогда. Так, значениеможно вычислить, посмотрев на Базовый случай для этого рекуррентного соотношения:и, если. Скопировать код1Split(v[1],…,v[n]):2ifv[1] + … + v[n] не делится целочисленно на3:3returnfalse4V = (v[1] + … + v[n]) /35split = ...// массив размера (n+1) × (V+1) × (V+1)6// заполнить массив split значениями false7split[0][0][0] =true8fori from1to n:9fors1 from0to V:10fors2 from0to V:11split[i][s1][s2] = split[i−1][s1][s2]12ifs1 >= v[i]:13split[i][s1][s2] = split[i][s1][s2] OR split[i -1][s1 - v[i]][s2]14ifs2 >= v[i]:15split[i][s1][s2] = split[i][s1][s2] OR split[i -1][s1][s2 - v[i]]16returnsplit[n][V][V] Время выполнения составляет."
            }
        ]
    },
    {
        "id": "q_0148",
        "question": "Какой метод позволяет уменьшить время вычисления максимального значения арифметического выражения с экспоненциального до кубического?",
        "answers": [
            "Динамическое программирование с запоминанием минимальных и максимальных значений всех подвыражений позволяет избежать повторных вычислений и сокращает время работы до кубического."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-suveniry",
                "text": "Теперь вы умеете вычислять максимальное значение арифметического выражения, расставляя скобки в нужном порядке. Вы научились использовать динамическое программирование с запоминанием минимальных и максимальных значений и применять аккуратные рекурсивные формулы. Далее — финальный параграф главы. В нём мы кратко обобщим ключевые идеи, которые вы встретили, и покажем, как они складываются в систему. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Порядок выполнения операций влияет на результат арифметического выражения — важно правильно расставить скобки. Можно эффективно найти максимальное значение, если сохранять минимумы и максимумы всех подвыражений в таблицах. Динамическое программирование позволяет избежать повторных вычислений и уменьшает время работы с экспоненциального до кубического. Даже при небольшом числе операций количество возможных расстановок скобок велико — поэтому важно автоматизировать перебор."
            }
        ]
    },
    {
        "id": "q_0149",
        "question": "Каковы основные структурные элементы односвязного списка и как они связаны между собой?",
        "answers": [
            "Односвязный список состоит из узлов, каждый из которых содержит данные и ссылку на следующий узел. Узлы последовательно связаны этими ссылками, образуя цепочку. Последний узел списка содержит ссылку на null, указывая на конец последовательности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/odnosvyaznyj-spisok",
                "text": "Как устроен односвязный список и чем он отличается от массива? Какие операции можно выполнять со списком и какова их сложность? Когда стоит использовать односвязный список вместо других структур?"
            }
        ]
    },
    {
        "id": "q_0150",
        "question": "Как называется последний элемент односвязного списка и какое значение содержит его ссылка?",
        "answers": [
            "Последний элемент односвязного списка называется хвостом (tail), и его ссылка содержит null-значение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/odnosvyaznyj-spisok",
                "text": "Односвязный список (иногда «связный список») — базовая структура данных, представляющая собой соединённые узлы с однотипными данными. Каждый узел состоит из элемента и ссылки на следующий элемент (см. рисунок). Самый первый элемент списка называют головой (head) односвязного списка, а последний — хвостом (tail). Последний элемент односвязного списка в качестве ссылки содержит null-значение. В отличие от классического массива, где данные в памяти расположены строго последовательно, в односвязном списке, наоборот, данные расположены хаотично и связывание узлов списка происходит посредством ссылок. За счёт этой особенности в односвязный список можно добавлять произвольное число элементов, однако доступ будет осуществляться только последовательно. Произвольного доступа к элементам в односвязном списке нет. Со списком можно производить ряд операций: Добавить элемент (add). Удалить элемент (remove). Найти элемент (find). Посчитать количество элементов по условию (count). Операция добавления элемента (add) может быть представлена в нескольких вариантах. В случае добавления в начало списка ссылка нового узла будет указывать на голову списка, а голова списка должна быть перемещена на новый узел. Сложность этого варианта —. Если добавление идёт в конце списка, то ссылка хвоста списка должна указывать на новый узел, а после должна быть перемещена на новый узел. Сложность этого варианта —. Вставка промежуточного элемента предполагает, что будет найдена позиция после которой будет вставлено новое значение. Сложность этого варианта —, где n число элементов в списке. Удаление элемента (remove) предполагает, что будет найден заданный элемент и следом он будет удалён. Нахождение узла требует прохода по односвязному списку, после чего необходимо ссылку с элемента перед удаляемым перенаправить на элемент после удаляемого. Сложность операции —, где— число элементов в списке. Нахождение элемента (find) предполагает простой однократный проход по списку с нахождением ссылки на заданный элемент. Сложность операции —, где— число элементов в списке. Подсчёт числа элементов по условию (count) предполагает проход по списку и сравнение всех элементов с заданным с подсчётом количества удовлетворяющих условию элементов. Сложность операции —, где— число элементов в списке."
            }
        ]
    },
    {
        "id": "q_0151",
        "question": "Как устроен односвязный список и что хранит каждый его узел?",
        "answers": [
            "Односвязный список состоит из узлов, где каждый узел хранит значение и ссылку на следующий элемент. Доступ к элементам возможен только через последовательный обход списка."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/odnosvyaznyj-spisok",
                "text": "Теперь вы знаете, как устроен односвязный список и как с ним работать: добавлять, удалять, искать и считать элементы. Вы поняли, чем он отличается от массива и в каких случаях может быть полезен. Далее — ещё одна важная структура данных: множество. Вы увидите, как оно позволяет хранить уникальные элементы и выполнять быстрые проверки на принадлежность. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткий гайд о том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Односвязный список состоит из узлов, где каждый узел хранит значение и ссылку на следующий элемент. В отличие от массива, доступ к элементам возможен только через последовательный обход списка. Основные операции (добавление, удаление) могут выполняться эффективно при работе с началом списка, но поиск элемента занимает больше времени. Односвязный список удобен, когда важнее динамическое изменение структуры, чем быстрый доступ по индексу."
            }
        ]
    },
    {
        "id": "q_0152",
        "question": "Какие преимущества имеет описание алгоритма на псевдокоде по сравнению с другими способами представления?",
        "answers": [
            "Псевдокод позволяет абстрагироваться от конкретного языка программирования, сосредоточившись на логике алгоритма, при этом сохраняя структуру, близкую к реальному коду. Это делает описание более понятным для людей с разным бэкграундом и облегчает последующую реализацию на любом языке."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
                "text": "Чем задача отличается от её конкретного экземпляра и почему это различие важно? Какие ошибки может допустить алгоритм и как проверить его корректность? В чём преимущества описания алгоритма на псевдокоде? Как измерять «быстроту» алгоритма и почему не всегда важно абсолютное время работы? Почему полиномиальные алгоритмы считаются приемлемыми, а экспоненциальные — проблемными?"
            }
        ]
    },
    {
        "id": "q_0153",
        "question": "Что такое алгоритм?",
        "answers": [
            "Алгоритм — это последовательность указаний, которые нужно исполнить, чтобы решить чётко сформулированную задачу. Он представляет собой способ превращения ввода в вывод."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
                "text": "Алгоритм — это последовательность указаний, которые нужно исполнить, чтобы решить чётко сформулированную задачу. Мы описываем задачи, исходя из ввода и вывода, и алгоритм становится способом превращения ввода в вывод. При этом формулировка задачи должна быть точной и недвусмысленной — это помогает избежать неверной интерпретации. Когда вы закончили проектировать алгоритм, необходимо ответить на два важных вопроса: «Правильно ли он работает?» и «Сколько времени занимает выполнение?». Разумеется, вас не устроит алгоритм, который выдаёт правильный результат лишь в половине случаев или требуетлет для поиска ответа."
            }
        ]
    },
    {
        "id": "q_0154",
        "question": "Что такое псевдокод и для чего он используется разработчиками?",
        "answers": [
            "Псевдокод — это язык, используемый разработчиками для описания алгоритмов. Он игнорирует многие детали, необходимые в языках программирования, но является более точным, чем обычный рецепт."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
                "text": "Чтобы понять, как работает алгоритм, нам необходимо перечислить шаги, которые он выполняет. Для этого мы будем использовать псевдокод — язык, которым пользуются разработчики для описания алгоритмов. Он игнорирует многие детали, необходимые в языках программирования, но он более точен, чем рецепт из кулинарной книги."
            }
        ]
    },
    {
        "id": "q_0155",
        "question": "Какой алгоритм используют кассиры по всему миру для выдачи сдачи минимальным количеством монет?",
        "answers": [
            "Кассиры используют жадный алгоритм: на каждом шаге выбирают монету с наибольшим номиналом, который не превышает оставшуюся сумму сдачи, и повторяют процесс, пока вся сдача не будет выдана."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
                "text": "Задача описывает класс возможных входных данных. Экземпляр задачи — это один конкретный ввод такого класса. Чтобы продемонстрировать понятия задачи и экземпляра задачи, рассмотрим следующий пример. Вы оказались в книжном магазине и собираетесь купить книгу за, расплатившись купюрой в. Вам должны вернутьцентов в качестве сдачи. Теперь кассир принимает решение, как именно это сделать. Согласитесь, неприятно получить горсть изпенни илиникелей ипенни. Возникает вопрос: как выдать сдачу, не расстроив клиента? Большинство кассиров стараются уместить сумму сдачи в наименьшее количество монет. Пример сцентами представляет собой экземпляр задачиРазмен. Предполагается, что естьноминалов, которые представлены массивом. Для упрощения будем считать, что номиналы даны в порядке убывания. Например,для монет, используемых в США. Переведите определенное количество денег в данные номиналы, используя как можно меньше монет. Входные данные: Целое числои массив изноминаловв порядке убывания (). Выходные данные: Список изцелых чисел, в которомикак можно меньше. Кассиры по всему миру решают эту проблему с помощью простого алгоритма: Скопировать код1Change(money, c, d):2whilemoney >0:3coin = ...// монета с самым большим номиналом, который не превышает money4// дать монету с номиналом coin клиенту5money = money - coin Вот быстрая версия Change: Скопировать код1Change(money, c, d):2fork inrange(1, d +1)3i_k=floor(money / c[k])// наибольшее количество монет номинала c[k]4// дать i_k монет с номиналом c[k] клиенту5money = money - c[k] * i_k"
            }
        ]
    },
    {
        "id": "q_0156",
        "question": "Какой алгоритм выдал бы неправильную сдачу для суммы 40 центов, если бы использовались монеты номиналом 25, 10, 5 и 20 центов?",
        "answers": [
            "Алгоритм Change выдал бы неправильный результат: 1 четвертак (25 центов), 1 дайм (10 центов) и 1 никель (5 центов) вместо оптимального варианта из 2 монет по двадцать центов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
                "text": "Мы называем алгоритм корректным, если на каждый получаемый ввод он делает правильный вывод. Алгоритм считается некорректным, если хотя бы один ввод приводит к неправильному выводу. Change— это некорректный алгоритм! Представьте сдачу в 40 центов, выданную в номиналах,,,и. Changeпривел бы к неправильному результату: он выдал бы 1 четвертак (25 центов), 1 дайм (10 центов) и 1 никель (5 центов) вместо 2 монет по двадцать центов. Хоть это и может выглядеть надуманно, в 1875 году в США существовала монета в двадцать центов. Насколько мы можем быть уверены, чтоChangeвыдаст минимальное количество монет в современных номиналах Соединенных Штатов или любой другой страны? Чтобы исправить алгоритмChange, нам нужно рассмотреть все возможные комбинации монет с номиналами, которые дают в сумме, и выдать комбинацию с минимальным количеством монет. Мы рассматриваем только комбинации, в которыхи(в целом, величинане должна превышать), в ином случае мы вернем большее количество денег, чем. В псевдокоде, приведенном ниже, используется символ. Он обозначает суммирование:. Псевдокод также использует концепт «бесконечность» (обозначается) в качестве начального значения для. Реализация описанного подхода на реальных языках программирования может различаться, но сейчас подробности для нас не важны. Скопировать код1BruteForceChange(money, c, d):2smallestNumberOfCoins = ∞3foreach combinations ofcoins(i_1,...,i_d)4// от (0,...,0) до (money/c[1],...,money/c[d])5valueOfCoins = ∑ i_k*c_k// сумма по всем k от 1 до d6ifvalueOfCoins = money:7numberOfCoins = ∑ i_k// суммарное количество монет8ifnumberOfCoins <smallestNumberOfCoins:9smallestNumberOfCoins = numberOfCoins10change = (i_1, i_2, ... ,i_d)11returnchange Цикл повторяется с каждой возможной комбинациейизиндексов и останавливается, когда достигает Как мы можем узнать, чтоBruteForceChangeне содержит ту же проблему, что иChange, — неверный результат при каком-то вводе? РазBruteForceChangeрассматривает все возможные комбинации номиналов, рано или поздно алгоритм придёт к оптимальному решению и запишет его в массив. В любой комбинации монет, которая даёт в сумме, должно быть как минимум столько же монет, сколько и в оптимальной. Таким образом,BruteForceChangeникогда не завершит работу с неоптимальным набором. На данный момент мы ответили только на один из двух важных вопросов об алгоритмах: \"Работает ли он?\". Однако мы не ответили на вопрос: \"Сколько времени занимает выполнение?\"."
            }
        ]
    },
    {
        "id": "q_0157",
        "question": "Какой алгоритм считается более эффективным при больших значениях ввода: линейный или квадратичный?",
        "answers": [
            "Линейный алгоритм более эффективен при больших значениях ввода, так как он выполняет меньше операций по сравнению с квадратичным алгоритмом для решения той же задачи."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
                "text": "Настоящие компьютеры требуют определенное количество времени на выполнение таких операций, как сложение, вычитание или проверка условий цикла while. Суперкомпьютер может выполнить сложение засекунды, а калькулятор — за. Представьте, что у вас есть компьютер, которому требуетсясекунды на выполнение простой операции (например, сложения), и вы знаете, сколько операций выполняет какой-то конкретный алгоритм. Вы могли бы рассчитать время выполнения алгоритма, просто взяв произведение количества операций и времени, которое занимает одна операция. Однако компьютеры постоянно улучшаются, благодаря чему им требуется меньше времени на операцию. Так, ваше представление о времени выполнения быстро стало бы устаревшим. Вместо того, чтобы рассчитывать время выполнения на каждом компьютере, мы описываем время выполнения через общее количество операций, необходимых алгоритму, — это характеристика самого алгоритма, а не компьютера, который вы используете. К сожалению, нам не всегда легко определить, сколько операций выполнит алгоритм. Однако если мы можем рассчитать количество базовых операций, выполняемых алгоритмом, то это позволит сравнить его с другим алгоритмом, решающим ту же задачу. Чтобы мучительно не подсчитывать каждое умножение и сложение, можно сравнивать только те участки кода, которые при увеличении размера ввода потребуют больше операций. Представьте, что алгоритмвыполняетопераций при вводе размера, и алгоритмрешает ту же задачу заопераций. Какой алгоритм быстрее:или? Хотяи может быть быстрее, чем, при более малом значении(например, примежду 1 и 3),будет быстрее при больших значениях(например,). (См. рис.). Так как— это, в каком-то смысле, более «быстрорастущая» функция относительно, чем. При этом константы 3 и 2 вне влияют на конкуренцию между двумя алгоритмами при больших значениях. Мы называемквадратичным алгоритмом и— линейным.менее эффективен, чем, потому что он выполняет больше операций для решения задачи, когда значениебольшое. Так, иногда мы будем допускать неточности при подсчете операций алгоритма: поведение алгоритма при маленьком вводе неважно. Рассчитаем примерное количество операций, которое потребуется дляBruteForceChangeпри вводе изцентов и номиналов. Чтобы рассчитать общее количество операций в цикле for, нам необходимо взять примерное число операций, выполняемое при каждой итерации, и умножить его на общее количество итераций. В нашем случае количество операций можно оценить сверху величиной Такой тип алгоритмов называется экспоненциальным в противоположность квадратичным, кубическим или другим полиномиальным алгоритмам. Выражение времени выполнения экспоненциального алгоритма использует, гдеи— это параметры задачи (например,иможно произвольно сделать большими, изменив ввод для алгоритма). Время выполнения полиномиального алгоритма ограничено, где— это константа, не связанная с тестовыми данными. Например, алгоритм с временем выполнения(линейный),(квадратичный),(кубический) или дажебудет полиномиальным. Конечно, алгоритм с временем выполненияне очень практичен. Возможно, даже менее практичен, чем некоторые экспоненциальные алгоритмы. Впрочем, разработчики тратят много усилий, чтобы проектировать всё более и более быстрые полиномиальные алгоритмы. Раз значениеможет быть большим при вызове алгоритма с большим количеством номиналов (например,), мы видим, что выполнениеBruteForceChangeможет потребовать много времени."
            }
        ]
    },
    {
        "id": "q_0158",
        "question": "Что такое псевдокод и для чего он используется?",
        "answers": [
            "Псевдокод — это способ описания шагов алгоритма, который помогает делать это понятно и точно. Он используется для формального представления алгоритмических решений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
                "text": "Теперь вы знаете, что такое алгоритм, чем задача отличается от её экземпляра и как алгоритмы помогают решать поставленные задачи. Вы познакомились с псевдокодом, понятием корректности алгоритма и идеей оценки его эффективности. А ещё узнали, почему время выполнения важно и как отличать «быстрые» алгоритмы от «медленных» с точки зрения роста числа операций. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Алгоритм — это способ преобразования входных данных в выходные. Он решает задачу, формулируемую через множество возможных входов и условий. Псевдокод помогает описывать шаги алгоритма понятно и точно, а корректность означает, что алгоритм всегда выдаёт правильный результат. Эффективность алгоритма оценивается по количеству операций, которые он выполняет, — это позволяет сравнивать алгоритмы независимо от устройства. Полиномиальные алгоритмы масштабируются лучше и считаются эффективными, тогда как экспоненциальные быстро становятся непрактичными при росте входных данных. В следующей главе вы познакомитесь со структурами данных: стеком, очередью, словарём, множеством и списками. Вы узнаете, как они устроены, где используются и чем отличаются друг от друга, — а заодно научитесь применять их в задачах."
            }
        ]
    },
    {
        "id": "q_0159",
        "question": "Какие критерии следует учитывать при выборе способа хранения графа для конкретной задачи?",
        "answers": [
            "Выбор представления графа зависит от критериев, связанных со скоростью выполнения алгоритмов и потреблением памяти, которые определяются особенностями конкретной задачи."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/predstavlenie-grafa-v-pamyati-kompyutera",
                "text": "Какие основные способы хранения графа применяются на практике? Как различия в представлениях отражаются на скорости работы алгоритмов и потреблении памяти? По каким критериям выбирать подходящее представление графа для конкретной задачи?"
            }
        ]
    },
    {
        "id": "q_0160",
        "question": "Какой способ хранения графа использует матрицу, где по строкам и столбцам располагаются номера вершин, а на пересечении ставится 0 или 1 в зависимости от наличия ребра?",
        "answers": [
            "Это матрица смежности. Она представляет собой матрицу, где строки и столбцы соответствуют номерам вершин графа, а значение 1 на пересечении указывает на наличие ребра между вершинами, а 0 — на его отсутствие."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/predstavlenie-grafa-v-pamyati-kompyutera",
                "text": "В прошлом параграфе мы обсудили основные определения теории графов. Однако, чтобы работать с графами, необходимо их как-то хранить в памяти компьютера. К сожалению, не существует универсального способа хранения графов, потому что каждый имеет свои достоинства и недостатки. Рассмотрим такой способ хранения графа, как матрица смежности. Матрица смежности представляет собой матрицу, где по строкам и столбцам располагаются номера вершин. Если рёбра между вершинами отсутствует, то на пересечении-ой строки и-ого столбца ставится 0. Если ребро есть, то ставят 1. Пример графа и его матрицы смежности приведён на рисунке ниже. Рассмотрим пример матрицы смежности для ориентированного графа. В целом, отличий не так много, кроме того, что матрица смежности перестала быть симметричной. Подумайте, почему. Также при работе с графами применяется и матрица инцидентности. По столбцам располагаются рёбра, а по строкам номера вершин. На пересечении-ой вершины и-ого ребра ставится 1, если одним из концов ребрабыла вершина. Пример приведён ниже. В случае ориентированного графа матрица инцидентности не сильно меняется, за исключением того, что на пересечении-ой вершины и-ого ребра ставится 1, когда дугавходит в вершинуи -1, когда выходит. Для экономии памяти может использоваться список смежности, который представляет из себя набор списков по числу вершин в графе. Каждый список представляет из себя перечисление всех смежных данной вершине. В случае ориентированного графа список смежности выглядит аналогичным образом. В некоторых случаях удобнее использовать список рёбер. Он представляет собой перечисление всех рёбер графа. Пример приведен ниже. Подумайте, а какой вариант хранения графа в памяти компьютера самый оптимальный. Почему?"
            }
        ]
    },
    {
        "id": "q_0161",
        "question": "Какие структуры данных можно использовать для хранения графа в памяти?",
        "answers": [
            "Граф можно хранить с помощью матрицы смежности, матрицы инцидентности, списка смежности или списка рёбер."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/predstavlenie-grafa-v-pamyati-kompyutera",
                "text": "Теперь вы умеете представлять граф в памяти с помощью разных структур: матриц и списков. Вы знаете, в каких задачах использовать матрицу смежности, а где лучше подойдёт список смежности или рёбер. Далее — перейдём к алгоритмам работы с графами. Начнём с базового действия — обхода графа, то есть последовательного просмотра всех его вершин и рёбер. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Граф можно хранить с помощью матрицы смежности, инцидентности, списка смежности или списка рёбер. Выбор способа зависит от размера графа, плотности связей и требований к скорости доступа. Нет универсального способа — у каждого формата есть свои плюсы и минусы. Эффективное представление графа — залог быстрого и надёжного алгоритма."
            }
        ]
    },
    {
        "id": "q_0162",
        "question": "Какие основные операции поддерживает структура данных, позволяющая добавлять и удалять элементы с обоих концов?",
        "answers": [
            "Дек поддерживает операции добавления элемента в начало (push_front) и конец (push_back), а также удаления элемента из начала (pop_front) и конца (pop_back). Все эти операции обычно выполняются за O(1) при эффективной реализации."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dek-(veque-double-ended-queue)",
                "text": "Что такое дек и как он отличается от обычной очереди или стека? Какие операции поддерживает дек и с какой сложностью? Как реализовать дек на практике и где он пригодится?"
            }
        ]
    },
    {
        "id": "q_0163",
        "question": "Какие операции поддерживает структура данных дек относительно её концов?",
        "answers": [
            "Дек поддерживает добавление и удаление элементов как в начало, так и в конец структуры."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dek-(veque-double-ended-queue)",
                "text": "Дек (deque, double-ended queue) — универсальная структура данных; представляет собой последовательность элементов, у которой есть два конца. Причём добавление и удаление элементов может происходить как в начало, так и в конец структуры. Структура дека обладает следующими особенностями: Доступ к первому и последнему элементу производится за константное время. Доступ к элементам в середине дека осуществляется за линейное время, так как элементы хранятся последовательно. В целом дек представляет собой смесь стека и очереди. Структура дек может реализовываться различными способами, например с использованием двух стеков или двусвязного списка."
            }
        ]
    },
    {
        "id": "q_0164",
        "question": "Какая структура данных позволяет добавлять и удалять элементы с обеих сторон за константное время?",
        "answers": [
            "Дек (двусторонняя очередь) позволяет добавлять и удалять элементы с обоих концов за O(1), совмещая свойства очереди и стека."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dek-(veque-double-ended-queue)",
                "text": "Теперь вы умеете использовать дек — структуру, которая совмещает свойства очереди и стека. Вы увидели, как с помощью дека можно реализовать гибкие алгоритмы обработки данных с доступом к обоим концам последовательности. Далее — базовые структуры стека и очереди, с помощью которых можно удобно организовывать данные в процессе выполнения алгоритмов. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Дек — структура данных, которая позволяет добавлять и удалять элементы с обеих сторон за O(1). Он совмещает поведение очереди и стека, сохраняя гибкость и эффективность. Часто используется в задачах, где нужен доступ к краям списка или симметричная обработка элементов."
            }
        ]
    },
    {
        "id": "q_0165",
        "question": "Какая проблема возникает у стандартной быстрой сортировки при обработке массивов с повторяющимися элементами?",
        "answers": [
            "Стандартная быстрая сортировка может деградировать до квадратичной сложности O(n²) на массивах с большим количеством повторяющихся элементов, так как разбиение становится несбалансированным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
                "text": "Почему стандартная быстрая сортировка может работать медленно на массивах с повторяющимися элементами? Как изменить алгоритм так, чтобы избежать деградации производительности? Как реализовать трёхчастное разбиение и почему оно даёт прирост в эффективности?"
            }
        ]
    },
    {
        "id": "q_0166",
        "question": "Какое ожидаемое время выполнения алгоритма RandomizedQuickSort, описанного в псевдокоде?",
        "answers": [
            "В псевдокоде указано, что ожидаемое время выполнения алгоритма составляет O(n log n)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
                "text": "Скопировать код1RandomizedQuickSort(c):2if|c| <=1: # тут и сортировать нечего3returnc4m =random_choice(c) # выбираем случайный элемент из массива5определяем элементы c_small меньшие m6определяем элементы c_large большие m7RandomizedQuickSort(c_small) # рекурсивный вызов алгоритма8RandomizedQuickSort(c_large)9объединяем c_small, m и c_large в итоговый массив c_sorted10returnc_sorted В этом псевдокоде подразумевается, что все элементы массива разные. Ожидаемое время выполнения алгоритма составляет."
            }
        ]
    },
    {
        "id": "q_0167",
        "question": "Как можно изменить алгоритм RandomizedQuickSort для эффективной обработки массивов с множеством повторяющихся элементов?",
        "answers": [
            "Входной массив разделяется на три подмассива: элементы меньше опорного, равные ему и элементы больше. Это позволяет избежать деградации производительности при наличии дубликатов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
                "text": "Алгоритм легко изменить для случая, когда в этом массиве есть повторы. Чтобы это сделать, пусть всодержатся все элементы со значением не более, а не элементы со значением менее. Тем не менее такая модификация становится медленной даже относительно ожидаемого времени выполнения. Например, если все элементыодинаковы,разделяется на две части: размерсоставляет, а внет элементов. Так как это разделение требует отRandomizedQuickSortвремени, общее время выполнения составляет: то естьвместо. Ваша цель — изменить описанный выше алгоритмRandomizedQuickSortтак, чтобы даже при последовательностях с множеством повторяющихся элементов ожидаемое время выполнения стало. Формат ввода: Первая строка содержит целое число. В следующей строке содержится последовательность изцелых чисел. Формат вывода: Вывод последовательности в неубывающем порядке. Ограничения:;для всех. Для ускоренияRandomizedQuickSortмы разделим входной массив на три подмассива: элементы меньше опорного, равные ему и элементы больше. В более простом подходе достаточно сканировать массив трижды и собрать необходимые элементы. Продемонстрируйте, как разделить массив на три части (меньше опорного элемента m, равняется ему и больше него) на месте— без использования дополнительной памяти."
            }
        ]
    },
    {
        "id": "q_0168",
        "question": "Как можно избежать деградации быстрой сортировки при наличии большого числа одинаковых элементов?",
        "answers": [
            "Для этого применяется модификация с трёхчастным разбиением, которая разделяет элементы на три группы: меньше опорного, равные опорному и больше опорного. Это делает сортировку стабильной по времени и предотвращает худшие сценарии."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
                "text": "Теперь вы умеете модифицировать быструю сортировку так, чтобы она оставалась эффективной даже при наличии большого числа одинаковых элементов. Вы освоили идею трёхчастного разбиения и поняли, как оно помогает избежать худших сценариев и ускорить работу алгоритма. Далее — задача на подсчёт инверсий. Вы узнаете, как можно сочетать сортировку и рекурсию, чтобы вычислять количество нарушений порядка быстрее, чем простым перебором. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Стандартная быстрая сортировка может деградировать, если в данных много одинаковых значений. Модификация с трёхчастным разбиением (на меньше, равные и больше опорного) делает сортировку стабильной по времени. Случайный выбор опорного элемента помогает избежать худших случаев. Алгоритм остаётся простым, но работает существенно быстрее в практических задачах."
            }
        ]
    },
    {
        "id": "q_0169",
        "question": "Какие методы помогают обнаружить ошибки, которые не видны при стандартной проверке?",
        "answers": [
            "Стресс-тестирование позволяет выявить ошибки, незаметные при обычной проверке, за счёт тестирования алгоритма на большом количестве случайных данных и сравнения его результатов с эталонным решением."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "Почему наивное решение не всегда укладывается в ограничение по времени? Как реализовать быстрый и надёжный алгоритм для вычисления максимального попарного произведения? Зачем нужно стресс-тестирование и как оно помогает найти ошибки, незаметные при обычной проверке?"
            }
        ]
    },
    {
        "id": "q_0170",
        "question": "Какие данные содержатся во второй строке входных данных для вычисления максимального попарного произведения?",
        "answers": [
            "Во второй строке содержатся n неотрицательных целых чисел, разделённых пробелами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "Разберём чуть более сложную задачу. Итак, вам дана последовательность неотрицательных целых чисел. Вычислите Обратите внимание, чтоидолжны быть разными, хотя в каких-то случаях можно наблюдать, что. Формат ввода: Первая строка содержит целое число. Следующая строка содержитнеотрицательных целых чисел(разделены пробелами). Формат вывода: Максимальное попарное произведение. Ограничения:;. Примеры"
            }
        ]
    },
    {
        "id": "q_0171",
        "question": "Какой алгоритм для нахождения максимального попарного произведения элементов массива может быть слишком медленным при больших размерах входных данных?",
        "answers": [
            "Наивный алгоритм MaxPairwiseProductNaive, который перебирает все возможные пары элементов массива, может быть слишком медленным. При размере массива n он выполняет порядка n² шагов, что при больших n может занимать десятки секунд и превышать временные ограничения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "Наивный способ решить задачуМаксимальное произведение— перебрать все возможные пары вводных элементови найти пару, которая даёт наибольшее произведение. Скопировать код1MaxPairwiseProductNaive(A[1..n]):2product =03fori from1to n4forj from1to n5ifi != j6ifproduct <A[i] * A[j]7product = A[i] * A[j]8returnproduct Этот код можно оптимизировать и сократить следующим образом. Скопировать код1MaxPairwiseProductNaive(A[1..n]):2product =03fori from1to n4forj from i+1to n5product =max(product, A[i] * A[j])6returnproduct Реализуйте этот алгоритм, используя ваш любимый язык программирования. Если вы используетеC++,JavaилиPython3, вам могут пригодиться начальные заготовки (для всех задач из хендбука мы предлагаем стартовые заготовки с использованием этих трёх языков в интерфейсе тестирующей системы). С другими языками вам понадобится сделать работу с нуля. Стартовые заготовки решений дляC++,JavaиPython3представлены ниже. Скопировать код1#include<iostream >2#include<vector >3#include<algorithm >45intMaxPairwiseProduct(conststd::vector <int>&numbers){6intmax_product =0;7intn = numbers.size();89for(intfirst =0; first <n; ++first) {10for(intsecond = first +1; second <n; ++second) {11max_product = std::max(max_product,12numbers[first] * numbers[second]);13}14}1516returnmax_product;17}1819intmain(){20intn;21std::cin >>n;22std::vector <int>numbers(n);23for(inti =0; i <n; ++i) {24std::cin >>numbers[i];25}2627std::cout <<MaxPairwiseProduct(numbers) <<\"\\n\";28return0;29} Скопировать код1importjava.util.*;2importjava.io.*;34publicclassMaxPairwiseProduct{5staticintgetMaxPairwiseProduct(int[] numbers){6intmax_product=0;7intn=numbers.length;89for(intfirst=0; first <n; ++first) {10for(intsecond=first +1; second <n; ++second) {11max_product = Math.max(max_product,12numbers[first] * numbers[second]);13}14}1516returnmax_product;17}1819publicstaticvoidmain(String[] args){20FastScannerscanner=newFastScanner(System.in);21intn=scanner.nextInt();22int[] numbers =newint[n];23for(inti=0; i <n; i++) {24numbers[i] = scanner.nextInt();25}26System.out.println(getMaxPairwiseProduct(numbers));27}2829staticclassFastScanner{30BufferedReader br;31StringTokenizer st;3233FastScanner(InputStream stream) {34try{35br =newBufferedReader(new36InputStreamReader(stream));37}catch(Exception e) {38e.printStackTrace();39}40}4142Stringnext(){43while(st ==null|| !st.hasMoreTokens()) {44try{45st =newStringTokenizer(br.readLine());46}catch(IOException e) {47e.printStackTrace();48}49}50returnst.nextToken();51}5253intnextInt(){54returnInteger.parseInt(next());55}56}5758} Скопировать код1defmax_pairwise_product(numbers):2n =len(numbers)3max_product =04forfirstinrange(n):5forsecondinrange(first +1, n):6max_product =max(max_product,7numbers[first] * numbers[second])89returnmax_product101112if__name__ =='__main__':13_ =int(input())14input_numbers =list(map(int,input().split()))15print(max_pairwise_product(input_numbers)) После проверки вы можете увидеть такое сообщение: Дело в том, что мы проверяем ваше решение на тестовых примерах — это помогает убедиться, что программа работает быстро и без ошибок. В результате мы, как правило, знаем, какие ошибки вы допустили. Сообщение выше говорит о том, что предложенная программа превышает ограничение по времени в 4-м тестовом примере из 17. MaxPairwiseProductNaiveвыполняет порядкашагов при последовательности длиной. При максимальном возможном значенииколичество шагов будет порядка. Так как большинство современных компьютеров выполняют около–базовых операций в секунду (разумеется, это зависит от компьютера), выполнениеMaxPairwiseProductNaiveможет занять десятки секунд. Это превысит временное ограничение задачи. Нам нужен более быстрый алгоритм!"
            }
        ]
    },
    {
        "id": "q_0172",
        "question": "Какой алгоритм предлагается для нахождения максимального попарного произведения в последовательности чисел?",
        "answers": [
            "Алгоритм MaxPairwiseProductFast выполняет два последовательных сканирования массива: сначала находит индекс максимального элемента, затем находит индекс второго по величине элемента, игнорируя значение максимального. Результатом является произведение этих двух элементов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "А что если внимательнее рассмотреть более мелкие примеры— скажем,? Эврика! Достаточно помножить два самых больших элемента массива —и. То есть нам достаточно просканировать последовательность лишь дважды. При первом сканировании мы найдем самый большой элемент, затем — второй по величине. Скопировать код1MaxPairwiseProductFast(A[1..n]):2index_1 =13fori from2to n4ifA[i] >A[index_1]5index_1 = i6index_2 =17fori from2to n8ifA[i] != A[index_1]andA[i] >A[index_2]9index_2 = i10returnA[index_1] * A[index_2]"
            }
        ]
    },
    {
        "id": "q_0173",
        "question": "Какой тип данных в C++ рекомендуется использовать для вычисления произведения в алгоритме MaxPairwiseProductFast, чтобы избежать целочисленного переполнения?",
        "answers": [
            "Для предотвращения целочисленного переполнения в C++ рекомендуется использовать тип int64_t вместо стандартного int, так как int64_t занимает 8 байтов и может хранить значения от -2^63 до 2^63-1."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "Реализуйте этот алгоритм и протестируйте его на вводе. Как и ожидалось, алгоритм выводит. Затем проверьте на вводе. На удивление, алгоритм выводит. Изучив код, вы обнаружите, что после первого цикла. Далее алгоритм инициализируетзначением, и цикл for не обновляет. В результате перед возвратом. Чтобы этого избежать, необходимо изменить псевдокод следующим образом: Скопировать код1MaxPairwiseProductFast(A[1..n]):2index_1 =13fori from2to n4ifA[i] >A[index_1]:5index_1 = i6ifindex_1 =17index_2 =28else:9index_2 =110fori from1to n11ifA[i] != A[index_1]andA[i] >A[index_2]12index_2 = i13returnA[index_1] * A[index_2] Опробуйте этот код на маленьких наборах данных, чтобы убедиться, что он выдает правильные результаты. Затем попробуйте ввод. Может оказаться, что программа выдает что-то вродеили даже отрицательное число вместо правильного результата —. Вероятнее всего, это вызвано целочисленным переполнением. Например, на языкеC++такое большое число, как, не умещается в стандартный типint, который занимает 4 байта на большинстве компьютеров и варьируется отдопри Соответственно, вместо использования типаintвC++при вычислении произведения и сохранении результата вам нужно использовать типint64_t. Это предотвратит целочисленное переполнение, так как типint64_tзанимает 8 байтов и хранимые значения варьируются отдопри Протестируйте вашу программу с большими наборами данных, например с массивом, гдедля всех. Это можно сделать двумя способами: Создать массив в программе и передать егоMaxPairwiseProductFast(чтобы не считывать его из стандартного ввода). Создать отдельную программу, которая запишет такой массив в файлdataset.txt. Затем передать этот набор данных вашей программе из консоли: Убедитесь, что при обработке данных ваша программа укладывается в ограничение по времени и выдаёт верный результат:. Теперь вы можете быть уверенным, что ваша программа работает! Однако система оценки снова ругается: Но как создать такой тестовый сценарий, который приведет к сбою программы и поможет понять, что с ней не так? Вероятно, вас интересует, почему мы не предоставили 5-й набор данных из 17 — тот, который привел к сбою программы? Причина проста: в реальности вам не будут показывать тестовые примеры. Даже опытные программисты при решении задач с алгоритмами часто совершают ошибки, которые трудно обнаружить. Поэтому важно научиться находить баги как можно раньше. Когда авторы этой книги только начинали программировать, они ошибочно полагали, что почти все их программы правильные. Сейчас же мы знаем, что при первом запуске наши программы почти никогда не верны. Когда разработчик уверен в работе своей программы, он зачастую использует всего лишь несколько примеров для тестирования. Если результаты выглядят приемлемо, он считает свою работу законченной — но это путь к катастрофе. Если вы хотите убедиться, что ваша программа работает всегда, то советуем тщательно подобрать примеры для тестирования. Реализация алгоритмов, а также их тестирование и отладка будут бесценным навыком для вашей будущей карьеры программиста. Представляем вам стресс-тестирование — технику, которая позволяет генерировать тысячи тестовых сценариев. С её помощью можно найти тот, из-за которого провалилось ваше решение. Стресс-тестирование состоит из четырёх частей: Реализация алгоритма. Альтернативная, банальная и медленная, но правильная реализация алгоритма для той же самой задачи. Генератор случайных тестов. Бесконечный цикл, генерирующий тесты и передающий их обоим вариантам реализации для сравнения результатов. Если результаты разнятся, выводятся оба результата и пример для тестирования, а программа останавливается. В ином случае цикл повторяется. Стресс-тестирование основано на идее, что две правильных реализации с каждым тестом должны приводить к одному ответу (при условии, что ответ на задачу уникален). Однако если одна из реализаций неправильна, должен существовать такой тест, который приводит к разным ответам. Единственный случай, при котором это не так, — когда в обеих реализациях есть одна и та же ошибка. Но это маловероятно — если ошибка не где-то в программе ввода/вывода, общей для обоих решений. Действительно, если одно решение правильно, а другое — нет, то существует сценарий тестирования, при котором они различаются. Если оба решения неверны, но баги отличаются — скорее всего, есть тест, при котором два решения дают разные результаты. Продемонстрируем стресс-тестированиеMaxPairwiseProductFast, используя MaxPairwiseProductNaiveв качестве тривиальной реализации: Скопировать код1StressTest(N, M):2whiletrue:3n = ...// случайное целое число между 2 и N4// создать массив A[1..n]5fori from1to n6A[i] = ...// случайное целое число между 0 и M7print(A[1..n])8result_1 =MaxPairwiseProductNaive(A)9result_2 =MaxPairwiseProductFast(A)10ifresult_1 = result_2:11print(\"OK\")12else:13print(\"Wrong answer:\", result_1, result_2)14return Представленный выше циклwhileсначала генерирует длину вводной последовательности, случайное число междуи. Оно должно быть не менее: формулировка задачи гласит, что. Параметрдолжен быть достаточно маленьким, чтобы позволить нам рассмотреть множество тестов, несмотря на то, что наши решения медленные. Сгенерировав, мы генерируем массивсцелыми числами отдои выводим его, чтобы по ходу бесконечного цикла мы всегда знали, какой тест проходит сейчас. Это упростит нахождение ошибок в коде для генерации теста. Затем мы вызываем два алгоритма дляи сравниваем результаты. Если результаты отличаются, мы их печатаем и останавливаемся. В ином случае мы продолжаем цикл while. Давайте запустимStressTest(10, 100'000)и скрестим пальцы в надежде, что он выдастWrong answer. Для нас это выглядит как-то так (результат может отличаться на вашем компьютере из-за другого генератора случайных чисел). Ура! Мы нашли пример, в которомMaxPairwiseProductNaiveиMaxPairwiseProductFastприводят к разным результатам, и теперь можем проверить, что именно пошло не так. Затем мы отлаживаем это решение через этот пример, находим баг, исправляем его и повторяем стресс-тестирование. Обратите внимание, что генерировать тесты автоматически и проводить стресс-тестирование легко, но находить и исправлять баги — сложно. Прежде чем углубиться в отладку багов, давайте попробуем сгенерировать тестовый пример поменьше — это упростит нам работу. Для этого мы поменяемс 10 на 5 исна. Затем мы заново начинаем стресс-тестирование и получаем следующее: Медленный алгоритмMaxPairwiseProductNaiveдаёт верный ответ(), но быстрыйMaxPairwiseProductFast— неверный (). Чтобы избавиться от багов в первом решении, давайте проверим, какие два числа он считает наибольшими. Для этого мы добавим следующую строку передreturnв функцииMaxPairwiseProductFast: Скопировать код1print(index_1, index_2) Когда мы снова начинаем стресс-тестирование, мы получаем следующее: Это значит, что последовательность выглядит случайной, но она одинакова каждый раз, когда работает программа. Такое свойство удобно и важно. Советуем вам использовать эту практику, потому что в детерминированных программах (тех, что всегда выдают одинаковый результат при одинаковых вводных данных) легче находить баги, чем в недетерминированных. Давайте теперь рассмотрими. Если мы обратим внимание на код для определения второго максимального числа, то заметим неочевидный баг. Когда мы использовали условие для(число не должно быть таким же, как предыдущее самое большое), вместо сравненияимы сравнилии. Это означает, что второе максимальное число отличается от первого по значению, а не по индексу элемента, который мы выбрали для решения задачи. Так, наше решение не работает при любом тесте, в котором второе самое большое число равно первому. Теперь изменим условие: вместо Скопировать код1A[i] != A[index_1] мы используем Скопировать код1i != index_1 Проведя стресс-тестирование еще раз, мы видим на экране шквал сообщенийOK. Ждём минуту, пока нам не надоест, и заключаем, чтоMaxPairwiseProductFastнаконец-то работает правильно! Однако не стоит останавливаться на этом, так как вы сгенерировали только очень маленькие тесты си. Теперь нужно проверить, работает ли наша программа при большеми бо́льших элементах массива. Таким образом, мы меняемна(при большемпримитивное решение будет довольно медленным из-за квадратичного времени выполнения). Мы также меняемнаи запускаем программу. Ещё раз наблюдаем, как экран заполняется сообщениямиOK. Затем ждём минуту, а потом решаем, чтоMaxPairwiseProductFastдействительно работает верно. После этого мы сдаём получившееся решение системе оценки и успешно проходим тест! Как вы можете заметить, даже при решении такой простой задачи какМаксимальное попарное произведениесложно избежать труднораспознаваемых ошибок на этапе проектирования и реализации алгоритма. Приведённый ниже псевдокод — это пример болеенадежногоспособа реализации алгоритма. Скопировать код1MaxPairwiseProductFast(A[1..n]):2index =13fori from2to n4ifA[i] >A[index]:5index = i6swap(A[index], A[n])// поставим наибольшее значение в конец массива7index =1:8fori from2to n -19ifA[i] >A[index]:10index = i11swap(A[index], A[n -1])// поставим второй по величине элемент предпоследним12returnA[n -1] * A[n] В этом хендбуке вы узнаете, как проектировать и реализовывать алгоритмы так, чтобы минимизировать вероятность ошибок. А заодно научитесь тестировать вашу реализацию."
            }
        ]
    },
    {
        "id": "q_0174",
        "question": "Какое минимальное количество сравнений требуется для нахождения двух самых больших элементов в массиве?",
        "answers": [
            "Не существует алгоритма, который может найти два самых больших элемента массива, выполнив менее n сравнений, где n — количество сравнений, требуемое алгоритмом MaxPairwiseProductFast."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "АлгоритмMaxPairwiseProductFastнаходит два самых больших числа примерно засравнений. Когда вы решите эту задачу, вас ждет ещё более сложное упражнение. Попробуйте с ним справиться! Если это упражнение показалось вам слишком простым, посмотрите задачи ниже. Они вполне могут оказаться на следующем собеседовании! Докажите, что не существует алгоритма, которому потребуется менеесравнений, чтобы найти два самых больших элемента массива. Какой алгоритм найдёт три самых больших элемента быстрее всего?"
            }
        ]
    },
    {
        "id": "q_0175",
        "question": "Какой алгоритм используется для решения задачи максимального попарного произведения в приведённом описании?",
        "answers": [
            "Алгоритм MaxPairwiseProductBySorting, который сначала сортирует массив в неубывающем порядке, а затем возвращает произведение двух последних элементов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "ЗадачуМаксимальное попарное произведениеможно решить с помощью следующего компактного алгоритма, который использует сортировку (в неубывающем порядке). Скопировать код1MaxPairwiseProductBySorting(A[1..n]):2Sort(A)3returnA[n-1]*A[n] Этот алгоритм делает даже больше, чем нам нужно: вместо того, чтобы найти два самых больших элемента, он сортирует весь массив. Поэтому его время выполнения, а не. Однако для таких ограничений () он достаточно быстрый, чтобы выполнить задачу за секунду и успешно пройти тесты в нашей системе оценки."
            }
        ]
    },
    {
        "id": "q_0176",
        "question": "Какие умения помогает отработать задача на попарное произведение?",
        "answers": [
            "Задача помогает отработать оценку сложности алгоритма, поиск оптимального решения, работу с переполнением и стресс-тестирование."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
                "text": "Теперь вы увидели, как задача на попарное произведение помогает отработать сразу несколько важных умений: оценку сложности алгоритма, поиск оптимального решения, работу с переполнением и стресс-тестирование. Вы научились сравнивать наивные и быстрые реализации, находить баги и проверять программу на надёжность с помощью генератора случайных тестов. Далее — небольшой параграф с итогами: вспомним, что вы узнали в этой главе, и наметим, куда двигаться дальше. А пока закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Даже в простой на первый взгляд задаче важно учитывать эффективность: наивный перебор может не уложиться в ограничение по времени. Быстрый алгоритм позволяет решить задачу линейно, но требует аккуратности в работе с индексами и типами данных. Стресс-тестирование помогает находить ошибки, которые не видны на демонстрационных примерах, и делает решение по-настоящему надёжным."
            }
        ]
    },
    {
        "id": "q_0177",
        "question": "Какие шаги выполняет алгоритм Дейкстры для нахождения кратчайших путей в графе?",
        "answers": [
            "Алгоритм Дейкстры начинает с выбора начальной вершины, присваивает ей нулевое расстояние, а всем остальным — бесконечность. Затем он последовательно выбирает вершину с наименьшим известным расстоянием, обновляет расстояния до её соседей через текущую вершину, помечает вершину как обработанную и повторяет процесс, пока не будут обработаны все вершины или не будет найдено расстояние до целевой вершины."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-poiska-kratchajshego-puti-v-grafe",
                "text": "Как устроен алгоритм Дейкстры и зачем нужны веса рёбер? Почему алгоритм не работает с отрицательными весами? Как восстановить кратчайший путь после завершения алгоритма?"
            }
        ]
    },
    {
        "id": "q_0178",
        "question": "Каковы условия работы алгоритма Дейкстры?",
        "answers": [
            "Алгоритм Дейкстры работает только для графов без рёбер отрицательного веса."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-poiska-kratchajshego-puti-v-grafe",
                "text": "Зачастую в графах требуется находить между вершинами кратчайшие пути. Один из алгоритмов нахождения кратчайших путей от заданной вершины до любой другой — алгоритм Дейкстры. Алгоритм работает только для графов без рёбер отрицательного веса. Асимптотическая сложность нахождения компонент связности в графе — O(V+E), где V — число вершин, а E — число рёбер и дуг. Опишем принцип работы алгоритма Дейкстры: Шаг 1. Всем вершинам, за исключением первой, присваивается вес равный бесконечности, а первой вершине — 0. Шаг 2. Все вершины не посещены. Шаг 3. Первая вершина объявляется текущей. Шаг 4. Вес всех невыделенных вершин пересчитывается по формуле: вес невыделенной вершины есть минимальное число из старого веса данной вершины, суммы веса текущей вершины и веса ребра, соединяющего текущую вершину с невыделенной. Шаг 5. Среди невыделенных вершин ищется вершина с минимальным весом. Если такова не найдена, то есть вес всех вершин равен бесконечности, то маршрута не существует. Следовательно, выход. Иначе, текущей становится найденная вершина. Она же выделяется. Шаг 6. Если текущей вершиной оказывается конечная, то путь найден, и его вес есть вес конечной вершины. Шаг 7. Переход на шаг 4. Пример работы алгоритма показан на картинке ниже. Посмотрим на реализацию. Скопировать код1Dijkstra(graph, start, finish, used):2vectord(n, inf),p(n,-1)3n=len(graph)4graph[v] =15for(inti =0; i <n; ++i)6intv =-17for(intj =0; j <n; ++j)8if(!used[j]and(v ==-1ord[j] <d[v]))9v = j10used[v] =true11for(intj =0; j <len(graph[v]); ++j)12to = graph[v][i].vertex13len = graph[v][i].edge14if(d[v] + len <d[to])15d[to] = d[v] + len16p[to] = v Асимптотическая сложность алгоритма Дейкстры —, где— число вершин, а— число рёбер и дуг. Подумайте, как восстановить путь, используя введённый массив p? Как изменится кратчайший путь, если все веса рёбер увеличить на какое-то число? Как изменится кратчайший путь, если все веса рёбер увеличить в какое-то число раз? Подумайте, почему алгоритм работает только для графов без рёбер отрицательного веса?"
            }
        ]
    },
    {
        "id": "q_0179",
        "question": "В каких случаях алгоритм Дейкстры не работает корректно?",
        "answers": [
            "Алгоритм Дейкстры не работает корректно при наличии в графе рёбер с отрицательными весами. Для таких случаев требуются другие подходы, например, алгоритм Беллмана — Форда."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-poiska-kratchajshego-puti-v-grafe",
                "text": "Теперь вы умеете находить кратчайшие пути в графах с помощью алгоритма Дейкстры. Вы научились пошагово уточнять расстояния до вершин, работать с массивом предков и восстанавливать путь. Вы также поняли, в каких случаях алгоритм применим, а в каких — нет. Далее — завершение главы. Мы кратко подведём итоги, сравним изученные подходы и обобщим стратегии, которые помогут вам уверенно решать задачи на графы. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Алгоритм Дейкстры находит кратчайшие пути от одной вершины до всех остальных в графе без отрицательных рёбер. Идея алгоритма — постепенно уточнять расстояния, переходя от ближайших вершин к более дальним. Для восстановления пути используется массив предков. Алгоритм не работает корректно при наличии отрицательных весов — для таких случаев нужны другие подходы (например, Беллмана — Форда)."
            }
        ]
    },
    {
        "id": "q_0180",
        "question": "Какой подход к сравнению строк чисел позволяет получить максимальное число при их конкатенации?",
        "answers": [
            "Для получения максимального числа при конкатенации строк чисел необходимо использовать компаратор, который сравнивает не сами числа, а результаты их попарной конкатенации в разном порядке. Например, для чисел a и b нужно сравнить строки a+b и b+a, и расположить их так, чтобы большая конкатенация шла первой."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnyj-oklad",
                "text": "Почему обычная сортировка по убыванию не работает для составления максимального числа? Как сравнивать строки чисел, чтобы результат был действительно максимальным? Какие ошибки чаще всего возникают при реализации таких задач — и как их избежать?"
            }
        ]
    },
    {
        "id": "q_0181",
        "question": "Какой алгоритм используется для составления самого большого числа из нескольких чисел, но требует модификации для правильной работы с многозначными числами?",
        "answers": [
            "Алгоритм LargestConcatenate, который последовательно выбирает максимальное число из оставшихся и добавляет его в конец строки-результата. Для правильной работы с многозначными числами нужно заменить сравнение чисел на функцию IsBetter, которая определяет, какое число следует ставить раньше."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnyj-oklad",
                "text": "Перед вами, возможно, самая важная задача в хендбуке. В качестве последнего вопроса на собеседовании будущий начальник даёт вам пять бумажек с одним числом на каждой и просит составить из них самое большое число. Получившееся число — ваша зарплата, поэтому мотивация, чтобы решить эту задачу, зашкаливает. Вспомните алгоритм для этой задачи, который работает с однозначными числами. Скопировать код1LargestConcatenate(Numbers):2yourSalary =\"\"# пустая строка3whileNumbers isnotempty:4maxNumber = -infinity5foreach number in Numbers:6ifnumber >= maxNumber:7maxNumber = number8yourSalary = yourSalary + maxNumber # добавляем число в конец9Numbers.remove(maxNumber) # удалить из рассмотрения число maxNumber10returnyourSalary Такой алгоритм не всегда будет приводить к самой большой зарплате: например, при вводе из двух целых чисел 23 и 3 он выдаст 233, в то время как самое большое число — 323. Не беспокойтесь, чтобы получить самую большую зарплату, вам всего лишь нужно заменить строку Скопировать код1ifnumber >= maxNumber: на следующую: Скопировать код1ifIsBetter(number, maxNumber):2 Для надлежаще реализованной функцииIsBetterнужно учесть порядок цифр и их количество. ФункцииIsBetter(first, second)должна возвращать булеву величину сооветствующую ответу на вопрос: нужно ли ставить числоfirstраньше числаsecond. Например,IsBetter(3, 23)выдастTrue. Входные данные: Первая строка ввода содержит целое число. Вторая строка содержит целые числа. Выходные данные: Самое большое возможное число, которое состоит из. Ограничения:;для всех. Обратите внимание, что в этом случае приведённый выше алгоритм также выдаёт неправильный ответ 212. Ввод состоит только из однозначных чисел, поэтому алгоритм выше выдаёт правильный ответ. Тем не менее алгоритмLargestConcatenate(неверный) в этом случае приводит к правильному результату — ещё одно напоминание, что всегда стоит проверять правильность жадных алгоритмов!"
            }
        ]
    },
    {
        "id": "q_0182",
        "question": "Какой способ сравнения строк не всегда даёт правильный результат при попытке получить максимальное число из их объединения?",
        "answers": [
            "Простая сортировка строк в порядке убывания не всегда работает корректно. Для получения максимального числа при объединении строк необходимо использовать специальное правило сравнения, учитывающее результат их конкатенации, а не стандартный алфавитный порядок."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnyj-oklad",
                "text": "Теперь вы знаете, как применять жадную стратегию не только к числам, но и к строкам. Вы научились сравнивать строки так, чтобы получить максимальное число, — и поняли, что простой порядок убывания не всегда работает. Эта задача — отличный пример того, как важно выбрать правильный критерий сравнения, даже если идея кажется простой. Далее — подведение итогов. Вы вспомните, какие приёмы жадных алгоритмов вы освоили, в чём их сила и в чём ограничения. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. В некоторых задачах важно уметь сравнивать строки нестандартным способом — не по алфавиту, а по результату объединения. Простая сортировка не всегда даёт правильный результат: нужно чётко задать правило, по которому элементы упорядочиваются. Жадные стратегии применимы и к строкам, но требуют особенно внимательной формулировки критерия выбора."
            }
        ]
    },
    {
        "id": "q_0183",
        "question": "Какие этапы включает в себя процесс решения алгоритмической задачи программистом?",
        "answers": [
            "Программист проходит несколько шагов при решении алгоритмической задачи, а затем проверяет корректность и эффективность решения перед его сдачей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/prakticheskie-zadaniya-s-avtomaticheskoj-proverkoj",
                "text": "Какие шаги проходит программист при решении алгоритмической задачи? Как проверить корректность и эффективность своего решения до его сдачи?"
            }
        ]
    },
    {
        "id": "q_0184",
        "question": "Какие языки программирования поддерживаются системой автоматической оценки?",
        "answers": [
            "Система поддерживает C++, Java и Python3."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/prakticheskie-zadaniya-s-avtomaticheskoj-proverkoj",
                "text": "Чтобы рассказать, как работает наша система автоматической оценки, мы по шагам разберём две простые задачи. А заодно покажем несколько распространённых проблем и способы их преодоления. Итак, решение задач по программированию состоит из пяти шагов: Разбор условия задачи.Формулировка задачи указывает формат ввода и вывода, ограничения для данных ввода и использования памяти. От вас требуется написать быструю программу, которая уложится в ограничения по времени и использованию памяти. Проектирование алгоритма.Когда вы поняли, в чём состоит задача, начинайте проектировать алгоритм. Не забудьте доказать, что он работает правильно. Реализация алгоритма.Когда алгоритм спроектирован, его можно реализовать в вашем языке программирования. Тестирование и отладка.Тестирование — это искусство поиска багов. Отладка — это искусство устранения багов. Когда программа готова, приступайте к тестированию! А если обнаружите баг — исправьте его и протестируйте программу снова. Отправка программы на оценку.Когда программа протестирована, сдайте её системе оценки. Если вы увидите сообщениеOK, значит всё в порядке. Если нет — возвращайтесь к предыдущим шагам. Для начала прочтите формулировку задачи. В неё входят описание вычислительной части, ограничения по времени и использованию памяти и несколько демонстрационных тестов. Убедитесь, что вы понимаете, как вывод соотносится с вводом в каждом из демонстрационных примеров. Если ограничения по времени и памяти не указаны прямо в формулировке задачи, используются следующие значения по умолчанию. Ограничение по времени (с):1 Ограничение памяти:512 Mb Когда вы разработали алгоритм, докажите, что он работает верно, и попробуйте оценить время выполнения с помощью самых сложных вводных данных, указанных в секции об ограничениях. Если ваш ноутбук выполняет около–операций в секунду, и максимальный размер набора данных в описании задачи, тогда алгоритм с квадратичным временем выполнения вряд ли уложится в ограничение по времени (так как), в то время как решение с временем выполнениясможет это сделать. Тем не менее решение сподойдёт, еслии если. Сработать могут даже решения с. Хотя для некоторых трудных задач в книге полиномиальные алгоритмы и остаются неизвестными, решение с временем выполненияможет уложиться в ограничение по времени приниже. Начните реализацию алгоритма на одном из языков программирования, которые поддерживаются нашей системой автоматической оценки. Напоминаем, это:C++,Java,Python3. ДляC++,Java, иPython3есть примеры (авторские решения) с правильным решением задачи, учитывающие ее ограничения. Они тратят максимум 1/3 заданного лимита по времени и максимум 1/2 по памяти. Сдавать вашу реализацию на оценку, не проверив её, — это плохая идея! Начните с маленьких наборов данных и убедитесь, что ваша программа выдаёт верный результат со всеми предложенными наборами данных. Затем проверьте, сколько времени занимает обработка большого набора данных. Для оценки времени выполнения имеет смысл реализовать ваш алгоритм как функцию — например,solve(dataset)— и потом реализовать дополнительную процедуруgenerate(), которая выдаст большой набор данных. Например, если ввод задачи — это последовательность целых чисел длиной, тогда сгенерируйте последовательность длиной, передайте её функцииsolve()и убедитесь, что программа выдаёт правильный результат. Проверьте ограничивающие значения, чтобы можно было гарантировать, что программа правильно обрабатывает и короткие (например, из 2 элементов), и длинные последовательности (например, из 105105 элементов). Если последовательность целых чисел от 00 до 106106 даётся в качестве ввода — проверьте, как ваша программа ведёт себя с последовательностью 0,0,…,00,0,…,0 или с 106,106,…,106106,106,…,106. После этого проверьте программу на случайном наборе данных. Дополнительно советуем проверить экстремальные случаи: пустой набор данных, три точки на одной строке, дерево из одного узла и так далее. Убедившись, что ваша программа выполняет все эти тесты, переходите к стресс-тестированию. Реализуйте медленный, но простой и верный алгоритм. Проверьте, выдают ли две программы одинаковый результат, — однако обратите внимание, что это не применимо к задачам, в которых вывод не уникален. Сгенерируйте случайные тестовые сценарии, а также тесты с изменением параметров — например, с использованием только маленького диапазона больших чисел, строки с одной буквойaили только двумя разными буквами (вместо строк, использующих все буквы латинского алфавита) и так далее. Подумайте, какие ещё тесты могут быть в каком-то смысле необычными. Например, если вы генерируете графы, попробуйте генерировать древовидные, несвязные, полные, двудольные и так далее. Если вы генерируете древовидные графы, попробуйте генерировать пути, двоичные деревья, звезды и так далее. Если вы генерируете целые числа, попробуйте генерировать и простые, и составные числа. Когда вы закончили тестирование, сдавайте вашу программу на проверку. Перейдите на страницу, где сдаются задания, и создайте новое выполненное задание. Загрузите файл с вашей программой (обязательно загрузите исходный файл, а не готовое приложение). После этого система оценки скомпилирует вашу программу и использует набор тщательно продуманных тестов, чтобы убедиться, что программа выдаёт правильный результат для всех тестов и что она укладывается в ограничения по времени и памяти. В большинстве случаев оценка занимает около минуты, но в редких случаях, когда серверы загружены, может потребоваться больше времени. Пожалуйста, наберитесь терпения. После загрузки решения можно спокойно уходить со страницы. В качестве результата вы получите обратную связь от системы оценки. Вам нужно получить вердиктOK— он обозначает, что ваша программа прошла все тесты. СообщенияWrong answer,Time limit exceeded,Memory limit exceededозначают, что программа не прошла тест по одной из этих причин. Если ваша программа даёт сбой, проходя один из первых двух тестовых сценариев, система оценки скажет вам об этом и покажет тестовый сценарий и вывод вашей программы. Это должно помочь вам использовать правильный формат ввода/вывода. В остальных случаях система оценки не будет показывать вам тестовый сценарий, который ваша программа не смогла выполнить."
            }
        ]
    },
    {
        "id": "q_0185",
        "question": "Какие пять ключевых этапов включает в себя решение задачи по программированию?",
        "answers": [
            "Решение задачи по программированию проходит через пять этапов: разбор условия, проектирование алгоритма, реализация, тестирование и анализ результатов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/prakticheskie-zadaniya-s-avtomaticheskoj-proverkoj",
                "text": "Теперь вы понимаете, как проходит полный цикл работы над задачей: от разбора условия до уверенного тестирования решения. Вы научились не только писать алгоритмы, но и проверять их корректность и производительность. Далее — простейшая задача, с которой удобно начать практику. Вы увидите, как её можно решить на C++, Java и Python 3, и попробуете реализовать свой первый рабочий код. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Решение задачи по программированию проходит через пять ключевых этапов: разбор условия, проектирование алгоритма, реализация, тестирование и анализ результатов. Оценка корректности и эффективности алгоритма помогает убедиться, что решение работает правильно и укладывается в заданные ограничения. Хорошее тестирование — это не просто проверка на примерах, а систематический подход: граничные случаи, случайные данные, стресс-тесты."
            }
        ]
    },
    {
        "id": "q_0186",
        "question": "Какая проблема возникает у стандартной быстрой сортировки при обработке массивов с повторяющимися элементами?",
        "answers": [
            "Стандартная быстрая сортировка может деградировать до квадратичной сложности O(n²) на массивах с большим количеством повторяющихся элементов, так как разбиение становится несбалансированным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
                "text": "Почему стандартная быстрая сортировка может работать медленно на массивах с повторяющимися элементами? Как изменить алгоритм так, чтобы избежать деградации производительности? Как реализовать трёхчастное разбиение и почему оно даёт прирост в эффективности?"
            }
        ]
    },
    {
        "id": "q_0187",
        "question": "Какой элемент считается доминирующим в последовательности согласно условию задачи?",
        "answers": [
            "Элемент считается доминирующим, если он встречается в последовательности больше, чем n/2 раз, где n — длина последовательности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
                "text": "Ваша задача — проверить, содержит ли данная последовательность элемент, который встречается более половины раз. Формат ввода: Первая строка содержит целое число, следующая — последовательностьцелых неотрицательных чисел. Формат вывода: Выведите, если в последовательности содержится элемент, который встречается больше, чемраз, ив противном случае. Ограничения:;для всех. Примеры: В первом примере— доминирующий элемент. Во втором примере у последовательности нет доминирующего элемента. Обратите внимание, что элемент— не доминирующий. Здесь приведён примитивный алгоритм, который решает задачу «Поиск доминирующего элемента» за квадратичное время: Скопировать код1MajorityElement(A[1..n]):2fori from1to n:3currentElement = A[i]4count =05forj from1to n:6ifA[j] = currentElement:7count = count +18ifcount >n/2:9return110return0 На практике входную последовательность можно просканировать и сохранить число вхождений каждого элемента в ассоциативном массиве. Время выполнения этого решения зависит от конкретной реализации ассоциативного массива. Если реализация представляет собой сбалансированное дерево поиска, тогда каждый уточняющий запрос в массиве занимает, а общее время выполнения составляет. Для хеш-таблиц уточняющие запросы эффективны на практике, хотя и могут варьироваться в зависимости от вводных данных. Стратегия «разделяй и властвуй» приводит к простому алгоритму с временем выполнения. Несложная, но невероятно важная вещь: если— это доминирующий элемент последовательности, тогдадолжен быть доминирующим элементом как минимум в одной из половин. Однако обратите внимание, что обратное неверно: обе половины последовательностисодержат доминирующие элементы (исоответственно), но ни один из них не является доминирующим элементом изначальной последовательности. Это приводит нас к следующему алгоритму: найти доминирующий элемент в обоих половинах с помощью рекурсии и для каждой из половин проверить количество вхождений в изначальную последовательность. Для последнего шага нам необходимо ещё раз сделать линейное сканирование, что может занять время. Следовательно, время выполненияудовлетворяет, поэтому."
            }
        ]
    },
    {
        "id": "q_0188",
        "question": "Какова основная идея алгоритма, описанного в тексте?",
        "answers": [
            "Основная идея заключается в разделении входных элементов на пары. Для каждой пары: если два элемента различны, то оба отбрасываются; если они одинаковы, то отбрасывается только один из них."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
                "text": "Сможете ли вы спроектировать еще более быстрый алгоритм с временем выполнения? В основе лежит следующая идея. Разделить вводные элементы на пары. Рассмотреть каждую пару: если два элемента различны, отбросить оба; в противном случае отбросить один из них."
            }
        ]
    },
    {
        "id": "q_0189",
        "question": "Какой алгоритм позволяет находить доминирующий элемент в последовательности, разбивая задачу на части?",
        "answers": [
            "Для нахождения доминирующего элемента используется стратегия «Разделяй и властвуй», которая разбивает задачу на части. Элемент считается доминирующим, если он встречается больше чем в половине элементов последовательности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
                "text": "Теперь вы умеете модифицировать быструю сортировку так, чтобы она работала эффективно даже на массивах с повторяющимися элементами. Вы узнали, как устроено трёхчастное разбиение, и научились избегать худших случаев, когда обычная реализация деградирует до квадратичного времени. Далее — задача на подсчёт инверсий. Вы увидите, как можно сочетать сортировку и рекурсию, чтобы решать аналитические задачи быстрее, чем простым перебором. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Стратегия «Разделяй и властвуй» позволяет находить доминирующий элемент за, разбивая задачу на части. Элемент считается доминирующим, если он встречается больше чем в половине элементов последовательности. Проверки в обеих половинах не гарантируют общий результат — требуется финальное сканирование. Можно спроектировать и более быстрый алгоритм за, если использовать идею попарного сравнения и отбрасывания."
            }
        ]
    },
    {
        "id": "q_0190",
        "question": "Какие таблицы используются для хранения минимальных и максимальных значений подвыражений при решении задачи группировки?",
        "answers": [
            "Для хранения минимальных и максимальных значений подвыражений создаются две таблицы: одна для минимальных значений, другая — для максимальных. Эти таблицы заполняются в процессе динамического программирования, где каждая ячейка соответствует результату подвыражения в определённом диапазоне исходного выражения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
                "text": "Почему результат арифметического выражения зависит от порядка скобок? Как использовать динамическое программирование для перебора всех вариантов группировки? Как устроены таблицы для хранения минимальных и максимальных значений подвыражений?"
            }
        ]
    },
    {
        "id": "q_0191",
        "question": "Какой максимальной длины может быть входная строка в данной задаче?",
        "answers": [
            "Входная строка может содержать максимум 19 символов, так как n ≤ 9, а длина строки составляет 2n+1."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
                "text": "Для выражениясуществуют два способа расставить скобки:и. Для максимального значения нужно поставить в скобки выражение. Входные данные: Ввод содержит только строкудлинойдля некогос символами. Каждый символ на чётной позиции— это цифра (то есть целое число от 0 до 9), а на нечетной позиции — одна из трёх операций из. Выходные данные: Максимальное значение данного арифметического выражения из всех возможных порядков арифметических операций. Ограничения:— таким образом, строка содержит максимумсимволов. Пример 1 Рассмотрим решение задачи. Каждая из пяти операций в выражении может быть последней — внешней. Рассмотрим случай, в котором последняя операция — «», то есть умножение. В этой ситуации нам необходимо поместить дваподвыраженияв скобки таким образом, чтобы произведение значений было максимальным. Чтобы это выяснить, мы находим минимальные и максимальные значения данных двух подвыражений: На основании этих значений мы заключаем, что общее значение произведения составляет. Предположим, что вводный набор данных имеет форму где каждая— это цифра, а каждая— базовая арифметическая операция. Сказанное выше предполагает, что мы вычисляем минимальное и максимальное значение каждого подвыражения в форме где. Пустьи— минимальное и максимальное значениесоответственно. Тогда Базовый случай — это: Эти два рекуррентных соотношения позволяют нам вычислить оптимальные значения, изучив все возможные варианты разделенияна два подвыраженияи. Тогда наше рекуррентное соотношение говорит о том, что дерево состоит из корня и двух поддеревьев. Для нахождения оптимальной формы дерева мы анализируем все возможные корни (за это отвечает параметр), а затем составляем дерево из двух оптимальных поддеревьев."
            }
        ]
    },
    {
        "id": "q_0192",
        "question": "Какой параметр используется в псевдокоде для перечисления всех пар в порядке возрастания значения?",
        "answers": [
            "В псевдокоде используется параметр s, который определяет размер интервала между индексами l и r (где r = l + s)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
                "text": "Как обычно, сделать из рекуррентного соотношения рекурсивный алгоритм довольно просто. Рекурсивная процедура берёт индексыив качестве параметров и использует их для вычисления минимального и максимального значения подвыражения. Перед тем, как начать вычисления, проверяется, не сохранены ли уже эти значения в, где— это ассоциативный массив, хранящий уже вычисленные результаты. Если записьотсутствует, рекурсивная процедура вычисляет два значения, используя рекуррентное соотношение, сохраняет их в таблицу и выдаёт их. Конечный ответ соответствуети. Время выполнения составляет: естьвозможных пар, для каждой из которых рекурсивная процедура проверяет возможные значения для. Для переведения рекурсивного алгоритма в итерационный используются двумерные таблицыи, в которых хранятся минимальные и максимальные значения всех подвыражений. Заполняя данные таблицы, нам нужно убедиться, что к окончанию вычислений оптимальных значений дляоптимальные значенияидля всехуже вычислены. Один из способов сделать это — перечислить все парыв порядке возрастания значения. Чтобы это сделать, в псевдокоде ниже используется параметр. Скопировать код1MaxValue(d[0],op[0],d[1],op[1],…d[n]):2mins, maxs =2d-arrays ofsize(n+1)×(n+1)3fill mins with +infinity, fill maxs with -infinity4fori from0to n:5mins[i][i]=d[i], maxs[i][i]←d[i]​6fors from1to n:7forl from1to n-s:8r = l+s9form from l to r-1:10a = mins[l][m] op[m] mins[m+1][r]11b = mins[l][m] op[m] maxs[m+1][r]12c = maxs[l][m] op[m] mins[m+1][r]13d = maxs[l][m] op[m] maxs[m+1][r]14mins[l][r] =min(mins[l][r],a,b,c,d)15maxs[l][r] =max(maxs[l][r],a,b,c,d)16returnmaxs[0][n]"
            }
        ]
    },
    {
        "id": "q_0193",
        "question": "Какой метод позволяет уменьшить время вычисления максимального значения арифметического выражения с экспоненциального до кубического?",
        "answers": [
            "Динамическое программирование с запоминанием минимальных и максимальных значений всех подвыражений в таблицах позволяет избежать повторных вычислений и сократить время работы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
                "text": "Теперь вы умеете вычислять максимальное значение арифметического выражения, расставляя скобки в нужном порядке. Вы научились использовать динамическое программирование с запоминанием минимальных и максимальных значений и применять аккуратные рекурсивные формулы. Далее — финальный параграф главы. В нём мы кратко обобщим ключевые идеи, которые вы встретили, и покажем, как они складываются в систему. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Порядок выполнения операций влияет на результат арифметического выражения — важно правильно расставить скобки. Можно эффективно найти максимальное значение, если сохранять минимумы и максимумы всех подвыражений в таблицах. Динамическое программирование позволяет избежать повторных вычислений и уменьшает время работы с экспоненциального до кубического. Даже при небольшом числе операций количество возможных расстановок скобок велико — поэтому важно автоматизировать перебор."
            }
        ]
    },
    {
        "id": "q_0194",
        "question": "Каковы преимущества алгоритма Евклида по сравнению с наивными подходами?",
        "answers": [
            "Алгоритм Евклида значительно эффективнее наивных методов, так как он позволяет быстро вычислять наибольший общий делитель даже для больших чисел, избегая полного перебора всех возможных делителей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
                "text": "Как работает алгоритм Евклида и чем он лучше наивных подходов? Как связаны НОД и НОК, и как их вычислить быстро даже для больших чисел? Почему важно контролировать сложность алгоритма даже в задачах с простой формулировкой?"
            }
        ]
    },
    {
        "id": "q_0195",
        "question": "Какой алгоритм для вычисления наибольшего общего делителя был описан греческим математиком двадцать три века назад?",
        "answers": [
            "Алгоритм Евклида был впервые описан греческим математиком двадцать три века назад для нахождения наибольшего общего делителя двух чисел."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
                "text": "Наибольший общий делительдвух положительных целых чисели— это самое большое целое число, на которое можно поделитьибез остатка. Двадцать три века назад греческий математик Евклид впервые описал, как найти самый большой общий делитель.Однако нам до сих пор неизвестно имя математика, разработавшего этот алгоритм за век до Евклида. Спустя много веков алгоритм Евклида ещё раз обнаружили индийские и китайские астрономы. Теперь эффективный алгоритм, вычисляющий наибольший общий делитель, — важный ингредиент для современных криптографических алгоритмов. Ваша задача — использовать алгоритм Евклида для вычисления. Формат ввода: Целые числаи(разделённые пробелом). Формат вывода:. Ограничения:. Примеры Числа 18 и 35 не обладают общими нетривиальными делителями. ,. Простой, но ужасно медленный способ вычислить наибольший общий делитель: Скопировать код1GCD(a, b):2ford отmin(a,b) вниз до1:3ifa % d ==0andb % d ==0:// d делит a и d делит b4returnd Рисунок к задаче даёт нам простую, но чрезвычайно важную подсказку: если и, иможно разделить на, значит иможно разделить на. Оказывается, что верно и обратное. Докажите, чтопри. Это наблюдение позволяет нам вычислить наибольший общий делитель,отнимая меньшее число от большего снова и снова.В конце концов одно из чисел дойдет до нуля. В таком случае мы просто возвращаем другое число (если, то). Скопировать код1GCD(a, b):2whilea >0andb >0:3ifa >= b:4a = a−b5else:6b = b−a7returnmax(a,b) Насколько этот алгоритм быстрый? Этот алгоритм всё ещё слишком медленный. Например, приион продолжает отниматьот— более миллиона раз (в то время как изначальный алгоритм находит наибольший общий делитель приимоментально), так как ему нужно только пройти через. Но не беспокойтесь. Сейчас мы сделаем наш алгоритм эффективнее. Правильно! Мы получим 6 — остатокпри делении на 7. Сказанное выше приводит нас к алгоритму Евклида. Скопировать код1GCD(a, b):2whilea >0andb >0:3ifa >= b:4a = a % b5else:6b = b % a7returnmax(a,b) Это быстрый алгоритм: при любых, он вычисляет их наибольший общий делитель мгновенно. Для значенийв этом диапазоне количество итераций циклаwhileне превышает сотни. Обоснование этого утверждения можно построить на факте, что после каждой итерации одно из чисел становится как минимум в два раза меньше. Следовательно, после максимумитераций или, илидойдёт до нуля. Так как,. В качестве последнего комментария мы подметим, что такой же алгоритм можно использовать рекурсивно, занимая всего три строки кода. Скопировать код1GCD(a, b):2ifa =0orb =0:3returnmax(a,b)4returnGCD(b,a mod b)"
            }
        ]
    },
    {
        "id": "q_0196",
        "question": "Какое наименьшее целое число делится и на 6, и на 8?",
        "answers": [
            "Наименьшее целое число, которое делится и на 6, и на 8, равно 24."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
                "text": "Наименьшее общее кратноедля двух положительных целых чисели— это самое маленькое целое число, которое можно разделить и на, и на. Рисунок выше демонстрируетдля каждой пары чисел,и, а также наименьшее общее кратное для всех трёх. Рисунок ниже показывает наибольший общий делитель для этих же чисел. Формат ввода: Целые числаи(разделённые пробелом). Формат вывода: Ограничения:. Примеры — Среди всех положительных целых чисел, которые можно разделить и на 6, и на 8 (например, 48, 480 и 24), 24 — наименьшее число.— Совет: для деления целых чисел вPython3используйте//(вместо/) Для обоснования соотношениярассмотрим разложениеина простые множители. Если простоевходит в разложениев степении в разложение— в степени, тоделится на, адолжно делиться на. Для завершения обоснования формулы стоит использовать соотношение."
            }
        ]
    },
    {
        "id": "q_0197",
        "question": "Какой алгоритм позволяет быстро находить наибольший общий делитель?",
        "answers": [
            "Алгоритм Евклида позволяет быстро находить наибольший общий делитель и работает значительно эффективнее наивных решений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
                "text": "Теперь вы знаете, как эффективно вычислять наибольший общий делитель при помощи алгоритма Евклида — и почему он работает в разы быстрее наивных подходов. Вы также научились находить наименьшее общее кратное и увидели, как связаны эти два понятия. Всё это — основа для задач, в которых важно понимать делимость и оптимально работать с числами. Далее — короткое заключение, в котором мы подведём итоги главы и соберём всё, чему вы научились в задачах на Фибоначчи, НОД и НОК. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Алгоритм Евклида позволяет быстро находить наибольший общий делитель и работает значительно эффективнее наивных решений. НОК удобно вычислять через НОД, используя формулу LCM(a,b)= a⋅b​ / GCD(a,b)."
            }
        ]
    },
    {
        "id": "q_0198",
        "question": "Какие аспекты необходимо учитывать при оформлении и тестировании базовых программ?",
        "answers": [
            "Важно учитывать оформление кода, включая читаемость и стиль, а также проводить тестирование для проверки корректности работы программы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-summa-dvuh-chisel",
                "text": "Как выглядит корректное решение самой простой задачи на разных языках программирования? Что важно учитывать при оформлении и тестировании даже самых базовых программ?"
            }
        ]
    },
    {
        "id": "q_0199",
        "question": "Какие языки программирования используются в системе тестирования, упомянутой в описании задачи?",
        "answers": [
            "В системе тестирования используются языки C++, Python3 и Java."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-summa-dvuh-chisel",
                "text": "Рассмотрим совсем простую задачу. Входные данные: Целые числаина одной строке (разделённые пробелом). Выходные данные: Суммаи. Ограничения:. Пример Ограничение по времени (с): 1 секунда Ограничение по памяти: 512 Mb. Поскольку задача решается в одно действие, шагСпроектировать алгоритммы пропустим и перейдём сразу к псевдокоду. Скопировать код1SumOfTwoDigits(a, b):2returna + b Так как псевдокод не уточняет вводи, ниже мы приводим решения для языковC++,JavaиPython3, а также рекомендации по компиляции и реализации. Вы можете скопировать и вставить код в файл, скомпилировать, запустить и протестировать с разными данными, а затем сдать исходный файл в систему проверки. Разумеется, мы рассчитываем, что вы знакомы с основами одного из языков программирования, который используется в нашей системе тестирования:C++,Python3,Java. Скопировать код1#include<iostream >23intsum_of_digits(intfirst,intsecond){4returnfirst + second;5}67intmain(){8inta =0;9intb =0;10std::cin >>a;11std::cin >>b;12std::cout <<sum_of_digits(a, b);13return0;14} Скопировать код1importjava.util.Scanner;23classSumOfTwoDigits{4staticintsumOfTwoDigits(intfirst_digit,intsecond_digit){5returnfirst_digit + second_digit;6}78publicstaticvoidmain(String[] args){9Scanners=newScanner(System.in);10inta=s.nextInt();11intb=s.nextInt();12System.out.println(sumOfTwoDigits(a, b));13}14} Скопировать код1defsum_of_digits(first_digit, second_digit):2returnfirst_digit + second_digit34if__name__ =='__main__':5a, b =map(int,input().split())6print(sum_of_digits(a, b)) Ваша цель — реализовать алгоритм, который даёт верный результат с ограничениями по времени и памяти и при любом вводе. Нет необходимости проверять, что входные данные соответствуют ограничениям, — например, в задачеСумма двух чиселвам не нужно следить за тем, чтобы целые числаидействительно были однозначными (это гарантировано)."
            }
        ]
    },
    {
        "id": "q_0200",
        "question": "Что рекомендуется сделать для закрепления материала после изучения простой задачи?",
        "answers": [
            "Рекомендуется отметить урок прочитанным, пройти мини-квиз для проверки усвоения темы и перейти к задачам параграфа для тренировки, предварительно ознакомившись с гайдом по системе проверки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-summa-dvuh-chisel",
                "text": "Теперь вы разобрались, как выглядит самая простая задача и как оформить корректное решение на разных языках программирования. Это важный шаг: вы научились уверенно работать с вводом, выводом и базовой логикой программы. Далее — задача посложнее. Она потребует не только корректной реализации, но и оценки эффективности. Вы увидите, почему наивный алгоритм не всегда подходит, и научитесь искать более быстрые решения. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Даже у простой задачи есть структура: ввод, обработка, вывод. Важно уметь оформить решение понятно и корректно, чтобы можно было уверенно работать с ним, проверять и развивать его дальше."
            }
        ]
    },
    {
        "id": "q_0201",
        "question": "Какие основные операции можно выполнять со стеком и какова их вычислительная сложность?",
        "answers": [
            "Основные операции со стеком — это добавление элемента (push), удаление верхнего элемента (pop) и просмотр верхнего элемента без удаления (peek). Все эти операции имеют константную временную сложность O(1), так как работают только с верхушкой структуры."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/stek",
                "text": "Что такое стек и как он устроен? Какие операции поддерживает стек и какова их сложность? Где и как стек применяется в алгоритмах и повседневных задачах?"
            }
        ]
    },
    {
        "id": "q_0202",
        "question": "Какой принцип работы у структуры данных стек?",
        "answers": [
            "Стек работает по принципу «последним пришёл, первым ушёл» (LIFO — last in, first out). Это означает, что элементы добавляются и извлекаются только из вершины стека."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/stek",
                "text": "Стек (stack) — структура данных, которая работает по принципу «последним пришёл, первым ушёл» (LIFO — last in, first out). Стек можно представить как некий контейнер, в котором элементы (например, числа, символы и так далее) могут быть добавлены в вершину, а затем извлечены только из вершины. В бытовом плане стек напоминает стопку тарелок. Тарелка, которую положили первой, в самый низ, будет использована последней. Существуют различные реализации стека. Например, стек может быть реализован на массиве, на односвязном списке, на двусвязном списке и так далее. В параграфе будем говорить о реализации стека на односвязном списке. Основные операции, которые можно производить со стеком, включают: Добавление элемента в вершину стека (push) —. Удаление элемента из вершины стека (pop) —. Возврат верхнего элемента без его удаления (peek) —. Проверка стека на пустоту (isEmpty) —. Стоит отметить, что стек представляет собой список с элементами и указателя на вершину стека, указывающего на последний элемент, добавленный в стек. Каждый раз, когда в стек добавляется новый элемент, указатель на вершину смещается на следующий элемент. Когда элемент удаляется из вершины стека, указатель смещается на предыдущий элемент. Если указатель находится в конце стека, то стек пуст."
            }
        ]
    },
    {
        "id": "q_0203",
        "question": "По какому принципу работает структура данных стек?",
        "answers": [
            "Стек работает по принципу LIFO — «последним пришёл — первым вышел»."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/stek",
                "text": "Теперь вы знаете, как устроен стек и как использовать его для решения задач с вложенностью, отменой действий или разворотом данных. Вы освоили основные операции и поняли, почему стек важен в алгоритмах. Далее — структура, которая позволяет не просто сохранять элементы, а учитывать их приоритет. Вы узнаете, как работает очередь с приоритетом и где она применяется в реальных алгоритмах. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Стек — структура данных, работающая по принципу LIFO («последним пришёл — первым вышел»). Основные операции: добавление (push), удаление (pop) и просмотр верхнего элемента (peek) — выполняются заO(1). Стек удобен для задач со вложенной структурой: проверка корректности скобок в выражениях (каждая открывающая должна иметь соответствующую закрывающую); поддержка рекурсии (системный стек вызовов); откат действий в редакторах и программах. Прост в реализации и широко используется в парсерах, алгоритмах обхода графов и обработке выражений."
            }
        ]
    },
    {
        "id": "q_0204",
        "question": "Какие методы можно использовать для поиска минимального числа шагов в задаче построения последовательности операций?",
        "answers": [
            "Для поиска минимального числа шагов можно использовать динамическое программирование, которое позволяет систематически вычислять оптимальные значения, в отличие от жадной стратегии, не гарантирующей оптимальности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-prostoj-kalkulyator",
                "text": "Почему жадная стратегия не гарантирует оптимальный результат при построении последовательности операций? Как использовать динамическое программирование для поиска минимального числа шагов? Как восстановить оптимальную последовательность действий из таблицы значений?"
            }
        ]
    },
    {
        "id": "q_0205",
        "question": "Какие три операции может выполнять калькулятор с целым числом в описанной задаче?",
        "answers": [
            "Калькулятор может выполнять следующие операции: прибавить 1 к числу, умножить число на 2 или умножить число на 3."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-prostoj-kalkulyator",
                "text": "У вас есть калькулятор, который выполняет с целым числомтолько следующие операции: сложитьи, умножитьнаили умножитьна. Имея положительное целое число, вы должны найти минимальное количество операций, необходимых для получения числаиз числа. Попробуем решить эту задачу с помощью «жадной» стратегии: если текущее число не превышает, то умножим его на 3; если оно больше, но не больше, то умножим его на 2; в остальных случаях добавим к нему 1. Это приводит к следующему псевдокоду. Скопировать код1GreedyCalculator(n):2numOperations =03currentNumber =14whilecurrentNumber <n:5ifcurrentNumber <= n/3:6currentNumber =3*currentNumber7elseifcurrentNumber <= n/2:8currentNumber =2*currentNumber9else:10currentNumber =1+currentNumber11numOperations = numOperations+112returnnumOperations Входные данные: Целое число. Выходные данные: В первой строке:— минимальное число необходимых операций для полученияиз. Во второй строке: последовательность промежуточных чисел. Так, вторая строка должна содержать положительные целые числа, при которых,, и для всехравно,или. Если таких последовательностей много, то можно вывести любую из них. Ограничения:. Ещё один корректный вывод в этом случае — это «1 3 9 10 11 33 99 297 891 2673 8019 16038 16039 48117 96234». Рассмотрим решение задачи. Пусть— минимальное количество операций, необходимых для получения числаиз числа. Так как последняя операция в оптимальной последовательности — это «», «» или «», мы получаем следующее рекуррентное соотношение для: Данное рекуррентное соотношение, вместе с базовым случаем, можно трансформировать в рекурсивный, а затем в итерационный алгоритм. Скопировать код1Calculator(n):2table[1..n]←[+infinity,…,+infinity]3table[1] =045fork from2to n:6table[k]=1+table[k−1]7ifk is divisible by2:8table[k]=min(table[k],1+table[k/2])9ifk is divisible by3:10table[k]=min(table[k],1+table[k/3])11returntable[n] Помните, что помимо оптимального значения необходимо вывести оптимальную последовательность операций. Для этого обратим внимание на то, что мы можем найти последнюю операцию следующим образом: это «», если; это «», еслиможно разделить наи; это «», еслиможно разделить наи. Эти действия позволяют нам выявить оптимальную последовательность: найти последнюю операцию; заменитьна,или(в зависимости от того, какой это из трёх случаев выше); повторить (пока). Скопировать код1Calculator(n):2table[1..n]←[+infinity,…,+infinity]3table[1] =045fork from2to n:6table[k]=1+table[k−1]7ifk is divisible by2:8table[k]=min(table[k],1+table[k/2])9ifk is divisible by3:10table[k]=min(table[k],1+table[k/3])1112operations = empty list13whilen >1:14append n to operations15iftable[n]=1+table[n−1]:16n = n -117elseifn is divisible by2andtable[n]=1+table[n/2]:18n = n/219elseifn is divisible by3andtable[n]=1+table[n/3]:20n = n/321returnoperations Время выполнения алгоритма составляет."
            }
        ]
    },
    {
        "id": "q_0206",
        "question": "Какой подход может не давать оптимальный результат при нахождении минимальной последовательности операций, даже если кажется разумным?",
        "answers": [
            "Жадный алгоритм может не давать оптимальный результат — даже если кажется разумным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-prostoj-kalkulyator",
                "text": "Теперь вы знаете, как находить минимальную последовательность операций для получения заданного числа, используя динамическое программирование. Вы научились строить таблицу значений и восстанавливать по ней путь — от цели к началу. А ещё убедились, что жадный подход может подвести, даже если кажется логичным. Далее — задача на редактирование строк. Вы узнаете, как рассчитать расстояние между двумя строками, используя матрицу изменений, и зачем это нужно в задачах на сравнение, поиск и коррекцию. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм может не давать оптимальный результат — даже если кажется разумным. Динамическое программирование позволяет найти кратчайшую последовательность операций с минимальными затратами. Чтобы восстановить путь, нужно не только посчитать значения, но и зафиксировать переходы. Умение строить такие цепочки важно для задач, где нужно не только посчитать, но и объяснить, как получить ответ."
            }
        ]
    },
    {
        "id": "q_0207",
        "question": "Какой принцип лежит в основе подхода, который позволяет ускорить решение задач за счёт разбиения на более мелкие части?",
        "answers": [
            "Это подход «Разделяй и властвуй», который заключается в разбиении сложной задачи на более мелкие и простые подзадачи, их независимом решении и последующем объединении результатов. Он ускоряет решение, так как мелкие задачи часто решаются эффективнее, а параллельная обработка сокращает общее время."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
                "text": "В чём суть подхода «Разделяй и властвуй» и как он помогает ускорить решение задач? Как работает MergeSort и чем он отличается от наивных алгоритмов сортировки? Почему объединение результатов подзадач — не менее важный шаг, чем их решение?"
            }
        ]
    },
    {
        "id": "q_0208",
        "question": "Как работает алгоритм SelectionSort?",
        "answers": [
            "SelectionSort — это итерационный метод сортировки. Он последовательно находит самый маленький элемент в неотсортированной части списка и меняет его местами с элементом на текущей позиции, начиная с первого. Этот процесс повторяется для каждой позиции, пока весь список не будет отсортирован."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
                "text": "Одна большая задача может казаться трудной. Но если разделить её на две задачи в два раза меньше, она станет намного проще. Для таких случаев хорошо подходят алгоритмы «разделяй и властвуй». Они так и работают: разделяют задачу на более мелкие подзадачи, независимо находят решения для них и соединяют результаты в решение изначальной задачи. Конечно, реальные ситуации бывают более сложными, чем мы описали. После разделения одной задачи на подзадачи, алгоритм обычно делит их на ещё более мелкие под-подзадачи и так далее. Он продолжает это делать, пока не дойдёт до точки, где в рекурсии уже нет необходимости. В качестве примера алгоритма «разделяй и властвуй» приведём задачу сортировки: Сортировка: Отсортируйте набор целых чисел. Входные данные: Список изразных чисел. Выходные данные: Отсортированный список целых чисел. Измененный порядокцелых чисел от, где. SelectionSort— это простой итерационный метод решения задачи по сортировке. Сначала он находит самый маленький элемент в, а затем меняет его местами с первым элементом (то есть с). Затем он находит второй самый маленький элемент ви переставляет его на второе место, меняя элемент местами с. Повторяя это действие в-й раз,SelectionSortнаходит-й самый маленький элемент ви переставляет его на-е место. Если,SelectionSort(a)будет состоять из следующих семи шагов: Время выполненияSelectionSortквадратично, то есть: используетсяитераций, для каждого из которых требуется время, чтобы просканировать не болееэлементов и найти самый большой из них для суффикса. Тем не менее общее время выполнения растёт как:"
            }
        ]
    },
    {
        "id": "q_0209",
        "question": "Какой алгоритм используется для объединения двух отсортированных списков в MergeSort?",
        "answers": [
            "Для объединения двух отсортированных списков в MergeSort используется алгоритм Merge, который последовательно выбирает наименьшие элементы из обоих списков и добавляет их в новый отсортированный список."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
                "text": "MergeSort— классический пример алгоритма «разделяй и властвуй» для сортировки. Он намного быстрее, чемSelectionSort. Начнём с задачи слияния, в которой нам нужно будет объединить два отсортированных списка —и— в один отсортированный список. АлгоритмMergeобъединяет два отсортированных списка в один за время. Для этого алгоритм повторно выбирает самый маленький элемент из оставшихся вии перемещает его в растущий отсортированный список. Скопировать код1Merge(List_1,List_2):2SortedList = ...// empty list3whileboth List_1andList_2 are non-empty:4ifthe smallest element in List_1 is smaller than the smallest element in List_2:5move the smallest element from List_1 to the end of SortedList6else:7move the smallest element from List_2 to the end of SortedList8move any remaining elements from either List_1orList_2 to the end of SortedList9returnSortedList Merge— полезный инструмент для сортировки произвольного списка, если мы знаем, как разделить неотсортированный список на две отсортированные половины. Вам может показаться, что мы вернулись к тому, с чего начали, только теперь нам нужно отсортировать два меньших списка вместо одного большого. Но сортировка двух мелких списков — более предпочтительная алгоритмическая задача. Чтобы понять, почему это так, мы рассмотрим алгоритмMergeSort. Он разделяет неотсортированный список на две части и использует рекурсию для выполнения мелких задач перед тем, как объединить отсортированные списки. Скопировать код1MergeSort(List):2ifList consists of a single element:3returnList4FirstHalf = first half of List5SecondHalf = second half of List6SortedFirstHalf =MergeSort(FirstHalf)7SortedSecondHalf =MergeSort(SecondHalf)8SortedList =Merge(SortedFirstHalf,SortedSecondHalf)9returnSortedList Нарис.изображено рекурсивное деревоMergeSort, состоящее изуровней, где— размер изначального неотсортированного списка. На нижнем уровне нам нужно объединить два отсортированных списка размером примерно вэлементов, что займётвремени. На следующем самом высоком уровне нам нужно объединить четыре списка изэлементов, что потребуетвремени. Такой шаблон можно описать следующим образом:-й уровень состоит изсписков, каждый из которых включает в себя приблизительноэлементов и занимаетвремени для объединения. Так как в рекурсивном деревеуровней, выполнениеMergeSortпотребует в общемвремени, что даёт нам большое ускорение по сравнению с более наивнымалгоритмом сортировки."
            }
        ]
    },
    {
        "id": "q_0210",
        "question": "Какой алгоритм сортировки использует подход «Разделяй и властвуй» и работает за O(n log n)?",
        "answers": [
            "Алгоритм MergeSort использует подход «Разделяй и властвуй» и сортирует список за O(n log n) благодаря рекурсивному делению и слиянию."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
                "text": "Теперь вы знаете, как работает подход «Разделяй и властвуй» и как с его помощью ускорить решение задач. Вы научились использовать рекурсию, объединять подзадачи и применять это к сортировке. Далее — рандомизированные алгоритмы. Вы увидите, как случайность может стать преимуществом в вычислениях, и узнаете, почему некоторые вероятностные алгоритмы работают быстрее, чем детерминированные. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Подход «Разделяй и властвуй» помогает решать задачи, разбивая их на части и объединяя решения. Алгоритм MergeSort сортирует список за O(n log n) благодаря рекурсивному делению и слиянию. Такие алгоритмы часто быстрее наивных и хорошо масштабируются."
            }
        ]
    },
    {
        "id": "q_0211",
        "question": "Как рекомендуется решать задачи и почему?",
        "answers": [
            "Задачи рекомендуется решать с компьютера, потому что это удобнее и интерфейс отображается корректно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
                "text": "Мы рекомендуем решать задачи с компьютера: так удобнее, и интерфейс отображается корректно. Когда вы открываете задачу, экран делится на две части: слева — описание задания, справа — редактор, где вы пишете код."
            }
        ]
    },
    {
        "id": "q_0212",
        "question": "Какие разделы содержит описание задачи на платформе?",
        "answers": [
            "Описание включает условие задачи, формат ввода и вывода данных, пример ожидаемого результата, а также ограничения по времени и памяти."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
                "text": "Описание включает: условие задачи; формат ввода и вывода — какие данные программа получает и должна вернуть; пример — демонстрирует ожидаемый результат; ограничения — по времени и памяти. Вы можете ввести код прямо в редакторе или загрузить файл с решением."
            }
        ]
    },
    {
        "id": "q_0213",
        "question": "Что происходит после того, как код отправлен на проверку?",
        "answers": [
            "Код тестируется на разных входных данных, и этот процесс занимает некоторое время."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
                "text": "После этого начнётся проверка — код будет протестирован на разных входных данных. Этот процесс занимает некоторое время."
            }
        ]
    },
    {
        "id": "q_0214",
        "question": "Какие вердикты могут быть получены при проверке решения задачи и что означает вердикт WA?",
        "answers": [
            "Основные вердикты: OK (Accepted), WA (Wrong Answer), CE (Compilation Error), RE (Runtime Error), TM (Time Limit), ML (Memory Limit). Вердикт WA означает, что программа выдала неверный результат хотя бы на одном из тестов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
                "text": "Эти данные не всегда совпадают с примерами из условия задачи — они подобраны так, чтобы проверить решение на корректность, граничные случаи и эффективность. Проверка занимает несколько секунд. Прогресс и историю можно отследить на вкладке «Отправленные решения». Результаты отображаются в виде вердиктов. Вот основные из них: OK (Accepted) — решение прошло все тесты успешно. WA (Wrong Answer) — программа выдала неверный результат хотя бы на одном из тестов. CE (Compilation Error) — ошибка компиляции. RE (Runtime Error) — ошибка выполнения. TM (Time Limit) — при выполнении превышено допустимое время. ML (Memory Limit) — при выполнении превышена допустимая память. В случае WA для тестов из примеров отображаются: входные данные; вывод вашей программы; ожидаемый правильный ответ; вывод системы. Это поможет вам отладить решение. Остальные тесты остаются скрытыми — попробуйте сами смоделировать граничные случаи. Означает, что в коде допущена синтаксическая или другая ошибка, из-за которой программа не запускается. Перейдите в «Лог компиляции», чтобы увидеть подробности: тип ошибки; строка, где она возникла; комментарий от компилятора. Это ошибка, которая возникает во время выполнения программы. Возможные причины: деление на ноль; выход за границы массива; необработанное исключение и т. п. Эти ошибки возникают в ответ на плохо оптимизированный код. Например, если встречается «матрёшка» из циклов. Решение тут только одно — вдумчиво изучить код и попробовать его оптимизировать, сделав менее ресурсоёмким. Если не удаётся разобраться с ошибкой — не спешите расстраиваться. Попробуйте: упростить тест и воссоздать ситуацию локально; добавить отладочный вывод; обсудить решение с участникамисообществахендбука."
            }
        ]
    },
    {
        "id": "q_0215",
        "question": "Какие ключевые шаги необходимо выполнить для разработки эффективного алгоритма динамического программирования?",
        "answers": [
            "Сначала нужно выделить перекрывающиеся подзадачи в исходной задаче. Затем сформулировать рекуррентное соотношение, связывающее решение задачи с решениями её подзадач. Наконец, реализовать алгоритм с оптимизацией по времени и памяти, чтобы он работал быстро и экономно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
                "text": "В чём суть динамического программирования и как оно отличается от других стратегий? Как выделить подзадачи и сформулировать рекуррентное соотношение? Как реализовать и оптимизировать алгоритм, чтобы он работал быстро и экономно?"
            }
        ]
    },
    {
        "id": "q_0216",
        "question": "В каких двух практических случаях применяется динамическое программирование?",
        "answers": [
            "Динамическое программирование применяется для поиска похожих страниц в интернете и для предсказания генов в последовательностях ДНК."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
                "text": "Динамическое программирование на практике применяется в большом числе случаев. Оно подходит и для поиска похожих страниц в интернете, и для предсказывания генов в последовательностях ДНК."
            }
        ]
    },
    {
        "id": "q_0217",
        "question": "Какова минимальная длина пути от узла S до узла T во взвешенном графе, описанном в головоломке?",
        "answers": [
            "Минимальная длина пути от S до T составляет 8. Это значение получается с помощью рекуррентных соотношений динамического программирования, где базовый случай — расстояние от S до S равно 0."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
                "text": "Для понимания идеи, которая используется в подходе динамического программирования, предлагаем вам попробовать решить следующую головоломку. Интерактивная головоломка «Количество путей». В нижеприведённой сети есть множество путей ведущих отк, — например:и. Каково общее количество путей? Так как мы начинаем с, существует уникальный способ добраться до. Давайте запишем: Дляитакже существует просто один путь. Так как существует только один путь ки только один к, количество путей ксоставляет(и). Аналогичным образом для достижениянеобходимо прийти либо к, либо к. Существует только один путь дои два пути до. Так количество путей, которые ведут к, составляет(,и). Количество путей, заканчивающихся на, равно, так как кможно прийти только от. Доесть два пути, до— три пути, до— один. Выходит, что путей досуществует. Рассмотрим наше решение головоломки «Количество путей» и изложим основные идеи динамического программирования. Для узла—будет количеством путей от стартового узлак узлу. Несомненно,. Это называется базовый случай. Соответствующее значение для всех других узлов можно найти с помощью рекуррентного соотношения: где предшественник— это узел, связанный ребром с. Многие алгоритмы динамического программирования используют одну схему: — Вместо того, чтобы решать изначальную задачу, алгоритм решает несколько подзадач такого же типа.— Алгоритм вычисляет решение для каждой подзадачи с помощью рекуррентного соотношения, в которое входят решения более мелких подзадач.— Алгоритм сохраняет решения подзадач и таким образом избегает перевычисления. Теперь рассмотрим взвешенный граф, в котором у каждого ребраобозначена длина. Длина пути в таком графе определяется суммой длины рёбер. Например, длина путисоставляет. Какова минимальная длина пути отдо? Так как каждый путь отдопроходит через,илиперед тем, как прийти к, где— минимальная длина пути отдо. Расстояния до,иможно найти с помощью похожих рекуррентных соотношений: Приведём рекуррентные соотношения дляи: Наконец, базовый случай — это. С его помощью можно найти расстояние до всех узлов сети, включая наш узел. Для этого нужно использовать вышеприведённые рекуррентные соотношения, которые можно записать в компактной форме: Для модельной ситуации удобно записывать результаты по мере того, как мы выполняем вычисления, прямо на изображении. Мы получаем следующие результаты. В алгоритме динамического программирования для этого выполняется бэктрекинг («поиск с возвратом») решений, которые привели к оптимальному результату. В особенности отметим один из трёх выборов, который приводит нас к значению. Исходя из этого, мы можем заключить, что последнее ребро оптимального пути — это. Аналогично, так мы приходим отк. Таким образом, путь отдодлинойсоставляет У вышеприведённой сети есть удобное свойство. Оно заключается в том, что мы можем определять порядок её узлов, что обеспечивает следующее: каждый узел идет после всех предшествующих — то есть узлы, которые указывают на текущий узел (например,,ипредшествуют). Сети с таким свойством называются ориентированные ациклические графы. Мы увидим, что многие алгоритмы динамического программирования используют ориентированные ациклические графы — явно или неявно."
            }
        ]
    },
    {
        "id": "q_0218",
        "question": "Какие основные шаги включает проектирование алгоритмов динамического программирования?",
        "answers": [
            "Проектирование включает: определение подпроблем и рекуррентного соотношения, создание рекурсивного алгоритма с мемоизацией, преобразование в итерационный алгоритм, оценку времени выполнения, обнаружение оптимального решения через бэктрекинг и оптимизацию использования памяти."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
                "text": "Теперь, когда вы познакомились с несколькими алгоритмами динамического программирования, подведём итог и повторим основные шаги для проектирования таких алгоритмов. Определить подпроблемы.Первый и самый важный шаг — это идентифицировать подпроблемы и записать рекуррентное соотношение (с базовым случаем). Как правило, это делается через анализ структуры оптимального решения или через оптимизацию решения, использующего исчерпывающий поиск. Спроектировать рекурсивный алгоритм.Сделать из рекуррентного соотношения рекурсивный алгоритм:сохранить решение каждой подзадачи в таблице;перед решением подзадачи проверить, нет ли уже в таблице её решения (мемоизация). сохранить решение каждой подзадачи в таблице; перед решением подзадачи проверить, нет ли уже в таблице её решения (мемоизация). Спроектировать итерационный алгоритм.Сделать из рекурсивного алгоритма итерационный алгоритм:инициализировать таблицу;продвигаться от мелких подзадач к большим. инициализировать таблицу; продвигаться от мелких подзадач к большим. Оценить время выполнения.Доказать верхнее ограничение времени выполнения. Обычно произведение количества подпроблем и времени, необходимого для решения подзадачи, предоставляет верхнее ограничение времени выполнения. Обнаружить решение.Обнаружить оптимальное решение, используя бэктрекинг рекуррентного соотношения. Экономить место.Использовать обычную структуру таблицы, чтобы проверить, можно ли сэкономить место по сравнению с более прямым решением."
            }
        ]
    },
    {
        "id": "q_0219",
        "question": "Какой алгоритм не справляется с задачей нахождения минимального количества монет, которую решает динамическое программирование в задаче «Размен-2»?",
        "answers": [
            "Жадный алгоритм не справляется с этой задачей, в отличие от динамического программирования, которое позволяет находить минимальное количество монет."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
                "text": "Теперь вы знаете, как работает динамическое программирование, — от базовых случаев и рекурсии до оптимизированных решений с таблицами и перебором подзадач. Вы познакомились с идеей сохранения промежуточных результатов, научились вычислять количество путей в графе и находить кратчайшие маршруты. Этот подход ляжет в основу всех задач этой главы. Далее — задача «Размен-2». Вы увидите, как динамическое программирование позволяет находить минимальное количество монет, даже когда жадный алгоритм не справляется. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться."
            }
        ]
    },
    {
        "id": "q_0220",
        "question": "Какие методы позволяют повысить точность и стабильность вычислений при работе с вещественными числами?",
        "answers": [
            "Для повышения точности и стабильности вычислений с вещественными числами можно использовать методы, такие как применение эпсилон-окрестностей для сравнения чисел, использование целочисленных представлений или библиотек с повышенной точностью, а также избегание вычитания близких по значению чисел."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-para-blizhajshih-tochek",
                "text": "Почему перебор всех пар точек работает медленно и как этого избежать? Как устроен алгоритм поиска ближайшей пары с помощью деления и сканирования полосы? Как добиться точного и стабильного результата при вычислениях с вещественными числами?"
            }
        ]
    },
    {
        "id": "q_0221",
        "question": "Какой алгоритм используется для нахождения ближайшей пары точек с временем выполнения O(n log n)?",
        "answers": [
            "Алгоритм «разделяй и властвуй», который рекурсивно делит множество точек вертикальной линией, находит минимальные расстояния в подмножествах, а затем проверяет точки в центральной полосе шириной 2δ, сортируя их по y-координате и сравнивая каждую точку с семью последующими."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-para-blizhajshih-tochek",
                "text": "Ваша задача — найти ближайшую пару точек из заданного множества. В компьютерных графике и зрении есть множество вариантов применения этой задачи из вычислительной геометрии. Примитивный алгоритм с квадратичным временем выполнения делает итерации, проходя через все пары точек, чтобы найти ближайшие друг к другу. Ваша цель — спроектировать алгоритм «разделяй и властвуй», время выполнения которого составит. Чтобы решить эту задачу за время, разобьём с помощью правильно подобранной вертикальной линии данныеточек пополам — множестваиразмера. Ради простоты предположим, что все координатыдля данных точек различные и количество точек чётное. С помощью двух рекурсивных вызовов с параметрамиимы находим минимальные расстоянияив этих поднаборах. Пусть. Остаётся проверить, существуют ли такие точкии, при которых расстояние между ними меньше. Мы не можем себе позволить проверять все возможные такие пары, так как их. Для более быстрой проверки мы отбросим все точки изи, расстояние которых от центральной линии побольше, чем. Таким образом, мы сосредотачиваемся на следующей полосе: Теперь отсортируем точки из полосы по координатами обозначим получившийся отсортированный список. Оказывается, что если, то расстояние между точкамииоднозначно будет больше. Упражнение ниже это демонстрирует. Разделите полосу наквадратов, как показано ниже, и продемонстрируйте, что каждый из таких квадратов содержит максимум четыре точки ввода. Это приводит к следующему алгоритму. Сначала мы сортируем данные намточек по их координатам, затем делим получившийся отсортированный список на две половиныиразмера. Находим минимальные расстоянияис помощью рекурсивных вызовов для каждого из наборови. Пусть. Тем не менее наша работа ещё не закончена, потому что нам также нужно найти минимальное расстояние между точками из разных наборов (то есть точкой изи точкой из) и проверить, ниже ли это расстояние, чем. Чтобы в этом убедиться, мы отфильтруем изначальный набор и оставим только точки с дистанцией подо средней линии, не превышающей. После этого мы сортируем набор точек в получившейся линии по координатами сканируем получившийся список. Вычислим расстояние от каждой точки до семи последующих точек списка и вычислим— минимальное расстояние, которое нам встретилось во время сканирования. Затем выведем. Время выполнения алгоритма соответствует рекуррентному соотношению. — результат сортировки точек в полосе по координатепри каждой итерации. Проанализируйте рекурсивное дерево алгоритма и докажите, что. Продемонстрируйте, как избежать сортировки при каждом рекурсивном вызове и понизить время выполнения до.* Формат ввода: Первая строка содержитточек. Каждая из следующихстрок определяет точку. Формат вывода: Минимальное расстояние. Ограничения:;— целые числа. Примеры Во втором примере самое маленькое расстояние —. Есть две пары точек на этом расстоянии. Ниже они выделены голубым и красным:и;и. Помните, что расстояние между точкамииравно. Так, хотя ввод и содержит только целые числа, ответ не обязательно будет целым числом, и потому вам нужно обратить внимание на точность при выводе результатов. Абсолютное значение разницы между ответом вашей программы и оптимальным значением не должно превышать. Для этого ваш ответ должен содержать не меньше четырех цифр в дробной части. Иначе даже правильно вычисленный результат может не пройти нашу систему проверки из-за ошибок при округлении. ✅ Получилось разобраться, как найти пару ближайших точек быстрее, чем за? 👉Оценить этот параграф"
            }
        ]
    },
    {
        "id": "q_0222",
        "question": "Какой алгоритм позволяет решить задачу нахождения пары ближайших точек на плоскости за время O(n log n)?",
        "answers": [
            "Алгоритм «Разделяй и властвуй» позволяет решить эту задачу за O(n log n). Он включает сортировку точек, рекурсивное деление множества и анализ узкой полосы при слиянии."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-para-blizhajshih-tochek",
                "text": "Теперь вы умеете находить пару ближайших точек на плоскости с помощью алгоритма «Разделяй и властвуй». Вы увидели, как сортировка, аккуратное разбиение и сканирование узкой полосы позволяют снизить сложность задачи до, сохранив точность вычислений. Далее — заключительный параграф главы: мы кратко подведём итоги и соберём воедино все стратегии, с которыми вы познакомились. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Задачу нахождения пары ближайших точек можно решить не за, а за, если использовать стратегию «Разделяй и властвуй». Алгоритм включает сортировку точек по координате, рекурсивное деление множества и слияние с анализом узкой полосы шириной. При слиянии достаточно проверить не все пары, а только точки в полосе, отсортированные по второй координате, — это снижает число сравнений. Точная реализация требует аккуратности: важно корректно обрабатывать базовые случаи, следить за порядком точек и не упустить минимум."
            }
        ]
    },
    {
        "id": "q_0223",
        "question": "Какие методы позволяют решить задачу о рюкзаке без полного перебора всех подмножеств?",
        "answers": [
            "Для решения задачи о рюкзаке без полного перебора можно использовать рекурсию с мемоизацией, которая сохраняет промежуточные результаты, а также итерационные реализации алгоритма."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
                "text": "Почему жадный алгоритм не подходит для задачи о рюкзаке? Как с помощью рекурсии и мемоизации находить решение без перебора всех подмножеств? В чём разница между рекурсивной и итерационной реализациями алгоритма?"
            }
        ]
    },
    {
        "id": "q_0224",
        "question": "Какой максимальный вес золотых слитков можно уместить в рюкзак заданной вместимости, если каждый слиток можно либо взять целиком, либо не брать вовсе?",
        "answers": [
            "Максимальный вес определяется решением задачи о рюкзаке, где входные данные включают вместимость рюкзака, количество слитков и их веса, а выходные данные — максимальный достижимый вес, не превышающий вместимость."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
                "text": "Вы нашли несколько золотых слитков. Ваша цель — положить как можно больше золота в рюкзак вместимостьюфунтов. Каждый слиток существует только в одном экземпляре. При этом можно либо взять слиток целиком, либо не брать его вовсе. И хотя все слитки на рисунке выше выглядят одинаково, они обладают разным весом — он приведён ниже. Естественная жадная стратегия — взять самый тяжелый слиток, на который хватает вместимости рюкзака, и повторно проверить, а осталось ли место на ещё один слиток. При наборе слитков, приведённом выше, и рюкзаке вместимостью«жадный» алгоритм выбирает слитки весоми. Однако оптимальное решение — использовать слитки весом 4, 6 и 10! Входные данные: Первая строка ввода содержит целое число(вместимость рюкзака) и количество золотых слитков. В следующей строке приведеныцелых чисел, которые определяют вес золотых слитков. Выходные данные: Максимальный вес золотых слитков, который можно уместить в рюкзак вместимостью. Ограничения:;;. Сумма веса первого и последнего слитков равна. Вместо решения изначальной задачи проверим, можно ли выбрать поднабор слитков с общим весом, если имеемслитков весом(мы перешли на отсчёт с нуля)?"
            }
        ]
    },
    {
        "id": "q_0225",
        "question": "Какие два случая рассматриваются при определении возможности полного заполнения рюкзака с учётом последнего слитка?",
        "answers": [
            "Случай 1: если последний слиток не входит в набор, то рюкзак можно заполнить первыми n-1 слитками. Случай 2: если последний слиток входит в набор, то его можно убрать, и оставшиеся слитки должны заполнять рюкзак с уменьшенной вместимостью."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
                "text": "Продемонстрируйте, как можно использовать это решение для выполнения задачи «Максимальное количество золота». Предположим, что заполнить рюкзак до конца действительно возможно: существует наборс общим весом. Включает ли он в себя последний слиток с весом? Случай 1: Если, тогда рюкзак вместимостьюможет быть заполнен первымислитками. Случай 2: Если, тогда мы можем убрать слиток с весомиз рюкзака, и вес оставшихся слитков составит. Таким образом, рюкзак с вместимостьюможно полностью заполнить первымислитками. В обоих случаях мы свели задачу к практически такой же, но с меньшим количеством слитков и меньшей вместимостью рюкзака. Так, переменнаябудет иметь значение, если существует возможность заполнить рюкзак с вместимостьюпервымислитками, и значениев остальных случаях. Анализ двух вышеприведённых случаев приводит нас к следующему рекуррентному соотношению для: Кроме того,идля любого. В целом Так как значенияварьируются между 0 и, а значения— между 0 и, мы имеемпеременных. Так какзависит от, мы обрабатываем все переменные в возрастающем порядке. В приведённом ниже псевдокоде мы используем двумерный массив pack размера, асохраняет значение. Время выполнения данного решения составляет. Скопировать код1Knapsack([w[0],…,w[n−1]],W):2pack = two-dimensional array ofsize(W+1)×(n+1)3initialize all elements of pack tofalse4pack[0][0] =true5fori from1to n:6forw from0to W:7ifw[i-1] >w:8pack[w][i] = pack[w][i−1]9else:10pack[w][i]←pack[w][i−1] OR pack[w−w[i−1]][i−1]11returnpack[W][n] В приведённой ниже двумерной таблице представлены результаты вызоваKnapsack([1,3,4], 8. F и T означают значенияfalseиtrue. Другое решение будет заключаться в анализе поднаборов всех слитков. Наша цель — найти поднабор изслитков с общим весом. Простой подход к такой задаче — просматривать все поднаборы и проверять, есть ли поднабор с весом. Так как каждый слиток можно или пропустить, или взять, каждый поднабор из трёх слитков, который мы анализируем (,,), можно представить сине-красным бинарным вектором: Теперь мы представим каждый поднабор слитков как путь, начинающийся от узласетки. Если первый бит — синий, то он соответствует синему горизонтальному сегменту сетки, связывающемус. Если первый бит — красный, то он соответствует красному сегменту сетки, связывающемус. Обработав первыебитов, мы получаем сине-красный путь отдо некого узлана сетке. Если следующий бит — синий, мы связываемс. Если следующий бит — красный, мы связываемс, как показано ниже для вектора 101: Рисунок ниже демонстрирует пути, которые соответствуют всем восьми бинарным векторам с длиной 3. Теперь мы накладываем все эти восемь путей на одну сетку: Мы классифицируем узелна сетке как истинный («true») при наличии пути откна рисунке выше. В других случаях — ложный («false»). Теперь мы можем полностью заполнить рюкзак с вместимостьюподнабором из первыхслитков, если узел— истинный («true»). Узел будет истинным в случаях, если в него проходит или синее, или красное ребро. То есть, еслиилиистинны. Это наблюдение приводит нас к предыдущему рекуррентному соотношению и к такому же решению с динамическим программированием. А вот ещё один вариант решения, который основан на мемоизации. Приведённый ниже псевдокод рекурсивно вычисляет рекуррентное соотношение из решения 1: Скопировать код1RecursiveKnapsack([w[0],…,w[n−1]],w,i):2ifi=0andw=0:3returntrue4elseifi=0andw >0:5returnfalse6elseifi >0andw_[i-1]>w:7returnRecursiveKnapsack([w[0],…,w[n−1]],w,i−1)8else:9returnRecursiveKnapsack([w[0],…,w[n−1]],w,i−1) ORRecursiveKnapsack([w[0],…,w[n−1]],w−w[i−1],i−1) ВызовRecursiveKnapsack([w_0, ..., w_{n-1}],W, n)решает задачу, но он сильно замедлен из-за необходимости перевычислять одни и те же значения снова и снова. Чтобы это продемонстрировать, рассмотрим рюкзак с вместимостьюислитков с весом,,. ВызовRecursiveKnapsack([1, 1, 1], 4, 3)создаёт рекурсивное дерево, приведённое ниже — каждый узел показывает значения. Даже в этом простом примере значениевычисляется дважды. С 20 слитками рекурсивное дерево может достичь гигантских размеров — одно и то же значение может вычисляться миллионы раз. Во избежание такого рекурсивного взрыва мы «оборачиваем» код мемоизацией с помощью ассоциативного массива, который изначально пуст. Ассоциативный массив — это абстрактный тип данных, в котором хранятся пары. Он поддерживается многими языками программирования и, как правило, реализуется как хеш-таблица или дерево поиска. К примеру, вC++иJavaассоциативный массив называется картой («map»), а вPython— словарём («dictionary»). В реализации, приведённой ниже, ассоциативный массивиспользуется для хранения логических значений для пар. Скопировать код1MemoizedKnapsack([w[0],…,w[n−1]],pack,w,i):2if(w,i) isnotin pack:3ifi=0andw=0:4pack[(w,i)] =true5elseifi=0andw >0:6pack[(w,i)] =false7elseifi >0andw_[i-1]>w:8pack[(w,i)] =MemoizedKnapsack([w[0],…,w[n−1]],pack,w,i−1)9else:10pack[(w,i)] =MemoizedKnapsack([w[0],…,w[n−1]],pack,w,i−1) ORMemoizedKnapsack([w[0],…,w[n−1]],pack,w−w[i−1],i−1)11returnpack[(w,i)] Время выполнения итогового решения составляет, так как количество рекурсивных вызовов, не являющихся уточняющими запросами в ассоциативный массив, не превышает это число. Следовательно, это такое же время выполнения, как и у соответствующего итерационного алгоритма. На практике же итерационное решение, как правило, быстрее, потому что в нём нет рекурсивных издержек и оно использует более простые структуры данных. Например, массив вместо хеш-таблицы. Тем не менее с рассматриваемой задачей ситуация иная: при некоторых наборах данных, рекурсивная версия быстрее итерационной. К примеру, если мы умножим все весовые значения на, то время выполнения итерационного алгоритма также умножится на, в то время как время выполнения рекурсивного останется таким же. В целом, если необходимо решить все возможные подзадачи, итерационный вариант обычно быстрее."
            }
        ]
    },
    {
        "id": "q_0226",
        "question": "Какие два основных подхода к решению задачи о рюкзаке с помощью динамического программирования рассматриваются?",
        "answers": [
            "Рекурсивный подход с мемоизацией и итерационный подход с заполнением таблицы достижимости весов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
                "text": "Теперь вы умеете решать задачу о рюкзаке с помощью динамического программирования — как рекурсивно с мемоизацией, так и итерационно. Вы научились строить таблицу достижимости весов и поняли, почему простая жадность здесь не работает. Далее — задача про сувениры: вы узнаете, как свести динамическую задачу к более простой, если ограничен не вес, а количество предметов и целевая сумма. Новый подход позволит взглянуть на подмножества и веса под другим углом. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадная стратегия не даёт оптимального решения в задаче о рюкзаке — нужно перебрать возможные комбинации. Решение строится через рекурсию с мемоизацией или итеративное заполнение таблицы достижимости. Итерационный подход обычно быстрее, но рекурсивный с мемоизацией может быть удобнее в реализации. Количество подзадач ограничено, поэтому решение работает за O(nW) — достаточно эффективно даже для больших входов."
            }
        ]
    },
    {
        "id": "q_0227",
        "question": "В каких ситуациях рекомендуется использовать алгоритм полного перебора?",
        "answers": [
            "Алгоритм полного перебора стоит применять, когда размер входных данных невелик, а другие, более эффективные методы решения задачи отсутствуют или неизвестны."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/polnyj-perebor-i-optimizaciya-perebora",
                "text": "Что такое алгоритм полного перебора и когда его стоит применять? Почему переборные алгоритмы считаются неэффективными? Как метод ветвей и границ помогает ускорить перебор?"
            }
        ]
    },
    {
        "id": "q_0228",
        "question": "Какой метод проектирования алгоритмов гарантирует нахождение решения, но может быть слишком медленным для серьёзных задач?",
        "answers": [
            "Алгоритм полного перебора (исчерпывающий поиск или метод грубой силы) гарантирует нахождение решения, рассматривая все возможные варианты. Однако такие алгоритмы являются самыми лёгкими в проектировании, но слишком медленными для решения серьёзных задач, кроме самых маленьких."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/polnyj-perebor-i-optimizaciya-perebora",
                "text": "За полвека программисты обнаружили, что многие алгоритмы основаны на схожих концептах, хотя и используются для решения разных проблем. Получается, основных методов проектирования алгоритмов относительно немного. Некоторые из них мы охватим в задачах, а пока расскажем о наиболее распространённых. Последующие примеры можно будет категоризировать по методологии проектирования. Для демонстрации мы рассмотрим очень простую ситуацию, с которой может столкнуться едва ли не каждый обладатель беспроводного домашнего телефона. Алгоритм, использующий полный перебор (также этот метод называют «исчерпывающий поиск» или «метод грубой силы»), рассматривает все возможные варианты и находит определенное решение. Если бы вы искали телефон по такому алгоритму, то игнорировали бы звонок и проверяли бы каждый квадратный сантиметр вашего дома. Вряд ли вы бы успели взять трубку, — иначе вашей удаче можно позавидовать, — но исчерпывающий поиск гарантирует, что рано или поздно вы найдете телефон, где бы он ни был. BruteForceChange— это алгоритм «грубой силы». Наши задачи включают несколько дополнительных примеров таких алгоритмов. Они самые легкие с точки зрения проектирования, но слишком медленные для решения более серьёзных задач, нежели самых маленьких. Мы советуем или избегать алгоритмов «грубой силы» или находить решения, которые ускоряют их работу. Если рассмотреть варианты, предложенные алгоритмом «грубой силы», мы увидим, что многие из них можно опустить. Эта техника называется методом ветвей и границ. Представьте, что вы прочёсываете первый этаж и слышите, как над вами звонит телефон. Значит, на первом этаже и в подвале можно больше не искать — и вы сэкономили себе время. Хотя алгоритмы полного перебора и не подходят для построения эффективных алгоритмов, мы рекомендуем использовать их для стресс-тестирования — техники поиска ошибок в алгоритмах, подробнее о которой мы поговорим впараграфе 4.3."
            }
        ]
    },
    {
        "id": "q_0229",
        "question": "Какой метод помогает ускорить перебор, отсекая заведомо бесполезные варианты?",
        "answers": [
            "Метод ветвей и границ помогает отсекать заведомо бесполезные варианты и ускорять перебор."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/polnyj-perebor-i-optimizaciya-perebora",
                "text": "Теперь вы знаете, как работает полный перебор и почему он не всегда подходит для сложных задач. Вы также познакомились с методом ветвей и границ — первым шагом к ускорению перебора. Далее — жадные алгоритмы. Вы узнаете, когда можно принимать решения на каждом шаге, не заглядывая вперёд, и почему это иногда приводит к оптимальному результату, а иногда — нет. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Полный перебор перебирает все возможные варианты и гарантирует нахождение решения, если оно существует. Такой подход прост, но становится неэффективным при росте объёма входных данных. Метод ветвей и границ помогает отсекать заведомо бесполезные варианты и ускорять перебор. Несмотря на неэффективность, переборные алгоритмы полезны для тестирования и понимания структуры задач."
            }
        ]
    },
    {
        "id": "q_0230",
        "question": "Какая основная идея лежит в основе жадного алгоритма?",
        "answers": [
            "Основная идея жадного алгоритма заключается в том, чтобы на каждом шаге принимать локально оптимальное решение, выбирая наилучший вариант в текущий момент, в надежде, что это приведёт к глобально оптимальному решению задачи."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zhadnye-algoritmy",
                "text": "Что такое жадный алгоритм и в чём его идея? Почему не всякая жадная стратегия приводит к оптимальному решению? Как формализовать и доказать корректность жадного алгоритма?"
            }
        ]
    },
    {
        "id": "q_0231",
        "question": "Какой алгоритм максимизирует количество непересекающихся отрезков в задаче «Бронирование переговорки»?",
        "answers": [
            "Оптимальный жадный алгоритм: выбрать отрезок, который заканчивается раньше всех (чемпионский отрезок), удалить все пересекающиеся с ним отрезки, и повторить процедуру для оставшихся отрезков."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zhadnye-algoritmy",
                "text": "Многие алгоритмы — это итерационные процедуры: с каждым повтором они делают выбор из определенного количества вариантов. Например, для кассира задача «Размен» может быть представлена как последовательность решений: какую монету (изценностей) вернуть первой, какую второй и так далее. Некоторые из этих вариантов приведут к правильному ответу, а некоторые — нет. При каждом повторе жадный алгоритм выбирает «самый привлекательный» вариант. Например, самый большой номинал из доступных монет. В случае с американскими деньгамиChangeиспользует номиналы четвертак (25 центов), дайм (10 центов), никель (5 центов) и пенни (1 цент), чтобы выдать сдачу, в данном порядке. Разумеется, мы показывали, как такой «жадный» подход приводит к неправильным результатам при добавлении монет некоторых новых номиналов. В примере с телефоном «жадная» стратегия состояла бы в том, чтобы идти на звук, пока вы его не найдете. Но есть проблема: между вами и телефоном может оказаться стена (или хрупкая ваза). К сожалению, такие сложности часто возникают и в реальных задачах. Во многих случаях «жадный» подход выглядит естественным и очевидным, но может оказаться неправильным. В задаче «Бронирование переговорки» вам дается несколько временных отрезков, и нужно выбрать как можно больше отрезков таким образом, чтобы ни один из них не пересекался с другим (отрезки пересекаются, если у них есть общая точка). Название задачи основано на следующей гипотетической ситуации. Представьте, что у вас есть зал для переговоров, и вам присылают заявки на бронирование 11 компаний. Нельзя удовлетворить все запросы (так как некоторые из них пересекаются), но мы хотим удовлетворить как можно больше. Для этого мы представим входные данные более удобным способом. Так как мы говорим о «жадных» стратегиях, давайте поэкспериментируем с разными «наиболее выгодными» подходами. Интуиция может нам подсказать, что нужно выбрать самый короткий отрезок, удалить пересекающиеся отрезки и повторить данное действие. Возможно, логичнее было бы выбрать отрезок слева (тот, что начинается раньше всех), убрать все остальные и повторить данное действие. Оказывается, что следующий «жадный» алгоритм максимизирует количество непересекающихся отрезков: выбрать чемпионский отрезок, убрать все пересекающиеся с ним отрезки, повторить выбор. Докажите, что если набор непересекающихся отрезков не содержит чемпионский отрезок, то при замене первого отрезка в этом наборе на чемпионский мы получаем набор непересекающихся отрезков. Вот мы и нашли оптимальную «жадную» стратегию. И действительно, если существует решение задачи, включающее в себя чемпионский интервал, мы можем выбрать этот интервал на первом шаге и решить задачу выбора непересекающихся отрезков из оставшихся. В нашем примере алгоритм работает следующим образом. Выбрать сегменти отбросить сегменты,,, и. Выбрать сегменти отбросить сегментыи. Выбрать сегмент. Выбрать сегмент. Выбрать сегмент."
            }
        ]
    },
    {
        "id": "q_0232",
        "question": "Какой подход позволяет решать сложные задачи, разбивая их на подзадачи и используя уже найденные решения?",
        "answers": [
            "Динамическое программирование — это подход, который позволяет решать сложные задачи, разбивая их на подзадачи и используя уже найденные решения, избегая повторных вычислений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zhadnye-algoritmy",
                "text": "Теперь вы понимаете, как устроены жадные алгоритмы и почему они могут быть одновременно простыми и опасными. Вы научились проверять, работает ли жадная стратегия в конкретной задаче, и даже доказывать её оптимальность. Далее — динамическое программирование. Это подход, который позволяет решать сложные задачи, разбивая их на подзадачи и используя уже найденные решения. Вы узнаете, как избежать повторных вычислений и добиться эффективности там, где перебор и жадность не справляются. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм на каждом шаге выбирает наиболее выгодный вариант, не заглядывая вперёд. Такой подход прост и работает быстро, но не всегда даёт оптимальное решение. Чтобы жадная стратегия была корректной, необходимо доказать, что локальный выбор всегда ведёт к глобально лучшему результату. В некоторых задачах — например, при выборе максимального числа непересекающихся отрезков — удаётся найти и обосновать корректную жадную стратегию."
            }
        ]
    },
    {
        "id": "q_0233",
        "question": "Каковы основные принципы стратегии «Разделяй и властвуй» и как они реализуются в алгоритме двоичного поиска?",
        "answers": [
            "Стратегия «Разделяй и властвуй» основана на рекурсивном разбиении задачи на меньшие подзадачи до достижения тривиального решения. В двоичном поиске это реализуется через постоянное деление отсортированного массива пополам и проверку среднего элемента, что позволяет отбрасывать половину оставшихся элементов на каждом шаге."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
                "text": "Как работает стратегия «Разделяй и властвуй» и как она применяется в двоичном поиске? Почему двоичный поиск так эффективен и в чём его отличие от линейного поиска? Как корректно реализовать двоичный поиск и что важно учесть при работе с границами и условиями?"
            }
        ]
    },
    {
        "id": "q_0234",
        "question": "Какие три шага необходимо выполнить для решения задачи с помощью стратегии «разделяй и властвуй»?",
        "answers": [
            "Сначала нужно разделить задачу на более мелкие подзадачи, затем рекурсивно решить каждую подзадачу, и наконец объединить решения подзадач в решение исходной задачи."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
                "text": "В этом параграфе вы узнаете об алгоритмах «разделяй и властвуй», которые помогают выполнять поиск по огромным базам данных в миллион раз быстрее, чем алгоритмы исчерпывающего поиска. Вооружившись этой техникой, вы узнаете, что стандартный способ умножать числа (которому вас учили в начальной школе) далеко не самый быстрый. Затем мы применим подход «разделяй и властвуй», чтобы спроектировать быстрые алгоритмы для сортировки. Вы узнаете, что эти алгоритмы оптимальны — то есть даже легендарный ученый Алан Тьюринг не смог бы спроектировать алгоритм сортировки быстрее! Если вы хотите решить задачу с помощью стратегии «разделяй и властвуй», вам нужно подумать о следующих трёх шагах: Разделение задачи на подзадачи поменьше. Рекурсивное решение каждой подзадачи. Объединение выполненных подзадач в решение изначальной задачи. Первые два шага — это и есть «разделяй», а последний — «властвуй». Мы продемонстрируем такой подход в нескольких примерах, сложность которых будет возрастать. Игра «Угадать число» состоит в том, что оппонент загадывает целое число. Вы задаёте вопрос: «?». Оппонент отвечает либо «да», либо «» (то есть «мое число меньше»), либо «» (то есть «мое число больше»). Ваша задача — получить ответ «да», задав минимальное количество вопросов. Пусть: ваша задача — угадать, задав не больше двух вопросов. Вы можете спросить: «?». Если ответ положительный, то вы победили.Но оппонент может ответить: «». Вы решаете, чторавенили, но у вас остаётся только один вопрос. Точно так же вы можете спросить: «?». Тогда ваш оппонент может ответить: «». В этом случае вы не сможете получить желаемый положительный ответ, задав лишь один вопрос. Посмотрим, что будет, если вы сначала спросите: «?». Если оппонент отвечает, что, тогда игра окончена. Если ответ —, то вы уже знаете, что. Следовательно, второй раз вы просто спрашиваете: «?». И теперь вы получаете положительный ответ. Если оппонент ответит, что, то вы спрашиваете: «?». Ответ на него: «Да». Угадать целое число, задав не больше трёх вопросов. Вы уже могли догадаться, что мы начнём с вопроса: «?». Дело в том, что в обоих случаях —и— мы сокращаем пространство поиска с 7 до 3 вариантов (нам уже известно, как решить задачу свозможными вариантами): если, тобудет 1, 2 или 3; если, тобудет 5, 6 или 7. Это означает, что в обоих случаях вы можете воспользоваться решением разобранного ранее случая. Получившийся протокол вопросов показан на рисунке. Следующий код имитирует процесс угадывания. Функцияquery«знает» целое число. Вызовquery(y)сообщает нам:, или, или. Функцияguess()находит числос помощью вызоваquery(). Она вызывается с двумя параметрами:lowerиupper— так, чтобы то естьнаходится в сегменте. Сначала она рассчитывает середину (middle) сегмента, затем вызывает. Если, тогда она продолжает работать с интервалом. Если, тогда она переходит к интервалу. Скопировать код1query(y):2x =16182353ifx == y:4return'equal'5ifx <y:6return'smaller'7else:8return'greater'91011guess(lower, upper):12middle = (lower + upper) /2// целочисленное деление13answer =query(middle)14// можно напечатать запрос и соответствующий результат15ifanswer =='equal':16return17ifanswer =='smaller':18guess(lower, middle -1)19else:20guess(middle +1, upper)212223guess(1,2097151)// начальный возможный диапазон значений Реализуйте этот алгоритм, измените значениеи запустите код, чтобы увидеть последовательность вопросов (удостоверьтесь, чтонаходится в сегменте, который используется при вызовеguess). В целом стратегия, угадывающая целое число, потребует околовопросов. Напомним, чторавняется, если. Это значит, что если мы продолжим делитьна 2, пока не получим 1, будет околоопераций деления. Важно здесь то, что— медленно растущая функция. К примеру, если, то. Метод, который мы использовали для угадывания числа, известен как двоичный поиск. Пожалуй, самый важный случай применения двоичного поиска — это поиск по отсортированным данным. Поиск — фундаментальная задача: имея последовательность и элемент, мы хотим проверить, входит лив последовательность. Например, 3 входит в последовательность, а 4 — не входит. Зная о важности задачи по поиску, неудивительно, что методы для её решения есть почти во всех языках программирования. Скопировать код1print(3in[7,2,5,6,11,3,2,9])2print(4in[7,2,5,6,11,3,2,9]) Что происходит внутри, когда мы вызываем методin? Ожидаемо,Pythonвыполняет линейное сканирование. На это требуетсясравнений при последовательности длиной. Если в последовательность не входит, нам необходимо просканировать все элементы: если мы будем пропускать, то мы не можем точно знать, отсутствует ли. Ситуация кардинально меняется, если полученные данные отсортированы, то есть составляют собой отсортированную последовательностьв порядке возрастания. Оказывается, что в этом случае достаточно околосравнений! Это значительное ускорение: линейный поиск по отсортированному массиву с миллиардом элементов потребует миллиарда сравнений, двоичному же поиску будет достаточно не больше!"
            }
        ]
    },
    {
        "id": "q_0235",
        "question": "Какой формат ввода используется для задачи поиска индекса элемента в отсортированном массиве?",
        "answers": [
            "Первые две строки содержат целое число n и последовательность из n неповторяющихся положительных целых чисел в возрастающем порядке. Следующая строка содержит целое число q — искомый элемент."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
                "text": "Ваша задача — найти индекс элемента в сортированной последовательности равного. Формат ввода: Отсортированный массивнеповторяющихся целых чисел и целое число. Первые две строки ввода содержат целое числои последовательностьизнеповторяющихся положительных целых чисел в возрастающем порядке. Следующая строка содержит целое число. Формат вывода: Позиция элемента вравногоилипри отсутствии такого элемента. Ограничения:;для всех;. Примеры Можно решить эту задачу примитивным способом — просканировать массив(время выполнения составит). Время решения этой задачи для алгоритмаBinarySearch—. Он инициализируется при присвоениизначения 0 изначения. Сначала алгоритм присваиваетзначение, а затем проверяет, больше, чем, или нет. Еслибольше, чем это значение, тоBinarySearchпроводит итерацию на подмассивеот minIndex до. В ином случае он проводит итерацию на подмассивеотдо. В конечном счёте алгоримт определит, находитсявили нет. Скопировать код1BinarySearch(K[0..n−1], q)2minIndex =03maxIndex = n−14whilemaxIndex >= minIndex:5midIndex = (minIndex+maxIndex) /2// целочисленное деление6ifK[midIndex] = q:7returnmidIndex8elseK[midIndex] <q:9minIndex = midIndex +110else:11maxIndex = midIndex -112return-1 Например, еслии,BinarySearchсначала задаст следующее:,и. Так какбольше, чем, мы рассматриваем подмассив, элементы которого больше, установив, и таким образомперевычисляется как. В этот разменьше, чем, поэтому мы рассматриваем подмассив, элементы которого ниже этого значения. Этот подмассив состоит из одного элемента —. Время выполненияBinarySearchсоставляет, так как алгоритм снижает длину подмассива минимум в два раза при каждой итерации циклаwhile. Дело в том, что любой программе требуется линейное время для чтения данных ввода. По этой причине мы предлагаем вам решить следующую более общую задачу."
            }
        ]
    },
    {
        "id": "q_0236",
        "question": "Какие данные содержатся в первых двух строках входных данных согласно описанию формата?",
        "answers": [
            "Первые две строки содержат целое число n и последовательность из n неповторяющихся положительных целых чисел, отсортированных в возрастающем порядке."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
                "text": "Вывод: При каждомнеобходимо проверить, входит лив. Формат ввода: Отсортированный массивнеповторяющихся целых чисел и массив целых чисел. Первые две строки ввода содержат целое числои последовательностьизнеповторяющихся положительных целых чисел в возрастающем порядке. Следующие две строки содержат целое числоиположительных целых чисел. Формат вывода: Для всехотдовыведите индекс, чтобыилипри отсутствии такого индекса. Ограничения:;;для всех;для всех. Примеры Совет: не используйте встроенный двоичный поиск"
            }
        ]
    },
    {
        "id": "q_0237",
        "question": "Какой процент профессиональных программистов из ведущих компаний допускал ошибки при реализации алгоритма двоичного поиска с дублированием по данным Дональда Кнута?",
        "answers": [
            "90% профессиональных программистов из ведущих компаний, таких как IBM, допускали ошибки при реализации алгоритма двоичного поиска с дублированием."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
                "text": "Как пишет автор книги «Искусство программирования» Дональд Кнут: «Хотя основная идея двоичного поиска относительно проста, детали могут быть на удивление сложными». Он подразумевает изменённую версию классической задачи двоичного поиска: Когда Кнут попросил профессиональных программистов из таких ведущих компаний, как IBM, реализовать эффективный алгоритм двоичного поиска с дублированием, в 90% из них были баги — год за годом. И правда, хотя первый алгоритм двоичного поиска был опубликован в 1946 году, первый алгоритм для поиска с дублированием, в котором не было багов, впервые опубликовали только в 1962 году. По аналогии с предыдущей задачей здесь мы предлагаем найтицелых чисел, а не одно. Формат ввода: Первые две строки ввода содержат целое числои последовательностьизположительных целых чисел в неубывающем порядке. Следующие две строки содержат целое числоиположительных целых чисел. Формат вывода: Для всехотдовывод индексапервого встречающегося(то есть) или— если такого индекса нет. Ограничения:;;для всех;для всех. Примеры Совет: не используйте встроенный двоичный поиск У вас есть ключи вам необходимо найти первое, самое раннее место, где этот ключ встречается в массиве. Например, еслии ключ— это, тогда первое место, где он встречается, — это индекс. Разумеется, вы можете найти одно из мест, просто начав двоичный поиск. Чтобы найти первое место, где ключ встречается, вы можете последовательно проверять элемент перед позицией того, который был найден, — что и демонстрируется в выделенных голубым строках приведенного ниже псевдокода. Скопировать код1NaiveBinarySearchWithDuplicates(K[0..n−1], q)2minIndex =03maxIndex = n−14whilemaxIndex >= minIndex:5midIndex = (minIndex + maxIndex) /26ifK[midIndex] = q:7top = midIndex8whiletop >0andK[top −1] = K[top]:9top = top -110returntop11ifK[midIndex] <q:12minIndex = midIndex +113else:14maxIndex = midIndex −115return-1 Этот алгоритм может существенно замедлиться при массиве с большим количеством повторов. Например, если повторяющийся элемент занимает половину массива, тоNaiveBinarySearchWithDuplicatesпотребует линейное времявместо логарифмического времени. Эта проблема устранена в псевдокоде ниже. Скопировать код1NaiveBinarySearchWithDuplicates(K[0..n−1], q)2minIndex =03maxIndex = n−14result =-15whilemaxIndex >= minIndex:6midIndex = (minIndex + maxIndex) /27ifK[midIndex] = q:8maxIndex = midIndex -19result = midIndex10elseifK[midIndex] <q:11minIndex = midIndex +112else:13maxIndex = midIndex −114returnresult"
            }
        ]
    },
    {
        "id": "q_0238",
        "question": "Какой алгоритм используется для быстрого определения самого популярного товара, занимающего более половины покупок?",
        "answers": [
            "Для этой задачи применяется стратегия «Разделяй и властвуй» с использованием рекурсии и постобработки для анализа последовательностей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
                "text": "Теперь вы знаете, как работает двоичный поиск — быстрый и надёжный способ находить элементы в отсортированных структурах. Вы научились реализовывать его корректно, аккуратно обращаться с границами и условиями, а также оценивать его эффективность. Далее — задача на определение доминирующего элемента. Представьте, что в базе заказов вам нужно быстро определить, какой товар покупают чаще всего и действительно ли он занимает больше половины всех покупок. Эта задача покажет, как использовать стратегию «Разделяй и властвуй» для анализа последовательностей и комбинировать рекурсию с постобработкой для точного результата. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Двоичный поиск — это способ найти элемент в отсортированной последовательности за логарифмическое время. Корректная реализация требует аккуратной работы с границами, особенно при вычислении середины. Ошибки в условиях цикла или смещении границ — частая причина багов, особенно на больших входах. Двоичный поиск можно адаптировать для решения более сложных задач — например, нахождения первого/последнего вхождения или границы условий."
            }
        ]
    },
    {
        "id": "q_0239",
        "question": "Какие шаги необходимо выполнить для оформления корректного, понятного и быстрого решения при использовании жадного подхода?",
        "answers": [
            "Решение должно включать доказательство корректности жадного алгоритма, а не опираться только на интуицию. Оформление должно быть структурированным, логичным и обеспечивать эффективную работу алгоритма."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-reklamnaya-kampaniya",
                "text": "Как работает жадный алгоритм в задаче выбора по критерию «прибыль за ресурс»? Почему важно доказывать корректность жадного подхода, а не полагаться только на интуицию? Как оформить решение, чтобы оно было корректным, понятным и быстрым?"
            }
        ]
    },
    {
        "id": "q_0240",
        "question": "Какой алгоритм предлагается для максимизации прибыли при распределении рекламных мест между рекламодателями?",
        "answers": [
            "Алгоритм заключается в последовательном объединении рекламного места с максимальным количеством кликов и рекламодателя с максимальной ценой за клик, после чего эти элементы исключаются из рассмотрения, и процесс повторяется."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-reklamnaya-kampaniya",
                "text": "Представим, что вы владелец популярной страницы в интернете, на которой естьрекламных мест. Вы хотите продать их рекламодателям, которые рассчитывают на,икликов в день и при этом готовы платить,иза клик. Как подобрать пары рекламных мест и рекламодателей так, чтобы получить максимальную прибыль? Например, доход от отмеченных голубым цветом пар, приведённых выше, составитдолларов; от отмеченных чёрным —. Входные данные: В первой строке приведено целое число, во второй — последовательность целых чисел, в третьей — последовательность целых чисел. Выходные данные: Максимальное значение, где— это перестановка. Ограничения:;для всех. . . Суть решения заключается в том, чтобы отдать самое популярное рекламное место самому дорогому объявлению. Вас вряд ли удивит, что жадный подход даст максимальную прибыль. Предположим, чтои— самые большие элементы:идля всех. Мы утверждаем, что существует оптимальное решение, объединяющеес. Чтобы доказать это, возьмём оптимальное решение и предположим, что в нём объединеныидляиидля. Покажем, что замена парина парыитолько повысит прибыль. Давайте оценим, как такая замена повлияет на общую прибыль. До замены рассматриваемые элементы давали следующую прибыль: После замены: Таким образом, замена увеличивает общую прибыль на Это приводит нас к алгоритму, который объединяет рекламное объявление с максимальным количеством кликов за максимальную цену, исключает их из вариантов на рассмотрение и повторяет то же самое. Скопировать код1Revenue(Click,Price):2revenue =03whileclicks isnotempty:4p = index with largest Click[p]5q = index with largest Price[q]6revenue = revenue+Clicks[p]⋅Price[q]7remove p-th element of Click8remove q-th element of Price9returnrevenue Время выполнения. Время выполнения этого алгоритма —. В каждой изитераций мы проводим линейное сканирование и находим два самых больших элемента. Также можно отсортировать эти два списка заранее, чтобы не искать самый большой элемент с нуля при каждой итерации. Это приводит нас к решению с временем выполнения."
            }
        ]
    },
    {
        "id": "q_0241",
        "question": "В каких практических задачах может применяться алгоритм покрытия отрезков минимальным числом точек?",
        "answers": [
            "Такой алгоритм может использоваться для планирования размещения рекламных щитов вдоль трассы или для выбора минимального числа дат для встреч, чтобы все участники могли присутствовать."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-reklamnaya-kampaniya",
                "text": "Теперь вы знаете, как работать с задачами, где допускается дробный выбор, и почему жадный отбор по плотности гарантирует оптимальное решение. Вы также увидели, что при работе с вещественными числами важно следить за точностью вычислений и оформлением кода. Далее — задача с другим типом постановки: нужно покрыть набор отрезков минимальным числом точек. Такой приём встречается, например, в планировании размещения рекламных щитов вдоль трассы или выборе минимального числа дат для встреч, чтобы все участники могли присутствовать. Это ещё один пример, где жадный алгоритм работает эффективно, — если правильно обосновать его корректность. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. В задачах с «дробным» выбором можно брать часть объекта, чтобы максимизировать результат — это принципиально отличается от дискретных задач. Жадная стратегия по убыванию плотности гарантирует оптимальное решение именно в дробном случае, но не всегда работает для целочисленных вариантов. Доказательство оптимальности помогает понять границы применения жадных алгоритмов и увидеть, где они перестают работать. Работа с вещественными числами требует особой аккуратности, чтобы избежать ошибок округления и потери точности."
            }
        ]
    },
    {
        "id": "q_0242",
        "question": "Какой подход к планированию последовательности наград позволяет максимизировать количество получателей?",
        "answers": [
            "Для максимизации числа получателей наград следует применять жадный подход."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-kolichestvo-prizov",
                "text": "Как спланировать последовательность наград, чтобы максимизировать число получателей? Почему здесь работает жадный подход и как доказать его корректность? Как использовать свойства суммы арифметической прогрессии при решении алгоритмических задач?"
            }
        ]
    },
    {
        "id": "q_0243",
        "question": "Какое максимальное количество различных положительных целых чисел можно использовать для представления заданного числа N в виде их суммы?",
        "answers": [
            "Максимальное количество k различных положительных целых чисел, которые можно использовать для представления числа N в виде их суммы, определяется условием N ≥ k(k+1)/2. Это следует из того, что минимальная сумма k различных положительных целых чисел равна 1+2+...+k = k(k+1)/2."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-kolichestvo-prizov",
                "text": "Вы занимаетесь организацией соревнований для детей, и у вас естьконфет, которые собираетесь раздать в качестве призов. Вы хотите отдать эти конфеты тем, кто займёт первыемест в соревнованиях, и распределить конфеты так, чтобы за более высокое место всегда выходило больше конфет. Чтобы порадовать как можно больше детей, вам понадобится найти самое большое значение, при котором это возможно. Входные данные: Целое число. Выходные данные: Первая строка содержит максимальное число, при которомможно представить как суммупар неповторяющихся положительных целых чисел. Вторая строка —пар неповторяющихся положительных целых чисел, сумма которых будет(если есть несколько таких вариантов, то можно использовать любой из них). Ограничения:. Можно ли представить 8 как сумму четырёх неповторяющихся положительных целых чисел? Нетрудно понять, что ответ на этот вопрос: «Нет». Предположим, чтои. Тогда,,и. Однако тогда. По этой же причине, еслиравно сумменеповторяющихся положительных целых чисел, то. Верно и обратное: если, то можно представитькак суммунеповторяющихся целых чисел. Действительно, пусть. Тогдабудет равно сумме следующих целых чисел:. Несложно заметить, что все они отличаются друг от друга. Алгоритм состоит в нахождении самого большого значения, при котором. Время выполнения —или."
            }
        ]
    },
    {
        "id": "q_0244",
        "question": "В каких задачах распределения хорошо работают жадные алгоритмы?",
        "answers": [
            "Жадные алгоритмы хорошо работают в задачах распределения, когда нужно покрыть максимум с минимальными затратами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-kolichestvo-prizov",
                "text": "Теперь вы умеете применять жадные алгоритмы для распределения ограниченного ресурса и знаете, в каких случаях такая стратегия приводит к оптимальному решению. Далее — финальная задача главы. Она покажет, что даже на собеседовании можно столкнуться с подводными камнями жадной стратегии: чтобы получить максимальный «оклад», придётся сравнивать не числа, а строки. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадные алгоритмы хорошо работают в задачах распределения, когда нужно покрыть максимум с минимальными затратами. Иногда достаточно отсортировать входные данные и обрабатывать их по порядку — это уже даёт оптимальный результат. Простые стратегии требуют точной формулировки и аккуратной реализации — особенно при работе с ограничениями."
            }
        ]
    },
    {
        "id": "q_0245",
        "question": "Какой вид генеративных моделей, помимо VAE и GAN, позволяет генерировать новые объекты из заданного распределения, удаляя шум шаг за шагом?",
        "answers": [
            "Диффузионные модели. Они берут шум и постепенно удаляют его компоненты, пока не получат объект из нужного распределения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
                "text": "В этом параграфе мы снова попробуем решить задачу генерации, когда нам дана выборка объектов из распределения, и хотим научиться генерировать новые объекты из распределения , которых нет в нашей выборке. Вероятно, вы уже знакомы с другими генеративными моделями, например VAE или GAN-ы. Здесь же мы познакомим вас с еще одним видом генеративных моделей:диффузионные модели, которые стали крайне популярны в последнее время благодаря своему высокому качеству генерации объектов из заданного распределения. В общий чертах, они работают следующим образом: берем шум изи шаг за шагом удаляем компоненты шума до тех пор, пока не получим объектиз распределения, см. иллюстрацию ниже."
            }
        ]
    },
    {
        "id": "q_0246",
        "question": "В чём заключается разница между прямым и обратным диффузионными процессами?",
        "answers": [
            "Прямой процесс заключается в постепенном зашумлении картинки с помощью распределения, а обратный процесс, наоборот, в расшумлении с помощью распределения. Прямой процесс добавляет гауссовский шум к объекту, а обратный процесс параметризуется моделью, которая по зашумленному объекту и шагу предсказывает среднее и дисперсию для восстановления."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
                "text": "Для детального понимания стоит объяснить, что такоепрямой и обратный диффузионные процессы.Прямойпроцесс заключается в постепенном зашумлении картинки с помощью распределения, аобратный, наоборот, в расшумлении с помощью распределения. Их можно схематично изобразить следующим образом: Прямойдиффузионный процесс определяется как апостериорное распределение. Это распределение также является Марковской цепочкой, которая постепенно добавляет гауссовский шум к объекту. На каждом шаге шум добавляется с различной магнитудой, которая определяется расписанием дисперсий. При правильном выборе расписания в пределе по числу шаговмы должны сойтись к шуму из. В качестве распределенийберут нормальные распределения: Теперь перейдем кобратномупроцессу и к самойдиффузионной модели. Диффузионная модель- это вероятностная модель с латентными переменными вида, где промежуточные состояниясоответствуют зашумленным объектам, a- объект из распределения. Совместное распределениеназываетобратным диффузионным процессом, который представляет собой Марковскую цепочку из гауссовских распределений: Таким образом, обратный процесс параметризуется моделью, которая по зашумленному объектуи шагупредсказывает среднееи дисперсию."
            }
        ]
    },
    {
        "id": "q_0247",
        "question": "На какие три компоненты разлагается ошибка алгоритма при использовании квадратичной функции потерь согласно bias-variance decomposition?",
        "answers": [
            "Ошибка разлагается на неустранимый шум в данных, смещение предсказания алгоритма относительно истинной зависимости и дисперсию (разброс) предсказаний в зависимости от обучающей выборки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
                "text": "Предположим, мы решаем задачу регрессии с квадратичной функцией потерь. При использовании квадратичной функции потерь для оценки качества работы алгоритмаможно воспользоваться следующим функционалом: где — обучающая выборка — точка из тестового множества — целевая зависимость, которую мы можем измерить с точностью до случайного шума — значение алгоритма, обученного на выборке, в точке — среднее по всем тестовым точкам и— среднее по всем обучающим выборками случайному шуму Длясуществует разложение на три компоненты — шум, смещение и разброс. Это разложение называетсяbias-variance decomposition, оно — одно из мощных средств для анализа работы ансамблей. О том, как его вывести, вы узнаете в соответствующемпараграфе, а здесь мы приведём его формулировку. Существует представлениев виде трёх компонент: где этосмещениепредсказания алгоритма в точке, усреднённого по всем возможным обучающим выборкам, относительно истинной зависимости, этодисперсия (разброс)предсказаний алгоритма в зависимости от обучающей выборки, это неустранимыйшумв данных. Раз нам известно, что ошибка алгоритма раскладывается на шум, смещение и разброс, можно подумать над способом сократить ошибку. Будет разумно попытаться сначала уменьшить одну из составляющих. Понятно, что с шумом уже ничего не сделать — это минимально возможная ошибка. Какую можно придумать процедуру, чтобы, например, сократить разброс, не увеличивая смещение? Пример приходит из жизни древних греков: если много человек проголосуют независимо друг от друга, то вместе они придут к разумному решению несмотря на то, что опыт каждого из них субъективен. Аналогом голосования в мире машинного обучения является бэггинг."
            }
        ]
    },
    {
        "id": "q_0248",
        "question": "Какой процесс называется бутстрепом в контексте бэггинга?",
        "answers": [
            "Бутстрепом называется процесс генерации подвыборок из обучающей выборки с помощью семплирования с возвращением."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
                "text": "Идеябэггинга(bagging,bootstrap aggregation) заключается в следующем. Пусть обучающая выборка состояла изобъектов. Выберем из неёпримеров равновероятно, с возвращением. Получим новую выборку, в которой некоторых элементов исходной выборки не будет, а какие-то могут войти несколько раз. С помощью некоторого алгоритмаобучим на этой выборке модель. Повторим процедуру: сформируем вторую выборкуизэлементов с возвращением и с помощью того же алгоритма обучим на ней модель. Повторив процедурураз, получиммоделей, обученных навыборках. Чтобы получить одно предсказание, усредним предсказания всех моделей: Процесс генерации подвыборок с помощью семплирования с возвращением называетсябутстрепом(bootstrap), а моделичасто называютбазовыми алгоритмами(хотя, наверное, лучше было бы назвать их базовыми моделями). Модельназывается ансамблем этих моделей. Посмотрим, что происходит с качеством предсказания при переходе от одной модели к ансамблю. Сначала убедимся, что смещение ансамбля не изменилось по сравнению со средним смещением отдельных моделей. Будем считать, что когда мы берём матожидание по всем обучающим выборкам, то в эти выборки включены также все подвыборки, полученные бутстрепом. Получили, что смещение композиции равно смещению одного алгоритма. Теперь посмотрим, что происходит с разбросом. Если предположить, что базовые алгоритмы некоррелированы, то: Получилось, что в этом случае дисперсия композиции враз меньше дисперсии отдельного алгоритма. Пусть наша целевая зависимостьзадаётся как и к ней добавляется нормальный шум. Пример семпла из таких данных: Попробуем посмотреть, как выглядят предсказания решающих деревьев глубины 7 и бэггинга над такими деревьями в зависимости от обучающей выборки. Обучим решающие деревья 100 раз на различных случайных семплах размера 20. Возьмём также бэггинг над 10 решающими деревьями глубины 7 в качестве базовых классификаторов и тоже 100 раз обучим его на случайных выборках размера 20. Если изобразить предсказания обученных моделей на каждой из 100 итераций, то можно увидеть примерно такую картину: По этому рисунку видно, что общая дисперсия предсказаний в зависимости от обучающего множества у бэггинга значительно ниже, чем у отдельных деревьев, а в среднем предсказания деревьев и бэггинга не отличаются. Чтобы подтвердить это наблюдение, мы можем изобразить смещение и разброс случайных деревьев и бэггинга в зависимости от максимальной глубины: На графике видно, как значительно бэггинг сократил дисперсию. На самом деле, дисперсия уменьшилась практически в 10 раз, что равняется числу базовых алгоритмов (), которые бэггинг использовал для предсказания: Код для отрисовки картинок и подсчёта смещения и разброса можно найтитут."
            }
        ]
    },
    {
        "id": "q_0249",
        "question": "Какой метод используется для управления степенью коррелированности базовых алгоритмов в случайном лесу?",
        "answers": [
            "В процессе обучения каждого дерева в каждой вершине случайно выбирается подмножество признаков (метод случайных подпространств), среди которых ищется оптимальный сплит. Этот приём позволяет управлять степенью скоррелированности алгоритмов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
                "text": "В предыдущем разделе мы сделали предположение, что базовые алгоритмы некоррелированы, и за счёт этого получили очень сильное уменьшение дисперсии у ансамбля относительно входящих в него базовых алгоритмов. Однако в реальной жизни добиться этого сложно: ведь базовые алгоритмы учили одну и ту же зависимость на пересекающихся выборках. Поэтому будет странно, если корреляция на самом деле нулевая. Но на практике оказывается, чтострогое выполнение этого предположения не обязательно. Достаточно, чтобы алгоритмы были в некоторой степени не похожи друг на друга. На этом строится развитие идеи бэггинга для решающих деревьев — случайный лес. Построим ансамбль алгоритмов, где базовый алгоритм — это решающее дерево. Будем строить по следующей схеме: Для построения-го дерева:Сначала, как в обычном бэггинге, из обучающей выборкивыбирается с возвращением случайная подвыборкатого же размера, что и.В процессе обучения каждого деревав каждой вершинеслучайно выбираютсяпризнаков, где— полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Сначала, как в обычном бэггинге, из обучающей выборкивыбирается с возвращением случайная подвыборкатого же размера, что и. В процессе обучения каждого деревав каждой вершинеслучайно выбираютсяпризнаков, где— полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации). Profit. Мы построилиRandom Forest (случайный лес)— комбинацию бэггинга и метода случайных подпространств над решающими деревьями. Внимательный читатель мог заметить, что при построении случайного леса у специалиста по машинному обучению есть несколько степеней свободы. Давайте обсудим их подробнее. Ошибка модели (на которую мы можем повлиять) состоит из смещения и разброса. Разброс мы уменьшаем с помощью процедуры бэггинга. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль. У неглубоких деревьев малое число параметров, то есть дерево способно запомнить только верхнеуровневые статистики обучающей подвыборки. Они во всех подвыборках будут похожи, но будут не очень подробно описывать целевую зависимость. Поэтому при изменении обучающей подвыборки предсказание на тестовом объекте будет стабильным, но не точным (низкая дисперсия, высокое смещение). Наоборот, у глубоких деревьев нет проблем запомнить подвыборку подробно. Поэтому предсказание на тестовом объекте будет сильнее меняться в зависимости от обучающей подвыборки, зато в среднем будет близко к истине (высокая дисперсия, низкое смещение). Вывод: используем глубокие деревья. Ограничивая число признаков, которые используются в обучении одного дерева, мы также управляем качеством случайного леса. Чем больше признаков, тем больше корреляция между деревьями и тем меньше чувствуется эффект от ансамблирования. Чем меньше признаков, тем слабее сами деревья. Практическая рекомендация — брать корень из числа всех признаков для классификации и треть признаков для регрессии. Выше было показано, что увеличение числа элементарных алгоритмов в ансамбле не меняет смещения и уменьшает разброс. Так как число признаков и варианты подвыборок, на которых строятся деревья в случайном лесе, ограничены, уменьшать разброс до бесконечности не получится. Поэтому имеет смысл построить график ошибки от числа деревьев и ограничить размер леса в тот момент, когда ошибка перестанет значимо уменьшаться. Вторым практическим ограничением на количество деревьев может быть время работы ансамбля. Однако есть положительное свойство случайного леса: случайный лес можно строить и применять параллельно, что сокращает время работы, если у нас есть несколько процессоров. Но процессоров, скорее всего, всё же сильно меньше числа деревьев, а сами деревья обычно глубокие. Поэтому на большом числе деревьев Random Forest может работать дольше желаемого и количество деревьев можно сократить, немного пожертвовав качеством."
            }
        ]
    },
    {
        "id": "q_0250",
        "question": "В чём состоит ключевое отличие процесса обучения базовых алгоритмов в бустинге по сравнению с бэггингом и случайным лесом?",
        "answers": [
            "В бустинге базовые алгоритмы обучаются последовательно, причём каждый следующий алгоритм обучается так, чтобы уменьшить общую ошибку всех своих предшественников. В бэггинге и случайном лесе базовые алгоритмы учатся независимо и параллельно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
                "text": "Бустинг (boosting)— это ансамблевый метод, в котором так же, как и в методах выше, строится множество базовых алгоритмов из одного семейства, объединяющихся затем в более сильную модель. Отличие состоит в том, что в бэггинге и случайном лесе базовые алгоритмы учатся независимо и параллельно, а в бустинге — последовательно. Каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников. Как следствие, итоговая композиция будет иметь меньшее смещение, чем каждый отдельный базовый алгоритм (хотя уменьшение разброса также может происходить). Поскольку основная цель бустинга — уменьшение смещения, в качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. На текущий момент основным видом бустинга с точки зрения применения на практике являетсяградиентный бустинг, о котором подробно рассказывается в соответствующемпараграфе. Хотя случайный лес — мощный и достаточно простой для понимания и реализации алгоритм, на практике он чаще всего уступает градиентному бустингу. Поэтому градиентный бустинг сейчас — основное продакшн-решение, если работа происходит с табличными данными (в работе с однородными данными — картинками, текстами — доминируют нейросети)."
            }
        ]
    },
    {
        "id": "q_0251",
        "question": "Какие методы ансамблирования машинного обучения обсуждаются в материалах Евгения Соколова, Joseph Rocca и Steven Yu?",
        "answers": [
            "В материалах рассматриваются bias-variance decomposition и бэггинг (Евгений Соколов), ансамбли (Joseph Rocca), а также стекинг и блендинг (Steven Yu)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
                "text": "ЛекцияЕвгения Соколова про bias-variance decomposition и бэггинг Блог-постпро ансамбли от Joseph Rocca Блог-постпро стекинг и блендинг от Steven Yu"
            }
        ]
    },
    {
        "id": "q_0252",
        "question": "Какой класс моделей рассматривается в работах Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting и Stability and Deviation Optimal Risk Bounds with Convergence Rate для равномерной оценки?",
        "answers": [
            "В этих работах рассматривается класс интерполирующих моделей, то есть моделей, имеющих нулевой эмпирический риск."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obobshayushaya-sposobnost-klassicheskaya-teoriya",
                "text": "Напомним, что построение равномерных оценок проходило в несколько шагов: Оценка супремумом Применение неравенства макДайармида: Оценка матожидания супремума (жёлтое слагаемое выше) с помощью симметризации с дальнейшим выходом на сложность Радемахера: На каждом шаге предыдущая величина оценивается сверху, и потенциально каждое из этих неравенств может оказаться слишком слабым и привести к бессмысленной оценке. Давайте это проиллюстрируем. Выше мы уже отмечали, что если класссодержит модель, для котороймал, авелик, то равномерная оценка становится бессмысленной. По этой причине, имеет смысл выбирать класскак можно более маленьким. Самым лучшим из возможных классов мог бы быть класс моделей, к которым сходится наш алгоритм обучения с высокой вероятностью. Рассмотрим случай, близкий к идеальному: тот, в котором существует, для которого при любыхимеем. Иными словами, предположим, что все модели классахорошо обобщают. В этом случае оценка выше близка к идеальной: Но что будет, если мы начнём честно воспроизводить процесс построения равномерных оценок? После второго шага мы получаем оценку вида которая не сильно хуже предыдущей, но в которой всё равно появилось лишнее слагаемое. Но допустим, что мы хотим честно проделать третий шаг процедуры получения равномерных оценок. Для этого нам необходимо было оценить матожидание супремума, которое после симметризации получает вот такую верхнюю оценку: Таким образом, малость истинного риска не гарантирует малость эмпирического риска на любом наборе данных. Так, авторы статьиUniform convergence may be unable to explain generalization in deep learningпредъявили пример, в котором для любогосуществует модель, такая что, но при этомималы. Иллюстрация такой ситуации приведена в начале параграфа. Тогдавелик, и оценки теряют смысл. К счастью, даже эта фундаментальная проблема не ставит крест на равномерных оценках. Так, работыUniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign OverfittingиStability and Deviation Optimal Risk Bounds with Convergence Rateрассматривают равномерную оценку в классе интерполирующих моделей, то есть, имеющих нулевой эмпирический риск: Для таких моделей контрпример выше не работает."
            }
        ]
    },
    {
        "id": "q_0253",
        "question": "Какое важное свойство выпуклых функций упрощает поиск минимума?",
        "answers": [
            "У выпуклых функций локальный минимум автоматически является глобальным минимумом. Это позволяет избегать ситуаций, характерных для невыпуклых функций, где может существовать множество локальных минимумов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
                "text": "Зачастую задачи машинного обучения формулируются таким образом, что «веса» модели, которую мы строим, возникают, как решение оптимизационной задачи. В качестве VIP-примера рассмотрим задачу линейной регрессии: По сути, мы получили чистейшую задачу квадратичной оптимизации. В чем особенность конкретно этой задачи? Онавыпуклая. Важное свойство выпуклых функций – локальный минимум автоматически является глобальным (но не обязательно единственным!). Это позволяет избегать уродливых ситуаций, которые с теоретической точки зрения могут встретиться в невыпуклом случае, например, вот такой: Теорема(No free lunch theorem) Пусть– алгоритм оптимизации, использующий локальную информацию (все производные в точке). Тогда существует такая невыпуклая функция, что для нахождения глобального минимума на квадратес точностьютребуется совершить хотя бышагов. Мы видим, что в общем случае без выпуклости нас ожидает полное разочарование. Ничего лучше перебора по сетке придумать в принципе невозможно. В выпуклом случае же существуют алгоритмы, которые находят глобальный минимум за разумное время. Встречаются ли в жизни функции невыпуклые? Повсеместно! Например, функция потерь при обучении нейронных сетей, как правило, не является выпуклой. Но отсюда не следует, что любой алгоритм их оптимизации будет обязательно неэффективным: ведь «контрпример» из теоремы довольно специфичен. И, как мы увидим, оптимизировать невыпуклые функции очень даже возможно. Найти глобальный минимум невыпуклой функции – очень трудная задача, но зачастую нам хватает локального, который является, в частности, стационарной точкой: такой, в которой производная равна нулю. Все теоретические результаты в случае невыпуклых задач, как правило, касаются поиска таких точек, и алгоритмы тоже направлены на их отыскание. Этим объясняется и то, что большинство алгоритмов оптимизации, придуманных для выпуклого случая, дословно перешли в невыпуклый. Теоретическая причина в следующем: в выпуклом случае поиск стационарной точки и поиск минимума –буквальноодна и та же задача, поэтому то, что хорошо ищет минимум в выпуклом случае, ожидаемо будет хорошо искать стационарные точки в невыпуклом. Практическая же причина в том, что оптимизаторы в библиотеках никогда не спрашивают, выпуклую ли им функцию подают на вход, а просто работают и работают хорошо. Внимательный читатель мог возразить на моменте подмены задачи: подождите-ка, мы ведь хотим сделать функцию как можно меньше, а не стационарную точку искать какую-то непонятную. Доказать в невыпуклом случае тут, к сожалению, ничего невозможно, но на практике мы снова используем алгоритмы изначально для выпуклой оптимизации. Почему? Причина номер1: сойтись в локальный минимум лучше, чем никуда. Об этом речь уже шла. Причина номер2: в окрестности локального минимума функция становится выпуклой, и там мы сможем быстро сойтись. Причина номер3: иногда невыпуклая функция является в некотором смысле «зашумленной» версией выпуклой или похожей на выпуклую. Например, посмотрите на эту картинку (функция Леви): У этой функции огромное количество локальных минимумов, но «глобально» она кажется выпуклой. Что-то отдаленно похожее наблюдается ив случае нейронных сетей. Нашей задачей становится не скатиться в маленький локальный минимум, который всегда рядом с нами, а в большую-большую ложбину, где значение функции минимально и в некотором смысле стабильно. Причина номер4: оказывается, что градиентные методывесьма частосходятся именно к локальным минимумам. Сразу отметим важную разницу между выпуклой и невыпуклой задачами: в выпуклом случае работа алгоритма оптимизации не очень существенно зависит от начальной точки, поскольку мы всегда скатимся в точку оптимума. В невыпуклом же случае правильно выбранная точка старта – это уже половина успеха. Теперь перейдём к разбору важнейших алгоритмов оптимизации."
            }
        ]
    },
    {
        "id": "q_0254",
        "question": "Какой алгоритм используется для минимизации функционала, представляющего собой матожидание, путём замены градиента на его оценку по случайной подвыборке?",
        "answers": [
            "Этот алгоритм называется стохастическим градиентным спуском (stochastic gradient descent, SGD). Он работает путём вычисления оценки градиента как среднего по мини-батчу данных и обновления параметров с использованием этого приближённого градиента."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
                "text": "Теперь мы попробуем сэкономить в случае регрессии и подобных ей задач. Будем рассматривать функционалы вида где сумма проходится по всем объектам выборки (которых может быть очень много).Теперь сделаем следующий трюк: заметим, что это усреднение – это по сути взятие матожидания. Таким образом, мы говорим, что наша функция выглядит как гдеравномерно распределена по обучающей выборке. Задачи такого вида возникают не только в машинном обучении; иногда встречаются и просто задачистохастического программирования, где происходит минимизация матожидания по неизвестному (или слишком сложному) распределению. Для функционалов такого вида мы также можем посчитать градиент, он будет выглядеть довольно ожидаемо: Будем считать, что вычисление матожидания напрямую невозможно. Новый взгляд из статистики дает возможность воспользоваться классическим трюком: давайте подменим матожидание на его несмещенную Монте-Карло оценку. Получается то, что можно назватьстохастическим градиентом: Говоря инженерным языком, мы подменили вычисление градиента по всей выборке вычислением по случайной подвыборке. Подвыборкучасто называют (мини)батчем, а число– размером батча. По-хорошему, наука предписывает нам каждый раз независимо генерировать батчи, но это трудно с вычислительной точки зрения. Вместо этого воспользуемся следующим приёмом: сначала перемешаем нашу выборку (чтобы внести дополнительную случайность), а затем будем рассматривать последовательно блоки поэлементов выборки. Когда мы просмотрели всю выборку – перемешиваем еще раз и повторяем проход. Очередной прогон по обучающей выборке называетсяэпохой. И, хотя, казалось бы, независимо генерировать батчи лучше, чем перемешивать лишь между эпохами, есть несколько результатов, демонстрирующих обратное:одна работаивторая (более новая); главное условие успеха – правильно изменяющийся размер шага. Получаем следующий алгоритм, называемыйстохастическим градиентным спуском(stochastic gradient descent,SGD): Скопировать код1x = normal(0,1)# инициализация2repeat E times:# цикл по количеству эпох3fori =0; i <= N; i += B:4batch = data[i:i+B]5h = grad_loss(batch).mean()# вычисляем оценку градиента как среднее по батчу6x -= alpha * h Дополнительное удобство такого подхода – возможность работы с внешней памятью, ведь выборка может быть настолько большой, что она помещается только на жёсткий диск. Сразу отметим, что в таком случаестоит выбирать достаточно большим: обращение к данным с диска всегда медленнее, чем к данным из оперативной памяти, так что лучше бы сразу забирать оттуда побольше. Поскольку стохастические градиенты являются лишь оценками истинных градиентов, SGD может быть довольно шумным: Поэтому если вы обучаете глубокую нейросеть и у вас в память влезает лишь батч размером с 2-4 картинки, модель, возможно, ничего хорошего не сможет выучить. Аппроксимация градиента и поведение SGD может стать лучше с ростом размера батча– и обычно его действительно хочется подрастить, но парадоксальным образом слишком большие батчи могут порой испортить дело (об этом дальше в этом параграфе!). Теперь перейдем к теоретической стороне вопроса. Сходимость SGD обеспечивается несмещенностью стохастического градиента. Несмотря на то, что во время итераций копится шум, суммарно он зачастую оказывается довольно мал. Теперь приведем оценки. Сначала, по традиции, в выпуклом случае. Для выпуклой функции потерь зашагов будет достигнута точность порядка где– это дисперсия стохградиента, а– константа сильной выпуклости, показывающая, насколько функция является «не плоской» в окрестности точки оптимума. Доказательство в том жепрепринте С. Стича. Мораль в следующем: дисперсия стохастического градиента, вычисленного по батчу размераравна, где– это дисперсия одного градиента. То есть увеличение размера батча помогает и с теоретической точки зрения. В невыпуклом случае оценка сходимости SGD просто катастрофически плохая: требуетсяшагов для того, чтобы сделать норму градиента меньше. В теории есть всевозможные дополнительные способы снижения дисперсии с лучшими теоретическими оценками (Stochastic Variance Reduced Gradient (SVRGD), Spider, etc), но на практике они активно не используются."
            }
        ]
    },
    {
        "id": "q_0255",
        "question": "Какие методы оптимизации предлагается использовать для ускорения сходимости, если функция является гладкой?",
        "answers": [
            "Для гладких функций предлагается использовать методы, учитывающие старшие производные, такие как метод Ньютона и подобные ему методы, включая L-BFGS."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
                "text": "Основной раздел. Постараемся усовершенствовать метод стохастического градиентного спуска. Сначала заметим, что мы используем явно не всю информацию об оптимизируемой функции. Вернемся к нашему VIP-примеру линейной регресии срегуляризацией: Эта функция достаточно гладкая, и может быть неплохой идеей использовать её старшие производные для ускорения сходимости алгоритма. В наиболее чистом виде этой философии следует метод Ньютона и подобные ему; о них вы можете прочитатьв соответствующем разделе. Отметим, что все такие методы, как правило, довольно дорогие (исключая L-BFGS), и при большом размере задачи и выборки ничего лучше вариаций SGD не придумали. Основной раздел. К сожалению, не всегда функции такие красивые и гладкие. Для примера рассмотрим Lasso-регресию: Второе, не гладкое слагаемое резко ломает все свойства этой задачи: теоретически оценки для градиентного спуска становятсягораздохуже (и на практике тоже). С другой стороны, регуляризационное слагаемое устроено очень просто, и эту дополнительную структурную особенность можно и нужно эксплуатировать. Методы решения задачи вида где– простая функция (в некотором смысле), а– гладкая, называются методамикомпозитной оптимизации. Глубже погрузиться в них можно всоответствующем разделе, посвященном проксимальным методам."
            }
        ]
    },
    {
        "id": "q_0256",
        "question": "Какой физический аналог используется для объяснения метода Momentum в градиентной оптимизации?",
        "answers": [
            "Метод Momentum сравнивается с мячиком, катящимся с горы, где гора представляет график функции потерь, а мячик — текущее значение функции. Инерция мячика позволяет ему преодолевать небольшие препятствия и продолжать движение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
                "text": "Следующая претензия к методу градиентного спуска – мы не используем информацию о предыдущих шагах, хотя, кажется, там может храниться что-то полезное. Начнем с физической аналогии. Представим себе мячик, который катится с горы. В данном случае гора – это график функции потерь в пространстве параметров нашей модели, а мячик – её текущее значение. Реальный мячик не застрянет перед небольшой кочкой, так как у него есть некоторая масса и уже накопленный импульс – некоторое время он способен двигаться даже вверх по склону. Аналогичный прием может быть использован и в градиентной оптимизации. В англоязычной литературе он называетсяMomentum. С математической точки зрения, мы добавляем к градиентному шагу еще одно слагаемое: Сразу заметим, что мы немного усугубили ситуацию с подбором шага, ведь теперь нужно подбирать не только, но и. Для обычного, не стохастического градиентного спуска мы можем адаптировать метод наискорейшего и получитьметод тяжелого шарика: Но, увы, для SGD это работать не будет. Выгода в невыпуклом случае от метода инерции довольно понятна – мы будем пропускать паразитные локальные минимумы и седла и продолжать движение вниз. Но выгода есть также и в выпуклом случае. Рассмотрим плохо обусловленную квадратичную задачу, для которой линии уровня оптимизируемой функции будут очень вытянутыми эллипсами, и запустим на SGD с инерционным слагаемым и без него. Направление градиента будет иметь существенную вертикальную компоненту, а добавление инерции как раз «погасит» паразитное направление. Получаем следующую картинку: Также удобно бывает представить метод моментума в виде двух параллельных итерационных процессов: Рассмотрим некоторую дополнительную модификацию, которая была предложена в качестве оптимального метода первого порядка для решения выпуклых оптимизационных задач. Можно доказать, что в сильно выпуклом и гладком случае найти минимум с точностьюнельзя быстрее, чем за итераций, где– число обусловленности задачи. Напомним, что для обычного градиентного спуска в экспоненте у нас был не корень из, а просто, то есть, градиентный спуск справляется с плохой обусловленностью задачи хуже, чем мог бы. В 1983 году Ю.Нестеровым был предложен алгоритм, имеющий оптимальную по порядку оценку. Для этого модифицируем немного моментум и будем считать градиент не в текущей точке, а как бы в точке, в которую мы бы пошли, следуя импульсу: Сравним с обычным momentum: Комментарий: иногда упоминается, что Nesterov Momentum «заглядывает в будущее» и исправляет ошибки на данном шаге оптимизации. Конечно, никто не заглядывает в будущее в буквальном смысле. В работе Нестерова были предложены конкретные (и довольно магические) константы для импульса, которые получаются из некоторой еще более магической последовательности. Мы приводить их не будем, поскольку мы в первую очередь заинтересованы невыпуклым случаем. Nesterov Momentum позволяет значительно повысить устойчивость и скорость сходимости в некоторых случаях. Но, конечно, он не является серебряной пулей в задачах оптимизации, хотя в выпуклом мире и является теоретически неулучшаемым. Также отметим, что ускоренный метод может напрямую примениться к проксимальному градиентному спуску. В частности, применение ускоренного метода к проксимальному алгоритму решениярегрессии (ISTA) называется FISTA (Fast ISTA). Общие выводы: Добавление momentum к градиентному спуску позволяет повысить его устойчивость и избегать маленьких локальных минимумов/максимумов; В выпуклом случае добавление моментного слагаемого позволяет доказуемо улучшить асимптотику и уменьшить зависимость от плохой обусловленности задачи. Идея ускорения применяется к любым около-градиентным методам, в том числе и к проксимальным, позволяя получить, например, ускоренный метод для-регрессии."
            }
        ]
    },
    {
        "id": "q_0257",
        "question": "Какой алгоритм адаптации стохастического градиентного спуска был предложен в статье JMLR 2011 года?",
        "answers": [
            "Это алгоритм, который динамически подбирает размер шага для каждой координаты отдельно, деля исходный learning rate на корень из суммы квадратов координат градиентов с добавкой для предотвращения деления на ноль."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
                "text": "Выше мы попытались эксплуатировать свойства градиентного спуска. Теперь же пришел момент взяться за больной вопрос: как подбирать размер шага? Он максимально остро встаёт в случае SGD: ведь посчитать значение функции потерь в точке очень дорого, так что методы в духе наискорейшего спуска нам не помогут! Нужно действовать несколько хитрее. Рассмотрим первый алгоритм, который является адаптацией стохастического градиентного спуска. Впервые он предложен встатье в JMLR 2011 года, но она написана в очень широкой общности, так что читать её достаточно сложно. Зафиксируем– исходный learning rate. Затем напишем следующую формулу обновления: Возведение в квадрат и деления векторов покомпонентные. По сути, мы добавляем некоторую квазиньютоновость и начинаем динамически подбирать размер шага для каждой координаты по отдельности. Наш размера шага для фиксированной координаты – это какая-то изначальная константа(learning rate), деленная на корень из суммы квадратов координат градиентов плюс дополнительный параметр сглаживания, предотвращающий деление на ноль. Добавкана практике оставляется дефолтными1e-8и не изменяется. Идея следующая: если мы вышли на плато по какой-то координате и соответствующая компонента градиента начала затухать, то нам нельзя уменьшать размер шага слишком сильно, поскольку мы рискуем на этом плато остаться, но в то же время уменьшать надо, потому что это плато может содержать оптимум. Если же градиент долгое время довольно большой, то это может быть знаком, что нам нужно уменьшить размер шага, чтобы не пропустить оптимум. Поэтому мы стараемся компенсировать слишком большие или слишком маленькие координаты градиента. Но довольно часто получается так, что размер шага уменьшается слишком быстро и для решения этой проблемы придумали другой алгоритм. Модифицируем слегка предыдущую идею: будем не просто складывать нормы градиентов, а усреднять их вскользящем режиме: Такой выбор позволяет все еще учитывать историю градиентов, но при этом размер шага уменьшается не так быстро. Общие выводы: Благодаря адаптивному подбору шага в современных оптимизаторах не нужно подбирать последовательностьразмеров всех шагов, а достаточно выбрать всего одно число – learning rate, всё остальное сделает за вас сам алгоритм. Но learning rate все еще нужно выбирать крайне аккуратно: алгоритм может либо преждевременно выйти на плато, либо вовсе разойтись. Пример приведен на иллюстрации ниже."
            }
        ]
    },
    {
        "id": "q_0258",
        "question": "Какие гиперпараметры в алгоритме Adam обычно оставляют стандартными и каковы их значения?",
        "answers": [
            "В алгоритме Adam гиперпараметры β₁, β₂ и ε обычно оставляют стандартными со значениями 0.9, 0.99 и 1e-8 соответственно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
                "text": "Теперь покажем гвоздь нашей программы: алгоритм Adam, который считается решением по умолчанию и практически серебряной пулей в задачах стохастической оптимизации. Название Adam = ADAptive Momentum намекает на то, что мы объединим идеи двух последних разделов в один алгоритм. Приведем его алгоритм, он будет немного отличаться оторигинальной статьиотсутствием коррекций смещения (bias correction), но идея останется той же самой: Как правило, в этом алгоритме подбирают лишь один гиперпараметр– learning rate. Остальные же:,и– оставляют стандартными и равными0.9,0.99и1e-8соответственно. Подборсоставляет главное искусство. Зачастую, при начале работы с реальными данными начинают со значения learning rate равного 3e-4. История данного значения достаточно забавна: в 2016 году Андрей Карпатый (Andrej Karpathy) опубликовал шутливыйпост в Twitter. После чего сообщество подхватило эту идею (до такой степени, что иногда число3e-4называют Karpathy constant). Обращаем ваше внимание, что при работе с учебными данными зачастую полезно выбирать более высокий (на 1-2 порядка) начальный learning rate (например, при классификации MNIST, Fashion MNIST, CIFAR или при обучении языковой модели на примере поэзии выбранного поэта). Также стоит помнить, что Adam требует хранения как параметров модели, так и градиентов, накопленного импульса и нормировочных констант (cache). Т.е. достижение более быстрой (с точки зрения количества итераций/объема рассмотренных данных) сходимости требует больших объемов памяти. Кроме того, если вы решите продолжить обучение модели, остановленное на некоторой точке, необходимо восстановить из чекпоинта не только веса модели, но и накопленные параметры Adam. В противном случае оптимизатор начнёт сбор всех своих статистик с нуля, что может сильно сказаться на качестве дообучения. То же самое касается вообще всех описанных выше методов, так как каждый из них накапливает какие-то статистики во время обучения. Интересный факт:Adam расходится на одномерном контрпримере, что совершенно не мешает использовать его для обучения нейронных сетей. Этот факт отлично демонстрирует, насколько расходятся теория и практика в машинном обучении. В той же работе предложено исправление этого недоразумения, но его активно не применяют и продолжают пользоваться «неправильным» Adamом потому что он быстрее сходится на практике. А теперь давайте добавим-регуляризацию неявным образом, напрямую в оптимизатор и минуя адаптивный размер шага: Это сделано для того, чтобы эффект-регуляризации не затухал со временем и обобщающая способность модели была выше. Оставим ссылку на однузаметкупро этот эффект. Отметим, впрочем, что этот алгоритм особо не используется."
            }
        ]
    },
    {
        "id": "q_0259",
        "question": "Какой эффект на обобщающую способность модели может оказывать использование большого размера батча при обучении нейронной сети?",
        "answers": [
            "Использование большого размера батча может приводить к так называемому generalization gap — ухудшению обобщающей способности итоговой модели. Это происходит потому, что больший батч позволяет оптимизатору лучше 'видеть' ландшафт функции потерь для конкретной выборки, что может привести к попаданию в узкие локальные минимумы без обобщающей способности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
                "text": "Часто learning rate понижают итеративно: каждые условные 5 эпох (LRScheduler в Pytorch) или же при выходе функции потерь на плато. При этом лосс нередко ведет себя следующим схематичным образом: Помимо этого используют другие варианты «расписаний» для learning rate. Из часто применяемых неочевидных лайфхаков: сначала сделать warmup, то есть увеличивать learning rate, а затем начать постепенно понижать. Использовалось в известнойстатье про трансформеры. В ней предложили следующую формулу: По сути, первыешагов происходит линейный рост размера шага, а затем он начинает уменьшаться как, где— число итераций. Есть и вариант с косинусом изотдельной библиотеки для трансформеров. В этой же библиотеке можно также почерпнуть идею рестартов: с какого-то момента мы снова включаем warmup, увеличивая размер шага. Представим ситуацию, что мы хотим обучить свою нейронную сеть на нескольких GPU. Одно из решений выглядит следующим образом: загружаем на каждую видеокарту нейронную сеть и свой отдельный батч, вычисляем стохастические градиенты, а затем усредняем их по всем видеокартам и делаем шаг. Что плохого может быть в этом? По факту, эта схема в некотором смысле эквивалентна работе с одним очень большим батчем. Хорошо же, нет разве? На самом деле существует так называемый generalization gap: использование большого размера батча может приводить к худшей обобщающей способности итоговой модели. О причине этого эффекта можно поспекулировать, базируясь на текущих знаниях о ландшафтах функций потерьпри обучении нейронных сетей. Больший размер батча приводит к тому, что оптимизатор лучше «видит» ландшафт функции потерь для конкретной выборки и может скатиться в маленькие «узкие» паразитные локальные минимумы, которые не имеют обобщающий способности — при небольшом шевелении этого ландшафта (distributional shift c тренировочной на тестовую выборку) значение функции потерь резко подскакивает. В свою очередь, широкие локальные минимумы дают модель с лучшей обобщающей способностью. Эту идею можно увидеть на следующей картинке: Иными словами, большие батчи могут приводить к переобучению, но это можно исправить правильным динамическим подбором learning rate, как будет продемонстрировано далее. Сразу отметим, что совсем маленькие батчи – это тоже плохо, с ними ничего не получится выучить, так как каждая итерация SGD знает слишком мало о ландшафте функции потерь. Мы рассмотрим нестандартный оптимизатор для обучения нейронных сетей, которого нет в Pytorch по умолчанию, но который много где используется:Layer-wise Adaptive Rate Scaling (LARS). Он позволяет эффективно использовать большие размеры батчей, что очень важно при вычислении на нескольких GPU. Основная идея заключена в названии – нужно подбирать размер шага не один для всей сети или каждого нейрона, а отдельный длякаждого слояпо правилу, похожему на RMSProp. По сравнению с оригинальным RMSProp подбор learning rate для каждого слоя дает большую стабильность обучения. Теперь рассмотрим формулу пересчета: пусть– это веса слоя,. Параметры алгоритма: базовый learning rate(на который запускается расписание), коэффициент инерции, коэффециент затухания весов(как в AdamW). Скопировать код1forlinrange(L):# Цикл по слоям2g_l = stochgrad(w_prev)[l]# Вычисляем стохградиент из батча для текущего слоя3lr = eta * norm(w[l]) / (norm(g_l) + beta * norm(w[l]))# Вычислеяем learning rate для текущего слоя4v[l] = m * v[l] + lr * (g_l + beta * w[l])# Обновляем momentum5w[l] -= v[l]# Делаем градиентный шаг по всему слою сразу6w_prev = w# Обновляем веса Этот оптимизатор введен в статьеLarge Batch Optimization For Deep Learningи является идейным продолжателем LARS, более приближенным к Adam, чем к обычному RMSProp. Его параметры – это параметры Adam, которые берутся как в Adam, а также параметр, который отвечает за затухание весов (в LARS). Скопировать код1forlinrange(L):# Цикл по слоям2g_l = stochgrad(w_prev)[l]# Вычисляем стохградиент из батча для текущего слоя3m[l] = beta_1 * m[l] + (1- beta_1) * g_l# Вычисляем моментум4v[l] = beta_2 * v[l] + (1- beta_2) * g_l# Вычисляем новый размер шага5m[l] /= (1- beta_1**t)# Шаг для уменьшения смещения из Adam6v[l] /= (1- beta_2**t)7r[l] = m[l] / sqrt(v[l] + eps)# Нормируем моментум как предписывает Adam8lr = eta * norm(w[l]) / norm(r[l] + llambda * w[l])# Как в LARS9w[l] = w[l] - lr * (r[l] + llambda * w[l])# Делаем шаг по моментуму10w_prev = w# Обновляем веса Теперь снова заглянем в теорию: на самом деле, все хорошие теоретические оценки для SGD проявляются, когда берётся усреднение по точкам. Этот эффект при обучении нейронных сетей был исследован в статье проалгоритм SWA. Суть очень проста: давайте усреднять веса модели по каждой-й итерации; можно считать, что по эпохам. В итоге, веса финальной модели являются усреднением весов моделей, имевших место в конце каждой эпохи. В результате такого усреднения сильно повышается обобщающая способность модели: мы чаще попадаем в те самые широкие локальные минимумы, о которых мы говорили в разделе про большие батчи. Вдохновляющая картинка из статьи прилагается: На второй и третьей картинке изображено сравнение SGD и SWA при обучении нейронной сети (Preactivation ResNet-164 on CIFAR-100) при одной и той же инициализации. На первой же картинке изображено, как идеологически должен работать SWA. Также мы видим тут демонстрацию эффекта концентрации меры: после обучения стохастический градиентный спуск становится случайным блужданием по области в окрестности локального минимума. Если, например, предположить, что итоговая точка – это нормальное распределение с центром в реальном минимуме в размерности, то все эти точки с большой вероятности будут находиться в окрестности сферы радиуса. Интуитивную демонстрацию многомерного нормального распределения можно увидеть на следующей картинке из книги Р.Вершинина \"High-Dimensional Probability\" (слева в размерности 2, справа в большой размерности): Поэтому, чтобы вычислить центральную точку этой гауссианы, усреднение просто необходимо, по такому же принципу работает и SWA. Теперь мы снова обратимся к теории: скорость сходимости градиентного спуска (даже ускоренного) очень сильно зависит от числа обусловленности задачи. Разумной идеей будет попытаться использовать какие-то сведения о задаче и улучшить этот показатель, тем самым ускорив сходимость. В теории, здесь могут помочь техникипредобуславливания. Но, к сожалению, попытки наивно воплотить эту идею приводят к чему-то, похожему на метод Ньютона, в котором нужно хранить большую-большую матрицу для обучения больших моделей. Способ обойти эту проблему рассмотрели в статье о методеShampoo, который использует то, что веса нейронной сети зачастую удобно представлять как матрицу или даже многомерный тензор. Таким образом, Shampoo можно рассматривать как многомерный аналог AdaGrad."
            }
        ]
    },
    {
        "id": "q_0260",
        "question": "Какой тип распределения обычно используется для вектора случайных значений на входе генератора в моделях вроде GAN или диффузионных моделей?",
        "answers": [
            "Обычно используется простое вероятностное распределение, такое как нормальное или равномерное. Это распределение задаётся до обучения модели и не меняется в процессе."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/vvedenie-v-generativnoe-modelirovanie",
                "text": "Большинство моделей генеративного моделирования позволяют семплировать новые объекты. Как правило, в результате обучения генеративной модели мы получаем генератор — функцию, которая на выходе выдаёт объект. В таких моделях, как генеративные состязательные нейронные сети, диффузионные модели, вариационные автокодировщики, генератор на вход принимает вектор случайных значений из простого вероятностного распределения (например, нормального или равномерного). Получается, что, где— объект,— функция генератора, а— вектор случайных значений. Пространство, в котором располагается, называется латентным. Обычно распределениезадаётся ещё до обучения модели и не меняется в процессе. Поскольку мы знаем распределение, мы можем семплировать из него сколько угодно разных. Рассмотрим два вектораииз латентного пространства и два соответствующих им сгенерированных объекта. Так каки— это две точки в латентном пространстве, между ними можно провести линию. Точки, лежащие на этой линии, будут так же принадлежать этому пространству. Если двигаться по этой линии и использовать точки с неё в качестве входа для генератора, то можно получить плавно изменяющийся сгенерированный объект. В примере выше мы рассмотрели движение вдоль линии, однако на практике интерполяция может быть по более сложной траектории. Манипуляции с латентным пространством позволяют не только создавать плавные переходы между объектами, но так же редактировать объекты. Обычно в таких случаях требуется найти направления в латентном пространстве, которое отвечает за нужное свойство сгенерированных объектов. Например, направление, отвечающее за цвет волос или улыбку человека. Подробнее такие методы мы рассмотрим в параграфах про конкретные модели."
            }
        ]
    },
    {
        "id": "q_0261",
        "question": "Какой метод аугментации данных, основанный на генеративных состязательных нейронных сетях, показал лучшие результаты по сравнению с бикубической интерполяцией при восстановлении разрешения изображений?",
        "answers": [
            "Метод SRGAN, основанный на генеративных состязательных нейронных сетях, работает гораздо лучше бикубической интерполяции, которая обычно смазывает картинку."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/vvedenie-v-generativnoe-modelirovanie",
                "text": "Зачем может понадобиться генерировать новые данные или восстанавливать их плотность? Самый простой пример – это аугментация набора данных, которая мешает переобучению и улучшает обобщаемость модели. Простые аугментации данных (случайные сдвиги, повороты, масштабирование, изменения цвета и контраста) активно используются почти во всех методах машинного обучения. Генеративные же модели представляют собой более сложный вид аугментации данных, который способен существенно расширить датасет, или обогатить его совершенно новыми элементами. Например, генеративную модель, которая переносит стиль одного изображения на другое (style transfer), можно использовать для обучения более робастных моделей классификации. ВстатьеSandfort et al. используют аугментацию генеративными нейросетями, чтобы улучшить качество сегментации компьютерной томографии. Помимо этого, у генеративных моделей есть ряд других применений для редактирования изображений. Их используют, чтобы повысить разрешение картинок (задача super-resolution). На изображении ниже оригинальную картинку (original) сначала сжали в четыре раза, а потом попробовали восстановить до исходных размеров разными методами. Видно, что метод SRGAN, метод на основе генеративных состязательных нейронных сетях работает гораздо лучше бикубической интерполяции (bicubic), которая обычно применяется по умолчанию и смазывает картинку. С помощью генеративных моделей можно закрашивать пропущенные куски изображений. Это полезно, когда мы хотим удалить с фото других людей, и нам нужно закрасить участки, образовавшиеся после их удаления. Эта функция представлена в некоторых современных смартфонах. В последние несколько лет хорошо стали работать модели, которые генерируют изображения на основе их текстового описания. Среди таких моделей: Stable Diffusion (Демо). Модель с открытымисходным кодом DALLE 2. Доступ по платному API Midjourney. Доступ через Discord Imagen Появились даже специальные базы изображений, сгенерированных нейронными сетями:Lexica,Openart. Доступность таких моделей приводит к появлению множества приложений: Иллюстрации для книг Создание логотипов Создание дизайнов помещений Генерация тату Кроме этого, некоторые модели позволяют совместить несколько задач и делать закрашивание изображения на основе текстового описания. Например, удалять какую-то область и говорить модели, что там должно быть нарисовано. На основе этой технологии появились редакторы изображений с генеративными моделями внутри:Neural love,Photoroom,ZMO. Современные генеративные модели достигли очень хорошего качества и уже стали использоваться в реальных задачах, о которых мы вам рассказали. В следующих параграфах этой главы мы рассмотрим основные методы генеративного обучения более детально."
            }
        ]
    },
    {
        "id": "q_0262",
        "question": "В каком направлении движется информация при обратном проходе в нейронной сети?",
        "answers": [
            "При обратном проходе информация движется от финального представления или функции потерь к исходному представлению через все преобразования сети."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
                "text": "Информация может течь по графу в двух направлениях. Применение нейронной сети к данным (вычисление выхода по заданному входу) часто называютпрямым проходом, или жеforward propagation(forward pass). На этом этапе происходит преобразование исходного представления данных в целевое и последовательно строятся промежуточные (внутренние) представления данных — результаты применения слоёв к предыдущим представлениям. Именно поэтому проход называют прямым. Приобратном проходе, или жеbackward propagation(backward pass), информация (обычно об ошибке предсказания целевого представления) движется от финального представления (а чаще даже от функции потерь) к исходному через все преобразования. Механизм обратного распространения ошибки, играющий важнейшую роль в обучении нейронных сетей, как раз предполагаетобратноедвижение по вычислительному графу сети. С ним вы познакомитесь в следующемпараграфе."
            }
        ]
    },
    {
        "id": "q_0263",
        "question": "Какую функцию удобно использовать в качестве функции потерь для бинарной классификации с нейросетями?",
        "answers": [
            "Для бинарной классификации удобно использовать log loss в качестве функции потерь."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
                "text": "Как мы уже упоминали выше, нейросети — это универсальный конструктор, который из простых блоков позволяет собрать орудия для решения самых разных задач. Давайте посмотрим на конкретные примеры. Безусловно, мир намного разнообразнее того, что мы покажем вам в этом параграфе, но с чего-то ведь надо начинать, не так ли? В тех несложных ситуациях, которые мы сейчас рассмотрим, архитектура будет отличаться лишь самыми последними этапами вычисления (у сетей будут разные «головы»). Для иллюстрации приведём примеры нескольких игрушечных архитектур для решения игрушечных задач классификации и регрессии на двумерных данных: Для решения задачи бинарной классификации подойдёт любая архитектура, на выходе у которой одно число отдо, интерпретируемое как «вероятность класса 1». Обычно этого добиваются, взяв где— некоторая функция, превращающая представлениев число (если— матрица, то подойдёт, где— вектор-столбец), а— наша любимая сигмоида. При этомможет получаться как угодно, лишь бы хватало оперативной памяти и не было переобучения. В качестве функции потерь удобно брать уже знакомый нам log loss. Работая с другими моделями, мы порой вынуждены были выдумывать сложные стратегии многоклассовой классификации; нейросети позволяют это делать легко и элегантно. Достаточно построить сеть, которая будет выдаватьнеотрицательных чисел, суммирующихся в 1 (где— число классов); тогда им можно придать смысл вероятностей классов и предсказывать тот класс, «вероятность» которого максимальна. Превратить произвольный набор изчисел в набор из неотрицательных чисел, суммирующихся в 1, позволяет, к примеру, функция Наиболее популярные архитектуры для многоклассовой классификации имеют вид где— функция, превращающаяв матрицу(где— размер батча), аможет быть получен любым приятным вам образом. Но какой будет функция потерь для такой сети? Мы должны научиться сравнивать «распределение вероятностей классов» с истинным (в котором на месте истинного класса стоит 1, а в остальных местах 0). Сделать это позволяеткросс-энтропия, она жеnegative log-likelihood— некоторый аналог расстояния между распределениями: где снова— размер батча, а— число классов. Легко видеть, что приполучается та самая функция потерь, которую мы использовали для обучения бинарной классификации. С помощью нейросетей легко создать модель, которая предсказывает не одно число, а сразу несколько. Например, координаты ключевых точек лица — кончика носа, уголков рта и так далее. Достаточно сделать, чтобы последнее представление было матрицей, где— размер батча, а— количество предсказываемых чисел. Особенностью большинства моделей регрессии является то, что после последнего слоя (часто линейного) не ставят функций активации. Вы тоже этого не делайте, если только чётко не понимаете, зачем вам это. В качестве функции потерь можно брать, например,по всей матрице. Если вы используете нейросети, то ваши таргеты могут иметь и различную природу. Например, можно соорудить одну-единственную сеть, которая по фотографии нескольких котиков определяет их количество (регрессия) и породу каждого из них (многоклассовая классификация). Лосс для такой модели может быть равен (взвешенной) сумме лоссов для каждой из задач (правда, не факт, что это хорошая идея). Так что, по крайней мере в теории, сетям подвластны любые задачи. На практике, конечно, всё гораздо хитрей: для обучения слишком сложной сети у вас может не хватить данных или вычислительных мощностей."
            }
        ]
    },
    {
        "id": "q_0264",
        "question": "Что произойдёт, если между двумя линейными слоями нейронной сети не будет функции активации?",
        "answers": [
            "Два последовательных линейных слоя без функции активации эквивалентны одному линейному слою, так как линейная комбинация линейных отображений остаётся линейным отображением. Это не позволяет получить нелинейное преобразование данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
                "text": "Для начала поговорим о том, зачем они нужны. Казалось бы, можно последовательно выстраивать лишь линейные слои, но так не делают: после каждого линейного слоя обязательно вставляют функцию активации. Но зачем? Попробуем разобраться. Рассмотрим нейронную сеть из двух линейных слоёв. Что произойдёт, если между ними будет отсутствовать нелинейная функция активации? Линейная комбинация линейных отображений есть линейное отображение, то есть два последовательных линейных слоя эквивалентны одному линейному слою. Добавление функций активации после линейного слоя позволяет получить нелинейное преобразование, и подобной проблемы уже не возникает. Вдобавок правильный выбор функции активации позволяет получить преобразование, обладающее подходящими свойствами. В качестве функции активации может использоваться, например, уже знакомая вам из логистической регрессии сигмоидаили ReLU (Rectified linear unit). К более глубокому рассмотрению разновидностей и свойств различных функций активации вернёмся позднее. Примечание. На самом деле бывают ситуации, когда два линейных слоя подряд — это полезно. Например, если вы понимаете, что у вас очень много параметров, а информации в данных не так много, вы можете заменить линейный слой, превращающий-мерные векторы в-мерные, на два, вставив посередине-мерное представление, где: С точки зрения линейной алгебры это примерно то же самое, что потребовать, чтобы матрица исходного линейного слоя имела ранг не выше. И с точки зрения сужения «информационного канала» это иногда может сработать. Но в любом случае вы должны понимать, что два линейных слоя подряд стоит ставить, только если вы хорошо понимаете, чего хотите добиться. Вернёмся к функциям активации. Вот наиболее популярные: Рассмотрим их подробнее. Формула: ReLU это простая кусочно-линейная функция. Одна из наиболее популярных функций активации. В нуле производная доопределяется нулевым значением. Плюсы: простота вычисления активации и производной. Минусы: область значений является смещённой относительно нуля; для отрицательных значений производная равна нулю, что может привести к затуханию градиента. ReLU и её производная очень просты для вычисления: достаточно лишь сравнить значение с нулём. Благодаря этому использование ReLU позволяет достигать прироста в скорости до четырёх-шести раз относительно сигмоиды. Формула: Гиперпараметробеспечивает небольшой уклон слева от нуля, что позволяет получить более симметричную относительно нуля область значений. Также меньше провоцирует затухание градиента благодаря наличию ненулевого градиента и слева, и справа от нуля. Формула: Аналогична Leaky ReLU, но параметрнастраивается градиентными методами. ELU – это гладкая аппроксимация ReLU. Обладает более высокой вычислительной сложностью, достаточно редко используется на практике. Формула: Исторически одна из первых функций активации. Рассматривалась в том числе и как гладкая аппроксимация порогового правила, эмулирующая активацию естественного нейрона. Плюсы: Минусы: область значений смещена относительно нуля; сигмоида (как и её производная) требует вычисления экспоненты, что является достаточно сложной вычислительной операцией. Её приближённое значение вычисляется на основе ряда Тейлора или с помощью полиномов, Stack Overflowquestion 1,question 2; на «хвостах» обладает практически нулевой производной, что может привести к затуханию градиента; максимальное значение производной составляет, что также приводит к затуханию градиента. На практике сигмоида редко используется внутри сетей, чаще всего в случаях, когда внутри модели решается задача бинарной классификации (например, вероятность забывания информации в LSTM). Формула: Плюсы: как и сигмоида, имеет ограниченную область значений; в отличие от сигмоиды, область значений симметрична. Минусы: требует вычисления экспоненты, что является достаточно сложной вычислительной операцией; на «хвостах» обладает практически нулевой производной, что может привести к затуханию градиента. Вопрос на подумать. А почему симметричность области значений может быть ценным свойством?"
            }
        ]
    },
    {
        "id": "q_0265",
        "question": "Какая теорема утверждает, что двухслойная нейросеть с сигмоидной функцией активации может приблизить любую непрерывную функцию?",
        "answers": [
            "Теорема Цыбенко, сформулированная в 1989 году, доказывает, что для любой непрерывной функции существует двухслойная нейросеть с сигмоидной функцией активации, способная её приблизить с заданной точностью."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
                "text": "Рассмотрим для начала задачу регрессии. Ясно, что линейная модель (то есть однослойная нейросеть) может приблизить только линейную функцию, но уже двухслойная нейросеть может приблизить почти что угодно. Есть ряд теорем на эту тему, мы упомянем одну из них. Обратите внимание на год: как мы уже упоминали, нейросети начали серьёзно изучать задолго до того, как они начали превращаться в state of the art. Теорема Цыбенко (1989).Для любой непрерывной функциии для любогонайдётся число, а также числа,, для которых для любыхиз единичного кубав. В сумме из теоремы Цыбенко легко опознать двуслойную нейросеть с сигмоидной функцией активации. В самом деле, сперва мы превращаемв— это можно представить в виде одной матричной операции (линейный слой!): где— вектор-столбцы, а каждое изприбавляется к-му столбцу, после чего поэлементно берём отсигмоиду (активация), после чего вычисляем и это второй линейный слой (без свободного члена). Правда, теорема не очень помогает находить такие функции, но это уже другое дело. В любом случае — если дать нейросети достаточно данных, она действительно может выучить почти что угодно. Упражнение.Мы не будем приводить результатов, касающихся классификации, но рекомендуем воспользоваться замечательнойпесочницей. Убедитесь сами, что при использовании одного скрытого слоя из двух нейронов и сигмоиды в качестве функции активации, можно неплохо классифицировать данные со сложной, совсем даже не линейной границей между классами. Вы также можете поиграть с разными функциями активации. А для получения решения нам необходим метод автоматической настройки всех параметров нейронной сети —метод обратного распространения ошибки, или жеerror backpropagation. Рассмотрим его в деталях в следующем параграфе."
            }
        ]
    },
    {
        "id": "q_0266",
        "question": "Кто и в каком году предложил метод обратного распространения ошибки в его актуальном виде?",
        "answers": [
            "В 1986 году метод был предложен Дэвидом Э. Румельхартом, Джеффри Э. Хинтоном и Рональдом Дж. Вильямсом, а также независимо и одновременно красноярскими математиками С. И. Барцевым и В. А. Охониным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "Открытие метода обратного распространения ошибки стало одним из наиболее значимых событий в области искусственного интеллекта. В актуальном виде он былпредложенв 1986 году Дэвидом Э. Румельхартом, Джеффри Э. Хинтоном и Рональдом Дж. Вильямсом, а также независимо и одновременно красноярскими математиками С. И. Барцевым и В. А. Охониным. С тех пор для нахождения градиентов параметров нейронной сети используется метод вычисления производной сложной функции, и оценка градиентов параметров сети стала хоть и сложной инженерной задачей, но уже не искусством. Несмотря на простоту используемого математического аппарата, появление этого метода привело к значительному скачку в развитии искусственных нейронных сетей. Суть метода можно записать одной формулой, тривиально следующей из формулы производной сложной функции: если, то. Уже сейчас мы видим, что градиенты можно вычислять последовательно, в ходе одного обратного прохода, начиная си умножая каждый раз на частные производные предыдущего слоя."
            }
        ]
    },
    {
        "id": "q_0267",
        "question": "Какой процесс позволяет вычислить все градиенты в один проход после forward propagation?",
        "answers": [
            "Этот процесс называется backward propagation (обратное распространение). Он выполняется после forward propagation, когда все промежуточные значения уже вычислены и сохранены в памяти."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "В одномерном случае всё выглядит особенно просто. Пусть— переменная, по которой мы хотим продифференцировать , причём сложная функция имеет вид где всескалярные. Тогда Суть этой формулы такова. Если мы уже совершили прямой проход (forward propagation), значит мы уже знаем Поэтому мы можем действовать следующим образом: берём производнуюв точке; умножаем на производнуюв точке; и так далее, пока не дойдём до производнойв точке. Проиллюстрируем это на картинке, расписав по шагам дифференцирование по весамфункции потерь логистической регрессии на одном объекте (то есть для батча размера 1): Собирая все множители вместе, получаем: Таким образом, сперва совершается forward propagation для вычисления всех промежуточных значений (да, все промежуточные представления нужно будет хранить в памяти), а потом запускается backward propagation, на котором в один проход вычисляются все градиенты."
            }
        ]
    },
    {
        "id": "q_0268",
        "question": "Почему в вычислениях градиентов иногда возникает четырёхмерный объект, и какие проблемы это создаёт?",
        "answers": [
            "При вычислении производных для последовательных промежуточных представлений, связанных функцией, возникает четырёхмерный объект (называемый «четырёхмерным кубиком»), который требует значительно больше памяти для хранения по сравнению с обычными матрицами градиентов. Это делает хранение таких промежуточных производных неэффективным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "В параграфе, посвящённомматричным дифференцированиям, мы поднимаем вопрос о том, что вычислять частные производные по отдельности — это зло, лучше пользоваться матричными вычислениями. Но есть и ещё одна причина: даже и с матричной производной в принципе не всегда хочется иметь дело. Рассмотрим простой пример. Допустим, чтои— два последовательных промежуточных представленияи, связанных функцией. Предположим, что мы как-то посчитали производнуюфункции потерь, тогда И мы видим, что, хотя оба градиентаи— это просто матрицы, в ходе вычислений возникает «четырёхмерный кубик». Его болезненно даже хранить: уж больно много памяти он требует —мпо сравнению с безобидными, требуемыми для хранения градиентов. Поэтому хочется промежуточные производныерассматривать не как вычисляемые объекты, а как преобразования, которые превращаютв. Целью следующих параграфов будет именно это: понять, как преобразуется градиент в ходе error backward propagation при переходе через тот или иной слой. Вы спросите себя: надо ли мне сейчас пойти и прочитать параграф учебника про матричное дифференцирование? Короткий ответ: Зависит от ваших знаний. Длинный ответ: Найдите производную функции по вектору: А как всё поменяется, еслитоже зависит от? Чему равен градиент функции, еслиявляется скаляром? Если вы готовы прямо сейчас взять ручку и бумагу и посчитать всё, то вам, вероятно, не надо читать про матричные дифференцирования. Но мы советуем всё-таки заглянуть в этот параграф, если обозначения, которые мы будем дальше использовать, покажутся вам непонятными: единой нотации для матричных дифференцирований человечество пока, увы, не изобрело, и переводить с одной на другую не всегда легко. А мы же сразу перейдём к интересующей нас вещи: к вычислению градиентов сложных функций."
            }
        ]
    },
    {
        "id": "q_0269",
        "question": "Как преобразуется градиент при проходе через слой нейронной сети, если известен градиент функции потерь по переменным промежуточного представления?",
        "answers": [
            "Градиент преобразуется путём применения сопряжённого к дифференциалу слоя линейного отображения к вектору градиента. Это позволяет получить градиент по переменным предыдущего слоя, что является основой механизма обратного распространения ошибки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "Напомним, что формула производной сложной функции выглядит следующим образом: Теперь разберёмся с градиентами. Пусть– скалярная функция. Тогда С другой стороны, То есть— применение сопряжённого клинейного отображения к вектору. Эта формула — сердце механизма обратного распространения ошибки. Она говорит следующее: если мы каким-то образом получили градиент функции потерь по переменным из некоторого промежуточного представлениянейронной сети и при этом знаем, как преобразуется градиент при проходе через слоймеждуи(то есть как выглядит сопряжённое к дифференциалу слоя между ними отображение), то мы сразу же находим градиент и по переменным из: Таким образом слой за слоем мы посчитаем градиенты по всемвплоть до самых первых слоёв. Далее мы разберёмся, как именно преобразуются градиенты при переходе через некоторые распространённые слои."
            }
        ]
    },
    {
        "id": "q_0270",
        "question": "Что происходит с матрицей, если векторы a и b являются просто векторами, а не матрицами, в контексте вычисления производной?",
        "answers": [
            "В этом случае матрица производной становится диагональной, поскольку результат зависит только от соответствующих элементов векторов из-за поэлементного применения операции. Матричное умножение при этом даёт тот же результат, что и вычисление по формуле."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "Рассмотрим несколько важных примеров. , где— вектор, а– поэлементное применение: Тогда, как мы знаем, Следовательно, гдеозначает поэлементное перемножение. Окончательно получаем Отметим, что еслии— это просто векторы, то мы могли бы вычислять всё и по формуле. В этом случае матрицабыла бы диагональной (так какзависит только от: ведьберётся поэлементно), и матричное умножение приводило бы к тому же результату. Однако еслии— матрицы, топредставлялась бы уже «четырёхмерным кубиком», и работать с ним было бы ужасно неудобно. , гдеи— матрицы. Как мы знаем, Тогда Здесь черезмы обозначили отображение, а в предпоследнем переходе использовалось следующее свойство следа: где— произвольные матрицы подходящих размеров (то есть допускающие перемножение в обоих приведённых порядках). Следовательно, получаем , гдеи— матрицы. Для приращенияимеем Тогда Здесь черезобозначено отображение. Значит, , где— матрица, а— функция, которая вычисляется построчно, причём для каждой строки: В этом примере нам будет удобно воспользоваться формализмом с частными производными. Сначала вычислимдля одной строки, где черезмы для краткости обозначим. Нетрудно проверить, что Так как softmax вычисляется независимо от каждой строчки, то где черезмы обозначили для краткости. Теперь пусть(пришедший со следующего слоя, уже известный градиент). Тогда Так какпри, мы можем убрать суммирование по: Таким образом, если мы хотим продифференцироватьв какой-то конкретной точке, то, смешивая математические обозначения с нотацией Python, мы можем записать:"
            }
        ]
    },
    {
        "id": "q_0271",
        "question": "Какие три основных шага необходимо выполнить для совершения шага SGD по мини-батчу при текущих значениях весов?",
        "answers": [
            "Сначала выполнить forward propagation с запоминанием всех промежуточных представлений, затем вычислить все градиенты с помощью backward propagation, и наконец совершить шаг SGD с использованием полученных градиентов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "Подытожим предыдущее обсуждение, описав алгоритмerror backward propagation(алгоритм обратного распространения ошибки). Допустим, у нас есть текущие значения весови мы хотим совершить шаг SGD по мини-батчу. Мы должны сделать следующее: Совершить forward propagation, вычислив и запомнив все промежуточные представления. Вычислить все градиенты с помощью backward propagation. С помощью полученных градиентов совершить шаг SGD. Проиллюстрируем алгоритм на примере двухслойной нейронной сети со скалярным output. Для простоты опустим свободные члены в линейных слоях. Итого матрица, как и Итого, как и Схематически это можно представить следующим образом: Если вы не уследили за вычислениями в предыдущем примере, давайте более подробно разберём его чуть более конкретную версию (для) Рассмотрим двуслойную нейронную сеть для классификации. Мы уже встречали её ранее при рассмотрении линейно неразделимой выборки. Предсказания получаются следующим образом: Пустьи— текущее приближение матриц весов. Мы хотим совершить шаг по градиенту функции потерь, и для этого мы должны вычислить её градиенты поив точке. Прежде всего мы совершаем forward propagation, в ходе которого мы должны запомнить все промежуточные представления:,,,. Они понадобятся нам дальше. Для полученных предсказаний вычисляется значение функции потерь: Дальше мы шаг за шагом будем находить производные по переменным из всё более глубоких слоёв. Градиентпо предсказаниям имеет видгде, напомним,(обратите внимание на то, чтоитут именно те, из которых мы делаем градиентный шаг). Следующий слой — поэлементное взятие. Как мы помним, при переходе через него градиент поэлементно умножается на производную, в которую подставлено предыдущее промежуточное представление:Аналогичным образом Следующий слой — снова взятие. Наконец, последний слой — это умножениена. Тут мы дифференцируем только по: Итоговые формулы для градиентов получились страшноватыми, но они были получены друг из друга итеративно с помощью очень простых операций: матричного и поэлементного умножения, в которые порой подставлялись значения заранее вычисленных промежуточных представлений."
            }
        ]
    },
    {
        "id": "q_0272",
        "question": "Какие две основные операции должен уметь выполнять слой с параметрами для обучения нейросети?",
        "answers": [
            "Слой должен уметь превращать градиент по выходу в градиент по входу и вычислять градиент по своим собственным параметрам."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "Итак, чтобы нейросеть обучалась, достаточно для любого слояс параметрамиуметь: превращатьв(градиент по выходу в градиент по входу); считать градиент по его параметрам. При этом слою совершенно не надо знать, что происходит вокруг. То есть слой действительно может быть запрограммирован как отдельная сущность, умеющая внутри себя делать forward propagation и backward propagation, после чего слои механически, как кубики в конструкторе, собираются в большую сеть, которая сможет работать как одно целое. Более того, во многих случаях авторы библиотек для глубинного обучения уже о вас позаботились и создали средства дляавтоматического дифференцирования выражений(autograd). Поэтому, программируя нейросеть, вы почти всегда можете думать только о forward-проходе, прямом преобразовании данных, предоставив библиотеке дифференцировать всё самостоятельно. Это делает код нейросетей весьма понятным и выразительным (да, в реальности он тоже бывает большим и страшным, но сравните на досуге код какой-нибудь разухабистой нейросети и код градиентного бустинга на решающих деревьях и почувствуйте разницу)."
            }
        ]
    },
    {
        "id": "q_0273",
        "question": "Какой метод используется для вычисления градиентов в обучении нейронных сетей?",
        "answers": [
            "Для вычисления градиентов используется метод обратного распространения ошибки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
                "text": "Метод обратного распространения ошибки позволяет удобно посчитать градиенты, но дальше с ними что-то надо делать, и старый добрый SGD едва ли справится с обучением современной сетки. Так что же делать? О некоторых приёмах мы расскажем в следующем параграфе."
            }
        ]
    },
    {
        "id": "q_0274",
        "question": "В чём заключается разница между функцией потерь и метрикой качества при построении модели машинного обучения?",
        "answers": [
            "Функция потерь используется при сведении задачи построения модели к задаче оптимизации и должна обладать хорошими вычислительными свойствами, например, дифференцируемостью. Метрика качества — это внешний, объективный критерий, который обычно зависит только от предсказанных меток, а не от параметров модели. В некоторых случаях, как в регрессии с MSE, они могут совпадать, но часто различаются, например, в бинарной классификации могут использоваться кросс-энтропия и accuracy."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
                "text": "Как мы узнали ранее, методы обучения реализуют разные подходы к обучению: обучение на основе прироста информации (как в деревьях решений); обучение на основе сходства (как в методах ближайших соседей); обучение на основе вероятностной модели данных (например, максимизацией правдоподобия); обучение на основе ошибок (минимизация эмпирического риска). И в рамках обучения на основе минимизации ошибок мы уже отвечали на вопрос: как можно штрафовать модель за предсказание на обучающем объекте. Во время сведения задачи о построении решающего правила к задаче численной оптимизации, мы вводили понятие функции потерь и, обычно, объявляли целевой функцией сумму потерь от предсказаний на всех объектах обучающей выборки. Важно понимать разницу между функцией потерь и метрикой качества. Её можно сформулировать следующим образом: Функция потерь возникает в тот момент, когда мы сводим задачу построения модели к задаче оптимизации. Обычно требуется, чтобы она обладала хорошими свойствами (например, дифференцируемостью). Метрика — внешний, объективный критерий качества, обычно зависящий не от параметров модели, а только от предсказанных меток. В некоторых случаях метрика может совпадать с функцией потерь. Например, в задаче регрессии MSE играют роль как функции потерь, так и метрики. Но, скажем, в задаче бинарной классификации они почти всегда различаются: в качестве функции потерь может выступать кросс-энтропия, а в качестве метрики —число верно угаданных меток(accuracy). Отметим, что в последнем примере у них различные аргументы: на вход кросс-энтропии нужно подавать логиты, а на вход accuracy — предсказанные метки (то есть по сути argmax логитов)."
            }
        ]
    },
    {
        "id": "q_0275",
        "question": "Какие два основных недостатка имеет метрика accuracy при оценке моделей бинарной классификации?",
        "answers": [
            "Accuracy не учитывает дисбаланс классов — например, при диагностике редких заболеваний модель, всегда предсказывающая отсутствие болезни, может иметь высокую accuracy из-за преобладания здоровых пациентов. Также эта метрика не учитывает разную цену ошибок на объектах разных классов, например, когда ложноотрицательный диагноз опаснее ложноположительного."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
                "text": "Перейдём к обзору метрик и начнём с самой простой разновидности классификации — бинарной, а затем постепенно будем наращивать сложность. Напомним постановку задачи бинарной классификации: нам нужно по обучающей выборке, гдепостроить модель, которая по объектупредсказывает метку класса. Первый критерий качества, который приходит в голову, —accuracy, то есть доля объектов, для которых мы правильно предсказали класс: Или же сопряженная ей метрика —доля ошибочных классификаций(error rate): Познакомившись чуть внимательнее с этой метрикой, можно заметить, что у неё есть несколько недостатков: она не учитывает дисбаланс классов. Например, в задаче диагностики редких заболеваний классификатор, предсказывающий всем пациентам отсутствие болезни будет иметь достаточно высокую accuracy просто потому, что больных людей в выборке намного меньше; она также не учитывает цену ошибки на объектах разных классов. Для примера снова можно привести задачу медицинской диагностики: если ошибочный положительный диагноз для здорового больного обернётся лишь ещё одним обследованием, то ошибочно отрицательный вердикт может повлечь роковые последствия. Исторически задача бинарной классификации — это задача об обнаружении чего-то редкого в большом потоке объектов, например, поиск человека, больного туберкулёзом, по флюорографии. Или задача признания пятна на экране приёмника радиолокационной станции бомбардировщиком, представляющем угрозу охраняемому объекту (в противовес стае гусей). Поэтому класс, который представляет для нас интерес, называется «положительным», а оставшийся — «отрицательным». Заметим, что для каждого объекта в выборке возможно 4 ситуации: мы предсказалиположительнуюметку иугадали. Будет относить такие объекты кtrue positive(TP) группе. True — потому что предсказали мы правильно, а positive — потому что предсказали положительную метку; мы предсказалиположительнуюметку, ноошиблисьв своём предсказании —false positive(FP). False, потому что предсказание было неправильным; мы предсказалиотрицательнуюметку иугадали—true negative(TN); и наконец, мы предсказалиотрицательнуюметку, ноошиблись—false negative(FN).Для удобства все эти 4 числа изображают в виде таблицы, которую называютconfusion matrix(матрицей ошибок): Не волнуйтесь, если первое время эти обозначения будут сводить вас с ума (будем откровенны, даже профи со стажем в них порой путаются), однако логика за ними достаточно простая: первая часть названия группы показывает угадали ли мы с классом, а вторая — какой класс мы предсказали. Пример Попробуем воспользоваться введёнными метриками в боевом примере: сравним работу нескольких моделей классификации наBreast cancer wisconsin (diagnostic) dataset. Объекты выборки — фотографии биопсии грудных опухолей. С их помощью было сформировано признаковое описание, которое заключается в характеристиках ядер клеток (таких как радиус ядра, его текстура, симметричность). Положительным классом в такой постановке будут злокачественные опухоли, а отрицательным — доброкачественные. Модель 1. Константное предсказание Решение задачи начнём с самого простого классификатора, который выдаёт на каждом объекте константное предсказание — самый часто встречающийся класс. Скопировать код1fromsklearn.datasets2importload_breast_cancer3the_data = load_breast_cancer()45# 0 — «доброкачественный»6# 1 — «злокачественный»7relabeled_target =1- the_data[\"target\"]89fromsklearn.model_selectionimporttrain_test_split10X = the_data[\"data\"]11y = relabeled_target12X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)1314fromsklearn.dummyimportDummyClassifier15dc_mf = DummyClassifier(strategy=\"most_frequent\")16dc_mf.fit(X_train, y_train)1718fromsklearn.metricsimportconfusion_matrix19y_true = y_test y_pred = dc_mf.predict(X_test)20dc_mf_tn, dc_mf_fp, dc_mf_fn, dc_mf_tp = confusion_matrix(y_true, y_pred, labels = [0,1]).ravel() Обучающие данные таковы, что наш dummy-классификатор все объекты записывает в отрицательный класс, то есть признаёт все опухоли доброкачественными. Такой наивный подход позволяет нам получить минимальный штраф за FP (действительно, нельзя ошибиться в предсказании, если положительный класс вообще не предсказывается), но и максимальный штраф за FN (в эту группу попадут все злокачественные опухоли). Модель 2. Случайный лес. Настало время воспользоваться всем арсеналом моделей машинного обучения, и начнём мы со случайного леса. Скопировать код1fromsklearn.ensembleimportRandomForestClassifier2rfc = RandomForestClassifier()3rfc.fit(X_train, y_train)4y_true = y_test5y_pred = rfc.predict(X_test)6rfc_tn, rfc_fp, rfc_fn, rfc_tp = confusion_matrix(y_true, y_pred, labels = [0,1]).ravel() Можно сказать, что этот классификатор чему-то научился, так как главная диагональ матрицы стала содержать все объекты из отложенной выборки, за исключением 4 + 1 = 5 объектов (сравните с 0 + 53 объектами dummy-классификатора, все опухоли объявляющего доброкачественными). Отметим, что вычисляя долю недиагональных элементов, мы приходим к метрикеerror rate, о которой мы говорили в самом начале: тогда как доля объектов, попавших на главную диагональ — это как раз таки accuracy: Модель 3. Метод опорных векторов. Давайте построим еще один классификатор на основе линейного метода опорных векторов. Важно: Не забудьте привести признаки к единому масштабу, иначе численный алгоритм не сойдется к решению и мы получим гораздо более плохо работающее решающее правило. Попробуйте проделать это упражнение. Скопировать код1fromsklearn.svmimportLinearSVC2fromsklearn.preprocessingimportStandardScaler3ss = StandardScaler() ss.fit(X_train)4scaled_linsvc = LinearSVC(C=0.01,random_state=42)5scaled_linsvc.fit(ss.transform(X_train), y_train)6y_true = y_test7y_pred = scaled_linsvc.predict(ss.transform(X_test))8tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0,1]).ravel() Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зренияerror rateмодели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная намидоля ошибочных классификацийне даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что, и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называетсяточностью (precision) Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называетсяполнотой (recall) Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит названиеF1-меры (F1-measure). Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоватьсямерой:"
            }
        ]
    },
    {
        "id": "q_0276",
        "question": "Как называется кривая, которая получается в осях TPR/FPR при варьировании порога отсечения в бинарной классификации?",
        "answers": [
            "Эта кривая называется ROC-кривой (receiver operating characteristics curve). Она строится при изменении порога классификации, где по оси X откладывается FPR (доля ложноположительных срабатываний), а по оси Y — TPR (полнота)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
                "text": "Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемыекалибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные предсказания и разное качество на отложенной выборке. Так, чем ниже порог отсечения, тем больше объектов модель будет относить к положительному классу. Как в этом случае оценить качество модели? Пусть мы хотим учитывать ошибки на объектах обоих классов. При уменьшении порога отсечения мы будем находить (правильно предсказывать) всё большее число положительных объектов, но также и неправильно предсказывать положительную метку на всё большем числе отрицательных объектов. Естественным кажется ввести две метрикиTPRиFPR: TPR(true positive rate) — это полнота, доля положительных объектов, правильно предсказанных положительными: FPR(false positive rate) — это доля отрицательных объектов, неправильно предсказанных положительными: Обе эти величины растут при уменьшении порога. Кривая в осях TPR/FPR, которая получается при варьировании порога, исторически называетсяROC-кривой(receiver operating characteristics curve, сокращённоROC curve). Следующийинтерактивный графикпоможет вам понять поведение ROC-кривой. Желтая и синяя кривые показывают распределение предсказаний классификатора на объектах положительного и отрицательного классов соответственно. То есть значения на оси X (на графике с двумя гауссианами) мы получаем из классификатора. Если классификатор идеальный, — две кривые разделимы по оси X, — то на правом графике мы получаем ROC-кривую (0,0)->(0,1)->(1,1), площадь под которой равна 1. Если классификатор случайный (предсказывает одинаковые метки положительным и отрицательным объектам), то мы получаем ROC-кривую (0,0)->(1,1), площадь под которой равна 0.5. Поэкспериментируйте с разными вариантами распределения предсказаний по классам и посмотрите, как меняется ROC-кривая. Чем лучше классификатор разделяет два класса, тем больше площадь (area under curve) под ROC-кривой — и мы можем использовать её в качестве метрики. Эта метрика называетсяAUCи она работает благодаря следующему свойству ROC-кривой: AUCравен доле пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил, то есть предсказание классификатора на первом объекте больше: Чтобы детальнее разобраться, почему это так, советуем вам обратиться кматериалам А.Г.Дьяконова. В каких случаях лучше отдать предпочтение этой метрике? Рассмотрим следующую задачу: некоторый сотовый оператор хочет научиться предсказывать, будет ли клиент пользоваться его услугами через месяц. На первый взгляд кажется, что задача сводится к бинарной классификации с метками 1, если клиент останется с компанией и— иначе. Однако если копнуть глубже в процессы компании, то окажется, что такие метки практически бесполезны. Компании скорее интересно упорядочить клиентов по вероятности прекращения обслуживания и в зависимости от этого применять разные варианты удержания: кому-то прислать скидочный купон от партнёра, кому-то предложить скидку на следующий месяц, а кому-то и новый тариф на особых условиях. Таким образом, в любой задаче, где нам важна не метка сама по себе, а правильный порядок на объектах, имеет смысл применять AUC. Утверждение выше может вызывать у вас желание использовать AUC в качестве метрики в задачах ранжирования, но мы призываем вас быть аккуратными. Будем постепенно уменьшать порог бинаризации. При этом полнота будет расти отдо, так как будет увеличиваться количество объектов, которым мы приписываем положительный класс (а количество объектов, на самом деле относящихся к положительному классу, очевидно, меняться не будет). Про точность же нельзя сказать ничего определённого, но мы понимаем, что скорее всего она будет выше при более высоком пороге отсечения (мы оставим только объекты, в которых модель «уверена» больше всего). Варьируя порог и пересчитывая значения Precision и Recall на каждом пороге, мы получим некоторую кривую примерно следующего вида: Рассмотрим среднее значение точности (оно равно площади под кривой точность-полнота): Получим показатель эффективности, который называетсяaverage precision. Как в случае матрицы ошибок мы переходили к скалярным показателям эффективности, так и в случае с кривой точность-полнота мы охарактеризовали ее в виде числа."
            }
        ]
    },
    {
        "id": "q_0277",
        "question": "Как оптимизировать метрики precision и recall, если их нельзя использовать напрямую в качестве функции потерь?",
        "answers": [
            "Модель обучается на стандартную функцию потерь (например, LogLoss), затем на валидационной выборке перебираются пороги бинаризации вещественных предсказаний от 0 до 1, строятся графики метрик в зависимости от порога, после чего выбирается нужное сочетание точности и полноты."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
                "text": "Пусть мы выбрали, что метрика качества алгоритма будет. Тогда мы хотим обучить модель так, чтобына валидационной выборке была минимальная/максимальная. Лучший способ добиться минимизации метрики— оптимизировать её напрямую, то есть выбрать в качестве функции потерь ту же. К сожалению, это не всегда возможно. Рассмотрим, как оптимизировать метрики иначе. Метрики precision и recall невозможно оптимизировать напрямую, потому что эти метрики нельзя рассчитать на одном объекте, а затем усреднить. Они зависят от того, какими были правильная метка класса и ответ алгоритма на всех объектах. Чтобы понять, как оптимизировать precision, recall, рассмотрим, как расчитать эти метрики на отложенной выборке.Пусть модель обучена на стандартную для классификации функцию потерь (LogLoss). Для получения меток класса специалист по машинному обучению сначала применяет на объектах модель и получает вещественные предсказания модели (). Затем предсказания бинаризуются по порогу, выбранному специалистом: если предсказание на объекте больше порога, то метка класса 1 (или «положительная»), если меньше — 0 (или «отрицательная»). Рассмотрим, что будет с метриками precision, recall в крайних положениях порога. Пусть порог равен нулю Тогда всем объектам будет присвоена положительная метка. Следовательно, все объекты будут либо TP, либо FP, потому что отрицательных предсказаний нет,, где— размер выборки. Также все объекты, у которых метка на самом деле 1, попадут в TP. По формуле точностьравна среднему таргету в выборке. А полнотаравна единице. Пусть теперь порог равен единице Тогда ни один объект не будет назван положительным,. Все объекты с меткой класса 1 попадут в FN. Если есть хотя бы один такой объект, то есть, будет верна формула. То есть при пороге единица, полнота равна нулю. Теперь посмотрим на точность. Формула для Precision состоит только из счётчиков положительных ответов модели (TP, FP). При единичном пороге они оба равны нулю,то есть при единичном пороге точность неопределена. Пусть мы отступили чуть-чуть назад по порогу, чтобы хотя бы несколько объектов были названы моделью положительными. Скорее всего это будут самые «простые» объекты, которые модель распознает хорошо, потому что её предсказание близко к единице. В этомпредположении. Тогда точностьбудет близка к единице. Изменяя порог, между крайними положениями, получим графики Precision и Recall, которые выглядят как-то так: Recall меняется от единицы до нуля, а Precision от среднего тагрета до какого-то другого значения (нет гарантий, что график монотонный). Итого оптимизация precision и recall происходит так: Модель обучается на стандартную функцию потерь (например, LogLoss). Используя вещественные предсказания на валидационной выборке, перебирая разные пороги от 0 до 1, получаем графики метрик в зависимости от порога. Выбираем нужное сочетание точности и полноты. Пусть теперь мы хотим максимизировать метрикуAUC. Стандартный метод оптимизации, градиентный спуск, предполагает, что функция потерь дифференцируема. AUC этим качеством не обладает, то есть мы не можем оптимизировать её напрямую. Поэтому для метрики AUC приходится изменять оптимизационную задачу. Метрика AUC считает долю верно упорядоченных пар. Значит от исходной выборки можно перейти к выборке упорядоченных пар объектов. На этой выборке ставится задача классификации: метка класса 1 соответствует правильно упорядоченной паре, 0 — неправильно. Новой метрикой становится accuracy — доля правильно классифицированных объектов, то есть доля правильно упорядоченных пар. Оптимизировать accuracy можно по той же схеме, что и precision, recall: обучаем модель на LogLoss и предсказываем вероятности положительной метки у объекта выборки, считаем accuracy для разных порогов по вероятности и выбираем понравившийся."
            }
        ]
    },
    {
        "id": "q_0278",
        "question": "Какая метрика регрессии позволяет сделать объекты в тестовой выборке равнозначными, перейдя от абсолютных ошибок к относительным?",
        "answers": [
            "MAPE (mean absolute percentage error) и её модификация SMAPE (symmetric mean absolute percentage error). Эти метрики помещают в знаменатель целевое значение или среднее от предсказания и истинного значения, что делает штрафы за ошибки на разных объектах сопоставимыми, независимо от масштаба значений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
                "text": "В задачах регрессии целевая метка у нас имеет потенциально бесконечное число значений. И природа этих значений, обычно, связана с каким-то процессом измерений: величина температуры в определенный момент времени на метеостанции количество прочтений статьи на сайте количество проданных бананов в конкретном магазине, сети магазинов или стране дебит добывающей скважины на нефтегазовом месторождении за месяц и т.п. Мы видим, что иногда метка это целое число, а иногда произвольное вещественное число. Обычно случаи целочисленных меток моделируют так, словно это просто обычное вещественное число. При таком подходе может оказаться так, что модель A лучше модели B по некоторой метрике, но при этом предсказания у модели A могут быть не целыми. Если в бизнес-задаче ожидается именно целочисленный ответ, то и оценивать нужно огрубление. Общая рекомендация такова: оценивайте весь каскад решающих правил: и те «внутренние», которые вы получаете в результате обучения, и те «итоговые», которые вы отдаёте бизнес-заказчику. Например, вы можете быть удовлетворены, что стали ошибаться не во втором, а только в третьем знаке после запятой при предсказании погоды. Но сами погодные данные измеряются с точностью до десятых долей градуса, а пользователь и вовсе может интересоваться лишь целым числом градусов. Итак, напомним постановку задачи регрессии: нам нужно по обучающей выборке, гдепостроить модель f(x). Величинуназывают ошибкой на объекте i или регрессионным остатком. Весь набор ошибок на отложенной выборке может служить аналогом матрицы ошибок из задачи классификации. А именно, когда мы рассматриваем две разные модели, то, глядя на то, как и на каких объектах они ошиблись, мы можем прийти к выводу, что для решения бизнес-задачи нам выгоднее взять ту или иную модель. И, аналогично со случаем бинарной классификации, мы можем начать строить агрегаты от вектора ошибок, получая тем самым разные метрики. MSE — одна из самых популярных метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток. При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки:У идеального решающего правиларавен, у наилучшего константного предсказания он равенна обучающей выборке. Можно заметить, чтопоказывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрикеMAE(mean absolute error): И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на объектах. Когда речь заходит об относительных ошибках, сразу возникает вопрос: что мы будем ставить в знаменатель? В метрикеMAPE(mean absolute percentage error) в знаменатель помещают целевое значение: С особым случаем, когда в знаменателе оказывается, обычно поступают «инженерным» способом: или выдают за непредсказаниена таком объекте большой, но фиксированный штраф, или пытаются застраховаться от подобного на уровне формулы и переходят к метрикеSMAPE(symmetric mean absolute percentage error): Если же предсказывается ноль, штраф считаем нулевым. Таким переходом от абсолютных ошибок на объекте к относительным мы сделали объекты в тестовой выборке равнозначными: даже если мы делаем абсурдно большое предсказание, на фоне которого истинная метка теряется, мы получаем штраф за этот объект порядка 1 в случае MAPE и 2 в случае SMAPE. Как и любая другая метрика, MAPE имеет свои границы применимости: например, она плохо справляется с прогнозом спроса на товары с прерывистыми продажами. Рассмотрим такой пример: Среднее MAPE — 36.7%, что не очень отражает реальную ситуацию, ведь два дня мы предсказывали с хорошей точностью. В таких ситуациях помогаетWAPE(weighted average percentage error): Если мы предсказываем идеально, то WAPE = 0, если все предсказания отдаём нулевыми, то WAPE = 1. В нашем примере получим WAPE = 5.9% Альтернативный способ уйти от абсолютных ошибок к относительным предлагает метрикаRMSLE(root mean squared logarithmic error): где нормировочная константавводится искусственно, чтобы не брать логарифм от нуля. Также по построению видно, что метрика пригодна лишь для неотрицательных меток. Все вышеописанные метрики легко допускают введение весов для объектов. Если мы из каких-то соображений можем определить стоимость ошибки на объекте, можно брать эту величину в качестве веса. Например, в задаче предсказания спроса в качестве веса можно использовать стоимость объекта. Еще одним способом охарактеризовать качество модели в задаче регрессии является доля предсказаний с абсолютными ошибками больше заданного порога: Например, можно считать, что прогноз погоды сбылся, если ошибка предсказания составила меньше 1/2/3 градусов. Тогда рассматриваемая метрика покажет, в какой доле случаев прогноз не сбылся."
            }
        ]
    },
    {
        "id": "q_0279",
        "question": "Как можно оптимизировать метрику MAPE в задачах регрессии?",
        "answers": [
            "Оптимизацию MAPE можно представить как оптимизацию MAE, где объектам выборки присвоены определённые веса."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
                "text": "Пусть мы выбрали, что метрика качества алгоритма будет. Тогда мы хотим обучить модель так, чтобы F на валидационной выборке была минимальная/максимальная. Аналогично задачам классификации лучший способ добиться минимизации метрики— выбрать в качестве функции потерь ту же. К счастью, основные метрики для регрессии: MSE, RMSE, MAE можно оптимизировать напрямую. С формальной точки зрения MAE не дифференцируема, так как там присутствует модуль, чья производная не определена в нуле. На практике для этого выколотого случая в коде можно возвращать ноль. Для оптимизации MAPE придётся изменять оптимизационную задачу. Оптимизацию MAPE можно представить как оптимизацию MAE, где объектам выборки присвоен вес."
            }
        ]
    },
    {
        "id": "q_0280",
        "question": "Какие две последовательные стадии включает в себя генеративный процесс, описанный в аналогии с рисованием лошади?",
        "answers": [
            "Сначала происходит семплирование из распределения скрытых переменных (например, размер, форма, цвет), а затем — семплирование из распределения данных при фиксированных скрытых переменных для добавления деталей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)",
                "text": "Давайте представим себе, что нам нужно нарисовать лошадь. Как бы мы это сделали? Наверное, сначала наметили бы общий силуэт лошади, её размер и позу, а затем стали бы добавлять детали: гриву, хвост, копыта, выбирать окраску шерсти и так далее. Кажется, что в процессе обучения рисованию мы учимся выделять для себя основной набор каких-тофакторов, наиболее важных для генерации нового изображения: общий силуэт, размер, цвет и тому подобное, а во время рисования уже просто подставляем какие-тозначенияфакторов. При этом одинаковые сочетания одних и тех же факторов могут привести к разным картинкам — ведь нарисовать что-то два раза абсолютно одинаково вы, скорее всего, не сможете. Попробуем формализовать описанный выше процесс. Пусть у нас есть датасетв многомерном пространстве исходных данных, — объектов, которые мы желаем генерировать, — и пространствоскрытых (латентных) переменныхменьшей размерности, которыми кодируются скрытые факторы в данных. Тогда генеративный процесс состоит из двух последовательных стадий (см. картинку ниже): Семплированиеиз распределения(красное) Семплированиеиз распределения(синее) То есть, рассуждая в терминах рисования картинок с лошадками, мы сначала мысленно семплируем некоторое(размер, форму, цвет, ...), затем дорисовываем все необходимые детали, то есть семплируем из распределения, и в итоге надеемся, что получившееся будет напоминать лошадку. Таким образом, построить генеративную модель в нашем случае — значит уметь семплировать с помощью описанного двустадийного процесса объекты, близкие к объектам из обучающей выборки. Говоря более формально, нам бы хотелось, чтобы наша модель максимизировала правдоподобиеэлементов обучающего множествапри описанной процедуре генерации: Предположим, что совместное распределениепараметризовано некоторым параметроми выражается непрерывной пофункцией при каждых фиксированныхи: Тогда и мы можем записать следующую задачу оптимизации: Решив её, мы построим нашу генеративную модель. Замечание 1. После приведённой выше аналогии с обучением рисованию может ошибочно показаться, что в скрытые переменные всегда заложен некоторый хорошо интерпретируемый смысл. Но на практике это всё же не обязано быть так: те скрытые переменные, которые мы найдём, могут как иметь простую интерпретацию, так и не иметь. С помощью объяснений выше мы прежде всего хотели проиллюстрировать понятие «скрытые переменные». Замечание 2. Может показаться, чтонам откуда-то уже известно, и тогда не ясно, зачем все эти сложности с введением латентных переменных и интегралами. На самом деле, мы действительно можем построитьстатистическую оценкупо данными даже пытаться генерировать новые данные с помощью таких моделей (как, например, делаетсятут). Но у статистических методов есть разные ограничения, наиболее серьёзным из которых представляется проклятие размерности: чем больше измерений у ваших данных, тем больше разнообразных примеров вам нужно для построения адекватной оценки. О проклятии размерности мы поговорим чуть подробнее далее. Замечание 3. Также может возникать вопрос — а зачем вообще нужно вводить латентные переменные, моделировать совместное распределение, а целевое распределениеопределять как маргинализациюпо? Почему такой подход в принципе должен работать? Ответ состоит в том, что, даже имея относительно простые выражения дляи, можно описать достаточно сложное распределение, что достаточно наглядно проиллюстрировано в примере ниже."
            }
        ]
    },
    {
        "id": "q_0281",
        "question": "Какой трюк позволяет получить оценку градиента по параметрам энкодера в вариационном автоэнкодере, несмотря на их участие в семплировании?",
        "answers": [
            "Для решения этой проблемы применяется репараметризация (reparameterization trick), которая представляет латентную переменную как дифференцируемую функцию от случайного шума, параметров энкодера и детерминированной переменной. Это позволяет вычислять градиенты по детерминированным переменным, перемещая источник случайности во входные данные."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)",
                "text": "Прежде чем пытаться решать задачу оптимизациидавайте подумаем, а как мы вообще могли бы посчитать такой интеграл? Первое, что приходит на ум, — попробовать получить его приближённое значение методом Монте-Карло: где в последнем переходе мы используем сэмплы. Однако, еслии— достаточно большое, мы столкнёмся спроклятием размерности— количество семплов, необходимых для того, чтобы хорошо покрыть, растёт экспоненциально с ростом: Есть ли способ как-то сократить число необходимых семплов для подсчёта? На самом деле, часто оказывается, что далеко не все возможныеотображаются в элементы, и вклад большинствав оценкупрактически нулевой. Это наводит на мысль, что для каждогонам может пригодиться знание распределениятаких, которые являются прообразами. Мы можем предположить, что распределениепараметризовано некоторым семейством параметров: Зная распределение, мы могли бы семлировать уже только из него, а не из всего, и, если распределениеокажется достаточно хорошим, число необходимых семплов значительно сократится. О том, как построить, мы поговорим позже. Сейчас стоит обратить внимание на то, что процессы семплирования из распределенийивзаимно обратны друг к другу: первое отображает элементы датасета в подмножество латентного пространства, то есть действует какэнкодер, а второе отображает латентные переменные в подмножество, то есть действует какдекодер: Так как оба эти распределения будут участвовать в обучении VAE, возникает аналогия между VAE имоделями-автоэнкодерами, имеющими похожую структуру. Сейчас у нас всё готово для того, чтобы записать общий вид функции потерь для обучения вариационного автоэнкодера. Напомним, что мы обучаем модель путём максимизации правдоподобияпо. Для удобства мы перейдём к логарифму правдоподобия: Оптимизировать напрямую это выражение тяжело из-за проклятия размерности, обсуждавшегося в прошлом разделе. Чтобы победить проклятие размерности, мы хотели бы заменить семплирование из априорного распределенияна семплирование из, для чего придётся осуществить некоторый трюк. Для любого, отличного от нуля для всех, мы можем выписать следующую цепочку равенств: Второе слагаемое в последнем равенстве —-дивергенция междуи, которая, как известно, неотрицательна: А первое слагаемое — это величина, именуемая в английской литературеevidence lower bound (ELBO): Первое слагаемое в последнем переходе обычно называютreconstruction loss, так как оно оценивает качество восстановления декодером объектаиз его латентного представления. А второе играет роль регуляризационного члена и подталкивает распределение, генерируемое энкодером, быть ближе к априорному распределению. Так как-дивергенция неотрицательна, ELBO является нижней границей для логарифма правдоподобия данных: Посмотрим повнимательнее на равенства, которые мы выписали. Функциюможно оптимизировать градиентным спуском (SGD), предварительно выбрав удобный вид для,и. Максимизируя, мы растим, тем самым улучшая нашу генеративную модель. Оптимизацию ELBO с помощью SGD мы будем подробно обсуждать в следующем разделе. Максимизируя, мы одновременно минимизируем. Распределениеоценивает, из какихмог бы быть сгенерирован объект, и заранее оно нам не известно. Но если мы выберем достаточно большую модель для, тов процессе оптимизации может очень сильно приблизиться к, и тогда мы будем напрямую оптимизировать. Заодно мы получаем приятный бонус: для оценки распределения прообразовмы сможем использоватьвместо невычислимого. То есть, которое мы при выводе формулы ввели в рассмотрение как произвольное распределение, действительно будет играть роль энкодера для модели. Важное свойство ELBO в том, что его можно оптимизировать градиентным спуском относительно параметрови. Если объекты датасетанезависимы и одинаково распределены, тозапишется как сумма (или среднее) значенийна объектах: Значенияи их градиентыв общем случае вычислить невозможно, однако можно получить их несмещённые оценки, что позволит нам использовать стохастический градиентный спуск. Оценку для градиента по параметрамполучить несложно: где в последней строчке. Однако оценку на градиент по параметрамполучить сложнее, ведь они также участвуют и в семплировании: В общем случае эта проблема не разрешима. Однако некоторые распределения позволяют применитьрепараметризацию (reparameterization trick): представить переменнуюкак обратимую дифференцируемую функцию от случайного шума, параметрови переменнной: Здесь распределениене зависит оти. Например, пусть. Тогдаможет иметь следующий вид: После такой замены мы сможем получить оценку на градиент по: где в последней строчке. Репараметризация хорошо иллюстрируется следующей картинкой: Здесь— функция потерь. Значенияна обеих схемах одинаковы, но на левой картинке градиенты порассчитать не получится, так как мы не можем дифференцировать по случайной переменной. Однако на правой картинке источник случайности перемещается во входные данные благодаря репараметризации, а градиенты вычисляются по детерминированным переменным. Таким образом, мы получили сетап, типичный для оптимизации с помощью SGD: там мы приближаем градиент функции потерь по случайным батчам входных данных, а здесь роль случайных батчей играют одновременно батчи из переменныхи случайных переменных. Кроме нормального распределения, есть довольного много примеров распределений, допускающих репараметризацию. Их можно найтипо ссылкев разделе \"The reparameterization trick\". Однако большая часть реализаций VAE используют именно нормальное распределение. В итоге примерный алгоритм обучения VAE такой: Скопировать код1dataset = np.array(...)2epsilon = RandomDistribution(...)34# Энкодер q_phi(z|x) — нейронная сеть с параметрами phi5encoder = Encoder()67# Декодер p_theta(x|z) — нейронная сеть с параметрами theta8decoder = Decoder()910for step in range(max_steps):11# Семплируем батч исходных данных и случайного шума12batch_x = sample_batch(dataset)13batch_noise = sample_batch(epsilon)1415# Считаем параметры распределения q(z | x) с помощью энкодера16latent_distribution_parameters = encoder(batch_x)1718# Делаем репараметризацию (семплируем из q(z | x))19z = reparameterize(latent_distribution_parameters, batch_noise)2021# Декодер отдаёт параметры выходного распределения22output_distribution_parameters = decoder(z)2324# Вычисляем ELBO и обновляем параметры моделей25L = -ELBO(26latent_distribution_parameters,27output_distribution_parameters,28batch_x29)30L.backward() Стоит подчеркнуть, что декодер выдаёт именно параметры выходного распределения, а не конкретный семпл из этого распределения. Например, если вы моделируете выходные изображения с помощью нормального распределения, то декодер на выходе предскажет некоторыеи, которые вместе с параметрами латентного распределения (выход энкодера) будут поданы в ELBO. Для генерации конкретной картинки на этапе инференса нужно будет либо честно провести семплирование из, либо, как часто делают, просто взять среднеев качестве выходного изображения. В общем случае конкретный способ проведения инференса зависит от вида используемого выходного распределения. Пришло время привести примеры конкретных,и, с которыми можно построить VAE. Для начала предположим, чтоможно положить равным стандартному нормальному распределению: Заметим, что в этом случае у априорного распределенияотсутствует зависимость от параметров. Распределениезависит от того, к какому распределению принадлежат ваши данные. Если ваши данные имеют непрерывное распределение, томожно задать, например, как гауссовское распределение: Вектор средних в этом примере определяется функциейс переменнымии, а матрица ковариаций определяется постоянной диагональной матрицей. Функциюможно задать с помощью нейронной сети с параметрами. При желании, матрицу ковариаций тоже можно задавать некоторой функцией и не ограничивать её вид только постоянными матрицами. Если же ваши данные дискретны, то может подойти категориальное распределение: в котором вектор вероятностей— выход нейросети после применения. Если у вас бинарные данные, вы можете использовать бернуллиевское распределение: где— выход нейронной сети после применения сигмоиды. Распределениеможет, в принципе, быть любым, но в самом простом случае оно имеет вид гауссовского распределения c диагональной матрицей ковариаций: Такое распределение позволяет, в частности, применить репараметризацию, обсуждавшуюся выше. Если выбратьдвумерным, то распределения, определямые, хорошо визуализируются: Вычислим его для приведённых выше распределений. Начнём с.-дивергенция между распределениямииравна: где— размерность этих распределений. Вывод этого соотношения можно найтиздесь. В нашем случае,и Тогда ELBO будет вычисляться как: где. Как было упомянуто вэтой статьеот авторов VAE в разделе 2.3, число семплированийможно положить равным единице при достаточно большом размере батча (например, 100). Если вы выберете биномиальное, то Если гауссовское, то Пример реализации обучения и применения VAE на датасете MNIST на Keras можно найтиздесь, а на PyTorch —здесь. Когда мы обучили VAE, мы сможем генерировать новые семплы, просто подаваяна вход декодеру: ![2](https://yastatic.net/s3/education-portal/media/vae_decoder_diagram_385be2e566_6c396a28e8.svg\"> Энкодер для генерации новых семплов не нужен. Однако нам может понадобиться оценитьдляиз тестового множества, чтобы понять, с какой вероятностью модель сможет сгенерировать. Для оценки интеграла нам нужно насемплировать некоторое количество, и если брать семплы из, то оценка может плохо сойтись. Но можно снова использовать ELBO как нижнюю границу дляи оценивать уже её, семплируя из распределения. Такая оценка сойдётся быстрее и даст примерное представление о том, насколько хорошо модель справляется с конкретным примером. Также интересно бывает взглянуть на то, как распределены коды обучающих примеров в латентном пространстве. Так, например, может выглядеть распределение латентных кодов цифр MNIST для обученного VAE в двумерном латентном пространстве: Разные типы цифр обозначены разными цветами (соответствие цифр и цветов показано на шкале сбоку). Здесь видно, что лучше всего модель различает нули и единицы, а восьмёрки и тройки — хуже всего. Стоит, конечно, отметить, что латентное пространство выбрано двумерным в целях визуализации, и при большей его размерности модель могла бы научиться различать цифры более качественно. Для двумерного латентного пространства есть ещё один интересный способ визуализировать структуру многообразия, выученного VAE. Можно взять равномерную сетку на единичном квадрате и отобразить её в латентное пространство, применив к ней функцию, обратную к CDF нормального распределения. Полученные семплы можно подать в декодер и посмотреть, какие картинки будут соответствовать узлам сетки: Здесь изображены примеры, сгенерированные для датасетов Frey Face и MNIST (оба доступны поссылке). Такая визуализация позволяет увидеть плавный переход латентных кодов одних объектов в коды других, а также взаимное расположение латентных кодов. Для MNIST снова видно, в частности, что коды нулей и единиц модель разнесла далеко друг от друга, а коды троек и восьмёрок очень близки. А ещё интересно наблюдать плавный переход от шестёрок к нулям и от семёрок к единицам. Для Frey Face видно, что весёлые лица расположены далеко от грустных, а по главной диагонали квадрата можно проследить плавный переход от серьёзного лица к улыбающемуся. Ещё интересно посмотреть на то, как меняется качество генерируемых цифр в зависимости от размерности латентного пространства (на картинках просто случайные семплы из модели): Заметный переход виден между размерностями 2 и 5, дальнейший рост размерности почти не оказывает значимого эффекта. Иногда мы можем захотеть сгенерировать не просто какой-то произвольный объект из датасета, а относящийся к конкретной группе или классу. Ранее мы выписывали уравнение для: Все распределения, участвующие в этом уравнении, мы можем сделать обусловленными по переменной: Переменнаяможет быть лейблом объектаили вообще произвольным тензором, как-то характеризующим. Вместо, единого для всехиз обучающей выборки, для каждого значениятеперь будет отдельное априорное распределение. Переменнаяможет принимать и дискретные, и непрерывные значения. Она может даже, например, быть половиной изображения, которую модели предлагается дополнить. На всякий случай подчеркнём, что обучение CVAE — это не то же самое, что обучение нескольких независимых VAE, так как веса CVAE общие для всех классов. На уровне имплементации это реализуется довольно просто: нужно всего лишь сконкатенировать входы энкодера и декодера с тензором, соответствующим. Еслиимеет категориальные значения, то бывает полезно предварительно закодировать их one-hot векторами. Алгоритм будет примерно таким: Скопировать код1dataset, labels = np.array(...), np.array(...)2epsilon = RandomDistribution(...)34# Энкодер q_phi(z|x) — нейронная сеть с параметрами phi5encoder = Encoder()67# Декодер p_theta(x|z) — нейронная сеть с параметрами theta8decoder = Decoder()910for step in range(max_steps):11# Семплируем батч исходных данных, лейблов и случайного шума12batch_x = sample_batch(dataset)13batch_y = sample_batch(labels)14batch_noise = sample_batch(epsilon)1516# Подаём в энкодер конкатенацию входных данных и лейблов17encoder_input = concatenate([batch_x, batch_y])1819# Считаем параметры распределения z с помощью энкодера20latent_distribution_parameters = encoder(encoder_input)21# Делаем репараметризацию22z = reparameterize(latent_distribution_parameters, batch_noise)2324# Конкатенируем полученный случайный вектор и лейблы25decoder_input = concatenate([z, batch_y])2627# Декодер отдаёт нам выходное изображение28output_distribution_parameters = decoder(decoder_input)2930# Вычисляем ELBO и обновляем параметры31L = -ELBO(32latent_distribution_parameters,33output_distribution_parameters,34batch_x35)36L.backward() Реализацию CVAE на PyTorch и Tensorflow можно найти, например,здесь. Если визуализировать распределение латентных кодов для цифр MNIST, полученных после обуславливания модели на класс цифры, то можно увидеть что-то такое: Мы видим непонятную смесь из точек вместо явных кластеров, которые выделяла обычная модель VAE. Однако дело тут в том, что, вместо того, чтобы пытаться размещать все цифры в одном пространстве, модель использует отдельное латентное пространстводля каждой цифры: На картинке справа — априорные распределения для цифр 6 и 7, а слева — визуализация структуры выученных многообразий для этих цифр, построенная так же, как аналогичная визуализация для VAE. Качество изображений каждой отдельной цифры заметно повышается: Видно, что вариабельность генерации цифр теперь тоже заметно выросла, и модель может имитировать написание цифр разными почерками."
            }
        ]
    },
    {
        "id": "q_0282",
        "question": "Какие направления улучшений VAE, помимо дискретных латентных переменных, упоминаются в тексте?",
        "answers": [
            "В тексте упоминаются использование иерархических латентных распределений, функций потерь, отличающихся от ELBO, выбор различных форм латентных пространств и применение adversarial-обучения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)",
                "text": "Итак, в этом параграфе мы поговорили о том, как устроен VAE в классическом смысле, — с непрерывным распределением латентных переменных, а также поговорили о работах, основанных на идеях использования дискретных распределений для VAE. Конечно, различные модификации VAE не исчерпываются только лишь отказом от непрерывных латентных переменных в пользу дискретных. Есть множество других возможных направлений для улучшения модели: использование иерархических латентных распределений (которые мы, кстати, видели в контексте VQ-VAE-2), использование функций потерь, отличающихся от ELBO, выбор различных форм латентных пространств, применение adversarial-обучения и многое другое. Хороший список различных статей, посвящённых модификациям VAE, можно найтиздесь. Из недавних работ, связанных с применением иерархических распределений, интересной кажетсяNVAE— семплы из модели выглядят весьма впечатляюще. Про неё есть хорошийвидеообзорот Yannic Kilcher. На этом мы завершаем рассказ о VAE. Будем надеяться, что он дал вам общее представление и об исходных идеях, из которых выросла модель VAE, и о наиболее интересных последних результатах, связанных с ней. А в следующем параграфе мы поговорим о генеративно-состязательных сетях."
            }
        ]
    },
    {
        "id": "q_0283",
        "question": "Как влияет сила моды на скорость её сходимости при градиентном спуске в линейной сети с одним скрытым слоем?",
        "answers": [
            "Чем сильнее мода (то есть чем больше её сила), тем быстрее она сходится. Время, необходимое для выучивания фиксированной доли силы моды, обратно пропорционально логарифму её силы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/implicit-bias",
                "text": "Каков implicit bias нейронных сетей? Сходится ли градиентный спуск в решение наименьшей нормы и если да, то о какой норме идёт речь? Частичный ответ на этот вопрос удаётся получить для линейных сетей. Следуя работеExact solutions to the nonlinear dynamics of learning in deep linear neural networks, рассмотрим линейную сеть с одним скрытым слоем: гдеи– матрицы. Поставим задачу многомерной (метка– вектор) регрессии с квадратичной функцией потерь: Шаг градиентного спуска выглядит следующим образом: где точка надозначает производную по времени (то есть по). Это нелинейная система матричных дифференциальных уравнений второго порядка; чтобы проинтегрировать её аналитически, нам придётся сделать ряд предположений. Определим ковариационную матрицу входови матрицу ковариации меток со входами. Предположим, что данные декоррелированы:; этого можно добиться, заменив входына. Что касается матрицы ковариации меток со входами, рассмотрим её сингулярное разложение: Назовёмсилой моды с индексомковариации между метками и входами. Сделаем замену координат: В новых координатах градиентный спуск принимает вид: Пустьи. Тогда в терминах векторови Получилась система векторных дифференциальных уравнений порядка, всё ещё нелинейная. К счастью, при определённом предположении об инициализации эта система распадается нанезависимых систем порядка. Предположим, что существует ортогональная матрица, такая что при всехимеет место равенство и для некоторых скалярных величини. Нетрудно заметить, что в этом случае при всехи в любой момент времениимеемидля некоторых скалярных величини. Тогда для различныхвыражения выше становятся независимыми друг от друга: Теперь это система нелинейных дифференциальных уравнений второго порядка. Еслив начальный момент, то это верно и в любой момент времени. Тогда система выше превращается в одно уравнение первого порядка. В самом деле, обозначив, получаем: Это уравнение задаёт следующую динамику градиентного спуска для функции потерь(её глобальный минимум – это). Перед тем, как интегрировать уравнение (1), напомним, как изперейти обратно к исходными. Имеем для: Аналогично для: Теперь проинтегрируем уравнение (1) в предположении, чтоидля выбранного: Рассмотрим время, необходимое, чтобы выучить фиксированную долю силы данной моды, где, стартуя из точки из окрестности нуля. Оно равняется Видим, что чем сильнее мода (то есть чем больше), тем быстрее она сходится. Рассмотрим две моды с силамии, такие что. Насколько вторая (более слабая) мода выучится к моменту, когда первая уже выучится на долю? Из уравнения выше имеем: Подставляяи, получаем: Поскольку, это выражение стремится к минус бесконечности при, из чего следует, чтостремится к нулю. Это означает, что если веса в инициализации лежат в окрестности нуля, то к моменту, когда данная мода выучивается на любую фиксированную долю, более слабые моды не успевают выучиться вообще. Таким образом, в любой момент времениматрицаявляется наилучшим малоранговым приближением заданного ранга матрицы корреляций, причём чем больше, тем больше ранг. Можно сказать, чтоградиентный спуск с фиксированным числом шагов «предпочитает» решения малого ранга. В выводе выше, мы использовали ряд предположений, в частности, что вектора, образующие матрицу, ортогональны в инициализации. Эмпирически те же выводы оказываются верными и без этого предположения, см. графики в оригинальной работеExact solutions to the nonlinear dynamics of learning in deep linear neural networks. Можно ли их обосновать строго математически? В работахTowards resolving the implicit bias of gradient descent for matrix factorizationиDeep Linear Networks Dynamicsдоказывается, что самая сильная мода выучивается в первую очередь. Тем не менее, на момент написания этого текста остаётся недоказанным, что все моды выучиваются последовательно от сильных к слабым. К сожалению, implicit bias градиентного спуска для нелинейных сетей пока остаётся почти неизученным."
            }
        ]
    },
    {
        "id": "q_0284",
        "question": "Какие два способа получения PAC-байесовской оценки для детерминированного алгоритма на несчётном множестве моделей рассматриваются в тексте?",
        "answers": [
            "Первый способ — добавить известный шум в финальную модель, выданную детерминированным алгоритмом. Второй способ — взять дискретное кодирование и применить дискретную PAC-байесовскую оценку к закодированной модели вместо оригинальной."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pac-bajesovskie-ocenki-riska",
                "text": "Выше были рассмотрены две PAC-байесовские оценки: одна для не более, чем счётного множества моделей, другая – для произвольного. За возможность использования несчётных классов моделей мы заплатили тем, что алгоритм обучения должен быть недетерминированным (для детерминированных алгоритмов KL-дивергенция в Теореме Макаллестера может вырождаться в бесконечность; например, это так, если априорное распределение гауссово). Чаще всего класс моделейвсё-таки несчетён: например, если это класс всех сетей фиксированной архитектуры, то он индексируется весами, которых несчётное множество. При этом, хотя используемый алгоритм обучения и в самом деле недетерминирован (стохастический градиентный спуск зависит от случайного выбора батчей и от инициализации весов) и теорема Макаллестера выполняется, финальное распределение моделей очень сложно охарактеризовать, и из-за этого непонятно, как считать KL-дивергенцию. Предположим, что алгоритм обучения всё-таки детерминирован; этого можно добиться, зафиксировав сид генератора случайных чисел при обучении. Как получить осмысленную PAC-байесовскую оценку для детерминированного алгоритма на несчётном множестве моделей? Мы рассмотримдва способа. Первый способ – добавить известный шум в финальную модель, выданную детерминированным алгоритмом. Так, для нейронных сетей, результатом работы алгоритма обучения является набор весов. Если добавить в этот набор гауссовский шум, а также в качестве априорного распределения взять гауссовское, то KL-дивергенцию в теореме Макаллестера можно будет посчитать аналитически. Дисперсию шума в апостериорном распределении тоже можно обучить с помощью градиентного спуска одновременно с весами, тем самым минимизируя правую часть оценки из вышеупомянутой теоремы. Если в найденную модель удастся добавить шум так, чтобы KL-дивергенция значительно уменьшилась, но при этом риск на обучающей выборке не сильно вырос, то оценка на истинный риск получится хорошей. Это рассуждение связывает PAC-байесовские оценки и гипотезу о том, что «плоские» («широкие») минимумы хорошо обобщают. В самом деле, если минимум «плоский», то в модель из него можно добавить много шума, не испортив качество на обучении. Оценки, основанные на этом принципе, можно найти в работахComputing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training dataиA PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks. Второй способ состоит в том, чтобы взять дискретное кодированиеи применить дискретную PAC-байесовскую оценку к закодированной модели вместо оригинальной. Обозначим закодированную модельчерез. Следуя работеNon-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach, возьмём априорное распределение с массой, убывающей с ростом длины кода: Здесь– длина кода модели,– некоторое вероятностное распределение на, а– нормализующая константа. Тогда KL-дивергенция примет следующий вид: Для того, чтобы KL-дивергенция выше была как можно меньше, необходимо, чтобы наш алгоритм обучения на реалистичных данных сходился в модели с маленькой длиной кода. Для этого будем применять наше кодирование не к оригинальной модели, а к сжатой с помощью некоторого алгоритма сжатия. Здесь мы предполагаем, что модели, к которым сходится наш алгоритм обучения, можно сжать с малыми потерями до моделей с малой длиной кода. Другими словами, мы опираемся на предположение, что обученные модели в некоторым смысле «простые». Если модель параметризована весами, типичный алгоритм сжатия выдаст набор, где – позиции ненулевых весов; – «словарь» весов; ,– квантизованные значения весов. Выход алгоритма будет выглядеть как, если, иначе. Тогда наивное 32-битное кодирование даст следующую длину: В работеNon-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approachописанный выше способ применяется к модели MobileNet (свёрточной сети, сконструированной специально для мобильных устройств), обученной на наборе данных ImageNet, и получают верхнюю оценку на истинный риск, равную(риск случайного угадывания –). Хотя такой результат и выглядит очень скромным, но это первая осмысленная оценка обобщающей способности реально используемой нейронной сети на реалистичном наборе данных."
            }
        ]
    },
    {
        "id": "q_0285",
        "question": "Какие типы моделей будут рассмотрены в хронологическом порядке после краткого исторического экскурса?",
        "answers": [
            "После исторического экскурса будут рассмотрены современные модели: GPT-1, GPT-2, GPT-3, InstructGPT, ChatGPT и LLaMa."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Говоря простым языком, языковые модели — это алгоритмы, способные продолжать тексты. Если чуть усложнить, то этовероятностные алгоритмы, и к ним сразу можно задать эмпирический критерий качества: хорошая модель даёт разумные продолжения данных ей текстов. Давайте разберём пример выше. Модель высчитывает вероятность возможных продолжений текста и предлагает их нам. Слово «фрукт» — наименее разумное продолжение нашей фразы, в то время как слово «наука» — наиболее разумное. И действительно, это часть определения машинного обучения, которое мы давали в начале этого учебника. Таким образом, нам осталось лишь научить алгоритм моделировать эти вероятности и максимизировать их для разумных предложений. Но как это сделать? По ходу развития языковых моделей подходы менялись, мы расскажем о каждом из них в хронологическом порядке. Начнём с краткого экскурса в историю — поговорим о статистических моделях, рекуррентных нейронных сетях и трансформерах. А затем перейдём к современным — GPT-1, GPT-2, GPT-3, InstructGPT, ChatGPT и LLaMa."
            }
        ]
    },
    {
        "id": "q_0286",
        "question": "Какой метод, используемый в клавиатурах смартфонов для исправления опечаток и быстрого набора через Т9, основан на вероятностной формулировке цепей Маркова?",
        "answers": [
            "Это статистическая языковая модель, которая аппроксимирует распределение слов на основе корпуса текстов, подсчитывая совместные встречаемости слов и вероятности их следования друг за другом. На практике часто ограничиваются контекстом размера 1 для предсказания следующего слова."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Идея модели лежит на поверхности, много где применяется в самых разных вариациях даже в ХХ веке, поэтому сложно назвать авторов или точную дату создания. Однако этот метод популярен до сих пор — используется в клавиатурах смартфонов для исправления опечаток и быстрого набора текстов через Т9. Теперь подробнее о методе. Напомним вероятностную формулировку цепей Маркова в общем виде: Если представить, что— это слово, а набор этих омега — это предложение, то по формуле становится возможным посчитать вероятность предложенияС практической точки зрения всё чуть сложнее, ведь распределение слов в реальном языке (какое, с какими и как часто встречается), вообще говоря, неизвестно. Его принято аппроксимировать на основекорпуса текстов(например, всего интернета) — в этом случае считаются совстречаемости слов друг с другом, и по ним считаются вероятности. В условной вероятности число переменных, от которых зависит распределение следующего слова, называется контекстом. Например, в выражениидлина контекста равна. На практике же редко считают вероятности с контекстом больше трёх, на это есть несколько причин: Сложность в подсчёте и хранении каждого возможного уникального контекста длины. Если корпус текстов состоит изразличных слов, то стоимость хранения счётчиков встречаемости для выбранной длины контекста равна, что очень много при больших. Большой контекст реже встречается. То есть слова «яблоку», «негде» и «упасть» поодиночке встречаются чаще, чем их комбинация «яблоку негде упасть». Отсюда достаточность статистик падает с ростом длины контекста. В учебном примере предлагается ограничиться шириной контекста размера 1: Интересно, что такой подход достаточно популярен до сих пор. Например, он используется в умных клавиатурах, чтобы подсказать следующее слово. Достоинства статистических моделей: Простота имплементации. Высокая скорость работы алгоритма. Низкая вычислительная стоимость обучения и инференса. Недостатки статистических моделей: Не сможет сгенерировать слова, которые не шли подряд в обучающем корпусе. Очень маленький контекст. Длинные последовательности равновероятны ≈ нулю (в цепях Маркова для длинных последовательностей много множителей меньше нуля, поэтому их произведение уже практически равно нулю для любых множителей). Отсюда алгоритм не может выдавать разумные продолжения большой длины. Языковые модели, да и вообще все модели, которые оперируют текстом, используют понятие токена. Токен — это единица текста, которую понимают алгоритмы. В примере выше токен — это отдельное слово(этот подход называетсямешком слов), однако текст можно разбивать на токены и иначе. Раньше предложение разбивалось на слова по пробелам, знакам препинания, исключались стоп-слова и так далее (назовем этоCountVectorizer). Но у этого подхода возникали две проблемы с разными словоформами. Они: Либо обозначались разными токенами, что не совсем верно, ведь слово-то одно и то же. И получалось, что похожим смыслом обладало сразу несколько токенов. Либо приводились к начальной форме — и в итоге терялся падеж, время, число. Современные токенизаторы построены на алгоритме BPE (Byte Pair Encoding; об устройстве BPE более подробно можно прочитать вучебнике Лены Войта). Решение требует фиксации определённого числа токенов. Как только это сделано, в словарь добавляются все символы из текста, ищутся самые частые их сочетания и снова добавляются. Этот процесс продолжается до тех пор, пока число токенов не станет равно заданному значению. Токенизатор SentencePiece в определённом смысле совершеннее, чем BPE, — он наследует логику Unigram- и BPE-токенизаторов, иначе работает с пробелами (добавляет_перед соответствующим токеном) и не построен на логике разбиения слов по разделителям. Поэтому, в отличие от BPE, он способен работать с такими языками, как японский или китайский. Подробнее о его устройстве можно прочитатьздесь. Появились после статистических моделей, подробнее о хронологииздесь. Рекуррентные нейронные сети концептуально можно описать формулой, где: — некоторая модель; — внутреннее состояние модели на момент времени; — токен, который сейчас обрабатывается. Тогда следующий токенполучается так: Подробно об устройстве RNN мы рассказываем в параграфеНейросети для работы с последовательностями. Здесь же коротко отметим, что существуют различные модификации рекуррентных сетей, которые усложняют структуру алгоритма, даже добавляют механизм внимания Attention. Если коротко, то он позволяет лучше оценивать взаимосвязи токенов в тексте. Все они в разной степени помогают модели усваивать более длинные и сложные последовательности токенов. Достоинства RNN: Высокая скорость инференса и сравнительно низкая стоимость. Более качественный текст, чем у моделей на статистиках. Теоретически понимает контекст в сотни слов (а с Attention ещё больше). Точно учитывает весь контекст документа. Недостатки RNN: Невозможность параллельного обучения на многих устройствах, отсюда не получится просто так обучить большую RNN. Модель «хорошо помнит» лишь несколько последних токенов контекста (без Attention). Проблемы с обучением (exploading/vanishing gradients)."
            }
        ]
    },
    {
        "id": "q_0287",
        "question": "Какие две основные части составляют архитектуру трансформеров?",
        "answers": [
            "Архитектура трансформеров состоит из двух частей: энкодера (encoder) и декодера (decoder)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Более подробно трансформеры и их устройство описаны в параграфеТрансформеры. Последней и наиболее успешной с точки зрения качества оказалась архитектура трансформеров. Она состоит из двух частей: encoder (на изображении слева) и decoder (на изображении справа). Изначально был популярен подход обучать части отдельно. Так на базе encoder-блоков были построеныBERT-модели. Идея обучения звучит несложно: давайте из входного текста замаскируем токеномMASK15% имеющихся токенов и обучим модель угадывать, какие именно токены были скрыты. Тогда, если модель обучится это делать, она сможет очень хорошо понимать текст. Таким образом, энкодеры обладают следующими особенностями: Анализируют входной текст и связи между токенами. Выделяют важные токены для определённой задачи. Ничего не генерируют. На базе декодеров сделаны GPT-модели. Они обучаются предсказывать следующий токен на основе предыдущих. На инференсе, когда очередной токен сгенерирован, он добавляется в контекст, и уже на основе него выбирается новый токен. Таким образом модель: генерирует токен за токеном. смотрит на весь контекст, архитектурно, нет забывания токенов. имеет возможность (как и BERT-модели) обучаться параллельно. обладает достаточно высокой вычислительной стоимостью инференса."
            }
        ]
    },
    {
        "id": "q_0288",
        "question": "Каков был размер контекста в токенах у модели GPT-1?",
        "answers": [
            "У модели GPT-1 размер контекста составлял 512 токенов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Начнём немного издалека, с моделей GPT-1 и GPT-2. Первая была обучена в 2018 году на 7000 книг и имела размер контекста в 512 токенов. И она сразу получилась довольно сильной: после дообучения на специализированные задачи (бенчмарки) показывала на них лучшее на то время качество. Так, в задачах CoLA (бенчмарк классификационный, в нём надо определить грамматическую корректность предложения) результат вырос до 45,4 против прежнего результата в 35,0 у RNN. А вGLUE— с 72,8 до 68,9. Вторая модель была обучена в 2019 году. Она состояла из рекордных для того времени 1,5 млрд параметров (то есть была в ~10 раз больше первой), имела контекст в 1024 токена и была обучена на 40 ГБ текстовых данных. GPT-2 снова побеждала предыдущие подходы, включая GPT-1, на многихбенчмарках. По сравнению с первой версией модели у второй произошел качественный рост: теперь она могла генерировать разумные тексты — а не только предложения. Правда, не всегда и не с первой попытки. GPT-3 стала революцией с точки зрения качества и размеров. В 2020 году была получена модель размером в 175 млрд параметров, она обучалась на 570 ГБ текстовых данных с контекстом в 2048 токенов. Модельмогларешать целый спектр задач, включая перевод, суммаризацию и ответы на вопросы, с качеством, близким к человеческому уровню, а также отличалась высокой способностью генерировать креативный контент. Демонстрацию работы модели лучше посмотреть вэтой статьена 28 странице и далее. Модель демонстрировала действительно впечатляющие результаты: собрав обучающие данные, можно было с высоким качеством решить практически любую текстовую задачу. Однако для применения таких решений остаётся проблема со стоимостью их обучения. Для обучения GPT-2 авторы использовали 16 GPU (иначе говоря — графических процессоров, видеокарт), а для GPT-3 уже 3200. Для дообучения модели под определенную задачу, конечно, понадобится меньше ресурсов, но всё равно достаточно много. Что с этим делать? Использовать подводки."
            }
        ]
    },
    {
        "id": "q_0289",
        "question": "Что такое zero-shot-пример в контексте использования языковых моделей?",
        "answers": [
            "Zero-shot-пример — это конструкция, где задание формулируется на естественном языке без предоставления обучающих примеров. Например, для перевода слова 'cheese' на французский просто описывается сама задача перевода."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Оказывается, что обучать большие языковые модели решать определённые задачи не всегда нужно (как мы говорили ранее, это ресурсоёмко): можно составитьfew-shotподводку. Подводка — словесное описание поставленной задачи, составленное определенным образом. Представим, что мы хотим осуществить перевод с английского на французский. Для обучения нам необходимо было бы составить пары, где— слово на английском, а— на французском. Сделаем иначе — опишем задание на естественном языке: Здесь на английском языке сформулировано задание и предлагается слово «cheese» перевести на французский. Назовем такую конструкциюzero-shot-примером. Такой запрос GPT-3, возможно, поймёт, но работать будет плохо. Давайте увеличим количество примеров в подводке и назовем эту конструкциюone-shot: Или больше, и это будетfew-shot: При этом приёме не тратятся ресурсы на обучение модели, она лишь смотрит на контекст и генерирует продолжение. Оказывается, этого достаточно, чтобы сравняться с downstream-обучением. Продемонстрируем преимущество такого подхода на двух бенчмарках. TriviaQA — вопросно-ответный бенчмарк, составленный на основе Википедии. Он помогает оценивать знания модели и ее ответы на вопросы. Lambada — оценивает меморизацию длинного контекста модели. Чем выше скор, тем лучше модель на обоих бенчмарках. Графики выше демонстрируют несколько особенностей: Few-shotпозволяет получать качество, сравнимое с дообучением на определённом датасете, и стремится к человеческому качеству. С ростом числа обучаемых параметров модели растет её качество. На правом графикеfew-shot-примеры начинают работать лучшеzero-shot-примеров лишь с некоторого размера модели. Это говорит о том, что модель начинает демонстрировать «умные» свойства лишь начиная с некоторого размера. Few-shotдействительно полезен и помогает получать от модели нужный результат без обучения, но всё же недостаточно хорошо. Предположим, мы хотим узнать у модели, как приготовить любимое блюдо. Пусть это будет лазанья: Можно заметить, что запрос к модели можно задать по-разному, но ответ ожидается обычно какой-то конкретный. Авторыэтой статьизаметили, что сама по себе конструкцияfew-shot-примера не приводит к стабильному результату. Качество решения задачи очень зависит от: Текстового описания задачи. Числа примеров в подводке. Порядка, в котором примеры следуют друг за другом в подводке. Формате составленияfew-shot. Чтобы улучшить качество решения задачи, авторы предлагают осуществлять калибровку подводок. В статье они заметили, что модели смещены относительно подводок, то есть переформулировка запроса ведёт к смещению в ответе модели, а также к росту разброса ответов. Например, модели задают вопрос и её задача — ответить «да» или «нет». Еслиfew-shotсостоит из четырёх примеров и они идут в порядке «да», «да», «нет», «нет», то, вероятнее всего, дальше модель ответит «нет» на любой вход, просто потому что слово «нет» встречалось последним. Калибровать модель предлагается с помощью выученного линейного преобразования: В этом преобразовании: и— обучаемые; — вероятности на выходе модели; — откалиброванные вероятности; Обучающие данные собираются так: Для различных задач собираем подводки и добавляем нейтральное слово N/A. В этом примере несмещённая модель должна давать с вероятностью 50% ответ «positive» или «negative». Чтобы добиться такого распределения ответов у смещённой модели, представим: Также всеfew-shot-примеры стандартизуются в специальный формат вопрос — ответ, как на картинке выше. Этот метод (синий график) по сравнению со стандартнымиfew-shot-примерами (красный график) помог повысить качество и уменьшить разброс результата. Таким образом, оптимизировав всего 4 параметра, авторы существенно улучшили итоговый результат. Качество работы модели зависит от подводки, иfew-shotпросто один из способов её построения. Эксперименты показывают, что грамотный подбор промта позволяет экономить на обучении и решать задачи с высоким качеством. Проблема в обучении больших моделей — нехватка оперативной памяти на GPU, поэтому не будем оптимизировать все параметры модели. Пусть необходимо решить задачу, к ней имеется обучающее множество вида. Введём дополнительные токены, которых не было в словаре:— и будем добавлять в каждый текст из X согласно какому-то правилу. Правило может быть таким: имеем 20 спецтокенов, добавим токены 1–10 в начало строки, а 11–20 в конец. Тогда, можно «заморозить» все параметры в модели, кроме этих токенов, и сэкономить на обучении. Если токенов 100 и каждый из них имеет размерность в 1024, то необходимооптимизироватьлишь 100 тысяч параметров вместо 175 млрд в случае обучения всей модели. Получается, что можно оптимизировать подводку, или, другими словами, находить наиболее оптимальный промт, который лучше прочих решает поставленную задачу. Языковые модели призваны решать самый широкий спектр текстовых задач — вопросно-ответные, суммаризацию, диалоговость, перевод и многие другие. Получается, что модель должна после некого обучения (подбора подводки или оптимизации вообще всех параметров под каждую задачу) решать каждую из них на высоком уровне. Однако модель обычно учится на текстах из интернета, книгах и других доступных ресурcах. И формат задачи, который обычно требуется от модели, не соответствует тому, что алгоритм привык видеть на обучении. К этому стоит добавить, что среди веб-документов просьба что-то сократить или определить тональность документа встречается не очень часто. Исправить этот недостаток призваны подходы по генерализации языковых моделей:FLANиT0. Инструкции даются на естественном языке и для подготовки качественного обучающего множества предлагается произвести следующие действия: Каждой отдельной задаче (будь то перевод, написание отзывов или суммаризация) пишется по несколько различных подводок, отражающих смысл задания. Итоговый датасет составляется из отдельных задач, все строчки датасета перемешиваются случайным образом. Авторы стараются собрать как можно более разнообразные задачи в обучающее множество. Две картинки сверху демонстрируют FLAN- и T0- подходы по созданию датасета, а картинка снизу — рост усреднённого качества модели после обучения на смеси. Таким образом с некоторого размера модели наблюдается повышение метрик качества при дальнейших дообучениях генерализованной модели на отложенных задачах. Предыдущий подход со смесью датасетов помогает решать многие задачи в среднем заметно лучше. Однако есть задачи, где качество результатов модели всё ещё низкое. Например, предложить эффективный код, решающий некую алгоритмическую задачу, найти минимум некоторой аналитической функции потерь, посчитать производную фукнции в точке и так далее. Такие вопросы требуют рассуждения, которое модель не может просто так провести из-за своей архитектуры. Выход — составить подводки в стилеChain-of-Thought (CoT): CoT-подводка состоит из трёх обязательных элементов: Формулировки задачи на естественном языке. Подробного пошагового решения. Ответа на задачу. Формирование такого промта, особенно наfew-shot, заставляет модель рассуждать, как можно правильно решить задачу. Авторыэтой статьисравнили на двух математических бенчмарках способность модели решать сложные задачи. MultiArith — проверяет умение решать простые арифметически задачки. GSM8K — более сложные. Результаты демонстрируют, что наличиеCoTв подводке увеличивает способность решать математические задачки у больших языковых моделей."
            }
        ]
    },
    {
        "id": "q_0290",
        "question": "Какие четыре этапа обучения включает процесс создания инструкционной модели?",
        "answers": [
            "Процесс включает: 1) подготовку качественного претрейна для накопления знаний, 2) SFT (supervised finetuning) для обучения следованию инструкциям, 3) обучение reward-модели для оценки качества ответов, 4) этап Reinforcement Learning для генерации ответов с наивысшей оценкой."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Наконец, обсудив, как готовить обучающие данные, перейдем к прародителю ChatGPT. Инструкционная модель — это та, которая обучена отвечать на пользовательские запросы в режимеzero-shot(а вообще, иfew-shot, и любой человекочитаемый формат) с высоким качеством. InstructGPT — это модель, и она интересна с точки зрения выработки концепции обучения всех инструкционных моделей (InstructGPT, ChatGPT, GPT-4 и других). С некоторыми нюансами обучение состоит из четырех этапов: Подготовка качественного претрейна. Языковая модель должна содержать в себе как можно больше знаний о мире, чтобы иметь возможность в последующем решать произвольные задачи с высоким качеством. На этом этапе необходимо озаботиться наибольшим разнообразием, чистотой и полнотой обучающих данных. Подробнее об этом мы поговорим в последнем разделе этого параграфа. SFT (supervised finetuning) — обучение модели следовать инструкциям. Этот пункт мы подробно обсудили в предыдущей части параграфа (T0, FLAN, CoT). На этом этапе важно составить грамотный инструкционный датасет, где инструкция содержит произвольные запросы к модели, а ответ на неё — подробный текст, которым будущий пользователь будет доволен. Грамотный сбор таких данных довольно дорогостоящий процесс, но от него напрямую зависит, каким образом модель будет взаимодействовать с пользователем. Обучение reward-модели. Каждый ответ алгоритма можно оценить с точки зрения вежливости, подробности или персонажности. Персонажность позволяет модели считать себя, например, капитаном Джеком Воробьем и общаться на пиратском говоре. Также есть менее формализуемые критерии качества ответов, их даже сложно описать словами. Например, что в основном людям ответ 1 нравится больше чем ответ 2.Reward-модель агрегирует эти кртитерии в число — меру качества. Чем оно выше, тем качественнее ответ модели. Для выравнивания поведения модели обычно важно уметь оценивать тысячи текстов, а вручную это делать дорого и долго, поэтому обучается специальная модель-оценщик. Про то, как обучать reward-модель, будет рассказано далее. Этап Reinforcement Learning (RL). На нём языковая модель обучается генерировать такие ответы, которые имели бы наивысшую оценку относительно reward-модели. Про то, как делать RL, будет рассказано далее."
            }
        ]
    },
    {
        "id": "q_0291",
        "question": "Какие основные отличия от Instruct GPT были реализованы в одной из самых нашумевших языковых моделей?",
        "answers": [
            "Основные отличия включают диалоговость, позволяющую модели работать с диалогами и помнить их контекст, а также увеличение размера и качества инструкционного датасета с большим вниманием к разметке, обучению reward-модели и этапу с RL."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Одна из самых нашумевших языковых моделей в мире наследует логику обучения Instruct GPT. Основные отличия от последней заключаются в: Диалоговости. Модель обучена работать с диалогами, держать их в контексте и помнить историю того, что требовал пользователь. Обучение производится посредством сбора/написания диалоговых данных. Размере и качестве инструкционного датасета. Том, что больше внимания уделено разметке и обучению reward-модели и этапу с RL. К сожалению, OpenAI не предоставили детали обучения ChatGPT, а предложили лишь общий ход действий. Также неизвестны архитектурные параметры модели."
            }
        ]
    },
    {
        "id": "q_0292",
        "question": "Какие архитектурные изменения отличают модель LLaMA от базовой архитектуры трансформеров?",
        "answers": [
            "LLaMA-модели используют Pre-нормализацию, RMSNorm вместо LayerNorm, SwiGLU-активацию вместо ReLU и роторные эмбединги для позиционного кодирования, которые вычисляются на каждом слое при подсчёте Attention."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Обсудим детально на примере доступных в open-source моделей семейства LLaMA. В качестве примера возьмём самую свежую архитектуру трансформеров на первую половину 2023 года —LLaMa, а также способы превращать её в чатовую модель, проводить Alignment на примереLLaMa-2. Вторая модель архитектурно не отличается от первой (кроме увеличенного контекста до 4096 токенов), поэтому содержание статей можно объединить в один рассказ. Для обучения с нуля качественной языковой модели необходимы: мощный кластер на сотни видеокарт, на котором можно производить параллельное обучение модели. Больше GPU — больше модель можно обучить и быстрее по времени обучения; терабайты текстовых данных для тренировки на них; архитектура, которая лучшим образом может моделировать язык. Поговорим подробнее о двух последних пунктах. Текстовые данные Текстовые данные можно брать из открытых источников, таких как CommonCrawl, C4, Taiga и прочее. Важно обеспечить: чистоту данных — например, убрать html-тэги, устранить дублирование текстов; полноту — чтобы модель одинаково хорошо решала математические задачи, писала код или сочиняла стихотворения, текстов соответствующих доменов должно быть в достатке в обучающем корпусе; разнообразие данных. Существуют эмпирические законы обученности модели, но здесь остановимся на числе пройденных за обучение токенов. В LLaMa-моделях это значение варьируется от 1T до 2Т. Ниже приведены основные параметры по числу размерности внутренних эмбедингов, числу голов Attention, слоёв и параметров обучения разных моделей: Архитектура У LLaMa-моделей предлагается целый ряд архитектурных изменений. Так как в учебнике рассматривался лишь базовая архитектура трансформеров, то опишем, что в ней необходимо изменить, чтобы получить LLaMa-модель. Pre-нормализация. ПустьТогда нелинейное преобразование в общем виде выглядит так: И LayerNorm можно описать следующими формулами: В свою очередь экспериментально RMSNorm демонстрирует лучшие результаты в сравнении с LayerNorm и высчитывается так: SwiGLU-активация используется вместо ReLU.— значок поэлементного умножения матриц. Роторные эмбединги. Информацию о том, в каком порядке следуют токены внутри модели, хранят в себе позиционные эмбединги. Они могут быть абсолютными (кодирование синусами и косинусами, как описано в параграфе отрансформерах) или относительными (кодируется расстояние между каждой парой токенов).Роторные эмбединги позволяют вычислять относительную связь между парой токенов на этапе вычисления Attention, также они выигрывают по сравнению с относительными в совместимости kernel-ов. То есть, одно из понятных не технических отличий их от других — вычисление позиционной информации на каждом слое модели при подсчёте Attention, а не только перед первым слоем. Это позволяет на каждом слое явно обрабатывать информацию об относительном расположении токенов. Роторные эмбединги показывают лучшее качество на многих задачах и являются стандартом для обучения языковых моделей. Подробнее о них можно почитать вэтой статье. Существуют также техники ускорения обучения моделей и оптимизации использования памяти, но с этим предлагаем читателям ознакомиться самостоятельно. Второй этап обучения инструкционных языковых моделей требует множество инструкций. Рецепт как их готовить был подробно описан всередине этого параграфа. Снова проговорим, что для написания инструкций или сбора датасета необходимо, чтобы инструкции были: разнообразными; качественными; имели одинаковый формат, чтобы чатовая модель могла обучиться диалоговости (где вопрос пользователя, где ее ответ); информативными; подробными; Chain-of-Thought (CoT),few-shotи так далее. Третий этап в создании инструкционных моделей. Есть несколько способов собрать датасет для обучения reward-модели. Он должен содержать тексты и метки к ним. Если меток много (например, в случае балльной оценки), можно использовать разновидностиранжирующих лоссов.Разберем способ обучения модели на бинарную оценку. Пусть модели подается на вход инструкция. Поменяв температуру, способ сэмплирования или использовав разные чек-пойнты модели, возможно получить два разнообразных ответаи. Не ограничивая общность, предположим, что, согласно некоторым предпочтениям, асессоры или пользователи установили, что первый ответ лучше второго. Проделаем эту операцию много раз и получим обучающее множество, состоящее из. Тогда reward-модель можно обучать минимизацией следующей функции потерь: Где: — reward-модель с обучаемыми параметрами тета; — некий margin, который определяет, насколько сильно модель должна отделять хороший и плохой ответы друг от друга. На четвёртом этапе, этапе выравнивания модели, можно воспользоваться разными алгоритмами. LLaMa-2 Chat была обучена последовательно сначала на Rejection Sampling fine-tuning (RL «для бедных») и Proximal Policy Optimization (PPO). Rejection Sampling fine-tuning. Этот подход основан на довольно простой стратегии. Пусть имеется инструкция. Сгенерируем для неёответов и выберем тот, который получает наивысшую оценку у reward-модели. График ниже демонстрирует, что чем больше, тем больше reward-score у лучшего ответа. Собрав парыинструкция — лучший ответ, можно обучить на них языковую модель и провести таким образом выравнивание поведения модели. Proximal Policy Optimization. Для лучшего понимания происходящего советуем прочесть параграф, посвященныйRL. Основная задача, как обычно, следовать некой политике, которая лучшим образом отражает human feedback. Политика — наша итоговая модель, value-функция оценивает средний reward в текущем состоянии (обычно это та же самая модель с линейным слоем поверх). Формализуем термины из RL для задачи выравнивания языковой модели: Политика— обучаемая языковая модель. Value-функция— обычно та же самая модель с линейным слоем поверх, оценивает средний reward, если действовать из состояниясогласно политике. — состояние в момент времени. Это весь контекст-токенов, которые модель успела сгенерировать к текущему моменту. — действие из текущего состояния в момент времени. Обозначает следующий токен, который будет сгенерирован. — траектория, т. е. тройки, — это состояния генерируемого токена и награды за него Сразу можно сделать вывод, что в языковых моделях, Также, в RL символомобозначается вся последовательность токенов, то есть на практике сюда можно подставлять количество сгенерированных токенов. Инициализируем— начальные веса политики и value-функции Для Соберем коллекцию траекторий, следуя политике. Посчитаем. Эта формула отражает разницу между финальной наградой за выбранное действиев текущем состояниии средней финальной наградой, которую можно было бы получить в этом состоянии. Вообще говоря, с помощью метода Generalized Advantage Estimation (GAE) её можно аппроксимировать следующим выражением: Обновляем веса политики согласно одному из лоссов PPO. Например, используем такой: С помощью MSE лосса оптимизируем значение value-функции:"
            }
        ]
    },
    {
        "id": "q_0293",
        "question": "Какие темы были рассмотрены в ходе обсуждения?",
        "answers": [
            "В ходе обсуждения были рассмотрены развитие языковых моделей, необходимые приёмы и техники для обучения инструкционных моделей, а также на примере архитектуры LLaMa разобрано, как самостоятельно обучить языковые модели с нуля."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
                "text": "Мы с вами обсудили, как развивались языковые модели, какие приёмы и техники необходимы для успешного обучения инструкционных моделей. Также на примере архитектуры LLaMa разобрали, как самостоятельно обучить языковые модели с нуля."
            }
        ]
    },
    {
        "id": "q_0294",
        "question": "Какие три способа восприятия формулы Composite Objective FTRL Online Mirror Descent, Proximal Gradient Descent, (F)ISTA упоминаются в тексте?",
        "answers": [
            "Online Mirror Descent рассматривается как метод онлайн-обучения, Proximal Gradient Descent — как метод (стохастической) батч-оптимизации, а (F)ISTA — как название аналитического решения уравнения для L1-регуляризации."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii",
                "text": "Вспомним вывод linearized FTRL. В ходе линеаризации мы заменяли все функциина их субградиентную оценку в точке. Для регуляризованного функционалаполучалась бы такая оценка: где черезмы обозначили для краткости субградиентв точке. Теперь субградиентную оценку можно подставить в метод FTRL: Идея неразложения состоит в следующем: заменим на субградиентную оценку только, а регуляризатор будем подбирать так, чтобы задача FTRL решалась аналитически. Интуитивно, оценка должна быть точнее оценки а значит, и метод оптимизации будет точнее и эффективнее. Эта идея очень важна для построения регуляризованных алгоритмов онлайн-обучения. Давайте выпишем, как будут выглядеть с учётом этой идеи регуляризованные алгоритмы. Composite Objective FTRL Online Mirror Descent, Proximal Gradient Descent, (F)ISTA Напомним, что три названия в заголовке соответствуют трём способам восприятия этой формулы: Online Mirror Descent — метод онлайн-обучения; Proximal Gradient Descent — метод (стохастической) батч-оптимизации. В стохастическом случае он неотличим от Mirror Descent; (F)ISTA — по сути, это название аналитического решения указанного уравнения для-регуляризации. В этом подразделе мы будем проводить рассуждения на примере-регуляритора. для других регуляризаторов выкладки будут аналогичными. Выпишем Proximal (он же Mirror) Gradient Descent с-регуляризацией: Необходимым условием минимума явняется равенство нулю градиента (а в данном случае субградиента) всего выражения: где- субградиент регуляризаторав точке. Отсюда получаем Если же переписать формулы в духе FTRL, мы получим Получился метод, который оптимизирует-регуляризатор в явном виде только на текущей итерации, а для остальных использует субоптимальные субградиентные оценки. Заметим, что тем же выражением можно ограничить сверху и функционал: Мы получили метод FTRL с incremental— более сильным и стабильным вариантом регуляризации, чем Mirror Descent. Подробнее его анализом мы займемся в параграфе про продвинутую-регуляризацию."
            }
        ]
    },
    {
        "id": "q_0295",
        "question": "Какие две проблемы возникают при замене градиентной оценки всей функции с регуляризатором в адаптивных методах оптимизации?",
        "answers": [
            "Во-первых, коэффициенты learning rate и регуляризации нетривиально взаимодействуют, что требует перебора гиперпараметров по полной сетке при изменении learning rate. Во-вторых, в квадратах градиентов появляется добавка, хотя там должна отражаться только адаптивность к кривизне самой функции."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii",
                "text": "Рассмотрим обыкновенный SGD. Weight decayсостоит во введение штрафа на размер текущих весов: Внимательные читатели уже заметили, что в случае с SGD это эквивалентно введению-регуляризации. Давайте разберёмся, как это сделать правильно. Попробуем заменитьна и запустить любой адаптивный метод, например, AdaGrad. Если мы беспечно заменим на градиентную оценку всю функцию(забыв, что с регуляризатором этого делать не стоит), то алгоритм примет вид где В этих формулах нехороши две вещи: Коэффициентыинетривиальным образом взаимодействуют. Это крайне неудобно при переборе гиперпараметров: изменение learning rateдолжно влечь за собой переподбор коэффициента регуляризациипо полной сетке; В квадратах градиентов мы хотим видеть только адаптивность к кривизне самой функции, но теперь там ещё добавка. Эта проблема была впервые замечена вDecoupled weight decay regularization. Авторы также рассматривали влияние на momentum, к этому мы вернёмся в параграфе про AdamW. Авторы статьи предлагают модифицировать метод AdaGrad следующим образом: Сразу отметим сходство с исходными формулами weight decay — его и добивались авторы. Легко видеть, что формула описывает обыкновенный покоординатный градиентный спуск с некоторым линеаризованным-регуляризатором. Давайте «проинтегрируем» это выражение обратно до аргминимума, из которого бы получились такие формулы обновления весов: Получается, что decoupled weight decay — это адаптивный-centered регуляризатор. Его можно усовершенствовать, вспомним наше важное правило не заменять регуляризатор на субградиентную оценку. Перейдём к задаче Она отличается от предыдущей заменойна. Её решение имеет вид Поскольку мы меньше огрубляем оптимизируемый функционал, обучение может стать немного стабильнее. Обратите внимание, что в оптимизационной задаче у нас теперь стоит не просто, а. Теперь посмотрим, как decoupled weight decay будте работать с Composite-Objective FTRL. Линеаризованная задача имеет вид: Перепишем её: Нетрудно показать, что решение имеет вид Дляможно написать и явную формулу:. Замечание. Чтобы оценить Regret такого метода, мы не сможем механически воспользоваться оценкой для AdaGrad: ведь она базированась на оценке на Regret, выведенной либо для целиком Proximal, либо для целиком Centered-регуляризаторов. Composite objective из теоремы 10 тут не годится, так как Centered регуляризатор в этом случае не поедет в оценку норм градиентов, а мы в текущем представлении рассматриваем Proximal и Centered как равноправные члены. Интуитивно, мы должны применить Lemma 7 к обоим регуляризаторам и получить точно такую же оценку с такой же двойственной нормой (напомним, что centered и proximal регуляризаторы имеют одинаковую двойственную норму). Двойственная норма такая же ->формулы оптимального метода AdaGrad будут такие же. Мы оставляем это читателям в качестве упражнения."
            }
        ]
    },
    {
        "id": "q_0296",
        "question": "Какой метод предлагается использовать для решения задачи проекции на шар после выноса из оптимизируемого функционала и превращения его в ограничение?",
        "answers": [
            "Для решения этой задачи предлагается применить метод множителей Лагранжа."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii",
                "text": "Напоминание: множествоназываетсявыпуклым, если Проекцией на это множество называют функцию Докажем, что— выпуклый регуляризатор. Для этого нам нужно проверить неравенство Единственный шанс, когда это может быть нарушено — это,,. Это значит, что, а, что противоречит выпуклости. Вернемся к формулам FTRL. Здесь ситуация сильно проще — от накидывания любых последовательностейна регуляризатор ничего не изменится, так что его всегда оставляют просто as is Аналитические решения для каждого виданужно искать отдельно. Примерно все решения получаются путем выносаиз оптимизируемого функционала и превращения его в ограничение, после чего можно применить метод множителей Лагранжа. Решим аналитически задачу проекции на шар Функция Лагранжа будет иметь вид а её градиент равен где- вектор, а— поэлементное умножение векторов. Приравнивая к нулю градиент, получаем где мы, как обычно, обозначили. Проанализируем условие дополняющей нежесткости. Если, то решениеуже находится внутри шара и имеет вид При практической реализации мы просто сначала посчитаем это выражение и проверим, не попадаем ли мы в шар. Если попадаем — отлично, если нет — то дальше говорим, чтои решаем продолжаем решение Теперь подставим это ви получим Получаем, что если мы находимся внутри шара, то мы действуем согласно обыкновенному adaptive алгоритму со всеми хорошими свойствами, иначе — проекция побеждает. Аналогичнорегуляризации, здесь тоже есть различия между lazy и greedy представлением этого регуляризатора. Однако, в классических DL задачах эти методы встречаются не слишком часто и здесь сложно привести какой-нибудь значимый успех, который мог бы улучшить качество в важной задача. Навскидку мы можем вспомнить разве что Adversatial White-Box learning, в котором можно было бы это попробовать."
            }
        ]
    },
    {
        "id": "q_0297",
        "question": "Какая функция потерь подходит для обучения регрессии на данных с большим количеством выбросов в целевой переменной и почему?",
        "answers": [
            "Для данных с большим количеством выбросов в таргете уместно использовать MAE (Mean Absolute Error), так как она считает модуль расстояния, а не квадрат, что уменьшает вклад больших ошибок по сравнению с MSE. Это происходит потому, что MAE приближает медиану условного распределения, а не матожидание."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
                "text": "Стохастический градиентный спуск можно очевидным образом обобщить для решения задачи линейной регрессии с любой другой функцией потерь, не только квадратичной: ведь всё, что нам нужно от неё, – это чтобы у функции потерь был градиент. На практике это делают редко, но тем не менее рассмотрим ещё пару вариантов. Mean absolute error, абсолютная ошибка, появляется при замененормы в MSE на: Можно заметить, что в MAE по сравнению с MSE существенно меньший вклад в ошибку будут вносить примеры, сильно удалённые от ответов модели. Дело тут в том, что в MAE мы считаем модуль расстояния, а не квадрат, соответственно, вклад больших ошибок в MSE получается существенно больше. Такая функция потерь уместна в случаях, когда вы пытаетесь обучить регрессию на данных с большим количеством выбросов в таргете. Иначе на эту разницу можно посмотреть так: MSE приближает матожидание условного распределения, а MAE – медиану. Mean absolute percentage error, относительная ошибка. Часто используется в задачах прогнозирования (например, погоды, загруженности дорог, кассовых сборов фильмов, цен), когда ответы могут быть различными по порядку величины, и при этом мы бы хотели верно угадать порядок, то есть мы не хотим штрафовать модель за предсказание 2000 вместо 1000 в разы сильней, чем за предсказание 2 вместо 1. Вопрос на подумать. Кроме описанных выше в задаче линейной регрессии можно использовать и другие функции потерь, например,Huber loss: Числоявляется гиперпараметром. Сложная формула принужна, чтобы функциябыла непрерывной. Попробуйте объяснить, зачем может быть нужна такая функция потерь."
            }
        ]
    },
    {
        "id": "q_0298",
        "question": "Какие два основных способа сведения задачи многоклассовой классификации к набору бинарных классификаций рассматриваются в контексте линейных моделей?",
        "answers": [
            "Рассматриваются два способа: one-vs-all (один против всех) и all-vs-all (все против всех). В первом случае для каждого класса обучается классификатор, отличающий его от всех остальных классов. Во втором случае для каждой пары классов обучается отдельный классификатор."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
                "text": "В этом разделе мы будем следовать изложениюиз лекций Евгения Соколова. Пусть каждый объект нашей выборки относится к одному изклассов:. Чтобы предсказывать эти классы с помощью линейных моделей, нам придётся свести задачу многоклассовой классификации к набору бинарных, которые мы уже хорошо умеем решать. Мы разберём два самых популярных способа это сделать – one-vs-all и all-vs-all, а проиллюстрировать их нам поможет вот такой игрушечный датасет Обучимлинейных классификаторов, выдающих оценки принадлежности классамсоответственно. В случае с линейными моделями эти классификаторы будут иметь вид Классификатор с номеромбудем обучать по выборке; иными словами, мы учим классификатор отличать-й класс от всех остальных. Логично, чтобы итоговый классификатор выдавал класс, соответствующий самому уверенному из бинарных алгоритмов. Уверенность можно в каком-то смысле измерить с помощью значений линейных функций: Давайте посмотрим, что даст этот подход применительно к нашему датасету. Обучим три линейных модели, отличающих один класс от остальных: Теперь сравним значения линейных функций и для каждой точки выберем тот класс, которому соответствует большее значение, то есть самый «уверенный» классификатор: Хочется сказать, что самый маленький класс «обидели». Проблема данного подхода заключается в том, что каждый из классификаторовобучается на своей выборке, и значения линейных функцийили, проще говоря, \"выходы\" классификаторов могут иметь разные масштабы. Из-за этого сравнивать их будет неправильно. Нормировать вектора весов, чтобы они выдавали ответы в одной и той же шкале, не всегда может быть разумным решением: так, в случае с SVM веса перестанут являться решением задачи, поскольку нормировка изменит норму весов. Обучимклассификаторов,,. Например, в случае с линейными моделями эти модели будут иметь вид Классификаторбудем настраивать по подвыборке, содержащей только объекты классови. Соответственно, классификаторбудет выдавать для любого объекта либо класс, либо класс. Проиллюстрируем это для нашей выборки: Чтобы классифицировать новый объект, подадим его на вход каждого из построенных бинарных классификаторов. Каждый из них проголосует за свой класс; в качестве ответа выберем тот класс, за который наберется больше всего голосов: Для нашего датасета получается следующая картинка: Обратите внимание на серый треугольник на стыке областей. Это точки, для которых голоса разделились (в данном случае каждый классификатор выдал какой-то свой класс, то есть у каждого класса было по одному голосу). Для этих точек нет явного способа выдать обоснованное предсказание. Некоторые методы бинарной классификации можно напрямую обобщить на случай многих классов. Выясним, как это можно проделать с логистической регрессией. В логистической регрессии для двух классов мы строили линейную модель а затем переводили её прогноз в вероятность с помощью сигмоидной функции. Допустим, что мы теперь решаем многоклассовую задачу и построилилинейных моделей каждая из которых даёт оценку принадлежности объекта одному из классов. Как преобразовать вектор оценокв вероятности? Для этого можно воспользоваться оператором, который производит «нормировку» вектора: В этом случае вероятность-го класса будет выражаться как Обучать эти веса предлагается с помощью метода максимального правдоподобия: так же, как и в случае с двухклассовой логистической регрессией:"
            }
        ]
    },
    {
        "id": "q_0299",
        "question": "Какие методы позволяют работать с данными, имеющими огромную размерность признаков, но малое количество ненулевых элементов?",
        "answers": [
            "Для таких данных можно использовать разреженное кодирование, при котором вместо плотного вектора хранится словарь с индексами и значениями ненулевых элементов. Также можно применять hashing trick, где веса хранятся в хэш-таблице, а индекс вычисляется по формуле hash(feature) % tablesize, что позволяет нескольким фичам иметь общий вес."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
                "text": "Мы уже обсуждали, что SGD позволяет обучению хорошо масштабироваться по числу объектов, так как мы можем не загружать их целиком в оперативную память. А что делать, если признаков очень много, или мы не знаем заранее, сколько их будет? Такое может быть актуально, например, в следующих ситуациях: Классификация текстов: мы можем представить текст в формате «мешка слов», то есть неупорядоченного набора слов, встретившихся в данном тексте, и обучить на нём, например, определение тональности отзыва в интернете. Наличие каждого слова из языка в тексте у нас будет кодироваться отдельной фичой. Тогда размерность каждого элемента обучающей выборки будет порядка нескольких сотен тысяч. В задаче предсказания кликов по рекламе можно получить выборку любой размерности, например, так: в качестве фичи закодируем индикатор того, что пользователь X побывал на веб-странице Y. Суммарная размерность тогда будет порядка. Кроме того, всё время появляются новые пользователи и веб-страницы, так что на этапе применения нас ждут сюрпризы. Есть несколько хаков, которые позволяют бороться с такими проблемами: Несмотря на то, что полная размерность объекта в выборке огромна, количество ненулевых элементов в нём невелико. Значит, можно использовать разреженное кодирование, то есть вместо плотного вектора хранить словарь, в котором будут перечислены индексы и значения ненулевых элементов вектора. Даже хранить все веса не обязательно! Можно хранить их в хэш-таблице и вычислять индекс по формулеhash(feature) % tablesize. Хэш может вычисляться прямо от слова или id пользователя. Таким образом, несколько фичей будут иметь общий вес, который тем не менее обучится оптимальным образом. Такой подход называетсяhashing trick. Ясно, что сжатие вектора весов приводит к потерям в качестве, но, как правило, ценой совсем небольших потерь можно сжать этот вектор на много порядков. Примером открытой библиотеки, в которой реализованы эти возможности, являетсяvowpal wabbit. Если при решении задачи ставки столь высоки, что мы не можем разменивать качество на сжатие вектора весов, а признаков всё-таки очень много, то задачу можно решать распределённо, храня все признаки в шардированной хеш-таблице Кружки здесь означают отдельные сервера. Жёлтые загружают данные, а серые хранят части модели. Для обучения жёлтый кружок запрашивает у серого нужные ему для предсказания веса, считает градиент и отправляет его обратно, где тот потом применяется. Схема обладает бесконечной масштабируемостью, но задач, где это оправдано, не очень много."
            }
        ]
    },
    {
        "id": "q_0300",
        "question": "Какие три основных компонента составляют решение любой ML-задачи согласно представленному материалу?",
        "answers": [
            "Решение любой ML-задачи состоит из выбора функции потерь, параметризованного класса моделей и способа оптимизации."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
                "text": "На линейную модель можно смотреть как на однослойную нейросеть, поэтому многие методы, которые были изначально разработаны для них, сейчас переиспользуются в задачах глубокого обучения, а базовые подходы к регрессии, классификации и оптимизации вообще выглядят абсолютно так же. Так что несмотря на то, что в целом линейные модели на сегодня применяются редко, то, из чего они состоят и как строятся, знать очень и очень полезно. Надеемся также, что главным итогом прочтения этого параграфа для вас будет осознание того, что решение любой ML-задачи состоит из выбора функции потерь, параметризованного класса моделей и способа оптимизации. В следующих параграфах мы познакомимся с другими моделями и оптимизаторами, но эти базовые принципы не изменятся. Теперь предлагаем вам потренировать изученный материал на практике. Скачайтеноутбукс лабораторной работой. В нём вы найдете описания заданий и дополнительные материалы. Задания из лабораторной прикреплены к этому параграфу в виде задач в системе Яндекс Контест. Чтобы проверить себя, отправляйте решения по соответствующим задачам в систему. Успехов в практике!"
            }
        ]
    },
    {
        "id": "q_0301",
        "question": "Какие две основные стратегии обучения были предложены для Word2vec в оригинальной статье 2013 года?",
        "answers": [
            "Авторы предложили две стратегии обучения: Skip-gram и CBOW (Continuous bag-of-words). В CBOW модель предсказывает центральное слово по контексту, а в Skip-gram — контекст по центральному слову."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
                "text": "Перед тем, как рассказать об архитектурах, которые часто используются для работы с текстами, надо разобраться, каким образом можно кодировать текстовые данные: ведь нужно их превратить во что-то векторное, прежде чем подавать на вход нейросети. К векторизации текстов есть два базовых подхода: векторизовать текст целиком, превращая его в один вектор; векторизовать отдельные структурные единицы, превращая текст в последовательность векторов. Первые, статистические подходы к векторизации следовали первому подходу и рассматривали текст как неупорядоченный набор («мешок») токенов (обычно токенами являются слова). Тем самым, тексты «Я не люблю ML» и «Я люблю не ML» получали одинаковые векторизации, то есть по ходу терялась существенная информация. Поэтому мы лишь коротко упомянем о них. Обратимся теперь к другому подходу и подумаем, как сопоставить векторы (эмбеддинги) словам. Допустим, что у нас одно и то же слово будет представлено одним и тем же вектором во всех текстах и в любых позициях. Как заключить в векторе его смысл, содержающуюся в нём информацию? Ответ предвосхищает одну из основных идей обучения представлений: нужно использоватьконтекст. Если, читая книгу на иностранном языке, вы встречаете незнакомое слово, вы нередко можете угадать его значение по контексту, что оно значит. Можно сказать, что смысл слова — это те слова, которые встречаются с ним рядом. Одним из воплощений такого подхода является Word2vec. Впервые он был предложен Т.Миколовым в 2013 году встатьеEfficient Estimation of Word Representations in Vector Space. Для обучения авторы предложили две стратегии: Skip-gram и CBOW (Сontinuous bag-of-words): В архитектуре CBOW модель учится предсказывать данное (центральное) слово по контексту (например, по двум словам перед данным и двум словам после него). В архитектуре Skip-gram модель учится по слову предсказывать контекст (например, каждого из двух соседей слева и справа); Авторы предложили для каждого словаобучать два эмбеддинга:и, первое из которых используется, когдаявляется центральным, а второе — когда оно рассматривается, как часть контекста. В модели CBOW при фиксированном контекстевычисляются логиты после чего «вероятности» всевозможных словбыть центральным словом для контекставычисляются как. Модель учится с помощью SGD на кросс-энтропию полученного распределения с истинным рапределением центральных слов. В модели Skip-gram по данному центральному словудля каждой позиции контекстанезависимо предсказывается распределение вероятностей. В качестве функции потерь выступает сумма кросс-энтропий распределений слов контекста с их истинными распределениями. Размерность эмбеддинга в каждой из архитектур — это гиперпараметр и подбирается эмпирически. В оригинальнойстатьепредлагается взять размерность эмбеддинга 300. Полученные представления центральных слов могут дальше использоваться в качестве эмбеддингов слов, которые сохраняют семантическую связь слов друг с другом. Мы не будем здесь останавливаться подробно на деталях работы Word2vec и его современных модификациях и предложим читателю обратиться к соответствующей лекции вучебникеЛены Войта по NLP. А мы лишь продемонстрируем, что он работает. Примеры. Возьмём несколько слов и посмотрим, как выглядят топ-10 слов, ближайших к ним в пространстве эмбеддингов (обученных на одном из датасетов Quora Questions с помощью word2vec): quantum: electrodynamics, computation, relativity, theory, equations, theoretical, particle, mathematical, mechanics, physics; personality: personalities, traits, character, persona, temperament, demeanor, narcissistic, trait, antisocial, charisma; triangle: triangles, equilateral, isosceles, rectangle, circle, choke (догадаетесь, почему?), quadrilateral, hypotenuse, bordered, polygon; art: arts, museum, paintings, painting, gallery, sculpture, photography, contemporary, exhibition, artist. Вопрос на подумать. В реальных текстах наверняка будут опечатки, странные слова и другие подобные неприятности. Word2vec же учится для фиксированного словаря. Что делать, если на этапе применения вам попадается неизвестное слово? Да и вообще, хорошо ли учить вложения для редких слов или слов с нетривиальными опечатками, которые, может быть, только раз встретятся в тексте? Вопрос на подумать. В некоторых случаях всё же полезно уметь строить эмбеддинги не отдельных слов, а текстов (например, для поиска похожих документов). Можете ли вы, вдохновившись идеей word2vec, придумать более тонкий способ сделать это, чем BoW или TF-IDF?"
            }
        ]
    },
    {
        "id": "q_0302",
        "question": "Какой подход используется для борьбы с накоплением ошибок при обучении модели энкодер-декодер?",
        "answers": [
            "Для борьбы с накоплением ошибок используется метод teacher forcing, при котором на этапе обучения на вход декодера подаётся не предсказанный на предыдущем этапе токен, а истинный токен из обучающей выборки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
                "text": "Вы, должно быть обратили внимание, что мы пока не касались задач, связанных с порождением последовательностей (синхронизованный варианты many-to-many не в счёт). Действительно: имевшиеся у нас пока инструменты не позволяли генерировать последовательности произвольной длины. Но как тогда переводить с одного языка на другой? Ведь мы не знаем, какой должна быть длина перевода фразы, да и однозначного соответствия между словами исходного предложения и его перевода обычно нет. Естественным решением для задачи sequence-to-sequence (seq2seq) является использование архитектурыэнкодер-декодер, состоящей из кодировщика (энкодера) для кодирования информации об исходной последовательности вконтекстном векторе(context vector) и декодировщика (декодера) для превращения закодированной энкодером информации в новую последовательность. Очевидным выбором на роль энкодера и декодера являются рекуррентные сети, например, LSTM. Простейшая архитектура будет иметь вид: Рассмотрим подробнее энкодер и декодер. Энкодер читает входное предложение токен за токеном и обрабатывает их с помощью блоков рекуррентной сети. Hidden state последнего блока становится контекстным вектором. Часто энкодер читает предложение в обратном порядке. Это делается для того, чтобы последний токен, который видит энкодер, совпал (или примерно совпал) с первыми токенами, которые будет генерировать декодер. Таким образом, декодеру проще начать процесс воссоздания предложения. Несколько первых правильных токенов сильно упрощают процесс дальнейшей генерации. Архитектура декодера аналогична энкодеру. При этом каждый блок декодера должен учитывать токены, сгенерированные к текущему моменту, и также информацию о предложении на исходном языке. Вектор скрытого состояния в нулевом блоке декодера () инициализируется с помощью контекстного вектора. Таким образом, декодер получит сжатое представление исходного предложения. Предложение генерируется следующим образом: в первый блок подаем метку начала последовательности (например, -токен, begin of sentence), на выходе первого блока получаем первый токен новой последовательности, и затем подаем его на вход следующего блока декодера. Повторяем аналогичную процедуру до тех пор, пока не сгенерируется метка конца последовательности (например, , end of sentence) или не будет достигнута максимально возможная длина предложения. Таким образом, декодер работает в режиме языковой модели, генерируя предложение токен за токеном и учитывая предыдущий контекст. Разумеется, энкодер может быть и более сложным. Например, можно использовать многослойную двунаправленную сеть, лишь бы выходом её был один вектор контекста. С декодером сложнее: он должен порождать слова по одному, в одном направлении. Далее мы очень коротко остановимся на нетривиальных моментах обучения и применения такой модели. В предыдущих разделах мы не останавливались подробно на том, что происходит с выходами, но сейчас всё-таки попробуем разобраться. Если мы решаем задачу машинного перевода, то на очередном этапе декодер выдаёт нам условное распределение на словах (или каких-то subword unit, например, BPE), из которого мы будем выбирать самое вероятное словои подавать его на вход следующего блока. Но эта, жадная, стратегия может и подвести. Легко представить себе ситуацию, в которой самое вероятное на данный момент слово приведёт дальше к менее вероятной подпоследовательности: Чтобы справиться с этим, на этапе применения модели используютbeam search. В каждый момент времени мы поддерживаем некоторое количествосамых вероятных гипотез, на-м шаге пытаясь продолжать все сохранённые, а из продолжений выбирая топ-по метрике Числонет смысла делать большим (это и вычислительно будет тяжко, и может привести к более плохим результатам), можете брать в пределах. Как уже было сказано выше, на каждом шаге декодер предсказывает распределение вероятностей. Вся модель учится на сумму по всемкросс-энтропиям этих распределений с истинными. Одна из сложностей такого обучения состоит в том, что единожды ошибившись и предсказав неправильныйвместо истинного, модель скорее всего и следующие токены предскажет неверно, а это сделает всё дальнейшее обучение малополезным: ведь мы будем учить декодер предсказывать правильное продолжение неправильного начала. Одним из способов борьбы с этим являетсяteacher forcing. Суть его в том, что на этапе обучения мы подаём на вход декодера не предсказанный им на предыдущем этапе токен, а истинный: У нас остался лишь один неразобранный тип задач: one-to-many. К счастью, чтобы с ним справиться, ничего нового не нужно: достаточно уже знакомой модели энкодер-декодер, лишь с корректировкой энкодера. Рассмотрим для примера задачу генерации подписей к изображениям (image captioning). Если мы уже умеем как-то превращать картинки в векторы, то эти векторы мы можем напрямую подавать в декодер в качестве векторов контекста: Более подробно о том, как строить векторизации для изображений, вы узнаете в параграфе прообучение представлений. А если у вас есть все данные мира, то вы можете в качестве энкодера взять свёрточную нейросеть и обучать её вместе с декодером end-to-end:"
            }
        ]
    },
    {
        "id": "q_0303",
        "question": "Какой механизм позволяет декодеру в seq2seq модели получать информацию о важности всех токенов входного предложения на каждом шаге генерации?",
        "answers": [
            "Это механизм внимания (attention), который предоставляет декодеру информацию обо всех токенах исходного предложения на каждом шаге генерации, вычисляя веса важности для каждого токена."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
                "text": "Как человек переводит предложения с одного языка на другой? Обычно переводчик уделяет особое внимание слову, которое записывает в данный момент. Хочется сообщить аналогичную интуицию нейронным сетям. Рассмотрим, как можно реализовать такой механизм на примере машинного перевода. Внимательно посмотрим на seq2seq модель для машинного перевода. Вся информация о предложении на исходном языке заключена в контекстном векторе, но разные слова в предложении могут иметь разную смысловую значимость и следовательно, должны учитываться с разными весами. Кроме того, при генерации разных частей перевода следует обращать внимание на разные части исходного предложения. Например, первое слово переведенной фразы нередко связано с первыми словами в предложении, поданном на вход энкодеру, а порой одно слово перевода передаёт смысл нескольких слов, разбросанных по исходному предложению (вдруг кто-нибудь сталкивался с отделяемыми приставками в немецком?). Механизм внимания(attention) реализует эту интуицию путем предоставления декодеру информации обо всех токенах исходного предложения на каждом шаге генерации. Рассмотрим классическую модель внимания, предложенную Bahdanau et al. в 2014 году. Обозначим скрытые состояния энкодера, а скрытые состояния декодера. Важно отметить, что, это контекстный вектор. На каждом шаге декодера будем считатьattention scores, умножаяна вектор скрытого состояния каждого блока энкодера. Таким образом, получаемзначений, указывающих, насколько каждый из токенов c номерамииз исходного предложения важен для генерации токенаиз перевода: (здесьи, как обычно, являются строками, так что— скаляр). Теперь превращаем эти значения в attention distribution, применив к ним softmax: Используемв качестве весов для нахождения окончательного вектора внимания: Теперь в декодере на шаге i вместо вектора скрытого состояниябудем использовать вектор-- конкатенацию скрытого состояния блока и соответствующего attention вектора. Таким образом, на каждом шаге декодер получает информацию о важности всех токенов входного предложения. Данная схема вычисления attention представлена на следующем рисунке. Существует много разных видов механизмов внимания, например: Базовый dot-product, рассмотренный ранее: Мультипликативный:, где— обучаемая матрица весов. MLP:, где,— обучаемые матрицы весов,— обучаемый вектор весов Важной особенностью механизма внимания является то, что его веса несут в себе информацию о связях слов в двух языках, участвующих в переводе. Визуализировав веса механизма внимания, получаем таблицу взаимосвязей между словами: Весьма логично, что словоdogsтеснее всего связано со словомсобак, а словуоченьсоответствуют целых два слова:veryиmuch."
            }
        ]
    },
    {
        "id": "q_0304",
        "question": "Какой процесс позволяет привести разные грамматические формы слова к его начальной форме с использованием морфологического анализа?",
        "answers": [
            "Этот процесс называется лемматизацией. Лемматизация — это алгоритм приведения слова к его начальной форме с использованием морфологического анализа и знаний об особенностях конкретного языка."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
                "text": "Перед тем, как применять описанные выше архитектуры (или даже использовать простые подходы, вроде TF-IDF или word2vec), нужно разобраться, как делать предобработку текстов. Первым делом надо научиться представлять связный текст в виде последовательности. Для начала имеет смысл разбить текст на предложения, а дальше уже на слова или символьные n-граммы. Этот процесс называется токенизацией. Можно делать токенизацию вручную, например, с помощью регулярных выражений, или воспользоваться готовыми методами из библиотеки NLTK. Представим, что мы получили упорядоченный список слов, из которых состоит текст. Но это еще не все. Обычно тексты содержат разные грамматические формы одного и того же слова. Привести все словоформы к начальной форме можно с помощью лемматизации. Лемматизация - это алгоритм приведения слова к его начальной форме с использованием морфологическего анализа и знаний об особенностях конкретного языка. Пример работы лемматизатора:«собаки, собака, с собакой, собаками ->собака» Другой способ приведения всех словоформ к одной форме - это стемминг. Стемминг — это более грубый процесс на основе эвристик, который действует без знания контекста, словарей и морфологии. Стеммер не поймет, что слова с чередованием имеют один и тот же корень (только если прописать в явном виде такую эвристику) или что слова «есть», «буду» и «был» - это формы глагола «быть». Стемминг - менее аккуратный процесс по сравнению с лемматизацией, зато гораздо более быстрый. Еще один важный этап предобработки текстов - это удаление стоп-слов. Стоп-словами называют междометия, союзы, предлоги, артикли, в общем все слова, которые будут вносить шум в работу алгоритма машинного обучения. Иногда дополнительно убирают слова общей лексики, оставляя только специфические термины. Универсального списка слов не существует, но для начала можно использовать список стоп-слов из библиотеки NLTK. Аугментации данных часто используются, чтобы увеличить количество данных в обучающей выборке, а также повысить обобщаемость модели. И если для компьютерного зрения аугментации относительно простые и могут выполняться на лету (масштабирование, обрезка, вращение, добавление шума и т.д.), то для текстов в виду грамматической структуры, синтаксиса и особенностей языка все не так просто. Аугментации текста менее «автоматические», в идеале нужно понимать смысл фразы и иметь под рукой отлично работающий механизм перефразирования. Рассмотрим несколько популярных способов аугментации текстовых данных: Обратный перевод. Переводим исходный текст на какой-то язык, и затем переводим его обратно. Это помогает сохранить контекст, но при этом получить синонимичную формулировку. Замены слова на синонимичное/близкое по смыслу. Для этого можно использовать словари синонимов либо искать близкое слово в пространстве эмбеддингов, минимизируя расстояние между соответствующими векторами. В качестве таких эмбеддингов можно взять привычный word2vec,fasttextили контекстуализированные эмбеддинги на основе претренированных моделей (BERT,ELMO,GPT-2/GPT-3и так далее). Вставка синонима слова в случайное место в предложении. Замена сокращения на полное наименование и обратно. Для английского языка этот способ более актуален, чем для русского. Случайная вставка/удаление/замена/перемена местами слов в предложении. Случайная перестановка местами предложений. Случайное изменение букв на произвольные/ближайшие на клавиатуре, добавление/исправление орфографических и пунктуационных ошибок, изменение регистра. MixUpдля текстов. В задаче классификации смешиваем признаковые описания двух объектов и с такими же весами смешиваем их метки классов, получаем новый объект с признакамии меткой класса: Для текстов признаковые описания можно смешивать на уровне слов (выбирать ближайшее слово в пространстве word embeddings) или на уровне предложений. Еще один вариант: сэмплировать слова из двух разных текстов с вероятностямии.9. Аугментации с использованием синтаксического дерева предложения.10. Генерация текста языковыми моделями. Например, генерация текста с помощью упоминавшейся ранее модели GPT-3. Подробнее про некоторые методы аугментации текстов можно почитать встатьеEasy Data Augmentation (EDA). Многие из описанных выше и в статье методов реализованы в библиотекеNLPAug, использование которой сильно упрощает задачу аугментации текстовых данных на практике."
            }
        ]
    },
    {
        "id": "q_0305",
        "question": "Какие три компонента необходимы для задания вероятностного пространства?",
        "answers": [
            "Для задания вероятностного пространства требуются: непустое множество (пространство элементарных событий), алгебра множеств (набор подмножеств, замкнутый относительно дополнений, объединений и пересечений) и вероятностная мера, приписывающая каждому событию вероятность."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnye-raspredeleniya",
                "text": "В учебниках вероятность традиционно поставляется в комплекте свероятностным пространством. Не увлекаясь чрезмерным формализмом, можно сказать, что для задания вероятностного пространства нужны: непустое множество, называемое пространствомэлементарных событий(исходов); алгебрамножеств— набор подмножеств, замкнутый относительно дополнений, объединений и пересечений; каждый элементназываетсясобытием; вероятностная мера, приписывающая каждому событиюнекоторуювероятность. К вероятностному пространствупредъявляются следующие требования: (невозможноесобытие),(достоверноесобытие); ; , еслии(аддитивность). Упражнение. Докажите, чтои, если. Аддитивность вероятности легко обобщается по индукции до свойстваконечной аддитивности: если событияпопарно несовместны, то Множествочасто называютносителем; говорят также, что вероятностная мера (масса)сосредоточена, илираспределена, на носителе. В зависимости от типа носителяраспределения делятся на два типа:дискретныеинепрерывные."
            }
        ]
    },
    {
        "id": "q_0306",
        "question": "Какой прогноз присваивается листовой вершине в решающем дереве?",
        "answers": [
            "Листовой вершине приписывается прогноз из области значений целевой переменной. В случае классификации листу может быть также приписан вектор вероятностей классов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
                "text": "Разобравшись с приведёнными выше примерами, мы можем дать определение решающего дерева. Пусть задано бинарное дерево, в котором: каждой внутренней вершинеприписан предикат; каждой листовой вершинеприписан прогноз, где— область значений целевой переменной (в случае классификации листу может быть также приписан вектор вероятностей классов). В ходе предсказания осуществляется проход по этому дереву к некоторому листу. Для каждого объекта выборкидвижение начинается из корня. В очередной внутренней вершинепроход продолжится вправо, если, и влево, если. Проход продолжается до момента, пока не будет достигнут некоторый лист, и ответом алгоритма на объектесчитается прогноз, приписанный этому листу. Вообще, предикатможет иметь, произвольную структуру, но на практике чаще используют просто сравнение с порогомпо какому-то-му признаку: При проходе через узел дерева с данным предикатом объекты будут отправлены в правое поддерево, если значение-го признака у них меньше либо равно, и в левое — если больше. В дальнейшем рассказе мы будем по умолчанию использовать именно такие предикаты. Из структуры дерева решений следует несколько интересных свойств: выученная функция — кусочно-постоянная, из-за чего производная равна нулю везде, где задана. Следовательно, о градиентных методах при поиске оптимального решения можно забыть; дерево решений (в отличие от, например, линейной модели) не сможет экстраполировать зависимости за границы области значений обучающей выборки; дерево решений способно идеально приблизить обучающую выборку и ничего не выучить (то есть такой классификатор будет обладать низкой обобщающей способностью): для этого достаточно построить такое дерево, в каждый лист которого будет попадать только один объект. Следовательно, при обучении нам надо не просто приближать обучающую выборку как можно лучше, но и стремиться оставлять дерево как можно более простым, чтобы результат обладал хорошей обобщающей способностью."
            }
        ]
    },
    {
        "id": "q_0307",
        "question": "Какой алгоритм предлагается для построения решающего дерева минимальной глубины, чтобы снизить переобучение?",
        "answers": [
            "Предлагается использовать жадный алгоритм, который строит дерево не целиком, а поэтапно — этаж за этажом. В каждой внутренней вершине решается задача, аналогичная построению решающего пня (дерева глубины 1)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
                "text": "Пусть, как обычно, у нас задан датасет, где— вектор таргетов, а— матрица признаков, в которой-я строка — это вектор признаков-го объекта выборки. Пусть у нас также задана функция потерь, которую мы бы хотели минимизировать. Наша задача — построить решающее дерево, наилучшим образом предсказывающее целевую зависимость. Однако, как уже было замечено выше, оптимизировать структуру дерева с помощью градиентного спуска не представляется возможным. Как ещё можно было бы решить эту задачу? Давайте начнём с простого — научимся строитьрешающие пни, то есть решающие деревья глубины 1. Как и раньше, мы будем рассматривать только самые простые предикаты: Ясно, что задачу можно решить полным перебором: существует не болеепредикатов такого вида. Действительно, индекс(номер признака) пробегает значения отдо, а всего значений порога, при которых меняется значение предиката, может быть не более: Решение, которое мы ищем, будет иметь вид: Для каждого из предикатовнам нужно посчитать значение функции потерь на всей выборке, что, в свою очередь, тоже занимает.Следовательно, полный алгоритм выглядит так: Скопировать код1min_loss = inf2optimal_border =None34forjinrange(D):5fortinX[:, j]:# Можно брать сами значения признаков в качестве порогов6loss = calculate_loss(t, j, X, y)7ifloss <min_loss:8min_loss, optimal_border = loss, (j, t) Сложность алгоритма —. Это не заоблачная сложность, хотя, конечно, не идеальная. Но это была схема возможного алгоритма поиска оптимального дерева высоты 1. Как обобщить алгоритм для дерева произвольной глубины? Мы можем сделать наш алгоритм поиска решающего пня рекурсивным и в теле цикла вызывать исходную функцию для всех возможных разбиений. Как мы упоминали выше, так можно построить дерево, идеально запоминающее всю выборку, однако на тестовых данных такой алгоритм вряд ли покажет высокое качество. Можно поставить другую задачу: построить оптимальное с точки зрения качества на обучающей выборке дерево минимальной глубины (чтобы снизить переобучение). Проблема в том, что поиск такого дерева —NP-полнаязадача, то есть человечеству пока неизвестны способы решить её за полиномиальное время. Как быть? Идеального ответа на этот вопрос нет, но до некоторой степени ситуацию можно улучшить двумя не исключающими друг друга способами: Разрешить себе искать не оптимальное решение, а просто достаточно хорошее. Начать можно с того, чтобы строить дерево с помощьюжадного алгоритма, то есть не искать всю структуру сразу, а строить дерево этаж за этажом. Тогда в каждой внутренней вершине дерева будет решаться задача, схожая с задачей построения решающего пня. Для того чтобы этот подход хоть как-то работал, его придётся прокачать внушительным набором эвристик. Заняться оптимизацией с точки зрения computer science — наивную версию алгоритма (перебор наборов возможных предикатов и порогов) можно ускорить и асимптотически, и в константу раз. Эти две идеи мы и будем обсуждать в дальнейшем. Сначала попытаемся подробно разобраться с первой — как использовать жадный алгоритм."
            }
        ]
    },
    {
        "id": "q_0308",
        "question": "Как можно упорядочить значения категориального признака для задачи бинарной классификации, чтобы работать с ними как с вещественными числами?",
        "answers": [
            "Значения категориального признака упорядочивают по неубыванию доли объектов класса 1. После такого упорядочения с ними можно работать как со значениями вещественного признака, разделяя на значения «не превосходящие» и «большие» определённого порога."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
                "text": "На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признакпринимает значения из множества, то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида(предикат будет иметь вид). Это очень логично и естественно, но проблема в том, что при большиху нас будетсплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образомупорядочиватьзначения, чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значенияможно упорядочить по неубыванию доли объектов класса 1 с, после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всехсплитов. Для задачи регрессии с функцией потерь MSE значенияможно упорядочивать по среднему значению таргета на подмножестве. Полученный таким образом сплит тоже будет оптимальным. Одна из приятных особенностей деревьев — это способность обрабатывать пропуски в данных. Разберёмся, что при этом происходит на этапе обучения и на этапе применения дерева. Пусть у нас есть некоторый признак, значение которого пропущено у некоторых объектов. Как обычно, обозначим черезмножество объектов, пришедших в рассматриваемую вершину, а через— подмножество, состоящее из объектов с пропущенным значением. В момент выбора сплитов по этому признаку мы будем просто игнорировать объекты из, а когда сплит выбран, мы отправим их в оба поддерева. При этом логично присвоить им веса:для левого поддерева идля правого. Веса будут учитываться как коэффициенты прив формуле информативности. Вопрос на подумать. Во всех критериях ветвления участвуют мощности множеств,и. Нужно ли уменьшение размера выборки учитывать в формулах для информативности? Если нужно, то как? Теперь рассмотрим этап применения дерева. Допустим, в вершину, где сплит идёт по-му признаку, пришёл объектс пропущенным значением этого признака. Предлагается отправить его в каждую из дальнейших веток и получить по ним предсказанияи. Эти предсказания мы усредним с весамии(которые мы запомнили в ходе обучения): Для задачи регрессии это сразу даст нам таргет, а в задаче бинарной классификации — оценку вероятности класса 1. Замечание. Если речь идёт о категориальном признаке, может оказаться хорошей идеей ввести дополнительное значение «пропущено» для категориального признака и дальше работать с пропусками, как с обычным значением. Особенно это актуально в ситуациях, когда пропуски имеют системный характер и их наличие несёт в себе определённую информацию."
            }
        ]
    },
    {
        "id": "q_0309",
        "question": "Какие критерии обычно используются для остановки процесса ветвления в деревьях решений?",
        "answers": [
            "Обычно используются четыре критерия: ограничение по максимальной глубине дерева, ограничение на минимальное количество объектов в листе, ограничение на максимальное количество листьев в дереве, и требование, чтобы функционал качества при делении улучшался не менее чем на определенный процент."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
                "text": "Мы уже упоминали выше, что деревья легко переобучаются и процесс ветвления надо в какой-то момент останавливать. Для этого есть разные критерии, обычно используются все сразу: ограничение по максимальной глубине дерева; ограничение на минимальное количество объектов в листе; ограничение на максимальное количество листьев в дереве; требование, чтобы функционал качествапри делении текущей подвыборки на две улучшался не менее чем напроцентов. Делать это можно на разных этапах работы алгоритма, что не меняет сути, но имеет разные устоявшиеся названия: можно проверять критерии прямо во время построения дерева, такой способ называетсяpre-pruningилиearly stopping; а можно построить дерево жадно без ограничений, а затем провестистрижку(pruning), то есть удалить некоторые вершины из дерева так, чтобы итоговое качество упало не сильно, но дерево начало подходить под условия регуляризации. При этом качество стоит измерять на отдельной, отложенной выборке."
            }
        ]
    },
    {
        "id": "q_0310",
        "question": "Как можно ускорить процесс выбора сплита в вершине дерева, используя одномерную динамику?",
        "answers": [
            "Для этого нужно отсортировать объекты по признаку, после чего за один проход по отсортированному массиву можно одновременно перебирать все значения предикатов и поддерживать необходимые статистики для пересчёта информативности каждого следующего варианта сплита."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
                "text": "Теперь временно снимем шапочку ML-аналитика, наденем шапочку разработчика и специалиста по computer science и посмотрим, как можно сделать полученный алгоритм более вычислительно эффективным. В базовом алгоритме мы в каждой вершине дерева для всех возможных значений сплитов вычисляем информативность. Если в вершину пришлообъектов, то мы рассматриваемсплитов и для каждого тратимопераций на подсчёт информативности. Отметим, что в разных вершинах, находящихся в нашем дереве на одном уровне, оказываются разные объекты, то есть сумма этихпо всем вершинам заданного уровня не превосходит, а значит, выбор сплитов во всех вершинах уровня потребуетопераций. Таким образом, общая сложность построения дерева —(где— высота дерева), и доминирует в ней перебор всех возможных предикатов на каждом уровне построения дерева. Посмотрим, что с этим можно сделать. Постараемся оптимизировать процесс выбора сплита в одной конкретной вершине. Вместо того чтобы рассматривать всевозможных сплитов, для каждого тратяна вычисление информативности, можно использовать одномерную динамику. Для этого заметим, что если отсортировать объекты по какому-то признаку, то, проходя по отсортированному массиву, можно одновременно и перебирать все значения предикатов, и поддерживать все необходимые статистики для пересчёта значений информативности задля каждого следующего варианта сплита (против изначальных). Давайте разберём, как это работает, на примере построения дерева для MSE. Чтобы оценить информативность для листа, нам нужно знать несколько вещей: дисперсию и среднее значение таргета в текущем листе; дисперсию и среднее значение таргета в обоих потомках для каждого потенциального значения сплита. Дисперсию и среднее текущего листа легко посчитать за. С дисперсией и средним для всех значений сплитов чуть сложнее, но помогут следующие оценки математического ожидания и дисперсии: Следовательно, нам достаточно для каждого потенциального значения сплита знать количество элементов в правом и левом поддеревьях, их сумму и сумму их квадратов. Впрочем, всё это необходимо знать только для одной из половинок сплита, а для второй это можно получить, вычитая значения для первой из полных сумм. Это можно сделать за один проход по массиву, просто накапливая значения частичных сумм. Если в вершину дерева пришлообъектов, сложность построения одного сплита складывается изсортировок каждая пои одного линейного прохода с динамикой, всего, что лучше исходного. Итоговая сложность алгоритма построения дерева —(где– высота дерева) противв наивной его версии. Какие именно статистики накапливать (средние, медианы, частоты), зависит от критерия, который вы используете. Если бы мощность множества значений признаков была ограничена какой-то разумной константой, то сортировку в предыдущем способе можно было бы заменитьсортировкой подсчётоми за счёт этого существенно ускорить алгоритм: ведь сложность такой сортировки —. Чтобы провернуть это с любой выборкой, мы можем искусственно дискретизировать значения всех признаков. Это приведёт к локально менее оптимальным значениям сплитов, но, учитывая, что наш алгоритм и без этого был весьма приблизительным, это не ухудшит ничего драматически, а вот ускорение получается очень неплохое. Самый популярный и простой способ дискретизации основан на частотах значений признаков: отрезок между максимальным и минимальным значением признака разбивается наподотрезков, длины которых выбираются так, чтобы в каждый попадало примерно равное число обучающих примеров. После чего значения признака заменяются на номера отрезков, на которые они попали. Аналогичная процедура проводится для всех признаков выборки. Полная сложность предобработки —— сортировка задля каждого изпризнаков. Теперь в процедуре динамического алгоритма поиска оптимального сплита нам надо перебирать не всеобъектов выборки, а всего лишьподготовленных заранее границ подотрезков. Частичные суммы статистик тоже придётся поддерживать не для исходного массива данных, а для списка извозможных сплитов. А для того чтобы делать это эффективно, необходим объект, называемыйгистограммой: упорядоченный словарь, сопоставляющий каждому значению дискретизированного признака сумму необходимой статистики от таргета на отрезке [B[i-1], B[i]]. Финальный вид алгоритма таков: Дискретизируем каждый из признаков назначений. Сложность. Создаём корневую вершинуroot. Вызываемbuild_tree_recursive(root, data). Функцияbuild_tree_recursiveвыглядит следующим образом: Проверяем, не пора ли остановиться. Если пора — считаем значение в листе. Теперь мы снова используем динамический алгоритм, но объекты будем сортировать не по исходным значениям признаков, а по их дискретизированным версиям, упорядочивая их с помощью сортировки подсчётом (для вершины, в которую попалообъектов, сложность будет равнапротивв стандартной динамике). Находим оптимальный сплит за. Делим данные, запускаем процедуру рекурсивно для обоих поддеревьев. Общая сложность: Если вам действительно хочется построитьоптимальное(или хотя бы очень близкое к оптимальному) дерево, то на сегодня для решения этой проблемы не нужно придумывать кучу эвристик самостоятельно, а можно воспользоваться специальными солверами, которые решают NP-полные задачи приближённо, но всё-таки почти точно. Так что единственной (и вполне решаемой) проблемой будет представить исходную задачу в понятном для солвера виде. По ссылке —примерпостроения оптимального дерева с помощью решения задачи целочисленного программирования."
            }
        ]
    },
    {
        "id": "q_0311",
        "question": "Какие факторы способствовали высокому интересу к решающим деревьям в период 1970–1990-х годов?",
        "answers": [
            "Интерес был высок как в индустрии, где требовался хорошо интерпретируемый классификатор, так и в науке, где учёные исследовали способы приближённого решения NP-полных задач."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
                "text": "Как вы, может быть, уже заметили, решающие деревья — это одна большая эвристика для решения NP-полной задачи, практически лишённая какой-либо стройной теоретической подоплёки. В 1970–1990-e годы интерес к ним был весьма велик как в индустрии, где был полезен хорошо интерпретируемый классификатор, так и в науке, где учёные интересовались способами приближённого решения NP-полных задач. В связи с этим сложилось много хорошо работающих наборов эвристик, у которых даже были имена: например,ID3был первой реализацией дерева, минимизирующего энтропию, аCART— первым деревом для регрессии. Некоторые из них были запатентованы и распространялись коммерчески. На сегодня это всё потеряло актуальность в связи с тем, что существуют хорошо написанные библиотеки (например,sklearn, в которой реализована оптимизированная версия CART)."
            }
        ]
    },
    {
        "id": "q_0312",
        "question": "Какой подход позволяет моделировать таргет, принимающий только целые значения, и шум с меняющейся дисперсией?",
        "answers": [
            "Подход заключается в использовании семейства распределений, где изменяемым параметром является зависящее от признаков математическое ожидание. Это позволяет, например, применять пуассоновское распределение для целочисленного таргета и получать модели с меняющейся дисперсией шума."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
                "text": "До сих пор мы рассматривали в основном модели вида с шумомиз того или иного распределения. Но у этих моделей: шум не зависит от; может принимать любые значения. А что, если мы захотим предсказывать время ожидания доставки? Казалось бы, чем дольше время потенциального ожидания, тем больше его дисперсия. А как корректно предсказывать таргет, который принимает только целые значения? Один из подходов мы обсудим в этом параграфе. Грубо говоря, вместо того, чтобы прибавлять один и тот же шум, мы зафиксируем семейство распределений, в котором изменяемым параметром будет зависящее отматематическое ожидание. Вот как могут выглядеть такие модели для случаев, еслинормальное с фиксированной дисперсией, экспоненциальное или пуассоновское соответственно: Как видим, такой подход позволяет получать и модели с меняющейся дисперсией шума, и модели с целочисленным таргетом."
            }
        ]
    },
    {
        "id": "q_0313",
        "question": "Какие две составляющие необходимо задать, чтобы получить обобщённую линейную модель (GLM)?",
        "answers": [
            "Чтобы получить обобщённую линейную модель, необходимо задать параметризованное семейство распределений и функцию связи."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
                "text": "Мы рассмотрим достаточно широкий класс моделей —обобщённые линейные модели(generalized linear models,GLM). К ним относятся, в частности, линейная и логистическая регрессии. В итоге мы научимся подбирать подходящую регрессионную модель для самых разных типов данных. Вспомним, что вероятностную модель линейной регрессии можно записать как а вероятностную модель логистической регрессии — как где— распределение Бернулли с параметром, а. Итак, чем в этих терминах отличаются вероятностные модели линейной и логистической регрессии? Во первых, параметризованное семейство распределений для, а именно,в случае линейной регрессии ив случае логистической. Во-вторых, в обоих случаях математическое ожидание условного распределенияявляется функцией от. На это можно посмотреть и по-другому: для каждой из задач выбрана функциятакая, что. Эта функция называетсяфункцией связи(link function). В случае линейной регрессии. В самом деле,. В случае логистической регрессии. Давайте это тоже проверим. В модели логистической регрессии условное распределение— это распределение Бернулли с вероятностью успеха, и этой же вероятности равно его математическое ожидание. Следовательно,. Обобщая, можно сказать, что, если данные таковы, чтоне является линейной функцией от, мы линеаризуемс помощью функции связи. Замечание:Вообще говоря, нормальное распределение определяется не только своим математическим ожиданием, но и стандартным отклонением. То есть, в отличие от логистической регрессии, модель линейной регрессии не позволяет для данногооценить все параметры распределения, и дисперсию приходится фиксировать изначально. К счастью, выбор её значения в нормальном распределении не влияет ни на оптимальный вектор весов, ни на итоговые предсказания, которые выдаёт обученная модель. Продолжим. Задав эти две составляющие — параметризованное семейство распределений и функцию связи — мы получим обобщённую линейную модель (GLM). Для нового объектаона выдаст предсказание, а выбор класса распределенийпотребуется нам для подбора весов. В принципе, можно выбрать любой класс распределенийи любую монотонную функцию связи, получив некоторую вероятностную модель. Однако обычно для упрощения поиска оптимальных весовв GLM предполагают, чтопринадлежит одному из достаточно простых семейств экспоненциального класса."
            }
        ]
    },
    {
        "id": "q_0314",
        "question": "Какая функция связи называется канонической в обобщённых линейных моделях?",
        "answers": [
            "Канонической функцией связи называется такая функция, для которой математическое ожидание отклика равно производной натурального параметра по линейному предиктору, что позволяет однозначно определить эту функцию."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
                "text": "В контексте GLM обычно рассматривают подкласс экспоненциального класса, состоящий из семейств, представимых в виде гдеи— скалярные параметры, причём— нечто фиксированное, обычно дисперсия, которая чаще всего полагается равной, а значенияпараметризуют распределения из семейства. Нетрудно переписать плотность в более привычном для нас виде, чтобы стало очевидно, что это семейство действительно из экспоненциального класса: Действительно, если вспомнить, что— это константа, а не параметр, то получается очень похоже на В частности, мы видим, чтосостоит из единственной компоненты, равной. По доказанной в предыдущем разделе лемме имеем тогда, что математическое ожиданиетакой случайной величины равно До сих пор мы рассуждали о распределениибезв условии. Что будет, если его добавить? Параметрмы договорились сохранять постоянным, тогда отдолжен зависеть единственный оставшийся параметр. Самый естественный в нашей ситуации вариант — это положить. В GLM мы вводили функцию, для которой, то есть. Но ведь матожиданиеравно, то есть. Это позволяет нам однозначно определить функцию связи. Такая функция связи называетсяканонической функцией связи(canonical link function)."
            }
        ]
    },
    {
        "id": "q_0315",
        "question": "Какая функция связи используется в пуассоновской регрессии для предсказания количества лайков?",
        "answers": [
            "В пуассоновской регрессии используется каноническая функция связи, которая является обратной к функции a(θ), что приводит к формуле предсказания λ = e^(θ^T x)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
                "text": "Поговорим немного о том, как на практике подбирать, чтобы по классу распределенийопределить каноническую функцию связи. Чтобы разобраться, рассмотрим несколько примеров. Пример 1. Пусть мы решили применить к данным линейную регрессию. Тогда Обозначим для краткостии будем рассматривать. Мы уже знаем, что семейство нормальных распределений относится к экспоненциальному классу, но давайте выразим эту плотность в описанном выше более частном виде: В формуле экспоненциального семейства распределений единственная часть, не зависящая от, — это функция. Поскольку, функциятакже не должна зависеть от. Так что внутри экспоненты выделим в качестве функциивсё, что не зависит от: Эта формула уже похожа на формулу экспоненциального семейства распределений и видно, что,(коэффициент при),,. Каноническая функция связи является обратной к, то есть, как мы и привыкли. Пример 2. Проделаем то же самое, но теперь для распределения Бернулли. Пример 3. Хорошо, про линейную и логистическую регрессию мы и так знали. Давайте попробуем решить с помощью GLM новую задачу. Пусть мы хотим по каким-то признакампредсказать количество «лайков», которое пользователи поставят посту в социальной сети за первые 10 минут после публикации. Конечно, можно использовать для этого линейную регрессию. Однако предположение линейной регрессии, что, в данном случае странное по нескольким причинам. Во-первых, количество лайков заведомо не может быть отрицательным, а нормальное распределение всегда будет допускать ненулевую вероятность отрицательного значения. Во-вторых, количество лайков — всегда целое число. В-третьих, у распределения количества лайков, скорее всего,положительный коэффициент асимметрии(skewness). То есть, если модель предсказывает, что под постом будет 100 лайков, мы скорее можем ожидать, что под ним окажется 200 лайков, чем 0. Нормальное распределение симметрично и не может описать такие данные. С другой стороны, если мы предположим, что в первые 10 минут после публикации есть какая-то постоянная частота (своя для каждого поста, зависящая от), с которой пользователи ставят лайк, мы получим, что количество лайков имеет распределение Пуассона. Распределение Пуассона не имеет описанных выше проблем: Но какая будет каноническая функция связи, если мы считаем, что? Аналогично первому и второму примерам: Откуда,,, Значит, эта модель (она называетсяпуассоновская регрессия), будет предсказывать с помощью формулы. Вопрос на подумать. В каких ситуациях была бы полезной функция связиcomplementary log-log link(cloglog)"
            }
        ]
    },
    {
        "id": "q_0316",
        "question": "В чём заключается ключевое отличие задач классификации и кластеризации с точки зрения наличия обучающей выборки?",
        "answers": [
            "В задаче классификации обучающая выборка с примерами объектов и их классов имеется, а в задаче кластеризации обучающая выборка отсутствует, так как классы заранее неизвестны."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
                "text": "В задаче классификации мы имели дело с восстановлением отображения из множества объектов в конечный набор меток классов. При этом классы были зафиксированы заранее, то есть мы с самого начала примерно понимали, какого рода объекты должны относиться к каждому из них, и мы располагали обучающей выборкой с примерами объектов и классов, к которым они относятся. В задаче кластеризации мы тоже разбиваем объекты на конечное множество классов, но у нас нет ни обучающей выборки, ни понимания, какой будет природа этих классов. То, что модель кластеризации какие-то объекты сочла «похожими», отнеся к одному классу, будет новой информацией, «открытием», сделанным этой моделью. Обучающей выборки у нас также не будет: ведь мы не знаем заранее, что за классы получатся (а иногда и сколько их будет). Таким образом,кластеризация— это задача обучения без учителя. Из-за общего сходства постановок задач в литературе кластеризацию иногда называютunsupervised classification. Методы кластеризации часто применяют, когда фактически нужно решить задачу классификации, но обучающую выборку собрать затруднительно (дорого или долго). При этом валидационную выборку для оценки результатов кластеризации собрать значительно проще, так как для неё требуется меньше примеров. При этом стоит помнить, что точность работы supervised-методов значительно выше. Поэтому, если обучающую выборку всё-таки можно собрать, лучше решать задачу классификации, чем задачу кластеризации."
            }
        ]
    },
    {
        "id": "q_0317",
        "question": "Какой метод анализа данных применялся в Яндекс.Такси для определения наиболее удобных точек вызова такси?",
        "answers": [
            "В Яндекс.Такси использовалась кластеризация координат точек заказа. Центры полученных кластеров становились кандидатами в пикап-пойнты, которые затем проверялись простыми фильтрами (например, чтобы не попадали в здания или воду)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
                "text": "Хороший пример применения методов кластеризации — анализ геоданных. В мобильных приложениях, собирающих геоданные пользователей, часто требуется понять, где именно пользователь находился. GPS-координаты известны с некоторой погрешностью, пользователь тоже обычно двигается, поэтому вместо точного положения часто приходится иметь дело с роем точек. Положение усугубляется, когда мы пытаемся анализировать поведение сразу тысяч людей в какой-то локации — например, определить, в каких точках люди чаще всего садятся в такси у аэропорта. Может показаться, что достаточно посмотреть на данные — и мы увидим в точности нужные нам кластеры. Изображение ниже показывает, как может выглядеть ситуация всего для нескольких пользователей: согласно данным GPS, такси подбирают пассажиров и внутри здания аэропорта, и на взлётной полосе, и там, где это происходит на самом деле: Подобная задача решалась в Яндекс.Такси при разработке пикап-пойнтов (наиболее удобных точек вызова такси, подсвечиваемых в приложении). Координаты точек заказа кластеризовались таким образом, чтобы кластер соответствовал какому-то одному, удобному для пользователя месту, и центры кластеров использовались как кандидаты в пикап-пойнты. Те кандидаты, которые удовлетворяли простым фильтрам (например, не попадали в здание или в воду), использовались в приложении. При этом не обходилось и без вручную проставленных пикап-пойнтов: например, такое решение использовалось в окрестностях аэропортов. Другой пример кластеризации геоданных, который всегда рядом с нами, — это интерфейсы для просмотра фотографий в вашем смартфоне. Почти наверняка вы можете просмотреть их в привязке к местам, где они были сделаны, и по мере масштабирования карты вы будете видеть разное количество кластеров фотографий. Кстати, если говорить об интерфейсах, то есть и другой интересный пример: если нужно подстроить цветовую схему вашего интерфейса под выбираемое пользователем изображение (например, фоновую картинку), достаточно кластеризовать цвета из пользовательского изображения, используя RGB-представление (или любое другое) как признаки цвета, и воспользоваться для оформления цветами, соответствующими центрам кластеров."
            }
        ]
    },
    {
        "id": "q_0318",
        "question": "Какой метод кластеризации предлагается использовать вместо построения графа с рёбрами между точками на определённом расстоянии?",
        "answers": [
            "Предлагается построить минимальное остовное дерево, считая расстояния между точками весами рёбер, а затем удалить рёбра с наибольшим весом, чтобы получить компоненты связности в качестве кластеров."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
                "text": "Можно приводить примеры не только про геоаналитику, однако тема геоданных поможет нам придумать пару наиболее простых и наглядных методов кластеризации. Представим, что перед нами рой геокоординат и нам нужно предложить по этим данным пикап-пойнты для такси. Разберём пару очевидных методов. Логично попробовать объединить точки, которые находятся друг от друга на расстоянии двух-трёх метров, а потом просто выбрать наиболее популярные места. Для этого давайте построим на известных нам точках граф: точки, расстояние между которыми в пределах трёх метров, мы соединим рёбрами. Выделим в этом графе компоненты связности, они и будут нашими кластерами. У этого способа есть пара очевидных недостатков. Во-первых, может найтись сколько угодно длинная цепочка точек, в которой соседние отстоят друг от друга на пару метров, — и вся она попадёт в одну компоненту связности. В итоге наша отсечка по трём метрам имеет очень опосредованное отношение к диаметру кластеров, а сами кластеры будут получаться значительно больше, чем нам хотелось бы. Во-вторых (и с первой проблемой это тоже связано), непонятно, как мы выбираем максимальное расстояние, при котором соединяем точки ребром. В данной задаче ещё можно предъявить хоть какую-то логику, а вот если бы мы кластеризовали не геометки, а что-то многомерное, например электронные письма по их тематике, придумать отсечку было бы уже сложнее. Если наша цель — не только решить практическую задачу, но и придумать достаточно общий метод кластеризации, понятно, что нам хочется понимать, как подбирать параметры этого метода (в данном случае условие добавления рёбер в граф). Эти соображения могут привести нас к другому решению. Вместо того чтобы проводить рёбра в графе, давайте их удалять. Построимминимальное остовное дерево, считая расстояния между точками весами рёбер. Тогда, удаливрёбер с наибольшим весом, мы получимкомпоненту связности, которые, как и в прошлом подходе, будем считать кластерами. Различие в том, что теперь нам нужно задавать не расстояние, при котором проводится ребро, а количество кластеров. С одной стороны, если мы решаем задачу расчёта пикап-пойнтов в какой-то конкретной локации (аэропорт, торговый центр, жилой дом), нам может быть понятно, сколько примерно пикап-пойнтов мы хотим получить. С другой стороны, даже без локального рассмотрения можно просто сделать достаточно много кластеров, чтобы было из чего выбирать, но при этом достаточно мало, чтобы в каждый кластер попадало репрезентативное количество точек. Аналогичная логика будет справедлива и во многих других задачах кластеризации: количество кластеров — достаточно общий и достаточно хорошо интерпретируемый параметр, чтобы настраивать его вручную, поэтому во многих методах кластеризации количество кластеров выступает как гиперпараметр. Далее будем рассматривать некоторую обобщённую задачу кластеризации без привязки к нашему примеру с анализом геоданных. Мы приведём три наиболее популярных метода кластеризации — k-средних, иерархическую кластеризацию и DBSCAN, а затем рассмотрим вопросы оценки качества кластеризации."
            }
        ]
    },
    {
        "id": "q_0319",
        "question": "Какие два основных типа алгоритмов кластеризации существуют в рамках иерархического подхода?",
        "answers": [
            "Агломеративные алгоритмы начинают с небольших кластеров (обычно из одного объекта) и постепенно объединяют их, а дивизивные начинают с больших кластеров (обычно с одного) и постепенно делят на более мелкие."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
                "text": "Другой классический метод кластеризации — этоиерархическая кластеризация. Иногда дополнительно уточняют:иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства. Во-первых, есть деление алгоритмов кластеризации наагломеративные(agglomerative) идивизивные, илидивизионные(divisive). Агломеративные алгоритмы начинают с небольших кластеров (обычно с кластеров, состоящих из одного объекта) и постепенно объединяют их в кластеры побольше. Дивизивные начинают с больших кластеров (обычно – с одного единственного кластера) и постепенно делят на кластеры поменьше. Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру). В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма. Сам алгоритм выглядит предельно просто: Создаём столько кластеров, сколько у нас объектов в выборке, каждый объект — в своём отдельном кластере. Повторяем итеративно слияние двух ближайших кластеров, пока не выполнится критерий останова. Как измерить расстояние между кластерами из одного объекта? Нужно просто взять расстояние между этими объектами. Остаётся вопрос, как обобщить расстояние между объектами до расстояния между кластерами (если в них более одного объекта). Традиционные решения — брать среднее расстояние между объектами кластеров, минимальное расстояние или максимальное. Если обозначить кластерыи, расстояние между ними в этом случае можем вычислять по одной из формул: Используемая формула расстояния между кластерами — один из гиперпараметров алгоритма. Кроме приведённых стандартных вариантов бывают и более экзотичные, например расстояние Уорда (Ward distance). В наиболее общем виде способы задания расстояния между кластерами даются формулой Ланса — Уильямса (Lance — Williams; более подробно вы можете почитать вэтой статье). Сами же расстояния между объектами можно задавать любой метрикой, как евклидовой, так и манхэттенским расстоянием или, например, косинусной мерой (с той лишь поправкой, что это мера близости, а не расстояние). В качестве условия для завершения работы алгоритма можем выбрать либо получение нужного количества кластеров (количество кластеров может быть гиперпараметром алгоритма), либо выполнение эвристик на основе расстояния между объединяемыми кластерами (например, если расстояние сливаемых кластеров значительно выросло по сравнению с прошлой итерацией). На практике же обычно кластеризацию проводят вплоть до одного кластера, включающего в себя всю выборку, а затем анализируют получившуюся иерархическую структуру с помощью дендрограммы. По мере объединения кластеров, каждой итерации алгоритма соответствует пара объединяемых на этой итерации кластеров, а также расстояние между кластерами в момент слияния. Расстояния с ростом итерации будут только увеличиваться, поэтому возникает возможность построить следующую схему, называемуюдендрограммой: Здесь по горизонтали внизу отмечены объекты кластеризуемой выборки, под горизонтальной осью подписаны номера объектов, а их расположение вдоль оси продиктовано только эстетическими соображениями: нам удобно строить дендрограмму так, чтобы никакие дуги в ней не пересекались. По вертикали отложены расстояния между кластерами в момент слияния. Когда происходит объединение кластеров, состоящих из нескольких объектов, соответствующая этой итерации алгоритма дуга идёт не до конкретных объектов выборки, а до дуги другого кластера. Таким образом мы получаем наглядную визуализацию древовидной структуры процесса кластеризации. В частности, на дендрограмме мы можем визуально заметить, в какой момент происходит скачок расстояний между кластерами, и попытаться определить «естественное» количество кластеров в нашей задаче. На практике же это соображение, как правило, остаётся лишь красивой теорией, так как любую кластеризацию можно делать в разной степени «мелкой» и «естественного» количества кластеров в практических задачах часто не существует. В случае же если данные были получены таким образом, что в них действительно есть какое-то естественное количество кластеров, иерархическая кластеризация обычно справляется с определением числа кластеров по дендрограмме заметно хуже, чем DBSCAN. Именно алгоритму DBSCAN мы и посвятим следующий раздел."
            }
        ]
    },
    {
        "id": "q_0320",
        "question": "Как в алгоритме DBSCAN классифицируются точки выборки на основе их окрестности?",
        "answers": [
            "Точки делятся на три типа: основные (core points) — в окрестности которых больше заданного порога точек; граничные (border points) — в окрестности которых есть основные точки, но общее количество точек меньше порога; шумовые (noise points) — в окрестности которых нет основных точек и общее количество точек меньше порога."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
                "text": "АлгоритмDBSCAN(Density-based spatial clustering of applications with noise) развивает идею кластеризации с помощью выделения связных компонент. Прежде чем перейти к построению графа, введём понятие плотности объектов выборки в пространстве признаков. Плотность в DBSCAN определяется в окрестности каждого объекта выборкикак количество других точек выборки в шаре. Кроме радиусаокрестности в качестве гиперпараметра алгоритма задается порогпо количеству точек в окрестности. Далее все объекты выборки делятся на три типа:внутренние / основные точки(core points),граничные(border points) ишумовые точки(noise points). К основным относятся точки, в окрестности которых большеобъектов выборки. К граничным — точки, в окрестности которых есть основные, но общее количество точек в окрестности меньше. Шумовыми называют точки, в окрестности которых нет основных точек и в целом содержится менееобъектов выборки. Алгоритм кластеризации выглядит следующим образом: Шумовые точки убираются из рассмотрения и не приписываются ни к какому кластеру. Основные точки, у которых есть общая окрестность, соединяются ребром. В полученном графе выделяются компоненты связности. Каждая граничная точка относится к тому кластеру, в который попала ближайшая к ней основная точка. Удобство DBSCAN заключается в том, что он сам определяет количество кластеров (по модулю задания других гиперпараметров —и), а также в том, что метод успешно справляется даже с достаточно сложными формами кластеров. Кластеры могут иметь вид протяжённых лент или быть вложенными друг в друга как концентрические гиперсферы. На изображении ниже показан пример выделения кластеров достаточно сложной формы с помощью DBSCAN: DBSCAN — один из самых сильных алгоритмов кластеризации, но работает он, как правило, заметно дольше, чем mini-batch K-means, к тому же весьма чувствителен к размерности пространства признаков, поэтому используется на практике DBSCAN только тогда, когда успевает отрабатывать за приемлемое время."
            }
        ]
    },
    {
        "id": "q_0321",
        "question": "Какой метод кластеризации наиболее часто используется по сравнению с иерархической кластеризацией и DBSCAN?",
        "answers": [
            "Наиболее часто используется метод K-means, который занимает первое место по частоте применения, тогда как иерархическая кластеризация и DBSCAN делят второе место."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
                "text": "Если сравнивать частоту использования K-means, иерархической кластеризации и DBSCAN, то на первом месте, бесспорно, будет K-means, а второе место будут делить иерархический подход и DBSCAN. Иерархическая кластеризация — более известный и простой в понимании метод, чем DBSCAN, но довольно редко отрабатывающий качественно. Частая проблема иерархической кластеризации — раннее образование одного гигантского кластера и ряда очень небольших, что приводит к сильной несбалансированности количества объектов в итоговых кластерах. В то же время DBSCAN — менее широко известный подход, но, когда его можно применить, качество, как правило, получается выше, чем в K-means или иерархической кластеризации."
            }
        ]
    },
    {
        "id": "q_0322",
        "question": "Какие условия должны выполняться для белого шума в модели MA(q)?",
        "answers": [
            "Белый шум в модели MA(q) должен быть гауссовским, иметь нулевое математическое ожидание и независимые значения в разные моменты времени."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель скользящего среднего порядкаили просто MA() предполагает следующую зависимость данных: где— стационарный ряд со средним, а— гауссовский белый шум, то естьи независимы. По сути наш рядвыражается через сумму некоторого фиксированного среднего, значения белого шума в текущий момент времении не болеепредыдущих значений белого шума, домноженных на некоторые коэффициенты, которые являются параметрами модели. Рассмотрим некоторые свойства модели MA(). Как уже было упомянуто выше, рядбудет являтьcя стационарным со средним. Найдем также. Воспользовавшись свойством независимости для, можем заключить, что Посчитаем автоковариационную функцию для ряда, то есть найдем значение. Легко понять, что если, то= 0, т.к.независимы. Если же, то тогда Записав более компактно, можем получить: где. Из посчитанных значений для дисперсии и ковариационной функции, можете попробовать получить выражение и для автокорреляционной функции. Ее особенностью будет как раз равенство нулю на лаге, превосходящим. Посмотрим на визуализацию:"
            }
        ]
    },
    {
        "id": "q_0323",
        "question": "При каких условиях на комплексные корни характеристического полинома модель AR(p) задаёт стационарный временной ряд?",
        "answers": [
            "Модель AR(p) задаёт стационарный временной ряд, если все комплексные корни характеристического полинома лежат вне единичного круга."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель авторегрессии для временного ряда можно записать следующим образом: где— стационарный ряд, а— гауссовский белый шум, то естьи независимы. Отметим, что, вообще говоря, для стационарности нужны некоторые условия на коэффициенты. По сути наш рядвыражается через сумму некоторого фиксированного числа, значения белого шума в текущий момент времении не болеепредыдущих значений этого же ряда, домноженных на некоторые коэффициенты, которые являются параметрами модели. Другими словами, модель AR() — это модельдля которой Таргет:— значение ряда в момент времени Признаки:— значения ряда в предыдущие моменты времени Введем— оператор сдвига, обладающий следующими свойствами: применениек ряду дает предыдущее значение этого же ряда: применениек белому шуму дает предыдущее значение шума: применениек константе — это константа: Операториногда называют такжелаговымоператором. Можно рассматривать функции от оператора сдвига, например, кратное применение оператора:или. Для записей некоторых моделей временных рядов будет удобно использовать лаговый многочлен: Обратным к операторуназывают оператортакой, что: Так, например, дляможно заключить, что: Рассмотрим модель AR(): С помощью оператора сдвига ее можно представить в следующем виде: где— характеристический полином. Сформулируем пару важных утверждений: Любой стационарный (в широком смысле) процесс представим в виде, то есть в виде модели скользящего среднего с неограниченным количеством слагаемых (конечное или бесконечное число). Этот результат так же известен кактеорема Волдао декомпозиции временного ряда. Модельзадает стационарный временной рядвсе комплексные корнилежат вне единичного круга. Приведем пояснение второго утверждения. В самом деле, пусть— все его комплексные корни (их ровнос учетом кратности), тогда справедливо представление: Тогда при представлении временного ряда в виде и дальнейшего его разложения на простые дроби возникнут слагаемые вида Если при этомлежит внутри единичного круга или на его границе, то соответствующий ряд будет расходящимся. На самом деле, случаймы в дальнейшем учтем. В качестве примера рассмотрим подробнее модель.Зависимость имеет вид, где. Для данного ряда можно выписать следующие свойства: Уравнение, имеет корень. Тем самым,стационарен. Кроме того, чем меньше, тем предыдущее значение ряда вносит меньший вклад в текущее значение. Если ряд стационарен, то:. . Разберем первое равенство, остальные получаются аналогично. Возьмем математическое ожидание в уравнении ряда Поскольку ряд стационарен, то его математическое ожидание не меняется во времени, а для белого шума математическое ожидание равно нулю. Тем самым мы получаем уравнение на, откуда следует доказываемая формула. Таким образом, в зависимости от значениямы можем получить следующие результаты: Если, то— представление ряда в виде MA(). Если, то— это случайное блуждание. Если, то— экспоненциально растущий процесс. Посмотрим на визуализацию. В первом случае мы имеем модель, отрицательный коэффициент является следствием больших колебаний ряда. Во втором случае модель, большой положительный коэффициент делает ряд менее шумным. В третьем случае показано несколько рядов вида случайного блуждания, что соответствует случаю. В четвертом случае показан экспоненциальный процесс, на графике шум уже не заметен из-за масштаба. На немного вернемся к модели MA(). Чуть выше мы выяснили, что при некоторых условиях на коэффицентывременной ряд модели AR() будет стационарным, а значит имеет представление в виде MA(). На самом деле, модель скользящего среднего порядкатоже можно представить с помощью оператораследующим образом: где—характеристический многочлен. Для простоты изложения пусть. Важным при такой записи оказывается понятие обратимости, то есть представления в виде которое означает, что ряд можно представить в виде бесконечной авторегрессионной модели.Здесь, как и в рассуждениях выше, можно заключить, что временной рядобратим, если все комплексные корнилежат вне единичного круга."
            }
        ]
    },
    {
        "id": "q_0324",
        "question": "Что определяет стационарность ряда в модели ARMA?",
        "answers": [
            "Стационарность ряда в модели ARMA определяется только его AR-компонентой, то есть значениями коэффициентов авторегрессии, поскольку MA-компонента всегда является стационарной."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель ARMA() по сути является суммой моделейи, иначе говоря, модель есть сумма нескольких предыдущих значений ряда и нескольких предыдущих значений белого шума с некоторым коэффициентами. Эквивалентную запись ряда в терминах оператора сдвига можно получить, рассмотрев два многочлена или гдеи.Заметим, что во втором представлении константазаменена на. На самом деле, стационарность такого ряда будет определяться только его AR() компонентой, то есть значениями коэффициентов, так ряд в модели MA() всегда является стационарным."
            }
        ]
    },
    {
        "id": "q_0325",
        "question": "Какой процесс можно привести в качестве примера нестационарного ряда, который становится стационарным после дифференцирования?",
        "answers": [
            "Примером является процесс случайного блуждания, где ряд после дифференцирования превращается в белый шум, который уже является стационарным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель ARIMA() — это расширение моделей типа ARMA на нестационарные временные ряды, которые однако могут стать стационарным после применениея процедуры дифференцирования ряда. Модель ARIMA() для рядаопределяется как модель ARMA() для ряда разностей порядкаряда. Разность порядка 1:. Разность порядка 2:. Получаем формулу модели ARIMA: или То есть многочленимеетединичных корней.Тем самым такая модель позволяет учесть нестационарности, в частности, тренд. В качестве примера рассмотрим процесс случайного блуждания: где— белый шум. Как уже упомяналось ранее, такой ряд не является стационарным. Однако, если мы применим операцию дифференцирования, то можем перейти к новому, уже стационарном ряду, который можно записать в виде:"
            }
        ]
    },
    {
        "id": "q_0326",
        "question": "Какую функцию используют для определения порядка модели авторегрессии AR(p)?",
        "answers": [
            "Для определения порядка модели авторегрессии AR(p) используют частичную (частную) автокорреляционную функцию (PACF). Значения PACF для модели AR(p) будут ненулевыми для лагов до p и равняться нулю для лагов больше p."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Для модели скользящего среднего порядкамы выяснили, что значения автокорреляционной функции для такого ряда оказывается равной нулю после лага. Эта особенность позволяет использовать автокорреляционную функцию для определения порядка модели скользящего среднего. Возникает разумный вопрос, как оценить порядокдля модели AR()? Здесь оказывается полезным понятие частичной (частной) автокорреляционной функции. Частичная автокорреляция (PACF)— корреляция ряда с собой после снятия линеной зависимости от промежуточных значений ряда. Иначе говоря, мы хотим как-то учесть опосредованного влияние промежуточных значений ряда и оценить непосредственное влияниена. Чуть более формально частичную автокорреляцию можно записать следующим образом: где— линейная регрессия на: Пример для: где— МНК-оценка в модели. Можно показать, что значение частиной автокорреляции для модели авторегресии AR() будет ненулевой для лагови равняться нулю для лагов. Имеет место быть полная аналогия с автокорреляционной функцией и моделью MA(). Таким образом, исследование поведения автокорреляционной и частичной автокорреляционной функции может быть использовано для определения порядкамодели скользящего среднего и порядкамодели авторегрессии соответсвтенно."
            }
        ]
    },
    {
        "id": "q_0327",
        "question": "Какой метод используется для поиска начальных приближений параметров p и q в модели ARIMA?",
        "answers": [
            "Для поиска начальных приближений параметров p и q используются автокорреляционная функция (ACF) и частичная автокорреляционная функция (PACF). Начальное приближение для p определяется по последнему значимому пику у PACF, а для q — по последнему значимому пику у ACF."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Пусть гиперпараметрыфиксированы.&tab;В предположении, что— гауссовский белый шум, в нашей модели мы можем выписать функцию правдоподобиягде— соместная плотность. Из-за того, чтоимеют нормальное распределение, она будет иметь разумный вид. Соответственно, в качестве оценок параметров берется оценка максимального правдоподобия. Для поиска начальных приближение для параметровивоспользуемся автокорреляционной и частичной автокорреляционной функцией. Начальное приближение: последний значимый пик у PACF. Начальное приближение: последний значимый пик у ACF. Далее обычно используется поиск по сетке вокруг подобранных значений, минимизируя информационный критерий: — критерий Акаике; — критерий Акаике (короткие ряды); — Байесовский информационный критерий или критерий Шварца, где— логарифм функции правдоподобия,— длина временного ряда. Приведем некоторый план при применению модели ARIMA для прогнозирования временных рядов. Анализ выбросов: замена нерелевантых выбросов наNAили усреднение по соседним элементам. Стабилизация дисперсии (преобразования). Дифференцирование, если ряд не стационарен. Выбор пилотныхипо PACF и ACF. Вокруг этих параметров подбираем оптим. модель по/. Пошаговое построение прогноза:— для:;— для:;— для:. Построение предсказательного интервала:— если остатки модели нормальны и гомоскедастичны (дисперсия постоянна), то строится теоретический предсказательный интервалгде— горизонт прогнозирования,— оценка на дисперсию шума,— коэф. для ряда при его представлении в виде бесконечного процесса скользящего среднего. И, имогут быть выражены через оценки на параметрыи.— иначе интервалы строятся с помощью бутстрепа."
            }
        ]
    },
    {
        "id": "q_0328",
        "question": "Какие компоненты добавляются в модель ARIMA для учета сезонности ряда?",
        "answers": [
            "Для учета сезонности в модель ARIMA добавляются компоненты, отвечающие за значения ряда в предыдущие сезоны. Полученная модель называется SARIMA и включает параметр сезонного дифференцирования, а также параметры, подбираемые с учетом сезонности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Рассмотрим некоторые расширение модели ARIMA. Обобщение модели ARIMA на ряды с наличием сезонной составляющей назвается SARIMA. Пусть— известная сезонность ряда. Добавим в модель ARIMA() компоненты, отвечающие за значения в предыдущие сезоны. Тогда модель SARIMAможет быть записана следующим образом: где Параметр сезонного дифференцирования, а также параметрыподбираются из тех же соображений, что и для, но только с поправкой, что делается это с учетом сезонности. ARIMAX — обобщение модели ARIMA, которая учитывает некоторые экзогенные факторы. Пусть— ряд регрессоров,известный до начала прогноза. Простой вариант: Общий случай: Пример: Вышеуказанные модели можно объединить и получить SARIMAX: Проведем аналогию с линейной регрессией. Это линейная по признакам модель, в которой Отклик:— значение ряда в моменты времени Признаки:— значения ряда в предыдущие моменты времениЗначение ряда за предыдущие сезоныЗначения признаков в предыдущие моменты времениЗначения признаков в предыдущие сезоны — значения ряда в предыдущие моменты времени Значение ряда за предыдущие сезоны Значения признаков в предыдущие моменты времени Значения признаков в предыдущие сезоны Ошибка:сумма шума за предыдущие моменты времени и предыдущие сезоны."
            }
        ]
    },
    {
        "id": "q_0329",
        "question": "Что такое MDP в обучении с подкреплением и из каких основных компонентов оно состоит?",
        "answers": [
            "MDP (Markov Decision Process) — это формальная модель задачи обучения с подкреплением, представленная четвёркой: пространство состояний, пространство действий, функция переходов и функция награды."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "Теперь попробуем формализовать всю эту концепцию и познакомиться с местной терминологией. Задача обучения с подкреплением задаётсяМарковским Процессом Принятия Решений(Markov Decision Processили сокращённоMDP) это четвёрка, где: —пространство состояний(state space), множество состояний, в которых в каждый момент времени может находиться среда. —пространство действий(action space), множество вариантов, из которых нужно производить выбор на каждом шаге своего взаимодействия со средой. —функция переходов(transition function), которая задаёт изменение среды после того, как в состояниибыло выбрано действие. В общем случае функция переходов может быть стохастична, и тогда такая функция переходов моделируется распределением: с какой вероятностью в какое состояние перейдёт среда после выбора действияв состоянии. —функция награды(reward function), выдающая скалярную величину за выбор действияв состоянии. Это наш «обучающий сигнал». Традиционно субъект, взаимодействующий со средой и влияющий на неё, называется в обучении с подкреплениемагентом(agent). Агент руководствуется некоторым правилом, возможно, тоже стохастичным, как выбирать действия в зависимости от текущего состояния среды, которое называетсястратегией(policy; термин часто транслитерируют и говорятполитика) и моделируется распределением. Стратегия и будет нашим объектом поиска, поэтому, как и в классическом машинном обучении, мы ищем какую-то функцию. Взаимодействие со средой агента со стратегиеймоделируется так. Изначально среда находится в некотором состоянии. Агент сэмплирует действие из своей стратегии. Среда отвечает на это, сэмплируя своё следующее состояниеиз функции переходов, а также выдаёт агенту награду в размере. Процесс повторяется: агент снова сэмплирует, а среда отвечает генерациейи скалярной наградой. Так продолжается до бесконечности или пока среда не перейдёт в терминальное состояние, после попадания в которое взаимодействие прерывается, и сбор агентом награды заканчивается. Если в среде есть терминальные состояния, одна итерация взаимодействия от начального состояния до попадания в терминальное состояние называетсяэпизодом(episode). Цепочка генерируемых в ходе взаимодействия случайных величинназываетсятраекторией(trajectory).Примечание:функция награды тоже может быть стохастичной, и тогда награды за шаг тоже будут случайными величинами и частью траекторий, но без ограничения общности мы будем рассматривать детерминированные функции награды. Итак, фактически среда для нас — это управляемая марковская цепь: на каждом шаге мы выборомопределяем то распределение, из которого будет генерироваться следующее состояние. Мы предполагаем, во-первых, марковское свойство: что переход в следующее состояние определяется лишь текущим состоянием и не зависит от всей предыдущей истории: Во-вторых, мы предполагаем стационарность: функция переходовне зависит от времени, от того, сколько шагов прошло с начала взаимодействия. Это довольно реалистичные предположения: законы мира не изменяются со временем (стационарность), а состояние — описывает мир целиком (марковость). В этой модели взаимодействия есть только одно нереалистичное допущение:полная наблюдаемость(full observability), которая гласит, что агент в своей стратегиинаблюдает всё состояниеполностью и может выбирать действия, зная об окружающем мире абсолютно всё; в реальности нам же доступны лишь какие-то частичные наблюдения состояния. Такая более реалистичная ситуация моделируется вчастично наблюдаемых MDP(Partially observable MDP,PoMDP), но мы далее ограничимся полностью наблюдаемыми средами. Итак, мы научились на математическом языке моделировать среду, агента и их взаимодействие между собой. Осталось понять, чего же мы хотим. Во время взаимодействия на каждом шаге агенту приходит награда, однако, состояния и действияв рамках такой постановки — случайные величины. Один и тот же агент может в силу стохастики как внутренней (в силу случайности выбора действий в его стратегии), так и внешней (в силу стохастики в функции переходов) набирать очень разную суммарную наградув зависимости от везения. Мы скажем, что хотим научиться выбирать действия так, чтобы собиратьв среднемкак можно больше награды. Что значит в среднем, в среднем по чему? По всей стохастике, которая заложена в нашем процессе взаимодействия со средой. Каждая стратегиязадаёт распределение в пространстве траекторий — с какой вероятностью нам может встретится траектория: Вот по такому распределению мы и хотим взять среднее получаемой агентом награды. Записывают это обычно как-нибудь так: Здесь мат.ожидание по траекториям — это бесконечная цепочка вложенных мат.ожиданий: Вот такую конструкцию мы и хотим оптимизировать выбором стратегии. На практике, однако, вносят ещё одну маленькую корректировку. В средах, где взаимодействие может продолжаться бесконечно долго, агент может научиться набирать бесконечную награду, с чем могут быть связаны разные парадоксы (например, получать +1 на каждом втором шаге становится также хорошо, как получать +1 на каждом сотом шаге). Поэтому вводятдисконтирование(discounting) награды, которое гласит: тортик сейчас лучше, чем тот же самый тортик завтра. Награду, которую мы получим в будущем, агент будет дисконтировать на некоторое число, меньшее единицы. Тогда наш функционал примет такой вид: Заметим, что обучение с подкреплением - это в первую очередь задача оптимизации, оптимизации функционалов определённого вида. Если в классическом машинном обучении подбор функции потерь можно считать элементом инженерной части решения, то здесь функция награды задана нам готовая и определяет тот функционал, который мы хотим оптимизировать."
            }
        ]
    },
    {
        "id": "q_0330",
        "question": "Как называется принцип выбора действия, при котором выбирается действие с максимальным значением Q-функции?",
        "answers": [
            "Такой выбор называется жадным (greedy) по отношению к Q-функции. Согласно принципу оптимальности Беллмана, жадный выбор по отношению к оптимальной Q-функции является оптимальным."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "Выглядит сложновато, но у человечества есть уже довольно много наработок, как подойти к этой на вид очень общей задаче, причём с основной идеей вы скорее всего уже сталкивались. Называется онадинамическим программированием. Дело в том, что мы оптимизируем не абы какой функционал, а среднюю дисконтированную кумулятивную награду. Чтобы придумать более эффективное решение, чем какой-нибудь подход, не использующий этот факт (например, эволюционные алгоритмы), нам нужно воспользоваться структурой поставленной задачи. Эта структура задана в формализме MDP и определении процесса взаимодействия агента со средой. Интуитивно она выражается так: вот мы сидим в некотором состояниии хотим выбрать действиекак можно оптимальнее. Мы знаем, что после выбора этого действия мы получим награду за этот шаг, среда перекинет нас в состояниеи, внимание, дальше нас ждётподзадача эквивалентной структуры: в точности та же задача выбора оптимального действия, только в другом состоянии. Действительно: когда мы будем принимать решение на следующем шаге, на прошлое мы повлиять уже не способны; стационарность означает, что законы, по которым ведёт себя среда, не поменялись, а марковость говорит, что история не влияет на дальнейший процесс нашего взаимодействия. Это наводит на мысль, что задача максимизации награды из текущего состояния тесно связана с задачей максимизации награды из следующего состояния, каким бы оно ни было. Чтобы сформулировать это на языке математики, вводятся «дополнительные переменные», вспомогательные величины, называемыеоценочными функциями. Познакомимся с одной такой оценочной функцией - оптимальной Q-функцией, которую будем обозначать. Скажем, что- это то, сколько максимально награды можно (в среднем) набрать после выбора действияиз состояния. Итак: Записьздесь означает, что мы садимся в состояние; выбираем действие, а затем продолжаем взаимодействие со средой при помощи стратегии, порождая таким образом траекторию. По определению, чтобы посчитать, нужно перебрать все стратегии, посмотреть, сколько каждая из них набирает награды после выбораиз состояния, и взять наилучшую стратегию. Поэтому эта оценочная функция называется оптимальной: она предполагает, что в будущем после выбора действияиз состоянияагент будет вести себя оптимально. Определение неконструктивное, конечно, поскольку в реальности мы так сделать не можем, зато обладает интересным свойством. Если мы каким-то чудом узнали, то мы знаем оптимальную стратегию. Действительно: представьте, что вы находитесь в состоянии, вам нужно сделать выбор из трёх действий, и вы знаете значения. Вы знаете, что если выберете первое действие, то в будущем сможете набрать не более чем, допустим,награды. При этом вы знаете, что существует какая-то стратегия, на которой достигается максимум в определении оптимальной Q-функции, то есть которая действительно позволяет набрать эти +3. Вы знаете, что если выберете второе действие, то в будущем сможете набрать, допустим,, а для третьего действия. Вопрос: так как нужно действовать? Интуиция подсказывает, что надо просто выбирать действие, что позволит набрать +10, ведь по определению больше набрать никак не получится. Значит, выбор в этом состоянии действияоптимален. Эта интуиция нас не обманывает, и принцип такого выбора называетсяпринципом оптимальности Беллмана. Выбор того действия, на котором достигается максимум по действиям Q-функции, называетсяжадным(greedy) по отношению к ней. Таким образом, принцип оптимальности Беллмана гласит:жадный выбор по отношению к оптимальной Q-функции оптимален: Примечание:если Q-функция достигает максимума на нескольких действиях, то можно выбирать любое из них. Заметим, что эта оптимальная стратегия детерминирована. Этот интересный факт означает, что нам, в общем-то, необязательно искать стохастичную стратегию. Наше рассуждение пока даже показывает, что мы можем просто пытаться найти, а дальше выводить из неё оптимальную стратегию, выбирая действие жадно. Но как искать? Тут на сцене и появляется наше наблюдение про структуру задачи. Оказывается,выражается через саму себя. Действительно: рассмотрим некоторую пару состояние-действие. С одной стороны, по определению, мы в будущем сможем при условии оптимального поведения получитьнаграды. С другой стороны, после того, как мы выберем действиев состоянии, мы получим награду за один шаг, вся дальнейшая награда будет дисконтирована на, среда ответит нам сэмплированием(на результат этого сэмплирования мы уже никак повлиять не можем и по этой стохастике нашу будущую награду надо будет усреднять), а затем в состояниимы, в предположении оптимальности поведения, выберем то действие, на котором достигается максимум. Другими словами, в дальнейшем после попадания вмы сможем получитьнаграды. А значит, верно следующее рекурсивное соотношение, называемоеуравнением оптимальности Беллмана для Q-функции: Мы получили систему уравнений, связывающую значенияс самой собой. Это нелинейная система уравнений, но оказывается, что она в некотором смысле «хорошая». У неё единственное решение - и, значит, решение этого уравнения можно считать эквивалентным определением, - и его можно искатьметодом простой итерации. Метод простой итерации решения систем уравнений позволяет улучшать своё текущее приближениерешения некоторого уравнения видаего подстановкой в правую часть. То есть: инициализируем произвольную функцию, которая будет приближать, затем итеративно будем подставлять её в правую часть уравнений оптимальности Беллмана и полученным значением обновлять наше приближение: Такая процедура в пределе приведёт нас к истинной, а значит и оптимальной стратегии. Кстати, когда вы в прошлом встречались с динамическим программированием, вы скорее всего неявно использовали именно эту идею, разве что часто в задачах для решения уравнений оптимальности Беллмана можно просто последовательно исключать неизвестные переменные; но метод простой итерации даёт более общую схему, применимую всегда. А сейчас для нас принципиально следующее: если у нас есть какое-то приближение, то вычисление правой части уравнения оптимальности Беллмана позволит получить приближение лучше."
            }
        ]
    },
    {
        "id": "q_0331",
        "question": "Какие два существенных ограничивающих условия необходимы для решения уравнений оптимальности Беллмана методом простой итерации в реальности?",
        "answers": [
            "Во-первых, возможность хранить текущее приближение в памяти, что требует конечных и небольших пространств состояний и действий. Во-вторых, необходимость уметь вычислять выражение в правой части уравнения оптимальности Беллмана, включая математическое ожидание по функции переходов, которую часто не знают."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "Решать методом простой итерации уравнения оптимальности Беллмана и таким образом получатьв реальности можно только при двух очень существенных ограничивающих условиях. Нужно, чтобы, во-первых, мы могли хранить как-то текущее приближениев памяти. Это возможно только если пространства состояний и действий конечные и не очень большие, то есть, например, в вашем MDP всего 10 состояний и 5 действий, тогда— это табличка 10x5. Но что, если вы хотите научиться играть в видеоигру, и состояние — это входное изображение? Тогда множество картинок, которые вам может показать видеоигра, сохранить в памяти уже не получится. Ну, допустим пока, что число состояний и число действий не очень большое, и мы всё-таки можем хранить таблицу в памяти, а позже мы снимем это ограничение, моделируяпри помощи нейросети. Во-вторых, нам необходимо уметь считать выражение, стоящее справа в уравнение оптимальности Беллмана: Мало того, что в сложных средах взять мат.ожидание по функции переходовв реальности мы не сможем, так ещё и обычно мы эту функцию переходов на самом деле не знаем. Представьте, что вы катаетесь на велосипеде: можете ли вы по текущему состоянию окружающего мира, например, положению всех атомов во вселенной, рассказать, с какими вероятностями в каком состоянии мир окажется в следующий момент времени? Это соображение также подсказывает, что было бы здорово, если б мы смогли решать задачу, избегая даже попыток выучить эту сложную функцию переходов. Что нам доступно? Мы можем взятькакую-нибудьстратегию(важный момент: мы должны сами выбрать какую) и повзаимодействовать ею со средой. «Попробовать решить задачу». Мы можем сгенерировать при помощицелую траекторию или даже сделать всего один шаг в среде. Таким образом мысоберём данные: допустим, мы были в состояниии сделали выбор действия, тогда мы узнаем, какую наградумы получаем за такой шаг и, самое главное, в какое состояниенас перевела среда. Полученный— сэмпл из функции переходов. Собранная так информация — четвёрка— называетсяпереходом(transition), и может быть как-то использована для оптимизации нашей стратегии. Можем ли мы, используя лишь переходы, то есть имея на руках лишь сэмплы, как-то пользоваться схемой динамического программирования? Что, если мы будем заменять значениене на которое мы не можем посчитать, а на его Монте Карло оценку: где— сэмпл из функции переходов из собранного нами опыта? В среднем-то такая замена верная. Такая Монте-Карло оценка правой части для заданного переходиканазываетсяБеллмановским таргетом, то есть «целевой переменной». Почему такое название — мы увидим чуть позже. Чтобы понять, как нам нужно действовать, рассмотрим какую-нибудь типичную ситуацию. Допустим, после выполнения действияиз некоторого состояниясреда награждает наси перекидывает нас с равными вероятностями то в состояние, для которого, то в состояние, для которого. Метод простой итерации говорит, что на очередной итерации нужно заменитьна, но в реальности мы встретимся лишь с одним исходом, и таргет — Монте-Карло оценка правой части уравнения оптимальности Беллмана — будет с вероятностью 0.5 равен, а с вероятностью 0.5 равен. Ясно, что нельзя просто взять и жёстко заменять наше текущее приближениена посчитанный Беллмановский таргет по некоторому одному переходу, поскольку нам могло повезти (мы увидели) или не повезти (мы увидели). Давайте вместо этого поступать также, как учат среднее по выборке: не сдвигать «жёстко» наше текущее приближение в значение очередного сэмпла, асмешиватьтекущее приближение с очередным сэмплом. То есть: берём переходик, и не заменяемна стохастичную оценку правой части уравнения оптимальности Беллмана, а только сдвигаемся в его сторону: Таким образом, мы проводимэкспоненциальное сглаживаниестарого приближенияи новой оценки правой части уравнения оптимальности Беллмана со свежим сэмплом. Выборздесь определяет, насколько сильно мы обращаем внимание на последние сэмплы, и имеет тот же физический смысл, что и learning rate. В среднем по стохастике (а стохастика в этой формуле обновления заложена в случайном) мы будем сдвигаться в сторону и значит применять этакий «зашумлённый» метод простой итерации. Итак, возникает следующая идея. Будем как-то взаимодействовать со средой и собирать переходики. Для каждого перехода будем обновлять одну ячейку нашей Q-таблицы размера число состояний на число действий по вышеуказанной формуле. Таким образом мы получим как бы «зашумлённый» метод простой итерации, где мы на каждом шаге обновляем только одну ячейку таблицы, и не заменяем жёстко значение на правую часть уравнений оптимальности, а лишь сдвигаемся по некоторому в среднем верному стохастичному направлению. Очень похоже на стохастическую оптимизацию вроде стохастического градиентного спуска, и поэтому гарантии сходимости выглядят схожим образом. Оказывается, такой алгоритм сходится к истинной, если для любой парымы в ходе всего процесса проводим бесконечное количество обновлений, а learning rate (гиперпараметр) в них ведёт себя как learning rate из условий сходимости стохастического градиентного спуска: Этот алгоритм, к которому мы уже практически пришли, называетсяQ-learning, «обучение оптимальной Q-функции». Нам, однако, осталось ответить на один вопрос: так как же нужно собирать данные, чтобы удовлетворить требованиям для сходимости? Как взаимодействовать со средой так, чтобы мы каждую ячейкуне прекращали обновлять?"
            }
        ]
    },
    {
        "id": "q_0332",
        "question": "Какой простой способ решения дилеммы исследования-использования предлагается в контексте обучения с подкреплением?",
        "answers": [
            "Предлагается использовать ε-жадную стратегию, которая с вероятностью ε выбирает случайное действие, а с вероятностью 1-ε — жадное действие на основе текущей аппроксимации Q-функции."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "Мы уже встречали дилемму exploration-exploitation (букв. «исследования-использования») в параграфе протюнинг гиперпараметров. Задача многоруких бандитов, которая там встретилась, на самом деле является частным случаем задачи обучения с подкреплением, в котором после первого выбора действия эпизод гарантированно завершается, и этот частный случай задачи часто используется для изучения этой дилеммы. Рассмотрим эту дилемму в нашем контексте. Допустим, на очередном шаге алгоритма у нас есть некоторое приближение. Приближение это, конечно, неточное, поскольку алгоритм, если и сходится к истинной оптимальной Q-функции, то на бесконечности. Как нужно взаимодействовать со средой? Если вы хотите набрать максимальную награду, наверное, стоит воспользоваться нашей теорией и заниматьсяexploitation-ом, выбирая действие жадно: Увы, такой выбор не факт что совпадёт с истинной оптимальной стратегией, а главное, он детерминирован. Это значит, что при взаимодействии этой стратегией со средой, многие парыникогда не будут встречаться просто потому, что мы никогда не выбираем действиев состоянии. А тогда мы, получается, рискуем больше никогда не обновить ячейкудля таких пар! Такие ситуации запросто могут привести к застреванию алгоритма. Мы хотели научиться кататься на велосипеде и получали +0.1 за каждый пройденный метр и -5 за каждое попадание в дерево. После первых проб и ошибок мы обнаружили, что катание на велосипеде приносит нам -5, поскольку мы очень скоро врезаемся в деревья и обновляли нашу аппроксимацию Q-функции сэмплами с негативной наградой; зато если мы не будем даже забираться на велосипед и просто займёмся ничего не деланьем, то мы сможем избежать деревьев и будем получать 0. Просто из-за того, что в нашей стратегии взаимодействия со средой никогда не встречались те, которые приводят к положительной награде, и жадная стратегия по отношению к нашей текущей аппроксимации Q-функции никогда не выбирает их. Поэтому нам нужно экспериментировать и пробовать новые варианты. Режимexploration-а предполагает, что мы взаимодействуем со средой при помощи какой-нибудьстохастичнойстратегии. Например, такой стратегией является случайная стратегия, выбирающая рандомные действия. Как ни странно, сбор опыта при помощи случайной стратегии позволяет побывать с ненулевой вероятностью во всех областях пространства состояний, и теоретически даже наш алгоритм обучения Q-функции будет сходится. Означает ли это, что exploration-а хватит, и на exploitation можно забить? В реальности мы понимаем, что добраться до самых интересных областей пространства состояний, где функция награда самая большая, не так-то просто, и случайная стратегия хоть и будет это делать с ненулевой вероятностью, но вероятность эта будет экспоненциально маленькая. А для сходимости нам нужно обновить ячейкидля этих интересных состояний бесконечно много раз, то есть нам придётся дожидаться необычайно редкого везения далеко не один раз. Куда разумнее использовать уже имеющиеся знания и при помощи жадной стратегии, которая уже что-то умеет, идти к этим интересным состояниям. Поэтому для решения дилеммы exploration-exploitation обычно берут нашу текущую жадную стратегию и что-нибудь с ней делают такое, чтобы она стала чуть-чуть случайной. Например, с вероятностьювыбирают случайное действие, а с вероятностью— жадное. Тогда мы чаще всё-таки и знаниями пользуемся, и любое действие с ненулевой вероятностью выбираем; такая стратегия называется-жадной, и она является самым простым способом как-то порешать эту дилемму. Давайте закрепим, что у нас получилось, в виде табличного алгоритма обучения с подкреплением под названием Q-learning: Проинициализироватьпроизвольным образом. Пронаблюдатьиз среды. Для: с вероятностьювыбрать действиеслучайно, иначе жадно: отправить действиев среду, получить награду за шаги следующее состояние. обновить одну ячейку таблицы:"
            }
        ]
    },
    {
        "id": "q_0333",
        "question": "Какие два способа борьбы с проблемой коррелированных данных при обучении Deep Q-learning описаны в тексте?",
        "answers": [
            "Первый способ — запуск параллельных агентов в виртуальном симуляторе, где каждый процесс взаимодействует со средой независимо. Второй способ — использование реплей буфера, в который сохраняются переходы, а затем из него случайно сэмплируются данные для обучения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "Чтобы окончательно собрать алгоритмDeep Q-learning(обычно называемыйDQN,Deep Q-network), нам понадобится сделать последний шаг, связанный опять со сбором данных. Коли мы хотим обучать нейросетку, нам нужно для каждого обновления весов откуда-то взять целый мини-батч данных, то есть батч переходов, чтобы по нему усреднить оценку градиента. Однако, если мы возьмём среду, сделаем в нейшагов, то встреченные намипереходов будут очень похожи друг на друга: они все придут из одной и той же области пространства состояний. Обучение нейросетки на скоррелированных данных — плохая идея, поскольку такая модель быстро забудет, что она учила на прошлых итерациях. Бороться с этой проблемой можно двумя способами. Первый способ, доступный всегда, когда среда задана при помощи виртуального симулятора — запускпараллельных агентов. Запускается параллельнопроцессов взаимодействия агента со средой, и для того, чтобы собрать очередной мини-батч переходов для обучения, во всех экземплярах проводится по одному шагу взаимодействия, собирается по одному переходику. Такой мини-батч уже будет разнообразным. Более интересный второй способ. Давайте после очередного шага взаимодействия со средой мы не будем тут же использовать переходдля обновления модели, а запомним этот переход и положим его себе в коллекцию. Память со всеми встретившимися в ходе проб и ошибок переходаминазываетсяреплей буфером(replay bufferилиexperience replay). Теперь для того, чтобы обновить веса нашей сети, мы возьмём и случайно засэмплируем из равномерного распределения желаемое количество переходов из всей истории. Однако, использование реплей буфера возможно далеко не во всех алгоритмах обучения с подкреплением. Дело в том, что некоторые алгоритмы обучения с подкреплением требуют, чтобы данные для очередного шага обновления весов были сгенерированы именно текущей, самой свежей версией стратегии. Такие алгоритмы относят к классуon-policy: они могут улучшать стратегию только по данным из неё же самой («on policy»). Примером on-policy алгоритмов выступают, например, эволюционные алгоритмы. Как они устроены: например, можно завести популяцию стратегий, поиграть каждой со средой, отобрать лучшие и как-то породить новую популяцию (подробнее про одну из самых успешных схем в рамках такой идеи можно посмотретьздесь). Как бы ни была устроена эта схема, эволюционный алгоритм никак не может использовать данные из, например, старых, плохих стратегий, которые вели себя, скажем, не сильно лучше случайной стратегии. Поэтому неизбежно в эволюционном подходе нужно свежую популяцию отправлять в среду и собирать новые данные перед каждым следующим шагом. И вот важный момент: Deep Q-learning, как и обычный Q-learning, относится кoff-policyалгоритмам обучения с подкреплением. Совершенно неважно, какая стратегия, умная или не очень, старая или новая, породила переход, нам всё равно нужно решать уравнение оптимальности Беллмана в том числе и для этой парыи нам достаточно при построении таргета лишь чтобыбыл сэмплом из функции переходов (а она-то как раз одна вне зависимости от того, какая стратегия взаимодействует в среде). Поэтому обновлять модельмы можем по совершенно произвольному опыту, и, значит, мы в том числе можем использовать experience replay. В любом случае, даже в сложных средах, при взаимодействии со средой мы всё равно должны как-то разрешить дилемму exploration-exploitation, и пользоваться, например,-жадной стратегией исследования. Итак, алгоритм DQN выглядит так: Проинициализировать нейросеть. Проинициализировать таргет-сеть, положив. Пронаблюдатьиз среды. Для: с вероятностьювыбрать действиеслучайно, иначе жадно: отправить действиев среду, получить награду за шаги следующее состояние. добавить переходв реплей буфер. если в реплей буфере скопилось достаточное число переходиков, провести шаг обучения. Для этого сэмплируем мини-батч переходиковиз буфера. для каждого переходика считаем целевую переменную: сделать шаг градиентного спуска для обновления, минимизируя еслиделится на 1000, обновить таргет-сеть:. Алгоритм DQN не требует никаких handcrafted признаков или специфических настроек под заданную игру. Один и тот же алгоритм, с одними и теми же гиперпараметрами, можно запустить на любой из 57 игр древней консоли Atari (пример игры в Breakout) и получить какую-то стратегию. Для сравнения алгоритмов RL между собой результаты обычно усредняют по всем 57 играм Atari. Недавно алгоритм под названием Agent57, объединяющий довольно много модификаций и улучшений DQN и развивающий эту идею,смог победить человека сразу во всех этих 57 играх."
            }
        ]
    },
    {
        "id": "q_0334",
        "question": "Какие алгоритмы относятся к подходу, позволяющему создавать off-policy алгоритмы для непрерывных пространств действий?",
        "answers": [
            "К такому подходу относятся алгоритмы DDPG, TD3 и SAC."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "Всюду в DQN мы предполагали, что пространство действий дискретно и маленькое, чтобы мы могли считать жадную стратегиюи считать максимум в формуле целевой переменной. Если пространство действий непрерывно, и на каждом шаге от агента ожидается выбор нескольких вещественных чисел, то как это делать непонятно. Такая ситуация повсюду возникает в робототехнике. Там каждое сочленение робота можно, например, поворачивать вправо / влево, и такие действия проще описывать набором чисел в диапазоне [-1, 1], где -1 — крайне левое положение, +1 — крайне правое, и доступны любые промежуточные варианты. При этом дискретизация действий не вариант из-за экспоненциального взрыва числа вариантов и потери семантики действий. Нам, в общем-то, нужно в DQN только одну проблему решить: как-то научиться аргмаксимум по действиям брать. А давайте, коли мы не знаем, приблизим его другой нейросеткой. А то есть, заведём вторую нейросетьс параметрами, и будем учить её так, чтобы Как это сделать? Ну, будем на каждой итерации алгоритма брать батч состоянийиз нашего реплей буфера и будем учитьвыдавать такие действия, на которых наша Q-функция выдаёт большие скалярные значения: Причём, поскольку действия непрерывные, всё слева дифференцируемо и мы можем напрямую применять самый обычный backpropagation! Теперь когда на руках есть приближение, можно просто использовать его всюду, где нам нужны аргмаксимумы и максимумы от нашей Q-функции. Мы получилиActor-Criticсхему: у нас естьактёр,— детерминированная стратегия, икритик, который оценивает выбор действий актёром и предоставляет градиент для его улучшения. Актёр учится выбирать действия, которые больше всего нравятся критику, а критик учится регрессией с целевой переменной Эта прикольная рабочая эвристика позволяет придумать off-policy алгоритмы для непрерывных пространств действий; к такому подходу относятся такие алгоритмы, как DDPG, TD3 и SAC."
            }
        ]
    },
    {
        "id": "q_0335",
        "question": "Какие основные недостатки алгоритмов RL с таргетами, заглядывающими на один шаг вперёд, упоминаются в тексте?",
        "answers": [
            "Основными недостатками являются проблема накапливающейся ошибки при распространении сигнала на много шагов, необходимость обучения Q-функции вместо прямого запоминания хороших действий и детерминированность стратегии, которая мешает обновлению Q-функции для всех пар состояние-действие."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "В рассмотренных алгоритмах есть несколько приниципиальных ограничений, которые вытекают непосредственно из самой идеи подхода. Мы учимся с таргетов, заглядывающих всего на один шаг вперёд, использующих только; это чревато проблемой накапливающейся ошибки, поскольку если между выполнением действия и получением награды +1 проходит 100 шагов, нам нужно на сто шагов «распространять» полученный сигнал. Мы должны учитьвместо того, чтобы как-то напрямую («end-to-end») запомнить, какие действия в каких состояниях хорошие. Наконец, наша стратегия всегда детерминирована, когда для взаимодействия со средой во время сбора данных, например, нам позарез нужна была стохастичная, чтобы гарантированно обновлять Q-функцию для всех пар, и эту проблему пришлось закрывать костылями. Есть второй подход model-free алгоритмов RL, называемыйPolicy Gradient, который позволяет избежать вышеперечисленных недостатков за счёт on-policy режима работы. Идея выглядит так: давайте будем искать стратегию в классе стохастичных стратегий, то есть заведём нейросеть, моделирующуюнапрямую. Тогда наш функционал, который мы оптимизируем, дифференцируем по параметрам, и градиент равен: где- reward-to-go с шага, то есть награда, собранная в сыгранном эпизоде после шага: Эта формула говорит нам, что градиент нашего функционала — это тоже мат.ожидание по траекториям. А значит, мы можем попробовать посчитать какую-то оценку этого градиента, заменив мат.ожидание на Монте Карло оценку, и просто начать оптимизировать наш функционал самым обычным стохастическим градиентным спуском! А то есть: берём нашу стратегиюс текущими значениями параметров, играем эпизод (или несколько) в среде, то есть сэмплируем, и затем делаем шаг градиентного подъёма: Почему эта идея приводит к on-policy подходу? Для каждого шага градиентного шага нам обязательно нужно взятьс самыми свежими, с текущими весами, и никакая другая траектория, порождённая какой-то другой стратегией, нам не подойдёт. Поэтому для каждой итерации алгоритма нам придётся заново играть очередной эпизод со средой. Этоsample-inefficient: неэффективно по числу сэмплов, мы собираем слишком много данных и очень неэффективно с ними работаем. Policy Gradient алгоритмы пытаются по-разному бороться с этой неэффективностью, опять же обращаясь к теории оценочных функций и бутстрапированным оценкам, позволяющим предсказывать будущие награды, не доигрывая эпизоды целиком до конца. Большинство этих алгоритмов остаются в on-policy режиме и применимы в любых пространствах действий. К этим алгоритмам относятся такие алгоритмы, как Advantage Actor-Critic (A2C), Trust-Region Policy Optimization (TRPO) и Proximal Policy Optimization (PPO)."
            }
        ]
    },
    {
        "id": "q_0336",
        "question": "Какие игры, помимо Го, можно обучать с помощью алгоритма AlphaZero?",
        "answers": [
            "Алгоритм AlphaZero можно запустить обучаться на шахматах и сёги."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
                "text": "Мы до сих пор разбиралиmodel-freeалгоритмы RL, которые обходились без знаний ои никак не пытались приближать это распределение. Однако, в каких-нибудь пятнашках функция переходов нам известна: мы знаем, в какое состояние перейдёт среда, если мы выберем некоторое действие в таком-то состоянии. Понятно, что эту информацию было бы здорово как-то использовать. Существует обширный классmodel-based, который либо предполагает, что функция переходов дана, либо мы учим её приближение, используяиз нашего опыта в качестве обучающей выборки. Алгоритм AlphaZero на основе этого подходапревзошёл человека в игру Го, которая считалась куда более сложной игрой, чем шахматы; причём этот алгоритм возможно запустить обучаться на любой игре:как на Го, так и на шахматах или сёги. Обучение с подкреплением стремится построить алгоритмы, способные обучаться решать любую задачу, представленную в формализме MDP. Как и обычные методы оптимизации, их можно использовать в виде чёрной коробочки из готовых библиотек, например,OpenAI Stable Baselines. Внутри таких коробочек будет, однако, довольно много гиперпараметров, которые пока не совсем понятно как настраивать под ту или иную практическую задачу. И хотя успехи Deep RL демонстрируют, что эти алгоритмы способны обучаться невероятно сложным задачам вродепобеды над людьми в Dota 2ив StarCraft II, они требуют для этого колоссального количества ресурсов. Поиск более эффективных процедур — открытая задача в Deep RL. В ШАДе есть курс Practical RL, на котором вы погрузитесь глубже в мир глубокого обучения с подкреплением, разберётесь в более продвинутых алгоритмах и попробуете пообучать нейронки решать разные задачки в разных средах."
            }
        ]
    },
    {
        "id": "q_0337",
        "question": "Какую аналогию используют для объяснения метода градиентного бустинга, сравнивая его с гольфистом?",
        "answers": [
            "Бустинг сравнивают с гольфистом, который постепенно загоняет мяч в лунку. Каждый следующий удар гольфиста — это поправка, которую вносит очередной базовый алгоритм в композицию, приближая предсказание к истинному значению."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/gradientnyj-busting",
                "text": "Рассмотрим задачу регрессии с квадратичной функцией потерь: Для решения будем строить композицию избазовых алгоритмов: Если мы обучим единственное решающее дерево, то качество такой модели, скорее всего, будет низким. Однако мы знаем, на каких объектах построенное дерево давало точные предсказания, а на каких ошибалось. Попробуем использовать эту информацию и обучим ещё одну модель. Допустим, что предсказание первой модели на объектена 10 больше, чем необходимо (т.е.). Если бы мы могли обучить новую модель, которая набудет выдавать ответ, то сумма ответов этих двух моделей на объектев точности совпала бы с истинным значением: Другими словами, если вторая модель научится предсказывать разницу между реальным значением и ответом первой, то это позволит уменьшить ошибку композиции. В реальности вторая модель тоже не сможет обучиться идеально, поэтому обучим третью, которая будет «компенсировать» неточности первых двух. Будем продолжать так, пока не построим композицию изалгоритмов. Для объяснения метода градиентного бустинга полезно воспользоваться следующей аналогией. Бустинг можно представить как гольфиста, цель которого — загнать мяч в лунку с координатой. Положение мяча здесь – ответ композиции. Гольфист мог бы один раз ударить по мячу, не попасть в лунку и пойти домой, но настырность заставляет его продолжить. По счастью, ему не нужно начинать каждый раз с начальной позиции. Следующий удар гольфиста переводит мяч из текущего положенияв положение. Каждый следующий удар — это та поправка, которую вносит очередной базовый алгоритм в композицию. Если гольфист все делает правильно, то функция потерь будет уменьшаться: то есть мяч постепенно будет приближаться к лунке. Удары при этом делаются не хаотично. Гольфист оценивает текущее положение мяча относительно лунки и следующим ударом старается нивелировать те проблемы, которые он создал себе всеми предыдущими. Подбираясь к лунке, он будет бить всё аккуратнее и, возможно, даже возьмет другую клюшку, но точно не будет лупить так же, как из первоначальной позиции. В итоге комбинация всех ударов рано или поздно перенесет мяч в лунку. Подобно тому, как гольфист постепенно подводит мяч к цели, бустинг с каждым новым базовым алгоритмом всё больше приближает предсказание к истинному значению метки объекта. Рассмотрим теперь другую аналогию — разложение функции в ряд Тейлора. Из курса математического анализа известно, что (достаточно хорошую) бесконечно дифференцируемую функциюна интервалеможно представить в виде бесконечной суммы степенных функций: Одна, самая первая степенная функция в разложении, очень грубо приближает. Прибавляя к ней следующую, мы получим более точное приближение. Каждая следующая элементарная функция увеличивает точность приближения, но менее заметна в общей сумме. Если нам не требуется абсолютно точное разложение, вместо бесконечного ряда Тейлора мы можем ограничиться суммой его первыхэлементов. Таким образом, интересующую нас функцию мы с некоторой точностью представили в виде суммы «простых» функций. Перенесём эту идею на задачи машинного обучения. В машинном обучении мы пытаемся по выборкевосстановить неизвестную истинную зависимость. Прежде всего, мы выбираем подходящий алгоритм. Мы можем выбрать «сложный» алгоритм, который сразу хорошо выучит истинную зависимость. А можем обучить «простой», который выучит истинную зависимость посредственно. Затем мы добавим к нему ещё один такой простой алгоритм, чтобы уточнить предсказание первого алгоритма. Продолжая этот процесс, мы получим сумму простых алгоритмов, где первый алгоритм грубо приближает истинную зависимость, а каждый следующий делает приближение всё точнее."
            }
        ]
    },
    {
        "id": "q_0338",
        "question": "Какой алгоритм используется для корректировки предсказаний на каждом шаге построения композиции?",
        "answers": [
            "На каждом шаге для корректировки предсказаний используется решающее дерево фиксированной глубины, которое обучается предсказывать разность между правильным ответом и текущим предсказанием композиции."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/gradientnyj-busting",
                "text": "Рассмотрим тот же пример с задачей регрессии и квадратичной функцией потерь: Для решения также будем строить композицию избазовых алгоритмов семейства: В качестве базовых алгоритмов выберем, как и условились в начале параграфа, семействорешающих деревьев некоторой фиксированной глубины. Используя известные нам методы построения решающих деревьев, обучим алгоритм, который наилучшим образом приближает целевую переменную: Построенный алгоритм, скорее всего, работает не идеально. Более того, если базовый алгоритм работает слишком хорошо на обучающей выборке, то высока вероятность переобучения: низкий уровень смещения, но высокий уровень разброса. Далее вычислим, насколько сильно отличаются предсказания этого дерева от истинных значений: Теперь мы хотим скорректироватьс помощью. В идеале так, чтобыидеально предсказывал величины, ведь в этом случае Найти совершенный алгоритм, скорее всего, не получится, но по крайней мере мы можем выбрать из семейства наилучшего представителя для такой задачи. Итак, второе решающее дерево будет обучаться предсказывать разности: Ожидается, что композиция из двух таких моделейстанет более качественно предсказывать целевую переменную. Далее рассуждения повторяются до построения всей композиции. На-ом шаге вычисляется разность между правильным ответом и текущим предсказанием композиции изалгоритмов: Затем-й алгоритм учится предсказывать эту разность: а композиция в целом обновляется по формуле Обучениебазовых алгоритмов завершает построение композиции."
            }
        ]
    },
    {
        "id": "q_0339",
        "question": "Какие авторы написали серию блог-постов о градиентном бустинге?",
        "answers": [
            "Серия блог-постов была написана Terence Parr и Jeremy Howard."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/gradientnyj-busting",
                "text": "Серия блог-постово градиентном бустинге от Terence Parr and Jeremy Howard Раздел документацииsklearn с теоретическими выкладками для градиентного бустинга"
            }
        ]
    },
    {
        "id": "q_0340",
        "question": "Какие свойства имеют оценки параметров, полученные методом моментов?",
        "answers": [
            "Оценки, полученные методом моментов, являются состоятельными, но могут быть смещёнными."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
                "text": "Метод моментов — это ещё один способ, наряду с методом максимального правдоподобия, оценки параметров распределения по данным. Суть его в том, что мы выражаем через параметры распределения теоретические значения моментовнашей случайной величины, затем считаем их выборочные оценки, приравниваем их все друг к другу и, решая полученную систему, находим оценки параметров. Можно доказать, что полученные оценки являются состоятельными, хотя могут быть смещены. Пример 1. Оценим параметры нормального распределенияс помощью метода моментов. Теоретические моменты равны Запишем систему: Из неё очевидным образом находим Легко видеть, что полученные оценки совпадают с оценками максимального правдоподобия Пример 2. Оценим параметрлогнормального распределения при известном. Будет ли оценка совпадать с оценкой, полученной с помощью метода максимального правдоподобия? Теоретическое математическое ожидание равно, откуда мы сразу находим оценку. Теперь запишем логарифм правдоподобия: Дифференцируя пои приравнивая производную к нулю, получаем что вовсе не совпадает с оценкой выше. Несколько приукрасив ситуацию, можно сделать вывод, что первые два выборочных момента позволяют если не править миром, то уверенно восстанавливать параметры распределений. А теперь давайте представим, что мы посчиталии, а семейство распределений пока не выбрали. Как же совершить этот судьбоносный выбор? Давайте посмотрим на следующие три семейства и подумаем, в каком из них мы бы стали искать распределение, зная его истинные матожидание и дисперсию? Почему-то хочется сказать, что в первом. Почему? Второе не симметрично — но почему мы так думаем? Если мы выберем третье, то добавим дополнительную информацию как минимум о том, что у распределения конечный носитель. А с чего бы? У нас такой инфомации вроде бы нет. Общая идея такова: мы будем искать распределение, которое удовлетворяет только явно заданным нами ограничениям и не отражает никакого дополнительного знания о нём. Но чтобы эти нестрогие рассуждения превратить в формулы, придётся немного обогатить наш математический аппарат и научиться измерять количество информации."
            }
        ]
    },
    {
        "id": "q_0341",
        "question": "Как можно неформально представить, что показывает энтропия случайной величины?",
        "answers": [
            "Энтропия показывает, насколько сложно предсказать значение случайной величины. Более строго — сколько в среднем бит нужно потратить, чтобы передать информацию о её значении."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
                "text": "Измерять «знание» можно с помощьюэнтропии Шэннона. Она определяется как для дискретного распределения и для непрерывного. В классическом определении логарифм двоичный, хотя, конечно, варианты с разным основанием отличаются лишь умножением на константу. Неформально можно представлять, что энтропия показывает, насколько сложно предсказать значение случайной величины. Чуть более строго — сколько в среднем бит нужно потратить, чтобы передать информацию о её значении. Пример 1. Рассмотрим схему Бернулли с вероятностью успеха. Энтропия её результата равна Давайте посмотрим на график этой функции: Минимальное значение (нулевое) энтропия принимает при. В самом деле, для такого эксперимента мы всегда можем наверняка сказать, каков будет его исход; обращаясь к другой интерпретации — чтобы сообщить кому-то о результате эксперимента, достаточнобит (ведь получатель сообщения и так понимает, что вышло). Максимальное значение принимается в точке, что вполне соответствует тому, что припредсказать исход эксперимента сложнее всего. Пример 2. Энтропия нормального распределенияравна, и чем меньше дисперсия, тем меньше энтропия, что и логично: ведь когда дисперсия мала, значения сосредоточены возле матожидания, и они становятся менее «разнообразными». Энтропия тесно связана с другим важным понятием из теории информации —дивергенцией Кульбака-Лейблера. Она определяется длякак в непрерывном случае и точно так же, но только с суммой вместо интеграла в дискретном. Дивергенцию можно представить в виде разности: Вычитаемое — это энтропия, которая, как мы уже поняли, показывает, сколько в среднем бит требуется, чтобы закодировать значение случайной величины. Уменьшаемое похоже по виду, и можно показать, что оно говорит о том, сколько в среднем бит потребуется на кодирование случайной величины с плотностьюалгоритмом, оптимизированным для кодирования случайной величины. Иными словами, дивергенция Кульбака-Лейблера говорит о том, насколько увеличится средняя длина кодов для значений, если при настройке алгоритма кодирования вместоиспользовать. Более подробно вы можете почитать, например, вэтом посте. Дивергенция Кульбака-Лейблера в некотором роде играет роль расстояния между распределениями. В частности,, причём дивергенция равна нулю, только если распределения совпадают почти всюду. Но при этом она не является симметричной: вообще говоря,. Вопрос на подумать. Пусть— распределение, заданное на отрезке. Выразите энтропию через дивергенцию Кульбака-Лейблерас равномерным на отрезке распределением."
            }
        ]
    },
    {
        "id": "q_0342",
        "question": "Какое распределение имеет наибольшую энтропию на конечном множестве из n элементов при отсутствии дополнительных ограничений?",
        "answers": [
            "Наибольшую энтропию имеет равномерное распределение, когда каждому элементу множества присваивается вероятность 1/n."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
                "text": "Теперь наконец мы готовы сформулировать, какие распределения мы хотим искать. Принцип максимальной энтропии. Среди всех распределений на заданном носителе, удовлетворяющих условиям, ...,, где— некоторые функции, мы хотим иметь дело с тем, которое имеет наибольшую энтропию. В самом деле, энтропия выражает нашу меру незнания о том, как ведёт себя распределение, и чем она больше — тем более «произвольное распределение», по крайней мере, в теории. Давайте рассмотрим несколько примеров, которые помогут ещё лучше понять, почему некоторые распределения так популярны: Пример 1. На конечном множественаибольшую энтропию имеет равномерное распределение (носитель — конечное множество изэлементов, других ограничений нет). Доказательство: Пусть,— некоторое распределение,— равномерное. Запишем их дивергенцию Кульбака-Лейблера: Так как дивергенция Кульбака-Лейблера всегда неотрицательна, получаем, что. При этом равенство возможно, только если распределения совпадают. Пример 2. Среди распределений, заданных на всей вещественной прямой и имеющих заданные матожиданиеи дисперсиюнаибольшую энтропию имеет нормальное распределение. Доказательство: Пусть— некоторое распределение,. Запишем их дивергенцию Кульбака-Лейблера: Так как дивергенция Кульбака-Лейблера всегда неотрицательна, получаем, что. При этом равенство возможно, только если распределенияисовпадают почти всюду, а с точки зрения теории вероятностей такие распределения различать не имеет смысла. Пример 3. Среди распределений, заданных на множестве положительных вещественных чисел и имеющих заданное матожиданиенаибольшую энтропию имеет показательное распределение с параметром(его плотность равна). Все хорошо знакомые нам распределения, не правда ли? Проблема в том, что они свалились на нас чудесным образом. Возникает вопрос, можно ли их было не угадать, а вывести как-нибудь? И как быть, если даны не эти конкретные, а какие-то другие ограничения? Оказывается, что при некоторых не очень обременительных ограничениях ответ можно записать с помощью распределений экспоненциального класса. Давайте же познакомимся с ними поближе."
            }
        ]
    },
    {
        "id": "q_0343",
        "question": "Какие распределения не относятся к экспоненциальному классу согласно приведённым примерам?",
        "answers": [
            "К экспоненциальным семействам не относятся равномерное распределение на отрезке, t-распределение Стьюдента, распределение Коши и смесь нормальных распределений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
                "text": "Говорят, что семейство распределений относится кэкспоненциальному классу, если оно может быть представлено в следующем виде: где— вектор вещественнозначных параметров (различные значения которых дают те или иные распределения из семейства),,— некоторая вектор-функция, и, разумеется, сумма или интеграл поравняется единице. Последнее, в частности, означает, что (или сумма в дискретном случае). Пример 1. Покажем, что нормальное распределение принадлежит экспоненциальному классу. Для этого мы должны представить привычную нам функцию плотности в виде Распишем Определим Если теперь всё-таки честно выразитьчерез(это мы оставляем в качестве лёгкого упражнения), то получится В данном случае функцияпросто равна единице. Пример 2. Покажем, что распределение Бернулли принадлежит экспоненциальному классу. Для этого попробуем преобразовать функцию вероятности (нижепринимает значенияили): Теперь мы можем положить,, и всё получится. Единственное, что смущает, — это то, что компоненты векторалинейно зависимы. Хотя это не является формальной проблемой, но всё же хочется с этим что-то сделать. Исправить это можно, если переписать и определить уже минимальное представление с,— мы ведь уже сталкивались с этим выражением, когда изучали логистическу регрессию, не так ли? Вопрос на подумать. Принадлежит ли к экспоненциальному классу семейство равномерных распределений на отрезках? Казалось бы, да: так как: В чём может быть подвох? Как мы увидели, к экспоненциальным семействам относятся как непрерывные, так и дискретные распределения. Вообще, к ним относится большая часть распределений, которыми Вам на практике может захотеться описать. В том числе: нормальное; распределение Пуассона; экспоненциальное; биномиальное, мультиномиальное (с фиксированным числом испытаний); геометрическое; -распределение; бета-распределение; гамма-распределение; распределение Дирихле. К экспоненциальным семействам не относятся, к примеру: равномерное распределение на отрезке; -распределение Стьюдента; распределение Коши; смесь нормальных распределений."
            }
        ]
    },
    {
        "id": "q_0344",
        "question": "Для каких распределений метод максимального правдоподобия совпадает с методом моментов, если в качестве моментов брать теоретические матожидания всех компонент?",
        "answers": [
            "Это совпадение методов происходит для распределений из экспоненциального класса. В этом случае теоретические матожидания всех компонент должны совпадать с их эмпирическими оценками."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
                "text": "Возможно, вас удивил странный и на первый взгляд не очень естественный вид. Но всё не просто так: оказывается, что оценка максимального правдоподобия параметров распределений из экспоненциального класса устроена очень интригующе. Запишем функцию правдоподобия выборки: Её логарифм равен Дифференцируя по, получаем Тут нам потребуется следующая Лемма. Доказательство: Как мы уже отмечали в прошлом пункте: Следовательно, Кстати, можно ещё доказать, что Приравниваяк нулю и применяя лемму, мы получаем, что Таким образом, теоретические матожидания всех компонентдолжны совпадать с их эмпирическими оценками, а метод максимального правдоподобия совпадает с методом моментов дляв качестве моментов. И в следующем пункте выяснится, что распределения из семейств, относящихся к экспоненциальному классу, это те самые распределения, которые имеют максимальную энтропию из тех, что имеют заданные моменты. **Пример.**Рассмотрим вновь логнормальное распределение: Как видим, логнормальное распределение тоже из экспоненциального класса. Вас может это удивить: ведь выше мы обсуждали, что для него метод моментов и метод максимального правдоподобия дают разные оценки. Но никакого подвоха тут нет: мы просто брали не те моменты. В данном случае,, их матожидания и надо брать; тогда для параметров, получаемых из MLE, должно выполняться Матожидания в левых частых мы должны выразить через параметры — и нам для этого совершенно не обязательно что-то интегрировать! В самом деле:"
            }
        ]
    },
    {
        "id": "q_0345",
        "question": "Какое распределение на множестве неотрицательных целых чисел с заданным математическим ожиданием обладает наибольшей энтропией?",
        "answers": [
            "Это геометрическое распределение с параметром p = 1/(λ+1), где λ — заданное математическое ожидание."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
                "text": "Теперь мы наконец готовы сформулировать одно из самых любопытных свойств семейств экспоненциального класса. В следующей теореме мы опустим некоторые не очень обременительные условия регулярности. Просто считайте, что для хороших дискретных и абсолютно непрерывных распределений, с которыми вы в основном и будете сталкиваться, это так. Теорема. Пусть— распределение, причём— вектор длиныидля некоторых фиксированных,. Тогда распределениеобладает наибольшей энтропией среди распределений с тем же носителем, для которых,. При этом оно — единственное с таким свойством: в том смысле, что любое другое распределение, обладающее этим свойством, совпадает с ним почти всюду. Рассмотрим несколько примеров: Пример 1. Среди распределений на множественеотрицательных целых чисел с заданным математическим ожиданиемнайдём распределение с максимальной энтропией. В данном случае у нас лишь одна функция, которая соответствует фиксации матожидания. Плотность будет вычисляться только в точках,и будет иметь вид В этой формуле уже безошибочно угадывается геометрическое распределение с. Параметрможно подобрать из соображений того, что математическое ожидание равно. Матожидание геометрического распределения равно, так что. Окончательно, Пример 2. Среди распределений на всей вещественной прямой с заданным математическим ожиданиемнайдём распределение с максимальной энтропией."
            }
        ]
    },
    {
        "id": "q_0346",
        "question": "Какие две основные группы методов поиска ближайших соседей существуют?",
        "answers": [
            "Методы поиска ближайших соседей делятся на точные и приближённые. Приближённые методы находят соседей лишь приближённо, то есть найденные объекты будут близки, но не обязательно самыми близкими."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metricheskiye-metody",
                "text": "Для того чтобы применять метод ближайших соседей, нужно уметь как-то находить этих самых соседей. С первого взгляда может показаться, что никакой проблемы нет: действительно, можно ведь просто перебрать все объекты из обучающей выборки, посчитать для каждого из них расстояние до тестового объекта и затем найти минимум. Однако несмотря на то что сложность такого поиска линейная по, она также зависит и от размерности пространства признаков. Если, то сложность такого алгоритма поиска. Если вспомнить, что в типичной задаче машинного обучения количество признаковможет быть порядка, а размер выборки и вовсе может исчисляться десятками и сотнями тысяч объектов, то становится ясно, что такая сложность никуда не годится. Проблема осложняется ещё и тем, что данный поиск необходимо выполнять на этапе применения модели, который должен быть быстрым. Всё это означает, что возникает необходимость в более быстрых методах поиска ближайших соседей, чем простой перебор. Все такие методы можно поделить на две основные группы: точные и приближённые. Последние, как следует из их названия, находят соседей лишь приближённо, то есть найденные объекты хоть и будут действительно близки, но не обязательно будут самыми близкими. В этом разделе мы подробнее рассмотрим методы из каждой группы. Перед началом обзора стоит сказать, что хоть мы и рассматриваем алгоритмы поиска соседей именно в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба»."
            }
        ]
    },
    {
        "id": "q_0347",
        "question": "Какие два основных точных метода существуют для решения задачи поиска ближайших соседей?",
        "answers": [
            "Первый метод — полный перебор с различными эвристиками, например, выбор подмножества признаков для оценки расстояния. Второй метод — использование k-d-деревьев (k-dimensional tree), которые являются аналогом бинарных деревьев поиска в многомерном пространстве."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metricheskiye-metody",
                "text": "Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие эвристики хоть и могут давать некоторый выигрыш по времени, но не улучшат асимптотическую сложность. Второй — k-d-деревья, о которых стоит поговорить подробнее. Представим на секунду, что у нас есть всего лишь один признак, то есть объекты выражаются вещественными числами, а не векторами. В этом случае для поиска ближайшего соседа напрашивается всем вам известное бинарное дерево поиска, которое позволяет находить элементы за логарифмическое время. Оказывается, существует аналог данной структуры в многомерном пространстве, который называетсяk-d-дерево(k-d tree, сокращение от k-dimensional tree). Как и в обычном дереве поиска, в k-d-дереве каждый узел является объектом обучающей выборки, который особым образом делит пространство на два полупространства. Таким образом, всё пространство оказывается поделено на множество малых областей, и такое деление оказывается очень полезным при поиске ближайших соседей. Рассмотрим подробнее, как строится такое дерево. Трудность в применении обычного дерева поиска состоит в том, что мы не можем напрямую сравнить два вектора так же, как два вещественных числа. Чтобы эту проблему преодолеть, узлы дерева будут делить пространство лишь по одной оси. При движении вниз по дереву оси, по которым точки делят пространство, циклически сменяют друг друга. Например, в двумерном пространстве корень будет отвечать за деление по x-координате, его сыновья — за деление по y-координате, а внуки — снова за x-координату, и т. д. Посмотрим, как это работает на примере: На картинке выше кореньделит все точки по оси х: слева оказываются точки, у которых, а справа — те, у которых. Аналогично левый сын корняделит своё поддерево по оси y: слева оказываются точки, у которых, а справа — те, у которых. Остаётся вопрос — как выбирать точки, которые будут делить пространство пополам? Чтобы дерево было сбалансированным, нужно находить точку с медианой, соответствующей уровню поддерева координаты. На практике часто ограничиваются выбором случайной точки или любой эвристикой по приближённому поиску медианы (например, медиана некоторого подмножества точек). Это позволяет ускорить построение дерева, но убирает все гарантии на его сбалансированность. Добавлять новые точки можно так же, как и в одномерном дереве поиска. Спускаясь по дереву, можно однозначно определить лист, к которому нужно подвесить новую точку, чтобы не нарушить все свойства дерева. При добавлении большого количества точек, однако, дерево может перестать быть сбалансированным, и нужно проводить ребалансировку. Также существуют варианты k-d-деревьев, которые сохраняют сбалансированность при добавлении / удалении точек. Поговорим теперь про то, как же находить ближайших соседей с помощью такого дерева. Будем производить обход дерева в глубину с двумя модификациями. Во-первых, будем запоминать наиболее близкую точку. Это позволит не заходить в поддеревья, задающие области, которые заведомо дальше, чем текущая наиболее близкая точка, поэтому не имеет смысла искать в них ближайших соседей. Во-вторых, будем прежде всего обходить те поддеревья, которые задают наиболее близкие области, а значит, с большей вероятностью содержат ближайшего соседа. Сложность метода по размеру обучающей выборки в среднем равнапри равномерном распределении точек. При большой размерности пространства, однако, алгоритму приходится посещать больше ветвей дерева, чтобы найти ближайших соседей. Например, если, то сложность становится примерно такой же, как и в случае полного перебора. В общем случае считается, что для того чтобы асимптотика действительно была логарифмической, нужно, чтобы. Поэтому уже при количестве признаков порядка сотни алгоритм не даёт существенных преимуществ перед полным перебором. Почитать по теме: Хорошая презентация, объясняющая структуру и поиск соседей. Балансировка деревьев."
            }
        ]
    },
    {
        "id": "q_0348",
        "question": "Что такое горизонт прогнозирования в контексте временных рядов?",
        "answers": [
            "Горизонт прогнозирования — это максимальное количество шагов вперёд, на которое строится прогноз временного ряда. Он обозначается как h и определяет, насколько далеко в будущее можно предсказать значения ряда на основе известных данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/vremennye-ryady",
                "text": "Временной ряд— значения меняющихся во времени признаков, полученные в некоторые моменты времени. Задача прогнозирования Пусть– временной ряд, для которого известны значения. Требуется построитьпрогноз– функцию, такую что величинакак можно лучше приближает значение, где– количество шагов, на которое нужно построить прогноз, а величина– горизонт прогнозирования, то есть максимальное количество шагов для построения прогноза. Иными словами, прогноз значения ряда в момент временистроится на основе известных значений ряда до момента времени. Кроме этого имеет смысл строитьпредсказательный интервал, то есть интервал, т.ч.. Например, пусть– значение какого-то признака в момент времени, и у нас есть значения ряда за месяц, то есть. Пусть также требуется предсказать значения ряда на неделю вперед. Тогда прогноз на первые сутки вперед будет равен, а прогноз на пятые сутки. Спустя некоторое время прогноз можно перестроить. Например, пусть прогноз перестраивается один раз в трое суток. Тогда оценку значениямы уточним как. При этом может оказаться, что функцияумеет принимать на вход лишь фиксированное количество предыдущих значений ряда. Например, если она умеем строить прогноз по последним 30 значениям ряда, то запись будет иметь вид. Иногда для уточнения того, в какой момент построен прогноз значения, указывают момент времени построения прогноза. Например, записьозначает, что прогноз на 35-й день построен в день 30, а– в день 33. Если признаков несколько, не обязательно прогнозировать каждый признак. Часто выделяется один или несколько целевых признаков, а остальные признаки являются вспомогательными и могут улучшить прогноз. Практические примеры: Прогноз погоды на 10 дней вперед. Прогноз осадков на 2 часа вперед."
            }
        ]
    },
    {
        "id": "q_0349",
        "question": "Какие два основных подхода к объяснению несовершенства модели в задаче регрессии описаны в тексте?",
        "answers": [
            "Первый подход — инженерный, где мы стремимся приблизить таргет предсказаниями наилучшим образом с помощью подобранной функции потерь. Второй — вероятностный, где неточности предсказаний объясняются случайным шумом, который добавляется к модели, и мы выбираем распределение этого шума."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Практически любая наша модель — несовершенна. Но объяснять это несовершенство можно по-разному. Представим, что мы решаем задачу регрессии: например, пытаемся по университетским оценкам выпускника предсказать его годовую зарплату. Ясно, что точная зависимость у нас не получится как минимум потому, что мы многого не знаем о выпускнике: куда он пошёл работать, насколько он усерден, как у него с soft skills и так далее. Как же нам быть? Первый вариант — просто признать, что мы не получим идеальную модель, но постараться выучить оптимальную, насколько это возможно. То есть приблизить таргет предсказаниями наилучшим образом с точки зрения какой-то меры близости, которую мы подберём из экспертных соображений. Так мы получаем простой инженерный подход к машинному обучению: есть формула, в которой присутствуют некоторые параметры (), есть формализация того, что такое «приблизить» (функция потерь) — и мы бодро решаем задачу оптимизации по параметрам. Второй вариант — свалить вину за неточности наших предсказаний на случайность. В самом деле: если мы что-то не можем измерить, то для нас это всё равно что случайный фактор. В постановке задачи мы заменяем приближённое равенствона точное Например, это может быть аддитивный шум (чаще всего так и делают): где— некоторая случайная величина, которая представляет этот самый случайный шум. Тогда получается, что для каждого конкретного объектасоответствующий ему истинный таргет — это суммаи конкретной реализации шума. При построении такой модели мы можем выбирать различные распределения шума, кодируя тем самым, какой может быть ошибка. Чаще всего выбирают гауссовский шум:с некоторой фиксированной дисперсией— но могут быть и другие варианты. Проиллюстрируем, как ведут себя данные, подчиняющиеся закону,: Вопрос на подумать. Зачем человеку может прийти в голову предположить, что в модели линейной регрессиишумимеет распределение Лапласа? А распределение Коши? Чем свойства таких моделей будут отличаться от свойств модели с нормальным шумом? Как вы могли заметить, в каждом из подходов после того, как мы зафиксировали признаки (то есть координаты), остаётся своя степень свободы: в инженерном это выбор функции потерь, а в вероятностном — выбор распределения шума. Дальше в этом параграфе мы увидим, что на самом деле эти два подхода глубинным образом связаны между собой, причём выбор функции потерь — это в некотором смысле то же самое, что выбор распределения шума."
            }
        ]
    },
    {
        "id": "q_0350",
        "question": "Что представляет собой значение y_i для конкретного объекта x_i в вероятностной модели с аддитивным шумом?",
        "answers": [
            "Для конкретного объекта x_i значение y_i является константой, но для случайной величины Y оно становится случайной величиной, зависящей от x_i и параметров w."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Допустим, что мы исследуем вероятностную модель таргета с аддитивным шумом где— некоторая функция, не обязательно линейная с (неизвестными пока) параметрами, а— случайный шум с плотностью распределения. Для каждого конкретного объектазначение— это просто константа, но дляоно превращается в случайную величину, зависящую от(и ещё от, на самом деле). Таким образом, можно говорить об условном распределении Для каждого конкретногоираспределение соответствующего— это просто, ведь. Пример. Рассмотрим вероятностную модель, где. Тогда для фиксированногоимеем. Поскольку— константа, мы получаем Это можно записать и так: где выражение справа — это значение функции плотности нормального распределения с параметрамив точке. В частности,."
            }
        ]
    },
    {
        "id": "q_0351",
        "question": "Как предлагается описать ситуацию на поле в вероятностной модели удара футболиста?",
        "answers": [
            "Ситуация на поле описывается как функция от позиций и движений других игроков, судьи и зрителей, но поскольку учесть все факторы невозможно, в модель вводится случайность."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "На самом деле, мы можем для нашей задачи придумывать любую вероятностную модель, не обязательно вида. Представьте, что мы хотим предсказывать точку в плоскости штанг, в которую попадает мячом бьющий по воротам футболист. Можно предположить, что она имеет нормальное распределение со средним (цель удара), которое определяется ситуацией на поле и состянием игрока, и некоторой дисперсией (то есть скалярной ковариационной матрицей), которая тоже зависит от состояния игрока и ещё разных сложных факторов, которые мы объявим случайными. Состояние игрока — это сложное понятие, но, вероятно, мы можем выразить его, зная пульс, давление и другие физические показатели. В свою очередь, ситуацию на поле можно описать, как функцию от позиций и движений других игроков, судьи и зрителей — но всего не перечислишь, поэтому нам снова придётся привлекать случайность. Таким образом, мы получаем то, что называетсяграфической моделью: Здесь стрелки означают статистические зависимости, а отсутствие стрелок — допущение о статистической независимости. Конечно же, это лишь допущение, принятое нами для ограничения сложности модели: ведь пульс человека и давление взаимосвязаны, равно как и поведение различных игроков на поле. Но мы уже обсуждали, что каждая модель, в том числе и вероятностная, является лишь приблизительным отражением бесконечно сложного мира. Впрочем, если у нас много вычислительных ресурсов, то никто не мешает нам попробовать учесть и все пропущенные сейчас зависимости. Расписав всё по определению условной вероятности, мы получаем следующую вероятностную модель: в которой, конечно же, мы должны все вероятности расписать через какие-то понятные и логически обоснованные распределения — но пока воздержимся от этого."
            }
        ]
    },
    {
        "id": "q_0352",
        "question": "Какая функция потерь получается при обучении вероятностной модели линейной регрессии с нормальным шумом методом максимального правдоподобия?",
        "answers": [
            "При обучении вероятностной модели линейной регрессии с нормальным шумом методом максимального правдоподобия получается квадратичная функция потерь (MSE)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Мы хотим подобрать такие значения параметров, для которых модельбыла бы наиболее адекватна обучающим данным. Сутьметода максимального правдоподобия(maximum likelihood estimation) состоит в том, чтобы найти такое, для которого вероятность (а в данном, непрерывном, случае плотность вероятности) появления выборкибыла бы максимальной, то есть Величинаназываетсяфункцией правдоподобия(likelihood). Если мы считаем, что все объекты независимы, то функция правдоподобия распадается в произведение: Теперь, поскольку перемножать сложно, а складывать легко (и ещё поскольку мы надеемся, что раз наши объекты всё-таки наблюдаются в природе, их правдоподобие отлично от нуля), мы переходим к логарифму функции правдоподобия: эту функцию мы так или иначе максимизируем по, находя оценку максимального правдоподобия. Как мы уже обсуждали выше,, то есть Максимизация функции правдоподобия соответствует минимизации а это выражение можно интерпретировать, как функцию потерь. Вот и оказывается, что подбор параметров вероятностей модели с помощью метода максимального правдоподобия — это то же самое, что «инженерная» оптимизация функции потерь. Давайте посмотрим, как это выглядит в нескольких простых случаях. Пример. Давайте предположим, что наш таргет связан с данными вот так: где, то есть Случайная величинаполучается из шумасдвигом на постоянный вектор, так что она тоже распределена нормально с той же дисперсиейи со средним Правдоподобие выборки имеет вид Логарифм правдоподобия можно переписать в виде Постоянными слагаемыми можно пренебречь, и тогда оказывается, что максимизация этой величины равносильна минимизации Мы получили обычную квадратичную функцию потерь. Итак, обучать вероятностную модель линейной регрессии с нормальным шумом — это то же самое, что учить «инженерную» модель с функцией потерь MSE. Вопрос на подумать. Какая вероятностная модель соответствует обучению линейной регрессии с функцией потерь MAE"
            }
        ]
    },
    {
        "id": "q_0353",
        "question": "Какое точечное предсказание является логичным в схеме с симметричными распределениями шума с нулевым математическим ожиданием?",
        "answers": [
            "В такой схеме логичным точечным предсказанием является ŷ, так как оно совпадает с условным математическим ожиданием."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Теперь представим, что параметры подобраны, и подумаем о том, как же теперь делать предсказания. Рассмотрим модель линейной регрессии Еслиизвестен, то для нового объектасоответствующий таргет имеет вид Таким образом,дан нам не точно, а в виде распределения (и логично: ведь мы оговорились выше, что ответы у нас искажены погрешностью, проинтерпретированной, как нормальный шум). Но что делать, если требуют назвать конкретное число? Кажется логичным выдать условное матожидание, тем более что оно совпадает с условной медианой и условной модой этого распределения. Если же медиана, мода и математическое ожидание различаются, то можно выбрать что-то из них с учётом особенностей задачи. Но на практике в схемечаще всего рассматривают именно симметричные распределения с нулевым матожиданием, потому что для нихсовпадает с условным матожиданиеми является логичным точечным предсказанием. Приведём пример. Допустим шумбыл бы из экспоненциального распределения. Тогдабыла бы условным минимумом распределения. В принципе, можно придумать задачу, для которой такая постановка (предсказание минимума) была бы логичной. Но это всё же довольно экзотическая ситуация. Приводим для сравнения модели с нормальным, лапласовским и экспоненциальным шумом:"
            }
        ]
    },
    {
        "id": "q_0354",
        "question": "Какой функцией можно преобразовать любое отображение из признакового пространства в R для построения модели бинарной классификации?",
        "answers": [
            "Для преобразования любого отображения из признакового пространства в R в модель бинарной классификации используется сигмоида. Она монотонно возрастает, отображает всю числовую прямую на интервал (0,1) и позволяет получать вероятности из произвольных значений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Допустим, мы имеем дело с задачей классификации склассами. Как мы можем её решать? Самый наивный вариант — научиться по каждому объектупредсказывать некоторое число для каждого класса, и у кого число больше — тот класс и выбираем! Наверное, так можно сделать, если мы придумаем хорошую функцию потерь. Но сразу в голову приходит мысль: почему бы не начать предсказывать не просто число, а вероятность? Таким образом, задача классификации сводится к предсказанию и как будто бы выбору класса с наибольшей вероятностью. Впрочем, как мы увидим дальше, всё не всегда работает так просто. Одну такую модель — правда, только для бинарной классификации — вы уже знаете. Это логистическая регрессия: которую также можно записать в виде где— распределение Бернулли с параметром. Нахождение вероятностей классов можно разделить на два этапа: где, напомним,— это сигмоида: Сигмоида тут не просто так. Она обладает теми счастливыми свойствами, что монотонно возрастает; отображает всю числовую прямую на интервал; . Вот такой вид имеет её график: Иными словами, с помощью сигмоиды можно делать «вероятности» из чего угодно, то есть более или менее для любого отображения(из признакового пространства в) с параметрамипостроить модель бинарной классификации: Как и в случае логистической регрессии, такая модель равносильна утверждению о том, что Похожим способом можно строить и модели для многоклассовой классификации. В этом нам поможет обобщение сигмоиды, которое называетсяsoftmax: А именно, для любого отображенияиз пространства признаков вмы можем взять модель Если все наши признаки — вещественные числа, а— просто линейное отображение, то мы получаем однослойную нейронную сеть Предостережение. Всё то, что мы описали выше, вполне работает на практике (собственно, классификационные нейросети зачастую так и устроены), но корректным не является. В самом деле, мы говорим, что строим оценки вероятностей, но для подбора параметров используем не эмпирические вероятности, а только лишь значения, то есть метки предсказываемых классов. Таким образом, при обучении мы не будем различать следующие две ситуации: Это говорит нам о некоторой неполноценности такого подхода. Заметим ещё вот что. В случае бинарной классификации выбор предсказываемого класса какравносилен выбору того класса, для которого. Но если наши оценки вероятностей неадекватны, то этот вариант проваливается, и мы встаём перед проблемой выбора порога: каким должно быть значение, чтобы мы могли приписать класс 1 тем объектам, для которых? В одном из следующих параграфов мы обсудим, как всё-таки правильно предсказывать вероятности."
            }
        ]
    },
    {
        "id": "q_0355",
        "question": "Что означает ситуация, когда жёлтые точки на диаграмме калибровки всегда ниже розовых?",
        "answers": [
            "Это означает, что модель систематически завышает предсказанную вероятность принадлежности объекта к классу 1. В таком случае порог отсечения для классификации следует сдвинуть вправо."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
                "text": "Ограничимся пока случаем двухклассовой классификации — с классами 0 и 1. Если утверждается, что мы предсказываем корректную вероятность класса 1 (обозначим её), то прогноз «объектпринадлежит классу 1 с вероятностью» должен сбываться вслучаев. То есть, условно говоря, если мы возьмём все объекты, то среди них что-то около двух третей действительно имеет класс 1. На математическом языке это можно сформулировать так:Если— предсказанная вероятность класса 1, то. К сожалению, в реальной жизни— это скорее всего вещественные числа, которые будут различными для различных, и никаких вероятностей мы не посчитаем, но мы можем разбить отрезокна бины, внутри каждого из которых уже вычислить, каковая там доля объектов класса 1, и сравнить эту долю со средним значением вероятности в бине: У модели, которая идеально предсказывает вероятности (как обычно говорят, у идеальнокалиброванноймодели) жёлтые точки на диаграмме калибровки должны совпадать с розовыми. А вот на картинке выше это не так: жёлтые точки всегда ниже розовых. Давайте поймём, что это значит. Получается, что наша модель систематически завышает предсказанную вероятность (розовые точки), и порог отсечения нам, выходит, тоже надо было бы сдвинуть вправо: Но такая картинка, пожалуй, говорит о какой-то серьёзной патологии классификатора. Гораздо чаще встречаются следующие две ситуации: Слишком уверенный (overconfident) классификатор:Такое случается с сильными классификаторыми (например, нейросетями), которые учились на метки классов, а не на вероятности: тем самым процесс обучения стимулировал их всегда давать ответ, как можно более близкий к 0 или 1. Неуверенный (underconfident) классификатор: Такое может случиться, например, если мы слишком много обращаем внимания на трудные для классификации объекты на границе классов (как, скажем, в SVM), в каком-то смысле в ущерб более однозначно определяемым точкам. Этим же могут и грешить модели на основе бэггинга (например, случайный лес). Грубо говоря, среднее нескольких моделей предскажет что-то близкое к единице только если все слагаемые предскажут что-то, близкое к единице — но из-за дисперсии моделей это будет случаться реже, чем могло бы. Подробнее можно почитать встатье."
            }
        ]
    },
    {
        "id": "q_0356",
        "question": "Какие проблемы возникают при использовании полиномиальных признаков в логистической регрессии на примере из текста?",
        "answers": [
            "Возникает сочетание двух проблем: неуверенность модели в предсказаниях посередине области и очень уверенные, но ошибочные предсказания по краям области."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
                "text": "Вам даже будут приводить какие-то обоснования. Важно понимать, что происходит на самом деле, и не дать ввести себя в заблуждение. В качестве противоядия от иллюзий предлагаем рассмотреть два примера. Рассмотрим датасет c двумя классами (ниже на картинке обучающая выборка) Обучим на нём логистическую регрессию из sklearn безо всяких параметров (то есть-регуляризованную, но это не так важно). Классы не так-то просто разделить, вот и логистическая регрессия так себе справляется. Ниже изображена часть тестовой выборки вместе с предсказанными вероятностями классов для всех точек области Видим, что модель не больно-то уверена в себе, и ясно почему: признаковое описание достаточно бедное и не позволяет нам хорошо разделить классы, хотя, казалось бы, это можно довольно неплохо сделать. Попробуем поправить дело, добавив полиномиальные фичи, то есть вседляв качестве признаков, и обучив поверх этих данных логистическую регрессию. Снова нарисуем некоторые точки тестовой выборки и предсказания вероятностей для всех точек области: Видим, что у нас сочетание двух проблем: неуверенности посередине и очень уверенных ошибок по краям. Нарисуем теперь калибровочные кривые для обеих моделей: Калибровочные кривые весьма примечательны; в любом случае ясно, что с предсказанием вероятностей всё довольно плохо. Посмотрим ещё, какие вероятности наши классификаторы чаще приписывают объектам: Как и следовало ожидать, предсказания слабого классификатора тяготеют к серединке (та самая неуверенность), а среди предсказаний переобученного очень много крайне уверенных — и совсем не всегда правильных."
            }
        ]
    },
    {
        "id": "q_0357",
        "question": "При каких условиях результат, полученный для совпадающих точек, будет приблизительно верным и для достаточно близких точек?",
        "answers": [
            "Это верно, когда признаковое описание данных достаточно хорошее (классы не перемешаны как попало и близки к разделимым) и модель не переобученная (предсказания вероятностей не скачут очень резко)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
                "text": "Попробуем понять и простить её. Как мы помним, логистическая регрессия учится путём минимизации функционала Отметим между делом, что каждое слагаемое — это кроссэнтропия распределения, заданного вероятностямии, и тривиального распределения, которое равнос вероятностью. Допустим, что мы обучили по всему универсуму данныхидеальную логистическую регрессию с идеальными весами. Пусть, далее, оказалось, что у нас естьобъектовс одинаковым признаковым описанием (то есть по сути представленных одинаковыми векторами), но, возможно, разными истинными метками классов. Тогда соответствующий им кусок функции потерь имеет вид где— частота-го класса среди истинных меток. В скобках также стоит кросс-энтропия распределения, задаваемого частотой меток истинных классов, и распределения, предсказываемого логистической регрессией. Минимальное значение кросс-энтропии (и минимум функции потерь) достигается, когда Результат, полученный длясовпадающих точек будет приблизительно верным и длядостаточно близких точек в случае, когда: признаковое описание данных достаточно хорошее — классы не перемешаны как попало и всё-таки близки к разделимым; модель не переобученная — то есть, предсказания вероятностей не скачут очень уж резко — вспомните второй пример. На всех этих точках модель будет выдавать примерно долю положительных, то есть тоже хорошую оценку вероятности."
            }
        ]
    },
    {
        "id": "q_0358",
        "question": "Какие методы позволяют преобразовать численные выходы бинарного классификатора в вероятности?",
        "answers": [
            "Для этого используются методы калибровки: гистограммная калибровка, изотоническая регрессия и калибровка Платта. Гистограммная калибровка разбивает отрезок на бины и предсказывает постоянную вероятность для каждого бина, изотоническая регрессия настраивает границы бинов с условием монотонности, а калибровка Платта применяет сигмоиду с параметрами, подобранными методом максимального правдоподобия."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
                "text": "Пусть наша модель (бинарной классификации) для каждого объектавыдаёт некоторое число. Как же эти числа превратить в корректные вероятности? Гистограммная калибровка. Мы разбиваем отрезокна бины(одинаковой ширины или равномощные) и хотим на каждом из них предсказывать всегда одну и ту же вероятность:, если. Вероятностиподбираются так, чтобы они как можно лучше приближали средние метки классов на соответствующих бинах. Иными словами, мы решаем задачу Вместо разности модулей можно рассматривать и разность квадратов. Метод довольно простой и понятный, но требует подбора числа бинов и предсказывает лишь дискретное множество вероятностей. Изотоническая регрессия. Этот метод похож на предыдущий, только мы будем, во-первых, настраивать и границыбинов, а кроме того, накладываем условие. Искатьимы будем, приближаякусочно постоянной функциейот: Минимизация осуществляется при помощи pool adjacent violators algorithm, и эти страницы слишком хрупки, чтобы выдержать его формулировку. Калибровка Платтапредставляет собой по сути применение сигмоиды поверх другой модели (то есть самый наивный способ получения «вероятностей»). Более точно, если— предсказанная вероятность, то мы полагаем гдеиподбираются методом максимального правдоподобия на отложенной выборке: Для избежания переобучения Платт предлагал также заменить меткиина регуляризованные вероятности таргетов: Калибровка Платта неплохо справляется с выколачиванием вероятностей из SVM, но для более хитрых классификаторов может спасовать. В целом, можно показать, что этот метод хорошо работает, если для каждого из истинных классов предсказанные вероятностираспределы нормально с одинаковыми дисперсиями. Подробнее об этом вы можете почитать вэтой статье. Там же описано обобщение данного подхода — бета-калибровка. С большим количеством других методов калибровки вы можете познакомиться вэтой статье"
            }
        ]
    },
    {
        "id": "q_0359",
        "question": "Какие две численные метрики упоминаются для оценки качества калибровки вероятностей в бинарной классификации?",
        "answers": [
            "В тексте упоминаются Expected/Maximum calibration error (на основе разбиения на бины) и Brier score (квадратичная ошибка между предсказанными вероятностями и фактическими исходами)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
                "text": "Калибровочные кривые хорошо показывают, что есть проблемы, но как оценить наши усилия по улучшению предсказания вероятностей? Хочется иметь какую-то численную метрику. Мы упомянем две разновидности — прямое воплощение описанных выше идей. Expected/Maximum calibration error. Самый простой способ, впрочем — он наследник идеи с калибровочной кривой. А именно, разобьём отрезокна биныпо предсказанным вероятностям и вычислим или где— среднее значение, а— среднее значениедля, таких что. Проблема этого способа в том, что мы можем очень по-разному предсказывать в каждом из бинов вероятности (в том числе константой) без ущерба для метрики. Brier score. Одна из популярных метрик, которая попросту измеряет разницу между предсказанными вероятностями и: Казалось бы, в чём смысл? Немного подрастить мотивацию помогает следующий пример. Допустим, наши таргеты совершенно случайны, то есть. Тогда хорошо калиброванный классификатор должен для каждогопредсказывать вероятность; соответственно, его brier score равен. Если же классификатор хоть в одной точке выдаёт вероятность, то в маленькой окрестности он должен выдавать примерно такие же вероятности. Поскольку же таргет случаен, локальный кусочек суммы из brier score будет иметь вид, что хуже, чем получил бы всегда выдающийклассификатор. Не обязательно брать квадратичную ошибку; сгодится и наш любимый log-loss: Это же и помогает высветить ограничения подхода, если вспомнить рассуждения о калиброванности логистической регрессии. Для достаточно гладких классификатора и датасета brier score и log-loss будут адекватными средствами оценки, но если нет — возможно всякое. Вопрос на засыпку: а как быть, если у нас классификация не бинарная, а многоклассовая? Что такое хорошо калиброванный классификатор? Как это определить численно? Как заставить произвольный классификатор предсказывать вероятности? Мы не будем про это рассказывать, но призываем читателя подумать над этим самостоятельно или, например, посмотретьтуториалс ECML KDD 2020."
            }
        ]
    },
    {
        "id": "q_0360",
        "question": "Какая модель позволяет приблизить датасет с помощью меньшего количества признаков через разложение матрицы объектов-признаков?",
        "answers": [
            "Анализ главных компонент (PCA) позволяет приблизить исходный датасет с помощью меньшего количества признаков, представляя исходные признаки как линейные комбинации латентных признаков. Это достигается через приближённое разложение матрицы объектов-признаков в произведение двух матриц меньшего ранга."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "Предположим, что нашу матрицу объекты-признакимы представили в виде произведения (или, более общно, приблизили в каком-либо смысле таким произведением): где внизу указаны размеры матриц (то есть в нашем датасетеобъектов ипризнаков). Что это может означать? Мы считаем, что каждый изпризнаков нашего исходного датасета — это смесь (то есть линейная комбинация)скрытых (латентных) признаков: По сути это одна из самых простых моделей с латентными переменными, в которой исходные признаки выражаются через латентные линейным образом. Если, то мы получаем приближённое описание нашего датасета с помощью меньшего количества признаков. На уровне объектов каждый объект(-мерная строка) приобретаетлатентное представление(-мерная строка), с которой он связан соотношением. Мы можем представлять, что наши объектыпредставляют из себя не-мерное облако, а лежат на некоторой-мерной плоскости; переходя к-мерным представлениям, мы обнажаем эту структуру. Точность аппроксимации можно измерять по-разному; наиболее популярной (в силу вычислительной простоты) является норма Фробениуса— соответствующую модель называютанализом главных компонент, или PCA (Principal Component Analysis). Мы можем захотеть описать наш датасет меньшим чемколичеством признаков (а может быть, и вообще каким-то весьма маленьким). У нас может быть несколько причин для этого, например: Признаков очень много, и мы боимся, что обучение на них будет занимать очень много времени или что в процессе обучения нам потребуется слишком много оперативной памяти; Мы считаем, что в данных есть шум или что часть признаков связаны соотношением приближённой линейной зависимости — иными словами, мы уверены, что значительную часть информации можно закодировать меньшим числом признаков Мы уже обсуждали, что это можно получить, построив приближённое разложение: Математика помогает. Матрица имеет рангтогда и только тогда, когда она представляется в видедляи не представляется в таком виде для меньших. Доказывать это мы не будем, но подметим, чтоприблизить датасет линейной смесьюпризнаков — это то же самое, что приблизить матрицуматрицейранга. Качество приближения.Нам, конечно же, хочется, чтобы приближение было наилучшим — скажем, в том смысле, чтобы разностьбыла минимальной в каком-либо смысле. Можно предложить много разных метрик; остановимся на двух: Норма Фробениуса.Представим, что матрица— это просто вектор изчисел, который зачем-то записали в виде прямоугольной таблицы. Тогда его норму можно записать в видеЭту норму (а точнее, её квадрат) легко оптимизировать. Операторная-норма.Вычислять её тяжко, а уж оптимизировать вообще непонятно как, зато звучит круто. Идея в том, что отображения можно сравнивать в зависимости от того, как оно действует на векторы: чем больше оно умеет удлинять векторы — тем оно «больше»:Поскольку, достаточно брать супремум только по векторам единичной длины, то есть по единичной сфере. Так как это компакт, непрерывная функциядостигает на нём своего максимального значения, то есть мы можем переписать Мы считаем, что каждый изобъектов нашего исходного датасета — смесь (то есть линейная комбинация)скрытых объектов: Такая интерпретация может быть полезна, например, в ситуации, когда объекты — это записи с каждого из нескольких микрофонов в помещении, признаки — фреймы, а скрытые объекты — это голоса отдельных людей. Также данную модель можно интерпретировать как что-то вроде поиска типичных объектов. Эту интерпретацию лучше всего пояснить на примере. Пусть объекты нашего датасета соответствуют пользователям интернет-магазина, а признаки — товарам, причём в клетке с индексомзаписана единица, если пользователь интересовался товаром, и ноль — если нет (или, в более общей ситуации, рейтинги, которые пользователи ставят товарам). При перемножении матрицина-м месте произведении стоит скалярное произведение-й строкии-го столбца. Таким образом, степень релевантности товара пользователю моделируется скалярным произведением (напрашивается сравнение с косинусным расстоянием) вектора, представляющего-го пользователя, и вектора, представляющего-й товар. Заметим ещё, чтокоординат вектора, ответчающего пользователю, равно как икоординат вектора, отвечающего товару, можно рассматривать каклатентных признаков, которые в идеальном мире являются интерпретируемыми и характеризуют «сродство» пользователя и товара с некоторым аспектом бытия: Но матрицы в разложении обычно не абы какие — так какие из разновидностей могут быть полезны? Во всех известных вам матричных разложениях к отдельным сомножителям предъявляются определённые требования: симметричность, треугольность, ортогональность — некоторые из них (скажем, симметричность) не имеют физического смысла ни в одной из указанных выше интерпретаций. Но одно оказывается полезным. Для начала — и это важно —предположим, что матрицацентрирована по столбцам, то есть среднее в каждом из столбцов (= признаков) равно нулю (если это не так, то вычтем из каждого столбца его среднее). Теперь матрица ковариации признаков может быть с точностью до константы оценена как: И мы видим:-й и-й столбцы матрицыортогональны тогда и только тогда, когда соответствующие признаки не коррелированы. При этом-й диагональный элемент матрицы— это дисперсия-го признака. Вывод: матрица, ортонормированная по столбцам, отвечает датасету, в котором признаки не коррелированы и имеют единичную дисперсию"
            }
        ]
    },
    {
        "id": "q_0361",
        "question": "Что такое сингулярное разложение матрицы?",
        "answers": [
            "Сингулярное разложение матрицы — это разложение вида A = UΣV^T, где U и V — матрицы, ортонормированные по столбцам, а Σ — диагональная матрица с сингулярными числами на диагонали."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "С помощью сингулярного разложения можно перейти отисходных признаков к потенциально небольшому количеству «самых важных» , по-быстрому визуализовать данные или построить простенькую рекомендательную систему. Конечно, глубинные автоэнкодеры, TSNE или DSSM справятся с этим гораздо лучше, но если данных относительно немного или если хочется что-нибудь быстро попробовать «на коленке», старое доброе сингулярное разложение всегда подставит плечо. Сингулярным разложениемматрицыназывается разложение гдеи— матрицы, ортонормированные по столбцам, а— диагональная матрица, у которой. Числаназываются, а столбцыи—исингулярными векторами соответственно (их алгебраический смысл станет ясен чуть ниже). Сингулярное разложение можно записать в полном или в усечённом виде: Пара предостережений по поводу ортогональности по столбцам: ортогональна по столбцам (элементы— скалярные произведения столбцов) но(не обязательно равно; элементы— скалярные произведения строк) Ясно, что хранить полное разложение нет смысла: ведь бесполезные, умножающиеся на нули, блоки будут лишь занимать память. По-английски сингулярное разложение называется SVD (singular value decomposition), и мы будем активно использовать эту аббревиатуру. Если вы не любите математику, можете пропустить. С точки зрения математики сингулярное разложение говорит следующее. Пусть— матрица линейного отображения. Тогда найдётся ортонормированый базисв пространствеи ортонормированый базисв пространстве, в которых действие оператора записывается следующим образом: (знатоки функционального анализа могут узнать в этом частный случай теоремы Гильберта-Шмидта). Сингулярное разложение и операторная l2-норма.Можно показать, что, эта самая операторная l2-норма матрицы, равна— квадрату наибольшего сингулярного числа. Сингулярное разложение и норма Фробениуса. Можно показать, что Есть и более тонкие, хотя и весьма частные, ситуации. Можете ли вы, например, указать несколько различных сингулярных разложений матрицы? Да-да, для неё сингулярное разложение максимально неоднозначно. Можете ли вы теперь придумать не скалярную матрицу, у которой были бы различные SVD, отличающиеся не только знаками столбцов матрици? Если(рассмотрим сейчас не усечённое, а полное разложение, в котором матрицыиквадратные ортогональные), то Отметим, что в рассматриваемой ситуациине обязательно квадратная, и поэтому нельзя написать, что; тем не менее,— это квадратная матрица с числамина диагонали. Как бы то ни было, в (ортогональном!) базисе из (ортогональных!) столбцовматрицаприводится к диагональному виду с числамина диагонали. Теперь представим, что наши объектывыбраны из-мерного нормального распределения где— вектор средних, а— матрица ковариации. Это, в частности, значит, что облако точек представляет из себя нечто вроде эллипсоида в-мерном пространстве с центром. Предположим, что(все признаки центрированы); тогда оценкой матрицы ковариации признаков является матрица. Допустим, что эта оценка точная, тогда разложениедаёт нам аналогичное разложение. Теперь замена координат(с матрицей замены— то есть переход происходит в базис из столбцов матрицы) даёт нам Обратите внимание, чтоистоят в формуле на непривычных местах, как будто их перепутали, но нет — простоу нас является строкой, а не столбцом. Итак, если наши данные взяты из многомерного нормального распределения, после перехода к базису из столбцовновые координаты становятся независимыми; вместе с тем это соответствует переходу к главным осям ковариационной матрицы — и геометрически столбцысоответствуют главным осям эллипсоида-облака точек."
            }
        ]
    },
    {
        "id": "q_0362",
        "question": "Какие свойства должны иметь латентные признаки в первой интерпретации матричного разложения?",
        "answers": [
            "Латентные признаки должны быть не коррелированы и упорядочены по невозрастанию дисперсии."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "Запишем и вспомним самую первую интерпретацию матричного разложения. латентные признаки не коррелированы латентные признаки упорядочены по невозрастанию дисперсии Заметим, что перед применением SVD признаки лучше центрировать, иначе первая компонента будет указывать в сторону центра масс облака точек (зачем нам это?), а остальные вынуждены будут ей быть ортогональны: Мы уже обсуждали, что это можно получить, построив приближение рангаили, что то же самое, приближённое разложение для некоторого и желательно небольшого. И тут SVD приходится более чем кстати. Наилучшее по норме Фробениуса приближение ранга— это Таким образом, если вы хотите получить«самых важных» признаков, то вы можете использовать SVD. Но что это за признаки? Что именно означают эти слова «самые важные»? Давайте обратимся к геометрии, которая, как мы помним, тесно связана с теорией вероятностей: Если применить SVD к датасету, изображённому на последней картинке, и взять два первых латентных признака, то эллипсоид превратится в эллипс; меньшая из полуосей, похожая на шум, будет забыта, останется две бOльших. Видим: самое важное для SVD — это самое масштабное. А правда ли у нас получится хорошее приближение с помощьюновых признаков? Посчитаем норму разности. Везде нижеи— квадратные ортогональные матрицы; в частностине обязательно квадратная матрица размера. Аналогичным образом потому что умножение на ортогональную матрицу не меняет операторную-норму. Таким образом, если сингулярные значения убывают достаточно медленно (например, линейно), то мы вряд ли сможем приблизить исходную матрицу матрицей маленького ранга с очень хорошей точностью. Как избавиться от иллюзий.Сгенерируйте матрицус помощьюnp.random.randилиnp.random.randn. Для какоговы сможете найти матрицу ранга, приближающую исходную с относительной точностью? К счастью, в реальных датасетах сингулярные значения убывают достаточно быстро или же нам хватает довольно грубого приближения. Допустим, мы построили приближённое разложение ранга: Матрица— это первыестолбцов матрицы, и они же первыестолбцов матрицы. Таким образом,для перевода объектав новое признаковое пространство нужно произвестии взять первыестолбцов или, что то же самое,. Теперь пусть задана вектор-строкадлины— латентное представление, соответствующего некоторому объекту, то есть одна из строк матрицы. Тогда точно восстановить исходныймы не сможем: ведь равенствоне точное, нодля приближённого восстановлениямы должны произвести."
            }
        ]
    },
    {
        "id": "q_0363",
        "question": "Какие проблемы могут возникнуть при использовании сингулярного разложения для анализа данных, не имеющих нормального распределения?",
        "answers": [
            "SVD будет упрямо искать эллипсоид, даже если данные обладают сложной геометрией, что может не соответствовать реальной структуре данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "Сингулярное разложение умеет находить дающие самый существенный вклад в дисперсию линейные комбинации признаков, притом некоррелированные; в случае нормально распределённых данных эти направления оказываются главными осями эллипсоида, которым является облако данных. К сожалению, эта суперспособность SVD столь же охотно превращается в слабость, ведь: Данные не всегда распределены нормально, они могут обладать сложной геометрией, но SVD будет упрямо искать эллипсоид. Самое важное не всегда самое масштабное. Забыть привести признаки к одному масштабу — хороший способ выстрелить себе в ногу при работе с сингулярным разложением. Новые признаки не обязаны быть хорошо интерпретируемыми. Линейная комбинация возраста, стажа работы и зарплаты — это не то, что хотелось бы показывать банковскому регулятору. Выбросы почти наверняка усложнят вам жизнь, хотя, возможно, SVD поможет вам их увидеть."
            }
        ]
    },
    {
        "id": "q_0364",
        "question": "Какие два действия с данными необходимо выполнить перед применением SVD для улучшения визуализации рукописных цифр из датасета MNIST?",
        "answers": [
            "Необходимо вытянуть каждое чёрно-белое изображение в вектор, получив матрицу, и центрировать данные, вычтя из каждого пикселя его среднее значение по всем картинкам."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "Возьмём большой датасет MNIST, состоящий из чёрно-белых изображений рукописных цифр размерапикселей (его можно загрузить, к примеру,отсюда), вытянем каждое из изображений в вектор, получив тем самым матрицу размера, и применим к этой матрице SVD. Теперь возьмём первые два латентных признака (то есть первые два столбца матрицы) — получается, что каждая рукописная цифра у нас теперь кодируется вектором из двух чисел. Нарисуем на плоскости точки, соответствующие этим векторам (скажем, по 100 из каждого класса, чтобы хоть что-нибудь было понятно): Что же мы видим? Единицы и нули оказались особенными, то есть уже первые два латентных признака хорошо их различают, правда, с середине какая-то каша. А почему? Да потому, что мы забыли центрировать данные. Давайте перед применением SVD вычтем из каждого признака (то есть из каждого пикселя) его среднее по всем картинкам, а потом нарисуем всё заново: Теперь стало получше: например, семёрки, девятки и четвёрки сгуппировались вместе с другой стороны от восьмёрок и троек (собственно говоря, это отражает тот факт, что рукописные написания семёрок, девяток и четвёрок могут быть похожи друг на друга, так и человек не сразу отличит — а вот с тройкой их спутать намного труднее). Заметим ещё вот что. В-мерном пространстве наборов пикселей совсем не каждая точка соответствует какой-то рукописной цифре — то, что может приходить из реального мира, лежит на некоторой хитрой поверхности в этом пространстве (если выражаться корректнее, то на подмногообразии). Если же мы попробуем нарисовать «изображения», лежащие на отрезке, соединяющем два изображения цифр, то получим нечто не слишком интересное: Одно изображение просто наложилось и затем сменило другое — скучно! Но если мы сделаем то же самое в двумерном пространстве, образованном первыми двумя латентными признаками SVD, то мы будем получать, может быть, не совсем реалистичные изображения цифр, но что-то явно из мира рукописных символов: Посмотрим на небольшой кусок вотэтого датасета, который доступен для скачивания нигде (ха-ха), и попробуем что-нибудь понять про химических состав рек европейского союза, а заодно соберём шишки, которые могут попасться при визуализации с помощью SVD. Конечно, сразу хочется нарисовать все объекты датасета в виде точек на плоскости. Мы знаем, что в этом может помочь SVD — попробуем же! Центрируем признаки — и рисуем: Ой, что-то пошло не так. Но почему же?! Наверное, надо хотя бы посмотреть на данные... Объекты имеют вид «GBPKER0059», «GB20227», «LVV0120100» и так далее — это коды станций, измеряющих состав воды; Признаки имеют вид «1985 BOD5», «1985 Chlorophyll a», «1985 Orthophosphates» и так далее — тут указан год измерения и показатель; Посмотрев статистики, убеждаемся, что все показатели неотрицательны (то есть уж точно распределены не нормально — но может, и так сработает); при этом почти все элементы нашей матрицы находятся в пределах 1000, но три значения космически огромны, причём в одном столбце «2008 Total oxidised nitrogen» (а строки соответствуют каким-то греческим станциям, с которыми вообще всё странно), и ещё одно тоже очень большое («2005 Total organic carbon (TOC)») — вот они-то и дали нам четыре точки на графике, отличных от начала координат.Кстати говоря, если космически большие значения, по-видимому, являются результатам поломки, то по поводу четвёртого, не столь злостного, выброса есть подозрение, что это реальные значения. Посмотрев в данные, мы видим, что показатель был измерен на станции Zidlochovice, на реке Srvatka ниже Брно — а, как говорит нам википедия:As a result of water pollution by communal sewage, the reservoir suffered from an extensive amount of cyanobacteria for a long time. Так или иначе, все четыре станции мы уберём, чтобы они не портили нам SVD. Один из признаков «2002 Kjeldahl Nitrogen» принимает только нулевые значения. Уберём его, чтобы не мешался. Почистив выбросы в исходных данных, опять центрируем и рисуем: Уже лучше. Попробуем понять, что за вещества внесли вклад в первые два латентных признака. Как это сделать? Латентные признаки — это столбцы матрицы; линейная алгебра говорит нам, что-й столбец произведения— это линейная комбинация столбцовс коэффициентами из-го столбца. Находим номера самых больших по модулю координат— и оказывается, что первые два латентных признака складываются почти сплошь из насыщения воды кислородом, только за разные годы (первый за более старые, второй за чуть более свежие): First latent feature Second latent feature Неужели насыщение кислородом действительно так важно? Нет, просто мы не отмасштабировали признаки. Оказывается, что насыщение кислородом имеет на порядок больший масштаб, чем многое другое, и потому забивает все остальные признаки. Тем не менее, мы можем попробовать сделать вывод и из имеющейся картинки. По оси \"у\" что-то не очень интересное, а по оси \"х\" видим большой кластер (напомним, это меньшие значения насыщения воды кислородом в начале 2000-х), содержащий, если проверить, примерно три четверти всех точек, и ещё некоторой размазанный шлейф. Итак, на многих станциях насыщение воды кислородом в начале 2000-х было примерно в одинаковой степени мало — проверив глазами, обнаруживаем, что там просто нули. Поскольку вряд ли это так на самом деле, видимо, стоит сделать вывод, что в первой половине 2000-х насыщение кислородом измерялось из рук вон плохо. Теперь вдобавок к центрированию поделим каждый признак на его стандартное отклонение и снова нарисуем: Опять видим тесный кластер. При этом первый латентный признак складывается в основном из «Nitrate» , «pH» и «Dissolved oxygen» за разные годы, все с положительными коэффициентами, а второй — из «Total ammonium», «Total phosphorus» и «Kjeldahl Nitrogen» за разные годы, причём с отрицательными коэффициентами. В частности, справа у нас точки с высоким содержанием нитратов и высокой кислотностью. Среди этих точек: Река Тейм, про которую Википедия пишет:The Tame was once one of Britain's dirtiest rivers. Река Кёрёш, про которую тоже можно найти вот такую информацию:For some time the municipal government of Kanjiža (to which the mouth of the river belongs) protests about the extreme pollution of the Kereš's water, as it represents the single largest polluter of the Tisa river Темза (станция немного выше Лондона). Что ещё можно было бы сделать? Например, мы можем посмотреть распределения признаков и увидеть, что многие из них далеки от нормальных и в целом выиграли бы от логарифмирования — тогда, возможно, итоговая картинка стала бы красноречивей."
            }
        ]
    },
    {
        "id": "q_0365",
        "question": "Какой алгоритм позволяет быстрее и надёжнее сходиться к решению в задаче рекомендательной системы, чередуя шаги минимизации по матрицам пользователей и товаров?",
        "answers": [
            "Это алгоритм Alternating Least Squares (ALS), который при фиксированной матрице пользователей находит минимум по матрице товаров методом наименьших квадратов, и наоборот, чередуя эти шаги."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "Мы уже обсуждали, что, вообще говоря, любое матричное разложение можно с той или иной степенью успеха использовать для построения рекомендательной системы. Основанные на этом модели называютсямоделями латентных факторов(Latent factor models). В 2006 году SVD-подобный алгоритм даже помог Саймону Фанку (Simon Funk; под этим псевдонимом скрывался Brandyn Webb) занять высокое место на соревновании Netflix Prize. Вернёмся к примеру из пункта 1.3. Пусть вновь объекты нашего датасета соответствуют пользователям интернет-магазина, а признаки — товарам, причём в клетке с индексомзаписаны рейтинги, которые пользователи ставят товарам. На основе этих данных мы хотим порекомендовать некоторому-му пользователюочередных товаров. Если бы нам были известныдля всех индексов товаров, задача не стоила бы выеденного яйца: мы бы просто взялитоваров с максимальными значениями рейтингов. Более того, мы могли бы с помощью матричного разложения построить модель и надеяться, что координаты латентных представлений пользователей и товаров окажутся интерпретируемыми (нет). А именно, если бы мы знали все, построить отдельные представления для пользователей и для товаров некоторой (подбираемой; это гиперпараметр модели) длинымы могли бы с помощью SVD и приближения из теоремы Эккарта-Янга: Но на деле матрицаобычно разреженная: в ней лишь сравнительно немного известных рейтингов, а в остальных ячейках стоят пропуски. Что же делать? Наивный вариант — заменить все пропуски нулями (то есть положить, что если пользователь не ставил рейтинг товару, то он ему вдребезги не интересен, что не всегда правдоподобно) или средними по строке/столбцу, после чего сделать SVD и радоваться жизни. В этой ситуации наша приближённая модель предсказывает рейтинг, выставленный-м пользователем-му товару, как скалярное произведение представлений пользователя и товара — то есть-й строки матрицыи-го столбца матрицы Теперьчтобы порекомендовать n-му пользователю k очередных товаров, мы просто берём n-ю строку матрицыи находим номера её наибольших элементов. К сожалению, у этого метода есть как минимум две проблемы: Пропусков обычно очень много; если их все заменить какими попало значениями, оценка будет очень шумной; При таком подходе нет простого способа обновить рекомендации при добавлении новых данных — SVD придётся переучивать заново. К счастью, есть и другой путь. Давайте подумаем: чего вообще мы требуем от матрици? По сути нам нужны две вещи: ; Обе матрицы ортогональны по столбцам. Последнее можно опустить. Ясной пользы для рекомендательной системы от этого нет; да, это давало бы нам некоррелированность латентных признаков, но мы уже видели, что интерпретируемости это не влечёт. Первое же условие удобно сформулировать в терминах векторов латентных представлений пользователей (обозначим их; это строки) и товаров (обозначим их— это строки). А именно, нам нужно, чтобыскалярное произведениебыло как можно ближе кдля всех пар, для которыхнам известно. Вот именно! Мы можем просто не обращать внимания на неизвестные значения, оптимизируя только по тем клеткам, для которых нам что-то известно: Но как решить эту оптимизационную задачу? Разумеется, с помощью стохастического градиентного спуска. В базовом варианте мы случайным образом перебираем пары, для которыхнам известно, и обновляем координаты векторовиследующим образом: где— гиперпараметр, отвечающий за темп обучения. Приятное свойство такого подхода: в нём легко добавлять новые товары/пользователей (дообучаем их векторы, заморозив остальные), а также новые оценки(добавляем в оптимизируемый функционал и проводим дооптимизацию). Отметим, что в ходе оптимизации мы попеременно осуществляем градиентный спуск, обновляя то, то. Эту идею можно развить следующим образом. Заметим, что при фиксированной матрицезадача минимизации повыражения превращается по сути в обычный метод наименьших квадратов, для которого можно даже выписать «точное» решение (а вы можете это сделать?). Точно так же и при фиксированномлегко находится минимум по. Чередуя эти два шага, мы будем сходиться к решению быстрее и надёжнее, чем с помощью SGD. Данный алгоритм носит названиеAlternating Least Squares (ALS). Можно ввести много дополнительных эвристик и предположений, которые уведут нас совсем далеко от старого доброго SVD. Например: Рейтинг не всегда является продуктом чистого взаимодействия пользователя с товаром. Бывают товары, которые сами по себе ужасно популярны (скажем, человек купит туалетную бумагу даже если не очень интересуется товарами для дома) или так ужасны, что даже интересующийся данной «латентной категорией» покупатель не станет их высоко оценивать. Это можно промоделировать, добавив к скалярному произведению члены, зависящие только от пользователя и только от товара соответственно: Тогда наша задача оптимизации примет вид: Можно добавлять регуляризационные члены. Например: Мы можем не игнорировать неизвестные нам элементы матрицы, а присвоить им нулевые значения и ставить более низкие веса соответствующим слагаемым функции потерь: гдемаленькое, если, и большое в противном случае. Это имеет смысл, например, если отсутствие данных в самом деле может быть логично интерпретировать, как отсутствие интереса. Можно ввести требования неотрицательности:,. Подробнее об этом в параграфе про неотрицательное матричное разложение. Или даже всё это вместе 😄"
            }
        ]
    },
    {
        "id": "q_0366",
        "question": "К какому виду оптимизационной задачи приводит метод максимального правдоподобия в описанном контексте?",
        "answers": [
            "Метод максимального правдоподобия приводит к задаче наименьших квадратов, которая представляет собой оптимизационную задачу."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "Вы могли заметить, что задача подозрительно напоминает задачу наименьших квадратов, и неспроста. В базовой формулировке мы предполагаем, что Иными словами, По крайней мере, те из них, которые нам известны. Нахождениеиметодом максимального правдоподобия как раз и приводит к описанной выше оптимизационной задаче. Как обычно, мы можем добавить априорную информацию о распределении латентных векторови. Например, такую: Расписывая логарифм правдоподобия и убирая константные члены, которые содержат только сигмы, приводим задачу максимизации логарифма правдоподобия к виду вполне объясняющему, почему в предыдущем пункте у нас могла появляться L2-регуляризация."
            }
        ]
    },
    {
        "id": "q_0367",
        "question": "Какой алгоритм, описанный в статье его создателей и реализованный в sklearn, используется для анализа независимых компонент?",
        "answers": [
            "Для анализа независимых компонент используется алгоритм FastICA, который базируется на поиске линейной комбинации исходных признаков, наименее близкой к гауссовскому распределению."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "ICA изначально был придуман для задачи разделения сигналов («blind source separation»). Рассмотримпример из sklearn Изначально были три сигнала (красный, рыжий и синий на второй сверху картинке), их смешали, получив три линейных комбинации (на верхней картинке). Теперь попробуем их разделить. Первая мысль, которая нам приходит в голову: воспользуемся SVD (проинтерпретировав моменты времени как объекты, а сигналы из смеси как признаки — то есть взяв матрицу)! Но на нижней картинке мы видим результат, который не радует, но не радует ожидаемо, и вот почему: В первый латентный признак SVD старается собрать максимально возможную дисперсию — мы видим, что красный график на нижней картинке действительно ловит самые значительные колебания сигналов из смеси; при этом в третий (рыжий) сигнал уже попадает более или менее случайный шум. Если посмотреть на значения исходных сигналов, то они распределены не нормально (распределения значений синего и красного имеют две моды, а у рыжего близко к равномерному), а мы помним, что SVD плохо приспособлено к работе с не гауссовскими данными. Анализ независимых компонент (ICA)состоит в аппроксимациинаблюдаемых признаков линейной смесью латентных, которые являютсянезависимымикак случайные величины. Замечание. Оригинальная формулировка несколько другая: изначально ICA — это аппроксимация наблюдаемых сигналов линейной смесью некоторого числа независимых сигналов, то есть речь шла о смеси объектов. Описываемые далее методы можно точно также использовать и для разделения смеси объектов, конечно. Важно, что в данном случае предъявляется требованиенезависимости, а не простонекоррелированности— более сильное, впрочем, труднодостижимое и столь же трудно проверяемое. Мы будем излагать алгоритм FastICA постатье его создателей, она же реализована в библиотеке sklearn; в статье вас ждёт гораздо больше подробностей и тонкостей реализации. Алгоритм базируется на следующем эвристическом соображении:линейная комбинация нескольких независимых негауссовских величин в большей степени гауссовская, чем сами эти величины— довольно смелый вывод из Центральной предельной теоремы. Таким образом, мы будем искатьлинейную комбинацию исходных признаков, которая была бы в наименьшей степени гауссовской— это и будет первая из независимых компонент. Но как померить близость к нормальности? Пусть— некоторая (одномерная) случайная величина с плотностью. Рассмотрим её энтропию Имеет место теорема:гауссовская случайная величина имеет максимальную энтропию среди всех случайных величин с заданной дисперсией. Рассмотрим теперь где— гауссовская случайная величина с той же дисперсией, что и у. Величинавсегда неотрицательна и равна нулю в том случае, еслигауссовская. Решая задачу мы могли бы найти самую негауссовскую линейную комбинацию наших признаков. Проблема в том, чтотрудно посчитать. Авторы статьи предлагают использовать приближение где, анеквадратичная функция (в статье предлагаются конкретные варианты). Последующие независимые компоненты можно искать в ортогональном подпространстве (всё-таки они должны быть и некоррелированными). Перед тем, как строить разложение нужно центрировать данные (вычесть из признаков их средние) и убедиться, что ковариационная матрица признаков является единичной."
            }
        ]
    },
    {
        "id": "q_0368",
        "question": "Какой метод можно использовать для решения факторизационных задач, если оптимизационная задача не является выпуклой в целом, но выпукла по отдельности для каждого сомножителя?",
        "answers": [
            "ALS (Alternating Least Squares) — это метод, который позволяет чередовать поиск одного сомножителя при фиксированном другом, итеративно сходясь к решению, поскольку задача становится выпуклой для каждого сомножителя отдельно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
                "text": "Допустим, что у нас есть датасет, в котором объекты — тексты, признаки — токены (например, слова), а на-м месте написана частота встречаемости-го токена в-м тексте (то есть, где— сколько раз-й токен встретился в-м документе, а— общее число токенов в этом документе). Приблизим нашу матрицу произведением Одна из возможных интерпретаций такова. Естьтем: За этим стоит вполне ясная вероятностная модель: Вопрос в том, как получить такое разложение. Конечно, чисто технически можно использовать SVD. Но тогда элементы матриц разложения вряд ли будут иметь вероятностный смысл: они же даже не обязаны быть неотрицательными. С другой стороны, если потребовать, чтобы все элементыибыли неотрицательными, ситуация исправится. Неотрицательное матричное разложениенеотрицательной матрицы— это произведениематриц с неотрицательным элементами, наилучшим образом приближающеепо норме Фробениуса ALS — один из популярных методов для решения факторизационных задач. Несмотря на то, что оптимизационная задача в целом не является выпуклой, по отдельности задача поиска каждого из сомножителей является выпуклой и может решаться с помощью привычных нам методов. Таким образом, мы можем чередовать поискпри фиксированноми поискпри фиксированном, итеративно сходясь к итоговому решению: Заметим, что из-за насильного обнуления элементов будут получаться разреженные матрицы. Разумеется, можно рассматривать и более сложные функционалы, прибавляя кразличные регуляризационные члены, скажем, поощряющие большую разреженность матрици."
            }
        ]
    },
    {
        "id": "q_0369",
        "question": "Какие два основных подхода к объяснению несовершенства моделей в задаче регрессии описаны?",
        "answers": [
            "Первый подход — инженерный, где мы приближаем таргет предсказаниями с помощью подобранной функции потерь. Второй — вероятностный, где неточности объясняются случайным шумом, для которого выбирается определённое распределение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Практически любая наша модель — несовершенна. Но объяснять это несовершенство можно по-разному. Представим, что мы решаем задачу регрессии: например, пытаемся по университетским оценкам выпускника предсказать его годовую зарплату. Ясно, что точная зависимость у нас не получится как минимум потому, что мы многого не знаем о выпускнике: куда он пошёл работать, насколько он усерден, как у него с soft skills и так далее. Как же нам быть? Первый вариант — просто признать, что мы не получим идеальную модель, но постараться выучить оптимальную, насколько это возможно. То есть приблизить таргет предсказаниями наилучшим образом с точки зрения какой-то меры близости, которую мы подберём из экспертных соображений. Так мы получаем простой инженерный подход к машинному обучению: есть формула, в которой присутствуют некоторые параметры (), есть формализация того, что такое «приблизить» (функция потерь) — и мы бодро решаем задачу оптимизации по параметрам. Второй вариант — свалить вину за неточности наших предсказаний на случайность. В самом деле: если мы что-то не можем измерить, то для нас это всё равно что случайный фактор. В постановке задачи мы заменяем приближённое равенствона точное Например, это может быть аддитивный шум (чаще всего так и делают): где— некоторая случайная величина, которая представляет этот самый случайный шум. Тогда получается, что для каждого конкретного объектасоответствующий ему истинный таргет — это суммаи конкретной реализации шума. При построении такой модели мы можем выбирать различные распределения шума, кодируя тем самым, какой может быть ошибка. Чаще всего выбирают гауссовский шум:с некоторой фиксированной дисперсией— но могут быть и другие варианты. Проиллюстрируем, как ведут себя данные, подчиняющиеся закону,: Вопрос на подумать. Зачем человеку может прийти в голову предположить, что в модели линейной регрессиишумимеет распределение Лапласа? А распределение Коши? Чем свойства таких моделей будут отличаться от свойств модели с нормальным шумом? Как вы могли заметить, в каждом из подходов после того, как мы зафиксировали признаки (то есть координаты), остаётся своя степень свободы: в инженерном это выбор функции потерь, а в вероятностном — выбор распределения шума. Дальше в этом параграфе мы увидим, что на самом деле эти два подхода глубинным образом связаны между собой, причём выбор функции потерь — это в некотором смысле то же самое, что выбор распределения шума."
            }
        ]
    },
    {
        "id": "q_0370",
        "question": "Что представляет собой значение y_i для конкретного объекта x_i в вероятностной модели с аддитивным шумом?",
        "answers": [
            "Для конкретного объекта x_i значение y_i является константой, но для случайной величины Y оно становится случайной величиной, зависящей от x_i и параметров w."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Допустим, что мы исследуем вероятностную модель таргета с аддитивным шумом где— некоторая функция, не обязательно линейная с (неизвестными пока) параметрами, а— случайный шум с плотностью распределения. Для каждого конкретного объектазначение— это просто константа, но дляоно превращается в случайную величину, зависящую от(и ещё от, на самом деле). Таким образом, можно говорить об условном распределении Для каждого конкретногоираспределение соответствующего— это просто, ведь. Пример. Рассмотрим вероятностную модель, где. Тогда для фиксированногоимеем. Поскольку— константа, мы получаем Это можно записать и так: где выражение справа — это значение функции плотности нормального распределения с параметрамив точке. В частности,."
            }
        ]
    },
    {
        "id": "q_0371",
        "question": "Как можно описать ситуацию на поле в предложенной вероятностной модели для предсказания точки попадания мяча?",
        "answers": [
            "Ситуацию на поле можно описать как функцию от позиций и движений других игроков, судьи и зрителей, но поскольку учесть все факторы невозможно, в модель вводится элемент случайности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "На самом деле, мы можем для нашей задачи придумывать любую вероятностную модель, не обязательно вида. Представьте, что мы хотим предсказывать точку в плоскости штанг, в которую попадает мячом бьющий по воротам футболист. Можно предположить, что она имеет нормальное распределение со средним (цель удара), которое определяется ситуацией на поле и состянием игрока, и некоторой дисперсией (то есть скалярной ковариационной матрицей), которая тоже зависит от состояния игрока и ещё разных сложных факторов, которые мы объявим случайными. Состояние игрока — это сложное понятие, но, вероятно, мы можем выразить его, зная пульс, давление и другие физические показатели. В свою очередь, ситуацию на поле можно описать, как функцию от позиций и движений других игроков, судьи и зрителей — но всего не перечислишь, поэтому нам снова придётся привлекать случайность. Таким образом, мы получаем то, что называетсяграфической моделью: Здесь стрелки означают статистические зависимости, а отсутствие стрелок — допущение о статистической независимости. Конечно же, это лишь допущение, принятое нами для ограничения сложности модели: ведь пульс человека и давление взаимосвязаны, равно как и поведение различных игроков на поле. Но мы уже обсуждали, что каждая модель, в том числе и вероятностная, является лишь приблизительным отражением бесконечно сложного мира. Впрочем, если у нас много вычислительных ресурсов, то никто не мешает нам попробовать учесть и все пропущенные сейчас зависимости. Расписав всё по определению условной вероятности, мы получаем следующую вероятностную модель: в которой, конечно же, мы должны все вероятности расписать через какие-то понятные и логически обоснованные распределения — но пока воздержимся от этого."
            }
        ]
    },
    {
        "id": "q_0372",
        "question": "Какая функция потерь получается при обучении вероятностной модели линейной регрессии с нормальным шумом методом максимального правдоподобия?",
        "answers": [
            "При обучении вероятностной модели линейной регрессии с нормальным шумом методом максимального правдоподобия получается квадратичная функция потерь (MSE). Максимизация логарифма правдоподобия в этом случае равносильна минимизации суммы квадратов отклонений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Мы хотим подобрать такие значения параметров, для которых модельбыла бы наиболее адекватна обучающим данным. Сутьметода максимального правдоподобия(maximum likelihood estimation) состоит в том, чтобы найти такое, для которого вероятность (а в данном, непрерывном, случае плотность вероятности) появления выборкибыла бы максимальной, то есть Величинаназываетсяфункцией правдоподобия(likelihood). Если мы считаем, что все объекты независимы, то функция правдоподобия распадается в произведение: Теперь, поскольку перемножать сложно, а складывать легко (и ещё поскольку мы надеемся, что раз наши объекты всё-таки наблюдаются в природе, их правдоподобие отлично от нуля), мы переходим к логарифму функции правдоподобия: эту функцию мы так или иначе максимизируем по, находя оценку максимального правдоподобия. Как мы уже обсуждали выше,, то есть Максимизация функции правдоподобия соответствует минимизации а это выражение можно интерпретировать, как функцию потерь. Вот и оказывается, что подбор параметров вероятностей модели с помощью метода максимального правдоподобия — это то же самое, что «инженерная» оптимизация функции потерь. Давайте посмотрим, как это выглядит в нескольких простых случаях. Пример. Давайте предположим, что наш таргет связан с данными вот так: где, то есть Случайная величинаполучается из шумасдвигом на постоянный вектор, так что она тоже распределена нормально с той же дисперсиейи со средним Правдоподобие выборки имеет вид Логарифм правдоподобия можно переписать в виде Постоянными слагаемыми можно пренебречь, и тогда оказывается, что максимизация этой величины равносильна минимизации Мы получили обычную квадратичную функцию потерь. Итак, обучать вероятностную модель линейной регрессии с нормальным шумом — это то же самое, что учить «инженерную» модель с функцией потерь MSE. Вопрос на подумать. Какая вероятностная модель соответствует обучению линейной регрессии с функцией потерь MAE"
            }
        ]
    },
    {
        "id": "q_0373",
        "question": "Какое точечное предсказание является логичным в схеме с симметричными распределениями шума с нулевым математическим ожиданием?",
        "answers": [
            "В такой схеме логичным точечным предсказанием является значение ŷ, которое совпадает с условным математическим ожиданием."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Теперь представим, что параметры подобраны, и подумаем о том, как же теперь делать предсказания. Рассмотрим модель линейной регрессии Еслиизвестен, то для нового объектасоответствующий таргет имеет вид Таким образом,дан нам не точно, а в виде распределения (и логично: ведь мы оговорились выше, что ответы у нас искажены погрешностью, проинтерпретированной, как нормальный шум). Но что делать, если требуют назвать конкретное число? Кажется логичным выдать условное матожидание, тем более что оно совпадает с условной медианой и условной модой этого распределения. Если же медиана, мода и математическое ожидание различаются, то можно выбрать что-то из них с учётом особенностей задачи. Но на практике в схемечаще всего рассматривают именно симметричные распределения с нулевым матожиданием, потому что для нихсовпадает с условным матожиданиеми является логичным точечным предсказанием. Приведём пример. Допустим шумбыл бы из экспоненциального распределения. Тогдабыла бы условным минимумом распределения. В принципе, можно придумать задачу, для которой такая постановка (предсказание минимума) была бы логичной. Но это всё же довольно экзотическая ситуация. Приводим для сравнения модели с нормальным, лапласовским и экспоненциальным шумом:"
            }
        ]
    },
    {
        "id": "q_0374",
        "question": "Какой функцией можно преобразовать любое отображение из признакового пространства в модель бинарной классификации?",
        "answers": [
            "Для этого используется сигмоида, которая монотонно возрастает и отображает всю числовую прямую на интервал (0,1), позволяя получать вероятности из произвольных значений."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
                "text": "Допустим, мы имеем дело с задачей классификации склассами. Как мы можем её решать? Самый наивный вариант — научиться по каждому объектупредсказывать некоторое число для каждого класса, и у кого число больше — тот класс и выбираем! Наверное, так можно сделать, если мы придумаем хорошую функцию потерь. Но сразу в голову приходит мысль: почему бы не начать предсказывать не просто число, а вероятность? Таким образом, задача классификации сводится к предсказанию и как будто бы выбору класса с наибольшей вероятностью. Впрочем, как мы увидим дальше, всё не всегда работает так просто. Одну такую модель — правда, только для бинарной классификации — вы уже знаете. Это логистическая регрессия: которую также можно записать в виде где— распределение Бернулли с параметром. Нахождение вероятностей классов можно разделить на два этапа: где, напомним,— это сигмоида: Сигмоида тут не просто так. Она обладает теми счастливыми свойствами, что монотонно возрастает; отображает всю числовую прямую на интервал; . Вот такой вид имеет её график: Иными словами, с помощью сигмоиды можно делать «вероятности» из чего угодно, то есть более или менее для любого отображения(из признакового пространства в) с параметрамипостроить модель бинарной классификации: Как и в случае логистической регрессии, такая модель равносильна утверждению о том, что Похожим способом можно строить и модели для многоклассовой классификации. В этом нам поможет обобщение сигмоиды, которое называетсяsoftmax: А именно, для любого отображенияиз пространства признаков вмы можем взять модель Если все наши признаки — вещественные числа, а— просто линейное отображение, то мы получаем однослойную нейронную сеть Предостережение. Всё то, что мы описали выше, вполне работает на практике (собственно, классификационные нейросети зачастую так и устроены), но корректным не является. В самом деле, мы говорим, что строим оценки вероятностей, но для подбора параметров используем не эмпирические вероятности, а только лишь значения, то есть метки предсказываемых классов. Таким образом, при обучении мы не будем различать следующие две ситуации: Это говорит нам о некоторой неполноценности такого подхода. Заметим ещё вот что. В случае бинарной классификации выбор предсказываемого класса какравносилен выбору того класса, для которого. Но если наши оценки вероятностей неадекватны, то этот вариант проваливается, и мы встаём перед проблемой выбора порога: каким должно быть значение, чтобы мы могли приписать класс 1 тем объектам, для которых? В одном из следующих параграфов мы обсудим, как всё-таки правильно предсказывать вероятности."
            }
        ]
    },
    {
        "id": "q_0375",
        "question": "Какие два основных недостатка рекуррентных нейронных сетей (RNN) затрудняли их применение к длинным последовательностям до появления трансформеров?",
        "answers": [
            "Во-первых, RNN хранят всю информацию о последовательности в скрытом состоянии, которое обновляется на каждом шаге, что приводит к потере информации о начале длинных последовательностей. Во-вторых, обучение RNN сложно распараллелить, так как для вычисления состояния на каждом шаге требуется последовательная обработка предыдущих шагов, что неэффективно на GPU."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/transformery",
                "text": "Для начала вспомним, что основным подходом для работы с последовательностями до 2017 года (выхода оригинальной статьи про архитектуру «трансформер») было использование рекуррентных нейронных сетей, или RNN. Однако у такого подхода есть несколько известных минусов: Во-первых, RNN содержат всю информацию о последовательности в скрытом состоянии, которое обновляется с каждым шагом. Если модели необходимо «вспомнить» что-то, что было сотни шагов назад, то эту информацию необходимо хранить внутри скрытого состояния и не заменять чем-то новым. Следовательно, придется иметь либо очень большое скрытое состояние, либо мириться с потерей информации. Во-вторых, обучение рекуррентных сетей сложно распараллелить: чтобы получить скрытое состояние RNN-слоя для шага, вам необходимо вычислить состояние для шага. Таким образом, обработка батча примеров длинойдолжна потребоватьпоследовательных операций, что занимает много времени и не очень эффективно работает на GPU, созданных для параллельных вычислений. Обе этих проблемы затрудняют применение RNN к по-настоящему длинным последовательностям: даже если вы дождетесь конца обучения, ваша модель по своей конструкции будет так или иначе терять информацию о том, что было в начале текста. Хочется иметь способ «читать» последовательность так, чтобы в каждый момент времени можно было обратиться к произвольному моменту из прошлого за константное время и без потерь информации. Таким способом и является лежащий в основе трансформеров механизм self-attention, о котором далее пойдет речь. Как мы узнаем позже, благодаря своей универсальности и масштабируемости этот механизм оказался применим к множеству задач помимо обработки естественного языка. Ниже приведено устройство архитектуры «трансформер» из оригинальнойстатьи: Слева на схеме представлено устройство энкодера. Он по очереди применяется к исходной последовательности изблоков: Каждый блок выдаёт последовательность такой же длины. В нём есть два важных слоя, multi-head attention и feed-forward. После каждого из них к выходу прибавляется вход (это стандартный подход под названием residual connection) и затем активации проходят через слой layer normalization: на рисунке эта часть обозначена как “Add &Norm”. У декодера схема похожая, но внутри каждого изблоков два слоя multi-head attention, в одном из которых используются выходы энкодера. Давайте подробнее обсудим каждую из составляющих частей этого механизма."
            }
        ]
    },
    {
        "id": "q_0376",
        "question": "Какую роль выполняют матрицы запросов, ключей и значений в слое self-attention?",
        "answers": [
            "Матрицы запросов, ключей и значений используются для преобразования входных представлений элементов последовательности. Запросы сравниваются с ключами для определения степени близости, а значения суммируются с полученными коэффициентами внимания, формируя выход слоя self-attention."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/transformery",
                "text": "Первая часть transformer-блока — это слой self-attention. От обычного внимания его отличает то, что выходом являются новые представления для элементов той же последовательности, что мы подали на вход, причем каждый элемент этой последовательности напрямую взаимодействует с каждым. Если говорить более подробно, то в вычислении внимания для последовательности будет участвовать три обучаемых матрицы. Представлениекаждого элемента входной последовательности мы умножаем на, получая вектор-строки(— номер элемента), которые соответственно называютсязапросами,ключамиизначениями(query, key и value). Их роли можно условно описать следующим образом: — запрос к базе данных; — ключи хранящихся в базе значений, по которым будет осуществляться поиск; — сами значения. Близость запроса к ключу можно определять, например, с помощью скалярного произведения: где— некоторая нормировочная константа. Именно так и делали в исходной статье; в качестве нормировочной константы брался кореньиз размерности ключей и значений. Теперь мы складываем значенияс полученными коэффициентами. Это и будет выходом слоя self-attention. В векторизованном виде можно записать: где,,— матрицы запросов, ключей и значений соответственно, в которых по строкам записаны,,, аберётся построчно. Как мы уже упоминали выше, в декодере один из attention-слоёв является слоем кросс-внимания (cross-attention), в котором запросы берутся из выходной последовательности, а ключи и значения — из входной (то есть из результатов работы энкодера). Также стоит учитывать, что в описанном выше виде внимания каждый токен будет «смотреть» на всю последовательность, что нежелательно для декодера. Действительно, на этапе генерации мы будем порождать по одному токену за шаг, и доступ к последующим шагам на этапе обучения приведёт к утечке информации в декодере и низкому качеству модели. Чтобы избежать этой проблемы, при обучении к вниманию нужно применять авторегрессивную маску, вручную обращая ввеса до softmax для токенов из будущего, чтобы после softmax их вероятности стали нулевыми. Как можно увидеть на рисунке внизу, эта маска имеет нижнетреугольный вид. Один набор,иможет отражать только один вид зависимостей между токенами, и матрицы извлекают лишь ограниченный набор информации из входных представлений. Чтобы скомпенсировать эту неоптимальность, авторы архитектуры предложили подход с несколькими «головами» внимания (multi-head attention): по сути вместо одного слоя внимания мы применяем несколько параллельных с разными весами, а потом агрегируем результаты. Рисунок ниже показывает, как выглядит multi-head attention: Подход к обработке последовательностей целиком через внимание позволяет избавиться от такого понятия, как скрытое состояние, обновляющееся рекуррентно: каждый токен может напрямую «прочитать» любую часть последовательности, наиболее полезную для предсказания. В частности, отсутствие рекуррентности означает, что мы можем применять слой ко всей последовательности одновременно, так как матричные умножения прекрасно параллелятся. Однако стоит помнить о затратах памяти и времени: поскольку каждый элемент последовательности взаимодействует с каждым, легко показать, что сложность self-attention составляетпо длине последовательности, а простые реализации, формирующие полную матрицу внимания, будут расходовать ещё ипамяти. С оптимизацией вычислительной сложности внимания связано множество работ как инженерного, так и архитектурного плана: в частности, есть подходы, которые позволяют сократить время работы self-attention до линейного или существенно уменьшают константы за счёт учёта иерархии памяти GPU. Например, на графиках ниже сравнивается время работы и потребление памяти трансформера со стандартным вниманием и с механизмом изстатьиLongformer:"
            }
        ]
    },
    {
        "id": "q_0377",
        "question": "Как называется второй компонент трансформерного блока и из чего он состоит?",
        "answers": [
            "Второй компонент называется feed-forward network (FFN) и состоит из двух полносвязных слоёв, которые применяются независимо к каждому элементу входной последовательности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/transformery",
                "text": "Вторая часть трансформерного блока называется feed-forward network (FFN) и представляет собой два обычных полносвязных слоя, применяемых независимо к каждому элементу входной последовательности. В последних архитектурах размер промежуточного представления (то есть выхода первого слоя) бывает весьма большим — в 4 раза больше выходов блока. Из-за этого вычислительной стоимостью FFN не стоит пренебрегать: несмотря на квадратичную асимптотику внимания, в больших моделях или на коротких последовательностях FFN может занимать существенно больше времени по сравнению с self-attention. В виде формулы применение FFN можно представить так: Промежуточные активациив FFN бывают разными: начиналось всё с широко известной ReLU, но в какой-то момент сообщество перешло наGELU (Gaussian Error Linear Unit)с формулой, где— функция распределения стандартной нормальной случайной величины. Скажем ещё пару слов о layer normalization: как было показано врядеработ, их положение внутри residual-ветки довольно важно. В стандартной архитектуре используется формулировка PostLN, где нормализация применяется после остаточной связи. Однако такое применение нормализации оказывается довольно нестабильным при обучении моделей с большим числом слоёв: вместо этого предлагается использовать PreLN (справа на рисунке снизу), где нормализация применяется ко входу residual-ветки."
            }
        ]
    },
    {
        "id": "q_0378",
        "question": "Какой метод позволяет слоям внимания в трансформер-блоке различать одинаковые токены, находящиеся на разных позициях в последовательности?",
        "answers": [
            "Для этого используются позиционные эмбеддинги — вспомогательные представления, которые прибавляются к обычным эмбеддингам токенов. Они позволяют модели учитывать порядок элементов в последовательности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/transformery",
                "text": "Внимательный читатель может заметить, что все операции внутри трансформер-блока, строго говоря, инвариантны к порядку элементов в последовательности. Например, результат внимания зависит от скалярных произведений между эмбеддингами токенов, но расположение этих токенов внутри текста значения не имеет. Таким образом, итоговые представления каждого токена на выходе из модели будут одинаковыми вне зависимости от порядка слов, что вряд ли нас устроит. Как с этим справиться? На помощь приходит такая вещь, как позиционные эмбеддинги. Это вспомогательные представления, которые прибавляются к обычным эмбеддингам токенов входной последовательности и позволяют слоям внимания различать одинаковые токены на разных местах. Исторически первым подходом были фиксированные эмбеддинги, однозначно кодирующие позицию тригонометрическими функциями (ниже— номер позиции,— индекс элемента в векторе, кодирующем эту позицию,— размерность эмбеддинга): С момента появления архитектуры «трансформер», однако, появилось множество других способов кодировать позиции токенов. Например, можно просто сделать позиционные эмбеддинги обучаемыми наряду с эмбеддингами токенов. Иной подход — напрямую учесть тот факт, что нам важны не абсолютные позиции токенов, а расстояние между ними, и обучатьотносительныепозиционные представления: подобный подход заметно улучшает качество на чувствительных к порядку слов задачах, а его более современныемодификациирегулярно используются в самых мощных моделях."
            }
        ]
    },
    {
        "id": "q_0379",
        "question": "Какая архитектура трансформера используется в модели GPT и как она предотвращает утечку данных при обучении?",
        "answers": [
            "Модель GPT реализована в виде последовательности слоёв декодера трансформера. Для предотвращения утечки данных используется нижнетреугольная матрица в качестве маски внимания, чтобы токены из «прошлого» не видели «будущее»."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/transformery",
                "text": "Несомненно, трансформер-модели не были бы так интересны, если бы практически все задачи NLP сейчас не решались бы с помощью этой архитектуры. Главными факторами, повлиявшими на бурный рост популярности идеи self-attention, послужили два семейства хорошо всем известных архитектур — BERT и GPT, которые в некотором роде являются энкодером и декодером трансформера, которые зажили своей жизнью. МодельGPT(Generative Pretrained Transformer) хронологическипоявиласьраньше. Она представляет собой обычную языковую модель, реализованную в виде последовательности слоев декодера трансформера. В качестве задачи при обучении выступает обычное предсказание следующего токена (то есть многоклассовая классификация по словарю). Важно, что в качестве маски внимания как раз выступает нижнетреугольная матрица: в противном случае возникла бы утечка в данных из-за того, что токены из «прошлого» будут видеть «будущее». Полученную модель можно использовать для генерации текстов и всех задач, которые на это опираются. Даже ChatGPT, обученная на специальных инструкциях, по своей сути незначительно отличается от базовой модели. Как понятно из названия, модельBidirectional Encoder Representations from Transformers(илиBERT) отличается от GPT двунаправленностью внимания: это значит, что при обработке входной последовательности все токены могут использовать информацию друг о друге. Это делает такую архитектуру более удобной для задач, где нужно сделать предсказание относительно всего входа целиком без генерации, например, при классификации предложений или поиске пар похожих документов. Важно, что при этом BERT не учится генерировать тексты с нуля: одна из его задач при обучении — это masked language modeling (предсказание случайно замаскированных слов по оставшимся, изображено на рисунке ниже), а вторая — next sentence prediction (предсказание по паре текстовых фрагментов, следуют они друг за другом или нет). Заметим, что самое ключевое отличие в моделях BERT и GPT (а не в задачах для обучения или применениях) можно свести к использованию разных видов внимания, изображенных на рисунке снизу."
            }
        ]
    },
    {
        "id": "q_0380",
        "question": "Какой подход используется для обработки больших батчей данных при обучении современных Transformer-моделей, если одна GPU не может обработать все данные за один шаг?",
        "answers": [
            "Для обработки больших батчей используются распределенное обучение и аккумуляция градиентов по микробатчам."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/transformery",
                "text": "К сожалению, если вы просто напишете код Transformer-нейросети и попробуете сразу обучить что-то содержательное, используя привычные для других архитектур гиперпараметры, то вас с большой вероятностью постигнет неудача. Оптимизационный процесс для таких моделей зачастую требуется изменить, и недостаточное внимание к этому может повлечь за собой существенные потери в итоговом качестве или вообще привести к нестабильному обучению. Первый момент, на который стоит обратить внимание, — размер батча для обучения. Практически все современные Transformer-модели обучаются на больших батчах, которые для самых больших языковых моделей могут достигать миллионов токенов. Разумеется, ни одна современная GPU не может обработать столько данных за один шаг: на помощь приходят распределенное обучение и чуть более универсальныйтрюкс аккумуляцией градиентов по микробатчам. Также в последних статьях зачастую прибегают кувеличению размера батчапо ходу обучения: идея заключается в том, что на ранних этапах важнее быстрее совершить много шагов градиентного спуска, а на поздних становится важнее иметь точную оценку градиента. Второй немаловажный фактор — выбор оптимизатора и расписания для learning rate. Обучить трансформер стандартным SGD, скорее всего, не выйдет: в оригинальной статье в качестве оптимизатора использовался Adam, и де-факто он остаётся стандартом до сих пор. Однако стоит заметить, что для больших размеров батча Adam порой работает плохо: из-за этого порой приходится прибегать к алгоритмам наподобиеLAMB, нормализующим обновления весов для каждого слоя."
            }
        ]
    },
    {
        "id": "q_0381",
        "question": "Какая архитектура на основе Transformer побила рекорды качества по классификации изображений?",
        "answers": [
            "Архитектура ViT (Vision Transformer) побила рекорды качества по классификации изображений, используя self-attention для картинок, разделённых на «лоскутные» сегменты квадратной формы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/transformery",
                "text": "Разумеется, успех этого семейства архитектур на множестве текстовых задач не мог остаться незамеченным для исследователей в других доменах. Одним из наиболее ярких примеров областей, в которой Transformer-модели нашли новое приложение, несомненно, является компьютерное зрение. К примеру,архитектураViT (Vision Transformer) в свое время побила рекорды качества по классификации изображений, задействуя идею self-attention для картинок, разделенных на множество «лоскутных» (patches) сегментов квадратной формы. Как пишут авторы статьи, идея использовать Transformer-архитектуру в зрении пришла к ним после наблюдения за успехами таких моделей в NLP: использование такого общего подхода, как self-attention, позволяет избежать необходимости явно закладывать в архитектуру особенности задачи (это ещё называют inductive bias) при достаточном времени обучения, числе параметров и размере выборки. Также именно на трансформерах базируется генеративная часть DALL-E — модели, положившей начало активным исследованиям последних лет в генерации изображений по тексту. Концептуально DALL-E довольно проста: её можно рассматривать как авторегрессивную «языковую модель», генерирующую изображение по одному «визуальному токену» за шаг. Применяют трансформеры и к обучению с подкреплением: ярким примером являетсяработаDecision Transformer, в которой предлагают использовать авторегрессивное моделирование с использованием этой архитектуры для построения агента. Авторы показали, что такой же подход, который используют для генерации текстов, можно использовать для предсказания действий в динамической среде: как показано на рисунке ниже, модель последовательно принимает стандартные тройки из закодированных состояний, текущих действий и наград и в качестве ответа на каждом шаге выдаёт следующее действие."
            }
        ]
    },
    {
        "id": "q_0382",
        "question": "Какие сокращённые обозначения приняты в литературе про онлайн-обучение для сумм?",
        "answers": [
            "В литературе про онлайн-обучение приняты сокращения: точка фиксирована и не меняется с индексацией в сумме; обычно это сумма функции потерь и регуляризатора; а также обозначение для субградиента функции в точке."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
                "text": "В выкладках очень часто используются суммы, и без сокращенных обозначений читать их невозможно. В литературе про онлайн-обучение приняты вот такие сокращения: ; Особо отметим обозначение, т.е. точкафиксирована и не меняется с индексацией в сумме; (обычно это будет сумма функции потерь и регуляризатора); — субградиент функциив точке."
            }
        ]
    },
    {
        "id": "q_0383",
        "question": "Какие условия должны выполняться для слагаемых функций в Setting 1?",
        "answers": [
            "Слагаемые функций должны быть выпуклыми вниз, иметь непустую область определения и непустой субдифференциал в каждой точке."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
                "text": "В новых обозначениях описанные выше алгоритмы примут вид: Adaptive FTRL: Adaptive Linearized FTRL: Опишем условия, накладываемые нами на алгоритм. В обзоре они называются Setting 1. От функциймы потребуем, чтобы они представлялись в виде: Слагаемые должны удовлетворять следующим условиям: Всевыпуклы (вниз); ; . Также наложим следующие требования на: Область определения— непустое множество. Это требование может показаться странным, но при желании можно придумать примерс пустой областью определения: достаточно взять несколько регуляризаторов-проекцийна непересекающиеся выпуклые множества (подробнее о таких регуляризаторах мы расскажем в одном из следующих разделов); Субдифференциалв точкенепуст."
            }
        ]
    },
    {
        "id": "q_0384",
        "question": "Какие два семейства аддитивных регуляризаторов рассматриваются в зависимости от расположения их минимума?",
        "answers": [
            "Рассматриваются семейства FTRL-Centered и FTRL-Proximal. Также существует их смешение, называемое Composite Objective."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
                "text": "Будем рассматривать аддитивные регуляризаторыиз двух семейств в зависимости от того, где у них минимум: FTRL-Centered:; FTRL-Proximal:; Composite Objective: смешение первых двух семейств. Обратите внимание: название Proximal напрямую связано с проксимальным градиентным спуском (ссылка на учебник с проксимальными методами). В обоих случаях мы накладываем регуляризатор в текущей точке. Обратите внимание: для Proximal регуляризаторов зачастую требуют выполнения более сильного условия:. Это не такое уж и серьёзное ограничение: все разумные Proximal регуляризаторы (например,) ему удовлетворяют. Обратите внимание: у обоих семейств есть значимые высокоцитируемые статьи FTRL-Centered: методRegularized Dual Averaging. Статья получила премию Test of Time Award на NeurIPS 2021, так как огромное количество последующих громких результатов (тот же AdaGrad) напрямую основывались на этих результатах. В названии Dual Averaging под dual average имеется в виду, то есть среднее по градиентам. Кардинально других техник оценок regret там нет, обзор McMahan строго улучшает все доступные там результаты. FTRL-Proximal: самая известная статья от гуглаAd Click Prediction. Известна она скорее потому, что там выписаны формулы и объяснено, как правильно реализовывать метод для large-scale задач с результатами применения различных дополнительных инженерных идей. Это хорошийинженерный обзор, а не математическая статья. Рассмотрим отдельно каждую из разновидностей алгоритмов Задача оптимизации имеет вид гдетаковы, что Пример: Рассмотрим SGD с фиксированным learning rate и стартом в точке. Положим Как мы уже знаем, итеративное обновление весов будет иметь вид Задача имеет похожий вид новыбираются так, чтобы Пример: Рассмотрим SGD с убывающим learning rate: Подробный вывод связиимы приведём в одном из следующих разделов, а сейчас просто приведём результат: Обратите внимание: как правило, на практике Proximal методы работают лучше. Интуитивно, центрирование в недавних точках вместо Рассмотрим смесь центрированных и проксимальных регуляризаторов: гдеитаковы, что Пример: FTRL-Proximal с L1 и L2 регуляризацией Обратите внимание: как правило, центрированные регуляризаторы в довесок к проксимальным вводят уже не для «дополнительной стабилизации» алгоритма, а для наложения ограничений на решение. Обратите внимание: наиболее правильные и хорошо работающие на практике способы подбора коэффициентовимы приведём в параграфе про учет дополнительнойирегуляризации."
            }
        ]
    },
    {
        "id": "q_0385",
        "question": "Какие два типа регуляризаторов упоминаются в теореме 10 из обзора McMahan?",
        "answers": [
            "В теореме 10 упоминаются Centered регуляризатор с минимумом в точке 0 и Proximal регуляризаторы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
                "text": "В этом разделе мы обсудим теоретические оценки на скорость сходимости алгоритма FTRL или, что то же самое, на скорость убывания maxRegret. Напомним формулу: Чтобы делать оценки на maxRegret, нужно пытаться оценить асимптотику ряда, каждое слагаемое которого — это решение сложной оптимизационной задачис произвольными функциями. Работать с такой сущностью крайне сложно. Наша основная цель — сделать верхнюю оценку на regret, в которой не будет этого члена.(???) Пусть— последовательность произвольных (не обязательно) функций; Пусть— последовательность выпуклых неотрицательных регуляризаторов; Пусть такжевсегда определен (относительно слабые условия 1-2 требуют от нас это явно проговорить);Тогда алгоритм, выбирающийпо правилу (3), удовлетворяет неравенству Из чего состоит эта лемма? Слагаемое— это суммарная регуляризация в точке. Совсем избавиться от вхожденияне получится, но мы можем выбирать регуляризатор так, чтобы оценить сверхубыло не очень сложно. Каждое слагаемое суммыотражает, насколько улучшается-й лосспри заменена. Поведение разностейхарактеризует стабильность алгоритма. Мы ожидаем, что при большиху хорошо сходящегося алгоритма на очередном шагебудет достаточно близок к оптимуму, то есть вся сумма будет меняться всё медленнее, и её получится разумно оценить. Пример ситуации, когда это не так, мы уже видели, когда рассматривали FTL без регуляризации для линейной функции потерь (там всё было максимально нестабильно и расходилось). К счастью, введение регуляризации обычно помогает добиться стабильности. Обе компоненты неразрывно связаны. Добавляя регуляризацию, мы увеличиваем первую компоненту, но улучшает стабильность алгоритма, чем уменьшаем вторую, и наоборот. Обратите внимание: в условиях леммы допускаются невыпуклые, и это позволяет применять её в весьма общей ситуации. Впрочем, все наши последующие выкладки все-таки будут опираться на выпуклость. Ниже мы представим теоремы 1,2 и 10 изобзора McMahan. Они дают оценки на regret в немного разных исходных предположениях и для разных типов регуляризаторов; асимптотика regret в каждом из случаев, хотя константы будут различными. О важности констант в сходимости мы поговорим в одной из следующих параграфов, когда будем разбирать метод AdaGrad. В самом конце параграфа мы обсудим, какие оценки получаются для линеаризованного regret. А в следующем параграфе мы займёмся выводом конкретных алгоритмов FTRL для разных видов регуляризаторов. Мы не будем полностью пересказывать обзор (если вам стало интересно, рекомендуем прочитать его самостоятельно) и докажем в качестве примера теорему 2, а для остальных приведём лишь формулировки. ОпределениеВыпуклая функцияназывается-сильно выпуклой по отношению к некоторой норме, если выполнено ОпределениеДвойственной нормойпо отношению к норменазывается Более подробно о-сильной выпуклости и двойственных нормах вы можете почитать, например, в книгеBoyd, 2004, Convex Optimization. Пусть Обновление параметров происходит по правилу Выполнены все условия Setting 1; Регуляризаторвыбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге). Тогда где— норма, двойственная к норме. Пусть Обновление параметров происходит по правилу Выполнены все условия Setting 1; Все регуляризаторылежат в семействе FTRL-Proximal, причёмдля всех; выбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге). Тогда где— норма, двойственная к норме. Пусть Обновление параметров происходит по правилу Выполнены все условия Settning 1; ; — неубывающая последовательность; — Centered регуляризатор с минимумом в точке; — Proximal регуляризаторы; выбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге). Тогда Если мы рассматриваем regret относительно, то Если мы рассматриваем regret относительно, то где— норма, двойственная к норме. Обратите внимание. Оценки Proximal и General отличаются индексацией: доили досоответственно. Это чисто техническое различие, однако именно из-за него с Proximal регуляризаторами удобнее работать как в теоретических выкладках, так и при выведении практических методов. Обратите внимание. Намы не хотим накладывать ограничения сильной выпуклости, но сильную выпуклость функцииможно обеспечить за счет выбора сильно выпуклых регуляризаторов. В самом деле, сумма выпуклой и сильно выпуклой функций сильно выпукла. Если и то Обратите внимание. Нормаявляется сопряженной к норме, относительно которой 1-сильно выпукла функция. Это значит, что норму мы будем выбирать посуммерегуляризаторов, а не просто по. Нам понадобится следующая чисто техническая лемма, доказательство которой мы опустим. Желающие могут прочитать Appendix B вобзоре. Lemma 7. Пусть — выпуклая функция, для которой существует; — выпуклая функция; — выпуклая функция, для которой существуети которая, кроме того, 1-сильно выпукла по норме. Тогда, для любого элементасубдифференциалаимеет место неравенство и для любогоимеет место неравенство Доказательство теоремы 2 Рассмотрим соседние раундыи. Имеем Обозначим. Посколькуодновременно минимизирует и(т.к. это proximal регуляризатор), и, имеем Далее, Выпишем оценку из Strong FTRL Lemma и постараемся оценить отмеченные рыжим слагаемые Так как по условию теоремы, мы можем убрать это слагаемое: Обозначим. Применив Лемму 7, получаем Вспомним, что для линеаризованного FTRL имеет место неравенство: Увы, верхняя оценка на левую часть неравенства не помогает оценить правую. Поэтому рассмотрим линеаризованный алгоритм более подробно. Он работает с последовательностью функций, где. Субдифференциалсостоит из одного вектора (градиента это функции) Применим приведённые выше оценки на regret для исходного и для линеаризованного алгоритма: Легко убедиться, чтооценки regret для обычного и линеаризованного FTRL совпадаюти выполнено соотношение Таким образом, для линеаризованного варианта любого алгоритма FTRL не нужно доказывать собственные оценки. А поскольку линеаризованный FTRL намного эффективнее, в дальнейшем мы всегда будем сразу переходить от исходного алгоритма к линеаризованному."
            }
        ]
    },
    {
        "id": "q_0386",
        "question": "Какое условие позволяет оценить плотность многомерного распределения через плотности одномерных распределений?",
        "answers": [
            "Это возможно при условии условной независимости признаков объектов каждого класса относительно класса. В таком случае плотность многомерного распределения можно оценить как произведение плотностей одномерных распределений отдельных признаков."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii",
                "text": "Предположим, что признакиобъектов каждого класса— независимые случайные величины: В таком случае говорят, что величиныусловно независимы относительно. Тогда справедливо Выражение (3) То есть для того, чтобы оценить плотность многомерного распределениядостаточно оценить плотности одномерных распределений,см. рисунок. На рисунке приведён пример условно независимых относительнослучайных величин. Для оценки плотности двумерных распределений объектов классов достаточно оценить плотности маргинальных распределений, изображённые графиками вдоль осей. Рассмотрим пример. Пусть решается задача классификации отзывов об интернет-магазине на 2 категории:— отрицательный отзыв, клиент остался не доволен, и— положительный отзыв. Пусть признакравен 1, если словоприсутствует в отзыве, и 0 иначе. Тогда условиевыраженияозначает, что, в частности, наличие или отсутствие слова «дозвониться» в отрицательном отзыве не влияет на вероятность наличия в этом отзыве слова «телефон». На практике в процессе feature engineering почти всегда создаётся много похожих признаков, и условно независимые признаки можно встретить очень редко. Поэтому генеративную модель, построенную в предположении условиявыражения, называют наивным байесовским классификатором (Naive Bayes classifier, NB). Обучение модели NB заключается в оценке распределенийи. Дляможно использовать частотную оценкувыражения.— одномерное распределение. Рассмотрим несколько способов оценки одномерного распределения."
            }
        ]
    },
    {
        "id": "q_0387",
        "question": "Какой метод оценки вероятности используется для дискретного распределения, если некоторое значение не встречается в обучающей выборке, чтобы избежать радикальных решений?",
        "answers": [
            "В этом случае применяется сглаживание Лапласа, которое добавляет гиперпараметр к частоте встречаемости значений, предотвращая нулевые оценки вероятности."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii",
                "text": "Пусть мы хотим оценить одномерное распределение. Если распределениедискретное, требуется оценить его функцию массы, то есть вероятность того, что величинапримет значение. Метод максимума правдоподобия приводит к частотной оценке: Выражение (4) Где— размер выборки, по которой оценивается распределение(количество объектов классав случае оценки плотности класса). При этом может оказаться, что некоторое значениени разу не встречается в обучающей выборке. Например, в случае классификации отзывов методом Наивного Байеса, слово «амбивалентно» не встретилось ни в одном положительном отзыве, но встретилось в отрицательных. Тогда использованиеоценки выраженияприведёт к тому, что все отзывы с этим словом будут определяться NB как отрицательные с вероятностью 1. Чтобы избежать принятия таких радикальных решений при недостатке статистики, используют сглаживание Лапласа: где— количество различных значений, принимаемых случайной величиной,— гиперпараметр. Для оценки плотностиабсолютно непрерывного распределения в точкеможно разделить количество объектов обучающей выборки в окрестности точкина размер этой окрестности: Обычно объекты, лежащие дальше от точки, учитывают с меньшим весом. Таким образом, оценка плотности приобретает вид где функция, называемая ядром, обычно имеет носитель(см. рисунок ниже). Такой способ оценки плотности называют непараметрическим. Результат оценки плотности с разными ядрами. Использованыизображения из: При параметрической оценке плотности предполагают, что искомое распределение лежит в параметризованном классе, и подбирают значения параметров при помощи метода максимума правдоподобия. Например, предположим, что искомое распределение нормальное. Тогда функция его плотности имеет вид Таким образом, чтобы оценить плотность, достаточно оценить параметры. Метод максимума правдоподобия в этом случае даст такие оценки: — выборочное среднее,— выборочное стандартное отклонение. Если в модели NB распределения всех признаков объектов каждого класса нормальные, оценив параметры этих распределений, мы сможем каждый классописать нормальным распределением со средними диагональной ковариационной матрицей, значения на диагонали которой обозначим. Таким образом, полученная модель (Gaussian Naive Bayes, GNB) эквивалентна моделиGDAс дополнительным ограничением на диагональность ковариационных матриц."
            }
        ]
    },
    {
        "id": "q_0388",
        "question": "При каких условиях модель GNB с общей ковариационной матрицей принимает такой же вид, как модель логистической регрессии?",
        "answers": [
            "Это происходит, когда в модели GNB всего 2 класса и соответствующие им ковариационные матрицы совпадают, как в модели LDA. В этом случае апостериорная вероятность представляется в виде сигмоидной функции от линейной комбинации признаков."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii",
                "text": "Предположим теперь, что в модели GNB класса всего 2, причём соответствующие им ковариационные матрицы совпадают, как это было в модели LDA. Таким образом. Посмотрим, как будет выглядетьв этом случае. По теореме Байеса имеем Разделим числитель и знаменатель полученного выражения на числитель: Из условной независимостиотносительнополучаем Формула (5) Перепишем сумму в знаменателе, воспользовавшись формулой плотности нормального распределения Подставляя это выражение вформулу (5), получаем Таким образом,представляется в GNB с общей ковариационной матрицей в таком же виде, как в модели логистической регрессии: Формула (6) где в случае GNB Однако это не значит, что модели эквивалентны: модель логистической регрессии накладывает менее строгие ограничения на распределение, чем GNB. Так,могут не являться условно независимыми относительно, а распределениямогут не удовлетворять нормальному закону, номожет при этом всё равно представляться в видеформулы (6). В этом случае использование метода логистической регрессии предпочтительнее. С другой стороны, если есть основания полагать, что требования GNB выполняются, то от GNB можно ожидать более высокого качества классификации по сравнению с логистической регрессией."
            }
        ]
    },
    {
        "id": "q_0389",
        "question": "Какова вероятность того, что в семье с двумя детьми, где один ребёнок уже мальчик, второй ребёнок тоже окажется мальчиком?",
        "answers": [
            "Вероятность того, что второй ребёнок в такой семье тоже мальчик, составляет 1/2 (или 50%), так как пол каждого ребёнка считается независимым событием."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "Условная вероятность возникает при ответе на вопрос о том, каковы шансы событияпри условии,что случилось событие, и обозначается. Пример. Согласно исследованиям, в среднемпациентов испытывают приступы кашля в течение дня, однако среди курильщиков доля кашляющих составляет. То есть (безусловная) вероятностьпри добавлении обусловливания может существенно измениться:. Упражнение. Известно, что в семье два ребёнка, причём один из них мальчик. Какова вероятность, что другой ребёнок тоже мальчик? В общем случае условная вероятностьприполагается равной В зависимости от соотношения событийиусловная вероятностьможет принимать разные значения, например: если, то событиеисключает реализацию события, и; если, то событиегарантирует осуществление события, и. Разумеется, чаще всего событияисоотносятся между собой более хитрым образом, и значение условной вероятностинаходится строго междуи."
            }
        ]
    },
    {
        "id": "q_0390",
        "question": "Какова вероятность допустимого переливания крови в случайно взятой паре донор-реципиент, если известны доли групп крови в популяции?",
        "answers": [
            "Вероятность допустимого переливания составляет 0.7825 или 78.25%. Это значение получено по формуле полной вероятности с учётом долей групп крови в популяции и правил совместимости между группами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "Пусть пространстворазбивается на попарно несовместные события: Тогда отсюда по свойству конечной аддитивности находим, что Переходя к условным вероятностям, получаемформулу полной вероятности: Пример. Среди населенияимеют первую группу крови,— вторую,— третью,— четвёртую. При переливании крови надо учитывать группы крови донора и рецепиента: реципиенту с четвёртой группой крови можно перелить кровь любой группы; реципиентам со второй и третьей группами можно перелить кровь той же группы или первой; реципиентам с первой группой крови можно перелить только кровь первой группы. С какой вероятностью допустимо переливание в случайно взятой паре донор—реципиент? Решение. Пусть событиесостоит в том, что переливание возможно, а событие— в том, что донор имеет группу. По формуле полной вероятности Вероятностиданы в условии, оттуда же находим, что Подставляя численные значения, получаем Упражнение. Решите предыдущий пример, выбирая в качестве разбиения набор событий, каждое из которых заключается в том, что реципиент имеет группу. Формула полной вероятности легко обобщается на случай счётного числа попарно несовместных событий, а также на случай обусловливания по некоторому событию, например:"
            }
        ]
    },
    {
        "id": "q_0391",
        "question": "Какова вероятность того, что человек действительно болен, если тест показал положительный результат, при условии, что вероятность болезни в группе составляет 0.02, тест даёт позитивный результат у 98% больных и у 4% здоровых?",
        "answers": [
            "Вероятность того, что человек с положительным результатом теста действительно болен, рассчитывается по формуле Байеса. Для этого используются данные: общая вероятность болезни 0.02, чувствительность теста 0.98 (положительный результат у больных) и ложноположительный результат 0.04 (положительный результат у здоровых)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "Заметим, что вероятностьможно записать двумя способами Оставимв левой части и получим формулу Байеса. Формула Байеса. Для любых событий,c положительной вероятностью Для вычисления знаменателя в формуле Байеса часто используется формула полной вероятности. Упражнение. Среди определенной группы людей вероятность некоторой болезни 0.02. Тест, позволяющий выявить болезнь, несовершенен. На больном он дает позитивный результат в 98 случаях из 100, и, кроме того, он дает позитивный результат в 4 случаях из 100 на здоровом. Найдите вероятность того, что человек, на котором тест дал положительный результат, действительно болен. Для непрерывного случая тоже есть своя формула полной вероятности, см. раздел проусловную вероятность."
            }
        ]
    },
    {
        "id": "q_0392",
        "question": "Какие условия должны выполняться, чтобы события A и B считались независимыми?",
        "answers": [
            "События A и B независимы, если вероятность их совместного наступления равна произведению их вероятностей: P(A∩B) = P(A)·P(B). Это эквивалентно тому, что информация о реализации одного события не влияет на вероятность другого."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "Событияиназываютсянезависимыми, если, то есть информация о реализации событияникак не влияет на вероятность события. По определению условной вероятности независимость событийиэквивалентна тому, что Последнее равенство годится для определения независмости событийидаже в том случае, еслиили. Пример. В полной колоде карт находитсякарты:масти от двойки до туза. Вероятность вытащить туза равна, карту пиковой масти —. Эти события независимы, поскольку в пересечении этих событий лежит ровно одна карта — туз пик, вероятность появления которого равна. Пусть теперь вытаскивается сразу две карты. Зависимы ли события «вытащены две карты пиковой масти» и «вытащены туз и король»? Посчитаем: Вероятность вытащить туза и короля пик равна, что отличается от. Таким образом, эти события зависимы. Событияпопарно независимы, еслипри. Эти же событиянезависимы в совокупности, если Упражнение. Приведите пример попарно независимых событий,,, не являющихся независимыми в совокупности. Определениенезависимости случайных величиниз предыдущего параграфа полностью согласуется с только что введённым определением независимых событий. Например, для случая дискретных случайных величиниобозначим тогда, и поэтому независимость случайных величиниэквивалентна независимости событийидля всевозможных значенийи."
            }
        ]
    },
    {
        "id": "q_0393",
        "question": "При каком условии зависимые события становятся независимыми?",
        "answers": [
            "Зависимые события становятся условно независимыми по отношению к выполнению некоторого третьего события, когда условная вероятность их произведения равна произведению их условных вероятностей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "Бывает так, что зависимые событияистановятся независимыми при выполнении некоторого третьего события. Более формально, событияиусловно независимыпо отношению к событию, еслии Поскольку то условная независимость событийиэквивалетна равенству а это, в свою очередь, означает, что Таким образом, вероятность произведения условно независимых событий равна произведению условных вероятностей. Эта формула полностью аналогична формуледля (безусловно) независимых событий. Пример(цепь Маркова). Последовательность событийназываетсямарковской цепью, если выполняетсямарковское свойство В марковском свойстве заложен следующий смысл: в каждый момент времени«будущее»зависит только от «настоящего», но не зависит от «прошлого» Итак, цепь Маркова характеризуется равенством, которое означает, что событияиусловно независимы по отношению к событию."
            }
        ]
    },
    {
        "id": "q_0394",
        "question": "Как определяется условное распределение дискретной случайной величины при известном значении другой случайной величины?",
        "answers": [
            "Условное распределение дискретной случайной величины при условии, что значение другой случайной величины равно определённому числу, определяется по формуле, аналогичной формуле условных вероятностей. Это действительно распределение вероятностей, поскольку все его значения неотрицательны и в сумме дают единицу."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "Пустьи— дискретные случайные величины и. По аналогии с условными вероятностямиусловное распределениеслучайной величиныпри условии, что значение случайной величиныравно, определяется по формуле Это действительно распределение вероятностей, посколькуи В непрерывном случае условное распределение задаётсяусловной плотностью где— совместная плотность случайных величини. И снова проведением маргинализации поубеждаемся в том, что с нормировкой всё в порядке: Поскольку, из формулы условной плотности получаем непрерывный аналогформулы полной вероятности: Пример. Выберем случайное число, а затем — случайное число. Как распределена случайная величина? Переформулируем задачу: известно, чтои. Требуется найти плотность случайной величины. Имеем Применяя формулу полной вероятности, находим Упражнение. Пусть случайные величины,, независимы в совокупности. Чему равна вероятность?"
            }
        ]
    },
    {
        "id": "q_0395",
        "question": "Как вычисляется условное математическое ожидание для непрерывных случайных величин?",
        "answers": [
            "Для непрерывных случайных величин условное математическое ожидание вычисляется через интеграл от произведения переменной y на условную плотность распределения f(y|x) по переменной y."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "Условное математическое ожиданиеотвечает на вопрос «чему равно среднее значение случайной величиныпри условии, что?».Имея в распоряжении матрицу условного дискретного распределенияили условную плотность, условное математическое ожидание можно вычислить следующим образом: в дискретном случае; для непрерывныхи. Важно отметить, что после суммирования или интегрирования по переменнойв формуле условного математического ожидания остаются зависимость от. Таким образом, в отличие от обычного среднего, которое является просто числом, условное ожидание представляет собой случайную величину, поскольку его значение зависит от случайного значения. Свойства условного математического ожидания (линейность). Если, то(монотонность). Если случайные величиныинезависимы, то. . (law of total expectation). Упражнение.Prove the law of total expectation. Условная дисперсияопределяется по формуле Справедливо равенство(law of total variance)."
            }
        ]
    },
    {
        "id": "q_0396",
        "question": "Какую функцию потерь обычно выбирают для одного объекта в задаче регрессии?",
        "answers": [
            "Обычно выбирают квадратичную функцию потерь."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
                "text": "В машинном обучении часто встречается задачарегрессии, в которой требуется восстановить зависимостьпри наличии выборки из некоторого неизвестного распределения с совместной плотностью. Стандартный способ решения задачи регресии — минимизация среднего значенияфункции потерь: В качестве функции потерь на одном объектев задаче регрессии обычно выбирают квадратичную функцию:. Тогда для минимизации этого функционала применим немножко вариационного исчисления и продифференцируем по функции. Получим откуда Полученное условное математическое ожидание, называемоефункцией регрессии, показывает, чему в среднем равно значение зависимой переменнойпри условии, что."
            }
        ]
    },
    {
        "id": "q_0397",
        "question": "Какие типы данных имеют графовую структуру в глубинном обучении?",
        "answers": [
            "К данным с графовой структурой относятся описания дорожных и компьютерных сетей, социальных графов и графов цитирований, молекулярных графов, а также графов знаний, описывающих взаимосвязи между сущностями, событиями и абстрактными категориями."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
                "text": "Наряду с обработкой табличных, текстовых, аудио данных и изображений, в глубинном обучении довольно часто приходится решать задачи на данных, имеющихграфовуюструктуру. К таким данным относятся, к примеру, описания дорожных и компьютерных сетей, социальных графов и графов цитирований, молекулярных графов, а также графов знаний, описывающих взаимосвязи между сущностями, событиями и абстрактными категориями. В этом параграфе мы с вами познакомимся с основными задачами, которые возникают при обработке графов, а также поговорим ографовых сверткахиграфовых нейронных сетях— специальном классе обучаемых преобразований, способных принимать в качестве входа графы и решать задачи на них."
            }
        ]
    },
    {
        "id": "q_0398",
        "question": "Какие два множества используются для представления графа?",
        "answers": [
            "Граф представляется двумя множествами: множеством вершин с их признаковыми описаниями и множеством связей (рёбер) между вершинами с их признаковыми описаниями."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
                "text": "Графпринято представлять двумя множествами: множеством, содержащим вершины и их признаковые описания, а также множеством, содержащим связи между вершинами (то есть рёбра) и признаковые описания этих связей. Для простоты математических выкладок и изложения дальнейшего материала давайте считать, что мы всегда работаем с ориентированными графами. Если граф содержит ненаправленное ребро, мы его заменяем на пару направленных ребер. Кроме того, давайте обозначать окрестность вершины как. Графовые данные довольно разнообразны. Они могут отличаться между собой в следующих моментах: По размеру, т.е.количеству вершин и/или ребер. Поналичию признаковых описаний вершин и рёбер. В зависимости от решаемой задачи, графы могут содержать информацию только в вершинах, только в ребрах, либо же и там и там. Кроме того, графы могут бытьгомо- и гетерогенными— в зависимости от того, имеют ли вершины и ребра графа одну природу либо же нет. Например, социальные графы содержат огромное количество вершин и ребер, часто измеряющееся в тысячах, содержат информацию в вершинах и очень редко в ребрах, а также являются гомогенными, так как все вершины имеют один тип. В то же время, молекулярные графы — это пример графов с, как правило, средним количеством вершин и ребер; вершины и связи в молекулярных графах имеют признаковое описание (типы атомов и ковалентных связей, а также информацию о зарядах и т.п.), но при этом также являются гомогенными графами. К классу гетерогенных графов относятся, например, графы знаний, описывающие некоторую систему, различные сущности в ней и взаимодействия между этими сущностями. Вершины (сущности) и связи (ребра) такого графа могут иметь различную природу: скажем, вершинами могут быть сотрудники и подразделения компании, а рёбра могут отвечать отношениям «Х работает в подразделении Y», «X и Z коллеги» и так далее."
            }
        ]
    },
    {
        "id": "q_0399",
        "question": "Какие три уровня классификации графов существуют и на чём они фокусируются?",
        "answers": [
            "Классификация графов может выполняться на трёх уровнях: на уровне всего графа (graph-level), на уровне отдельных вершин (node-level) и на уровне связей (edge-level)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
                "text": "Разнообразие графовых данных закономерно породило множество разнообразных задач, которые решаются на этих данных. Среди них можно встретить классические постановки классификации, регрессии и кластеризации, но есть и специфичные задачи, не встречающиеся в других областях — например, задача восстановления пропущенных связей внутри графа или генерации графов с нужными свойствами. Однако даже классические задачи могут решаться на различныхуровнях: классифицировать можно весь граф (graph-level), а можно отдельные его вершины (node-level) или связи (edge-level). Так, в качестве примераgraph-levelзадач можно привести классификацию и регрессию на молекулярных графах. Имея датасет с размеченными молекулами, можно предсказывать их принадлежность к лекарственной категории и различные химико-биологические свойства. Наnode-level, как правило, классифицируют вершины одного огромного графа, например, социального. Имея частичную разметку, хочется восстановить метки неразмеченных вершин. Например, предсказать интересы нового пользователя по интересам его друзей. Часто бывает такое, что граф приходит полностью неразмеченным и хочетсябез учителяразделить на компоненты. Например, имея граф цитирований, выделить в нем подгруппы соавторов или выделить области исследования. В таком случае принято говорить оnode-levelкластеризации графа. Наконец, довольно интересна задача предсказания пропущенных связей в графе. В больших графах часто некоторые связи отсутствуют. Например, в социальном графе пользователь может добавить не всех знакомых в друзья. А в графе знаний могут быть проставлены только простые взаимосвязи, а высокоуровневые могут быть пропущены. В конце, хотелось бы отметить очень важные особенности всех задач, связанных с графами. Алгоритмы решения этих задач должны обладать двумя свойствами. Во-первых, графы в датасетах, как правило, могут отличаться по размерам: как по количеству вершин, так и по количеству связей. Алгоритмы решения задач на графах должны уметь принимать графы различных размеров. Во-вторых, алгоритмы должны быть инварианты к перестановкам порядка вершин. То есть если взять тот же граф и перенумеровать его вершины, то алгоритмы должны выдавать те же предсказания с учетом этой перестановки."
            }
        ]
    },
    {
        "id": "q_0400",
        "question": "Какие операции могут использоваться на месте readout операции в графовых нейронных сетях для агрегации информации на graph-level уровне?",
        "answers": [
            "На месте readout операции могут располагаться любые инвариантные к перестановкам операции, такие как подсчет максимума, среднего или даже обучаемый self-attention слой."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
                "text": "Развитие глубинного обучения повлияло на подходы к решению задач на графовых данных. Был предложен концептграфовых нейронных сетей, которые в последнее время либо полностью заменили классические алгоритмы обработки графов, либо породили мощные синергии с этими алгоритмами. Графовые нейронные сети по принципу работы и построения идейно очень похожи на сверточные нейронные сети. Более того, забегая немного вперед, графовые нейроные сети являютсяобобщениемсверточных нейронных сетей. На вход графовой нейронной сети подается граф. В отличие от сверточных нейронных сетей, которые требуют, чтобы все картинки в батче были одинакового размера, графовые нейронные сети допускают разные размеры у объектов батча. Кроме того, в отличие от картинок, у которых информация довольно однородна (это, как правило, несколько цветовых каналов) и хранится в пикселях, у графов информация может также храниться в вершинах и/или ребрах. Причем в одних задачах информация может быть только в вершинах, в других только в ребрах, а в третьих и там, и там. Сама информация может быть довольно разнородной: это могут быть и вещественные значения, и дискретные значения, в зависимости от природы графа и от типа решаемой задачи. Поэтому, довольно часто первым слоем в графовых нейронных сетях идут Embedding слои, которые переводят дискретные токены в вещественные векторы. Однако, сама суть работы у графовых и сверточных сетей совпадает. В графовой нейронной сети по очереди применяются слои, которые собирают информацию с соседей и обновляют информацию в вершине. То же самое делают и обычные свертки. Поэтому такие слои и называютсяграфовыми свертками. Графовая свертка принимает на вход граф со скрытыми состояниями у вершин и ребер и выдает тот же граф, но уже с обновленными более информативными скрытыми состояниями. В отличие от сверточных нейронных сетей, при обработке графа pooling слои вставляют редко, в основном в graph-level задачах, при этом придумать разумную концепцию графового пулинга оказалось нелегко. Если вам станет интересно, вы можете познакомиться с несколькими вариантами графовых пулингов в следующих статьях: Learning Spectral Clustering Kernel k-means, Spectral Clustering and Normalized Cuts Weighted Graph Cuts without Eigenvectors В большинстве же архитектур пулинги не используются, и структура графа на входе и выходе графовой нейронной сети совпадает. Полученная после череды сверток информация с вершин и ребер в конце обрабатывается с помощью полносвязных сетей для получения ответа на задачу. Для node-level классификации и регрессии полносвязная сеть применяется к скрытым состояниям вершин, а для edge-level, соответственно, к скрытым состояниям ребер. Для получения ответа на graph-level уровне информация с вершин и ребер сначала агрегируется с помощьюreadoutоперации. На месте readout операции могут располагаться любые инвариантные к перестановкам операции: подсчет максимума, среднего или даже обучаемый self-attention слой. Как говорилось ранее, графовые нейронные сети являются обобщением сверточных. Если представить пиксели изображения вершинами графа, соединить соседние по свертке пиксели ребрами и предоставить относительную позицию пикселей в информации о ребре, то графовая свертка на таком графе будет работать так же, как и свертка над изображением. К графовым нейронным сетям, как и к сверточным, применим терминreceptive field. Это та область графа, которая будет влиять на скрытое состояние вершины после N сверток. Для графов receptive field после N графовых сверток — это все вершины и ребра графа, до которых можно дойти от фиксированной вершины не более чем за N переходов. Знание receptive field полезно при проектировании нейронной сети - имея представление о том, с какой окрестности вершины надо собрать информацию для решения задачи, можно подбирать нужное количество графовых сверток. Многие техники стабилизации обучения и повышения обобщаемости, такие как Dropout, BatchNorm и Residual Connections, применимы и к графовым нейронным сетям. Однако стоит помнить про их особенности. Эти операции могут независимо применяться (или не применяться) к вершинам и ребрам. Так, если вы применяете Dropout, то вы вправе поставить для вершин и для рёбер различные значения dropout rate. Аналогично и для Residual Connections - они могут применяться только для вершин, только для ребер или же и там и там. Кроме того, стоит иметь ввиду, что графы различных размеров будут неравноценно влиять на среднее и дисперсию в BatchNorm слое. Более стабильной альтернативой BatchNorm в обработке графов, например, являютсяLayerNormиGraphNorm, которые производят нормировку активаций по каждому графу независимо. LayerNorm, по сути, применяет BatchNorm для каждого графа: A вот GraphNorm содержит несколько обучаемых параметров и является более гибким вариантом нормализации:"
            }
        ]
    },
    {
        "id": "q_0401",
        "question": "Какие три большие темы соединяет постановка задачи онлайн-обучения?",
        "answers": [
            "Постановка задачи онлайн-обучения соединяет 'классическое' онлайн-обучение, стохастическую оптимизацию на фиксированном датасете и adversarial обучение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
                "text": "Во многих случаях обучение ML-модели ― это однократный процесс, после которого она не меняется и только используется для предсказания. А что, если к нам постоянно поступает новая информация и мы должны её учитывать? Тогда модель должна уметь обновляться при поступлении нового объекта или батча объектов. Грубо говоря, этим и занимается онлайн-оптимизация. Можно заметить, что обновление модели на батче объектов проходит и в процессе стохастической оптимизации, ― и это сходство не случайно. Оказывается, что все известные вам методы стохастической оптимизации первого порядка ― такие как SGD, AdaGrad, Adam, AMSgrad и другие ― являются в первую очередь алгоритмами онлайн-обучения. Чтобы в этом убедиться, достаточно открыть эти статьи и увидеть, для какой задачи выводятся гарантии на сходимость. Постановка задачи онлайн-обучения является одновременно математически простой и очень общей, соединяя три больших темы: «Классическое» онлайн обучение. Стохастическую оптимизацию на фиксированном датасете. Мы покажем, что любой алгоритм онлайн обучения можно переформулировать, как алгоритм стохастической оптимизации; при этом из гарантий на сходимость, полученных для онлайн обучения, автоматически будет следовать сходимость на фиксированном датасете. Adversarial обучение. Данный текст является в первую очередь систематизирующим. Мы постараемся достичь следующих целей: Подведем единую математическую базу, необходимую для вдумчивого чтения статей по оптимизации. Это будет полезноML-теоретикам. Покажем, как исторически развивались методы оптимизации, как из одного метода получался другой, какие проблемы они решали и ― главное ― актуальны ли эти проблемы сейчас. Разберём все «именные» методы оптимизации на набор базовых концепций и покажем, как вы можете самостоятельно их сочетать, создавая оптимальный метод для решения своей задачи. Спойлер: базовых концепцийнамногоменьше, чем наименований методов. Эти знания будут полезныML-инженерам. Пройдемся по относительно нишевым темам, таким как разреженные методы регуляризациии, и рассмотрим наилучшие методы оптимизации для них. Такие методы невозможно получить в стандартной постановке стохастической оптимизации. Эти знания будут полезныML-инженерам, занимающимся рекомендательными системами. В параграфе «Введение в онлайн-обучение», которую вы читаете сейчас, вы познакомитесь с общей постановкой задачи онлайн-обучения, а также с семейством алгоритмов Follow the Regularized Leader (FTRL), которое включает в себя все методы первого порядка. Кроме того, вы узнаете, как сводить задачи стохастической оптимизации к задачам онлайн-обучения и увидите, что этот переход позволяет строить более эффективные методы стохастической оптимизации, особенно для разреженных регуляризаторов вроде. В параграфе «Адаптивный FTRL» вы узнаете, как улучшить сходимость алгоритмов стохастической оптимизации с помощью регуляризаторов и каковы гарантии сходимости для регуляризованных задач. Это позволит вывести AdaGrad как наилучший адаптивный метод для онлайн-оптимизации. В параграфе «Регуляризация в онлайн-обучении» мы снова поговорим о регуляризации, но на этот раз речь пойдёт о регуляризаторах, которые накладывают на решение определённые органичения, например, разреженность. Вы сможете с новой стороны взглянуть на разреживающие свойства-регуляризаторов. Кроме того, мы получим не достижимые с помощью обычных SGD/AdaGrad результаты для разреженныхирегуляризаторов. В параграфе «Стохастическая оптимизация в Deep Learning» мы перейдём к методам оптимизации в глубоких нейросетях. Вас ждёт краткий исторический обзор и мотивация появления двух важных модификаций AdaGrad ― Adam и RMSprop. Мы покажем, что эти методы ломаются вокруг критических точек, и поговорим о том, как починить это и достичь более точной сходимости (этого эффекта можно достичь либо прямой модификацией алгоритмов (AMSgrad и RAdam), либо косвенно с помощью Learning Rate Scheduler'ов). В конце параграфа мы соберём воедино все рассмотренные концепции и покажем, как можно комбинировать лучшее из разных методов оптимизации в один новый метод."
            }
        ]
    },
    {
        "id": "q_0402",
        "question": "Какие задачи приводятся в качестве примеров, где хорошо работает выпуклая оптимизация?",
        "answers": [
            "В тексте в качестве примеров приводятся задачи линейной оптимизации, проблема Expert Advice, а также линейная и логистическая регрессия."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
                "text": "Выпуклая оптимизация играет центральную роль в анализе алгоритмов онлайн-обучения и позволяет получать эффективные алгоритмы. Вот примеры задач, в которых она хорошо работает: Линейная оптимизация; Expert Advice problem; Линейная/логистическая регрессия. Для задач, возникающих в глубинном обучении, мы поступим согласно рекомендациям ведущих ученых: возьмем теоретически обоснованный алгоритм выпуклой оптимизации, воткнем в нейросеть и помолимся, чтобы он сохранил свои хорошие свойства. С методами первого порядка, как правило, работает (а здесь мы будем рассматривать только такие методы) Введём в нашу игру предположение о выпуклости, а заодно попробуем сделать вычисления менее громоздкими. Для этого определим упрощённуюигру (2): Выбираем параметрическую модель; Получаем извневыпуклуюфункцию потерь; Считаемв точкеи получаем наш loss. Первое упрощение состоит в том, что прогнози бейзлайнмы теперь берём не из абстрактного функционального множества, а из некоторого параметризованного семейства. Говоря «модель», мы имеем в виду «модель, заданная параметрами». Скажем, для линейной регрессии это может быть вектор весов и bias. Regret будет записываться следующим образом: Второе упрощение в том, что мы не думаем о признакахи таргетах. Вся эта информация спрятана в определение функции. Например, для линейной регрессии. При этом теперь у нас нет частичной информации о текущем раунде игрыпередвыбором новой модели: ведь мы сначала выбираеми лишь потом получаем. Обратите внимание: если вы попробуете себе представить онлайн алгоритм на практике, то, как правило, частичная информация о функцииперед выборомвамдоступна. Например, рассмотрим рекомендательную систему с онлайн-дообучаемой ранжирующей моделью: Пользователь пришел, мы сразу пошли в базу данных за его историей покупок и получили признаковое описание (возможно частичное); С учётом этого признакового описания мы выбираем модельи с её помощью оцениваем релевантность товаров этому пользователю; Смотрим, что купил пользователь и купил ли, это даёт нам. Тем не менее, в этом параграфе мы будем считать, что частичной информации нет, потому что хотим разрабатывать наиболее общий фреймворк, а не ad-hoc алгоритмы, использующие конкретный вид этой частичной информации. Если даже для какой-то узкой проблемы можно сформулировать специфический алгоритм, учитывающий частичную информацию, с высокой вероятностью он не будет работать значимо лучше стандартного решения. Если знаете контрпримеры ― напишите, добавим сюда для полноты."
            }
        ]
    },
    {
        "id": "q_0403",
        "question": "Какой алгоритм минимизирует ошибку на всех предыдущих раундах и почему он получил такое название?",
        "answers": [
            "Это алгоритм Follow The Leader (FTL), который называется так потому, что следует за наилучшим возможным алгоритмом-бейзлайном в regret, учитывающим информацию с текущего шага."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
                "text": "Предположим, что мы провелишагов игры (2) и теперь выбираем модель(как условились, без информации о). Наиболее естественным выбором будет алгоритм, минимизирующий ошибку на всех предыдущих раундах Такой алгоритм называетсяFollow The Leader (FTL), потому что мы идем вплотную за наилучшим возможным алгоритмом-бейзлайном в regret (лидером), который учитывает ещё и информацию с-го шага: К сожалению, для алгоритма в таком виде есть важные примеры выпуклых задач, когда он не работает. Допустим, наши функции потерь линейны. Вам может показаться, что линейная функция не особенно похожа на функцию потерь, но, забегая вперед, именно такие функции потерь встретятся дальше при изучении градиентных онлайн-алгоритмов (). Рассмотрим одномерную задачу,,. Пусть Алгоритм FTL выглядит так: Такие осциллирующие суммы коэффициентов будут заставлять FTL выбирать наихудшее возможное решение в каждом раунде. Функция потерь в каждом раунде будет равна, а кумулятивная функция потерь примет вид. При этом кумулятивная функция потерь константного решениябудет равна 0. Получаем линейный regretотносительно бейзлайна, алгоритм не сходится."
            }
        ]
    },
    {
        "id": "q_0404",
        "question": "Какой алгоритм получается при использовании регуляризатора L2?",
        "answers": [
            "Использование регуляризатора L2 приводит к алгоритму Follow The Regularized Leader (FTRL)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
                "text": "Чтобы стабилизировать алгоритм, мы добавим регуляризаторы, и назовем получившийся алгоритмFollow The Regularized Leader (FTRL): Упражнение. Проверьте, что в примере из предыдущего параграфа добавление регуляризатора стабилизирует осцилляцию решения. Добавкадолжна быть выпуклой и неотрицательной. При этом различный выборбудет приводить к различным алгоритмам и различным оценкам на regret. Первое, что приходит в голову ― эторегуляризатор. Он даёт алгоритм"
            }
        ]
    },
    {
        "id": "q_0405",
        "question": "Какие современные градиентные алгоритмы являются примерами data-dependent регуляризаторов?",
        "answers": [
            "К таким алгоритмам относятся Adam, RMSProp и AdaGrad. Они работают значительно эффективнее алгоритмов с константными регуляризаторами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
                "text": "Следующая идея―сделать регуляризатор зависящим от данных (то есть от) и своим на каждом раунде T: Забегая вперед―все современные градиентные алгоритмы Adam, RMSProp, AdaGrad и т.д. попадают в это семейство data-dependent регуляризаторов и работаютзначительноэффективнее любых алгоритмов с константными регуляризаторами. Обратите внимание: регуляризаторы являются частью алгоритма FTRL, онине входятв формулу для regret, которая по-прежнему имеет вид Таким образом, мы не изменили постановку решаемой нами задачи, изменили лишь метод ее решения. Обратите внимание: введение регуляризаторов влияеттолькона онлайн-алгоритм и выбор. Бейзлайнывыбираются как и раньше:"
            }
        ]
    },
    {
        "id": "q_0406",
        "question": "Какой пример классического использования онлайн логистической регрессии приведён в тексте?",
        "answers": [
            "Классическим примером использования онлайн логистической регрессии является предсказание CTR (click-through rate) в рекламе."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
                "text": "Рассмотрим пример с логистической регрессиейи константнымрегуляризатором: Классический пример использования онлайн логистической регрессии ―предсказание CTR в рекламе. Миллионы запросов в секунду =>миллионы решений этой оптимизационной задачи в секунду (если разбивать на батчи ― тысячи, но сути это не меняет). Успех онлайн-алгоритма в таких задачах определяется его вычислительной эффективностью, как по памяти, так и по скорости. Увы, с этим у нашего алгоритма не всё так хорошо: Скорость: аналитически задача не решается =>FAIL Память: нужно хранить все предыдущие запросы,=>FAIL Здесь нам на помощь приходит линеаризация задачи. Если фунциивыпуклые (вниз) и гладкие (на негладкие посмотрим позже), то они удовлетворяют основному свойству выпуклых функций Разложим все функциив точках: Просуммируем от 1 до Теперь обозначими рассмотрим выпуклуюлинейнуюзадачу онлайн обучения с функцией потерь. Regret для нее выглядит как Неравенство выше позволяет нам оценить regret исходной задачи через regret линеаризованной: Минимизируя правую часть неравенства, мы, безусловно, будем минимизировать и левую, так что мы можем выбиратьалгоритмом, решающим линеаризованную задачу, и получать хорошо сходящийся метод для исходной задачи. Посмотрим, будет ли линеаризованный алгоритм вычислительно эффективнее. Посмотрим на линеаризацию задачи с data-depedent регуляризатором: Линейные задачи имеют аналитическое решение для широкого спектра. Собственно, это и есть основное, что нужно помнить на практике ― выбирать регуляризатор так, чтобы эта задача решалась аналитически. Мы рассмотрим простейший случай: Справа дифференцируемая функция, так что мы можем найти, приравняв к нулю градиент: где― это сумма векторов, которую не нужно пересчитывать заново на каждом шаге, а можно инкрементально обновлять. Благодаря этому нам больше не нужно помнить все предыдущие объекты выборки, достаточно хранить лишь некоторую статистику. Готово, мы построили наш первый вычислительно эффективный алгоритм онлайн обучения! В дальнейшем мы займемся тем, чтобы найтинаилучшийвычислительно эффективный алгоритм. Обратите внимание: теперь вы понимете, почему пример с линейной функцией потерь был так важен: линейные функции соответствуют линеаризованному regret. При этом, как мы уже выяснили, без регуляризатора такие линеаризованные задачи нестабильны. Обратите внимание: если переписать немного формулу для, мы получим: Таким образом, формулы FTRL c константным регуляризаторомэквивалентны формулам обычного стохастического градиентного спуска. Забегая вперед, скажем, что различия в формулах градиентного спуска и FTRL будуттольков разделе Composite objective FTRL. В этих отличиях и будет заключаться преимущество FTRL перед привычным SGD. Обратите внимание: концепции FTRL и gradient descent в литературе часто называютlazy(ленивая) иgreedy(жадная) соответственно. Gradient descent жадный, потому что алгоритм для обновленияиспользует только текущийи текущий градиент. Всё, что было на предыдущих шагах, алгоритм забывает. FTRL ленивый, потому что алгоритм в явном виде сохраняет всю информацию с начала обучения и рассчитывает, исходя из всей истории, и только после этого применяет все регуляризаторы. Подробнее мы расскажем об этом в разделе «Сравнение Composite Objective FTRL-Proximal и Adaptive Gradient Descent»."
            }
        ]
    },
    {
        "id": "q_0407",
        "question": "Какое условие минимума для выпуклых функций используется в негладком случае?",
        "answers": [
            "Точка является минимумом, если её субдифференциал содержит ноль."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
                "text": "Выше мы рассматривали гладкие функции. Гладкость ― сильное ограничение, и оно на самом деле необязательно, можно ослабить условие, если использовать субградиенты. Когда мы переходили от исходной задачи к линеаризованной, мы использовали основное свойство гладких выпуклых функций Гладкость обеспечивает существованиедля всех. Но нам ведь не нужно, чтобы существовал именноградиентфункции. Нам достаточно, чтобы существовалкакой-товектор, для которого выполнено неравенство И в этом помогают следующие два понятия. Субдифференциаломфункциив точкеназывается множество Субградиентомфункциив точкеназывается любой элемент множества. Потребуем, чтобы для любой точки был непустой субдифференциал, и дело в шляпе, можно вместовезде подставлять субградиенти обобщить все выкладки выше на негладкий случай. Примеры. Для гладких функций субдифференциал состоит из одной точки: градиента функции, а субградиент равен градиенту. В качестве примера функции с нетривиальным субградиентом рассмотрим функцию, где― скаляр. Субградиент в точке― это можество Легко видеть, что― это отрезок. Замечание. На практике субдифференциал используют не так часто. Оптимизационные задачи с популярными негладкими регуляризаторамирешают «в лоб», без перехода к субградиентной оценке, например, с помощьюпроксимальных методов. Обратите внимание. В литературе очень часто используется термин Online Mirror Descent. Mirror descent ― это оптимизационная процедура вида в которой― дополнительный негладкий регуляризатор (например, тот же), который мы как раз таки не заменяем на субградиентную оценку, а вместо этого оптимизируем всё «в лоб». Заметьте, что эти формулыидентичныформуламProximal Gradient Descent. Если у нас нет регуляризатора, то формулы эквивалентны обычному gradient descent. Как вы увидите дальше, Mirror Descent ― это частный случай общего фреймворка, который мы описываем. Почти все градиентные методы оптимизации обобщаются на негладкие функции. Модифицируется необходимое и достаточное условие минимума для выпуклых функций: точкаявляется минимумом, если субдифференциал содержит ноль:. Очевидно, это прямое обобщение условия для гладких функций, где субдифференциал состоит только из градиента функции."
            }
        ]
    },
    {
        "id": "q_0408",
        "question": "Какой принцип является основополагающим для каждого краудсорсингового проекта, создаваемого для задач машинного обучения?",
        "answers": [
            "Основополагающим принципом является декомпозиция — деление сложной задачи на несколько микрозадач."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "Применение краудсорсинга в машинном обучении значительно ускорило процесс развития AI продуктов. Беспилотные автомобили, голосовые помощники, поисковые системы, онлайн-карты, машинный перевод появились и развиваются во многом благодаря данным, полученным с помощью краудсорсинга. Например, чтобы поисковая система смогла точно отвечать на вопросы пользователей, нужно проделать большую работу по разметке данных: проанализировать запросы и поведение пользователя, оценить возможные результаты на соответствие запросу, сравнить разные варианты поисковых выдач и выбрать лучший. Все эти данные ложатся в основу моделей, которые учатся искать лучшие ответы, опираясь на размеченные людьми образцы. Такие задачи, на первый взгляд, кажутся трудозатратными и продолжительными по времени. Но если воспользоваться возможностями краудсорсинга и подойти к ним, как к инженерной проблеме, эти сложности будут преодолены. В этом тезисе содержится основная идея краудсорсинга для AI и машинного обучения:чтобы решить задачу по разметке данных для обучения или оценки качества модели, нужно подойти к ней как к инженерной проблеме. Это значит, что нужно организовать выполнение задачи таким образом, чтобы конечный результат зависел от качества самого процесса, а не от добросовестности или экспертности отдельных исполнителей. Такой подход требует соблюдения ряда правил. Прежде всего, чтобы проект был доступен максимальному количеству исполнителей и не зависел от редких компетенций, его необходимо разделить на сценарии или небольшие задачи. Принцип деления сложной задачи на несколько микрозадач называетсядекомпозицией. Это основополагающий принцип для каждого краудсорсингового проекта, создаваемого для задач машинного обучения. Каждую микрозадачу необходимо детально продумать. Определить элементы, которые будут ее сопровождать. Некоторые из них (например, инструкции или интерфейсы) обязательно должны присутствовать в проекте. Другие — такие как предварительная фильтрация исполнителей или отслеживание их поведения в проекте — используются в случае необходимости. Все эти элементы решают вопрос качества данных: чем лучше продуман проект, чем эффективнее он «сопровождает» исполнителя во время разметки, тем меньше остается пространства для ошибок или недобросовестного поведения. Детальную схему проекта, состоящую из цепочки микрозадач и сопровождающих их элементов, называют пайплайном (от англ. pipeline — «линия, очередь»). Его создают на этапе планирования проекта и обращаются к нему как к «дорожной карте»."
            }
        ]
    },
    {
        "id": "q_0409",
        "question": "На какие две основные группы делятся ML-задачи, решаемые с помощью краудсорсинга?",
        "answers": [
            "Краудсорсинг помогает решить ML-задачи, разделяемые на две основные группы: разметка данных и сбор данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "Краудсорсинг помогает решить разнообразный спектр ML-задач. Разделим их на две основные группы — разметка и сбор данных."
            }
        ]
    },
    {
        "id": "q_0410",
        "question": "Какие задачи относятся к группе, где пользователи краудсорсинговых платформ выполняют действия с уже полученными данными?",
        "answers": [
            "К таким задачам относятся транскрипция аудио, NLP-задания по выделению смысловых частей в запросах, проверка автоматического перевода, модерация контента, разметка видео и сегментация объектов на изображениях."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "К этой группе относится целый ряд задач, в рамках которых пользователю краудсорсинговой платформы необходимо выполнить некоторое действие с уже полученными данными. Например, его могут попросить перевести записи из аудио в текст (транскрипция аудио) или выделить в запросе пользователя в поисковой системе определенные смысловые части, такие как тип продукта, цвет, бренд (NLP-задания). Также в эту группу входят задачи по проверке автоматического перевода, модерации контента, разметке видео или сегментации объектов на изображениях. В качестве примера рассмотрим задачи по сегментации изображений. Как правило, они нужны для обучения алгоритмов компьютерного зрения. Они используются, например, для создания беспилотного транспорта, который должен распознавать всевозможные препятствия на дорогах: людей, светофоры, разметку, дорожные знаки, дома, заборы, искусственные неровности и т. д. Чтобы эти модели были качественными и могли без труда распознавать любые объекты на своем пути, им нужно показать большое количество изображений и в, более сложных случаях, видео с выделенными на них объектами разных классов. Выделением этих объектов занимаются пользователи краудсорсинговых платформ. На 2D и 3D изображениях, а также видео, снятых во время движения с помощью камер, радаров и лидаров, они находят нужные объекты и обводят их. Изображения и видео, размеченные по требованиям инструкции, используются для обучения моделей компьютерного зрения. Самый простой пайплайн задачи по сегментации изображений для беспилотных автомобилей состоит из трех проектов (рис. 1). В первом проекте исполнители отвечают на вопрос, есть ли на фото нужные объекты (например, дорожные знаки). Те изображения, на которых эти объекты есть, перенаправляются в проект номер два. В нем вторая группа исполнителей обводит дорожные знаки с помощью прямоугольников. Эту разметку проверяет еще одна группа исполнителей в следующем проекте, третьем по счету. Далее включается схема так называемой отложенной приёмки заданий. В случае отклонения задание отправляется на повторную разметку. Верно выполненная работа включается в итоговый датасет. Подобные пайплайны, но еще более многоступенчатые, используются для обучения моделей компьютерного зрения Яндекса. В январе 2020 года инженерам компании удалось продемонстрировать одну из моделей на конференции Consumer Electronics в Лас-Вегасе. Беспилотные автомобили со встроенной моделью проследовали по маршруту с разными дорожными сценариями: нерегулируемыми перекрестками, сложными поворотами со встречным разъездом, пешеходными переходами и многополосными участками. Всего эти автомобили преодолели более 7 тысяч км."
            }
        ]
    },
    {
        "id": "q_0411",
        "question": "Какой процесс используется для сбора фраз для обучения голосового помощника?",
        "answers": [
            "Для сбора фраз используется краудсорсинг, где исполнители записывают необходимые фразы (например, «Привет, Алиса») и загружают их на платформу, после чего другая группа проверяет записи на соответствие требованиям."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "Суть задач, связанных со сбором контента, заключается в поиске материалов (изображений, фотографий, фактов), необходимых для решения проблемы. Например, используя краудсорсинг, инженеры собирают фразы для обучения голосового помощника (рис. 2). Пайплайн такого проекта выглядит довольно просто: исполнители записывают необходимую фразу, например, «Привет, Алиса», и загружают ее в интерфейс задания на краудсорсинговой платформе. Далее другая группа исполнителей проверяет эти записи на предмет ошибок и других требований: если запись соответствует инструкции, вторая группа подтверждает ее, а если в записи допущены ошибки, отклоняет. В следующем проекте еще одна группа исполнителей записывает недостающие фразы, затем они вновь проходят проверку. Этот процесс повторяется по кругу, пока не будет собрано достаточное количество фраз нужного качества."
            }
        ]
    },
    {
        "id": "q_0412",
        "question": "Какие инструменты помогают быстрее спроектировать интерфейс задания на краудсорсинговой платформе?",
        "answers": [
            "Готовые шаблоны позволяют быстрее спроектировать интерфейс задания на краудсорсинговой платформе."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "Масштабируемость и скорость выполнения задач по разметке данных напрямую зависят от доступа заказчика к большому облаку исполнителей. Залог успеха здесь — использование открытых краудсорсинговых платформ, которые позволяют постоянно пополнять это облако и, следовательно, масштабировать процессы сбора или разметки данных. Открытые краудсорсинговые платформы — например, Amazon Mechanical Turk или Толока — работают по принципу маркетплейсов. Заказчик может создать на такой платформе свой проект, найти для него нужных исполнителей, обучить их и поручить им выполнение задания, контролируя качество результата. Пользователи открытой платформы, в свою очередь, могут выбрать интересующий их проект, выполнить задания и получить за проделанную работу вознаграждение. Свой выбор проекта они могут сделать как на основе рейтинга проекта, так и с учетом итогового вознаграждения — либо просто потому, что какая-то задача им интересна больше других. Открытые краудсорсинговые платформы — инструмент для тех, кто планирует самостоятельно контролировать разметку данных. А это, как правило, большинство проектов в сфере AI и машинного обучения. Для ML-разработчиков крайне важно, чтобы кропотливая работа по написанию инструкций, проектированию интерфейсов, отбору и обучению участников, настройке контроля качества была выполнена в точности так, как это запланировано в пайплайне проекта. Все эти шаги напрямую влияют на качество тренировочных данных, а от них в немалой степени зависит успех продукта. При выборе краудсорсинговой платформы важно учесть и то, какими инструментами они располагают. Например, с готовыми шаблонами можно быстрее спроектировать интерфейс задания, а инструменты контроля качества помогут отсеять роботов и недобросовестных исполнителей. Кроме того, выбор платформы во многом определит то, с какими исполнителями будет вестись работа. Изучение их характеристик даст понимание, в каких странах они проживают, на каких языках разговаривают и, что немаловажно, сталкивались ли они с проектами, подобными тому, над которым планируется работа. Альтернативой платформам-маркетплейсам могут стать проекты, которые предлагают готовые датасеты и помощь в разметке данных для проекта. Это, например, Scale AI, Hive Data, Alegion. Такие платформы подойдут не всем — выше уже шла речь о том, что некоторые проекты (как, например, обучение алгоритмов компьютерного зрения) нуждаются в специфическом контексте для сбора датасета. Кроме того, построенные по общим принципам краудсорсинга проекты могут запускаться и на внутреннее облако исполнителей, связанных с компанией какими-либо договорными отношениями. Это важно в случаях, если речь идет о разметке чувствительных данных. Однако такой процесс тяжело поддается масштабированию, потому что требует больших ресурсов для сопровождения сотрудников."
            }
        ]
    },
    {
        "id": "q_0413",
        "question": "В каких случаях применение краудсорсинга для перевода текста может быть эффективным?",
        "answers": [
            "Краудсорсинг может быть эффективен для перевода отдельных фраз в конечном контексте, например, отдельных реплик для голосового ассистента, где не требуется поддержание последовательности и согласованности всего текста."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "Несмотря на все многообразие задач, которые можно решить с помощью краудсорсинга, есть случаи, когда его применение затруднено либо просто нецелесообразно. Во-первых, необходимо оценить затраты, сопутствующие запуску проекта. Создание и настройка эффективного пайплайна для сбора или обработки данных требуют времени и квалификации высокоуровневого специалиста. Потраченный им ресурс может не окупиться, если требуется лишь один раз разметить небольшое количество данных. Облаку исполнителей с трудом поддаются задачи, требующие серьезного включения и поддержания контекста. Секрет краудсорсинга — в создании небольших автономных заданий, каждое из которых может быть решено согласно несложной инструкции. Если исполнителю требуется учитывать большой объем сопутствующей информации, чтобы выполнить задачу верно — скорее всего, ее лучше выполнять без использования краудсорсинга. Например, облако исполнителей вряд ли сможет осуществить перевод книги: ее не стоит разбивать на отдельные предложения, ведь перевод должен быть последовательным и согласованным. В то же время, краудсорсинг может помочь при переводе отдельных фраз в конечном контексте, например, отдельных реплик для голосового ассистента. Наконец, если задача требует крайне специфических навыков, то поиск или обучение подходящего исполнителя на краудсорсинговой платформе сравнится с наймом эксперта. В таких случаях стоит оценить возможность декомпозиции задачи так, чтобы она оказалась разбита на ряд менее сложных действий. Если сделать это невозможно (например, для выполнения задания требуется знание редкого языка), оптимальным способом поиска исполнителя могут стать профессиональные сообщества."
            }
        ]
    },
    {
        "id": "q_0414",
        "question": "Из каких шести этапов состоит типичная краудсорсинговая задача?",
        "answers": [
            "Типичная краудсорсинговая задача состоит из следующих этапов: декомпозиция, инструкция и интерфейс, контроль качества, отбор и обучение исполнителей, выбор схемы оплаты и бонусирования, а также агрегация ответов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "Типичная краудсорсинговая задача состоит из шести этапов: Декомпозиция; Инструкция и интерфейс; Контроль качества; Отбор и обучение исполнителей; Выбор схемы оплаты и бонусирования; Агрегация ответов. Разберем каждый из этапов на примере уже упомянутого проекта по сбору данных для обучения беспилотных автомобилей. Мы запустим этот проект на краудсорсинговой платформе «Толока»."
            }
        ]
    },
    {
        "id": "q_0415",
        "question": "Какой инструмент на платформе «Толока» позволяет выделять объекты прямоугольниками на изображениях?",
        "answers": [
            "Для выделения объектов прямоугольниками используется готовый шаблон с инструментом «полигон», который легко позволяет выполнять такие задания."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "В качестве исходных данных возьмем объемный набор фотографий с изображением улиц. После запуска краудсорсингового проекта мы должны получить те же изображения, но с выделенными на них дорожными знаками. Наша задача — выделить прямоугольниками дорожные знаки на каждой фотографии. Пример того, как должен выглядеть итоговый датасет с выделенными на них объектами приведен на рисунке 3. Можем ли мы поручить нашу задачу участникам краудсорсинговой платформы напрямую? В данном случае — нет. Изображения для разметки могут полностью не соответствовать нашему запросу. Например, на изображениях может не быть нужных объектов. Некоторые фотографии могут не загрузиться в интерфейсе (появится ошибка). Чтобы избежать подобных ситуаций, нам нужно отобрать фотографии с подходящими объектами. Отбор фото или их фильтрация станет первой микрозадачей илипервым пулом(так называется набор заданий в рамках проекта на платформе «Толока») нашего проекта. Что дальше? Когда мы получили фотографии с дорожными знаками, мы сможем запустить проект по выделению объектов на изображениях. Наша задача — выделить на фотографиях все дорожные знаки прямоугольниками. Чтобы создать подобное задание на краудсорсинговой платформе «Толока», можно воспользоваться готовым шаблоном. Он предусматривает специальный инструмент, «полигон», который с легкостью позволяет выполнять подобные задания. На этом мы могли бы остановиться. Получили изображения с выделенными объектами — задача выполнена. Однако для данного проекта потребуется запустить еще одно микрозадание. Фотографии с выделенными объектами необходимо проверить. Кто-то из исполнителей может пропустить некоторые знаки или выделить их неверно. Таким образом, проверка размеченных изображений в конкретном проекте необходима. Но специфика задачи такова, что мы не можем просто сравнить работу отдельного исполнителя с заведомо верным примером: выделенные области могут отличаться на несколько пикселей, но это не будет означать, что ответ неверен. Итак, что мы делаем? Мы создаем новый пул заданий, в котором спрашиваем «Верно ли выделены объекты на фото?». Участники отвечают на вопрос, после чего фото с верно отмеченными объектами отправляются в итоговый датасет и оплачиваются. Фото с неверно выделенными объектами отклоняются и не оплачиваются. Все фотографии, которые не проходят проверку, отправляются на переразметку (т. е. размечаются повторно). Какие выводы мы можем сделать по итогу разбора декомпозиции проекта? Самый главный вывод — решение о декомпозиции задачи следует принимать, исходя из типа задачи и данных, которые есть на входе — это могут быть изображения, видео, ссылки, точки на карте, координаты этих точек. Также следует различать типичные случаи, в которых декомпозиция особенно рекомендована для проекта. Речь идет об объемных проектах, многослойных задачах, задачах со множеством вариантов ответов и объемных процессах: Объемные проекты. Если в рамках проекта нужно ответить на несколько вопросов, то лучше сделать это поочередно или в выбранной последовательности. Многослойные задачи. Если в рамках одной задачи нужно выполнить более одного действия (например, отнести объект к определенной группе и ответить на вопрос, предназначен ли он только для взрослых), то лучше сделать это поочередно или в выбранной последовательности. Задачи со множеством вариантов ответов. Если в задании есть один вопрос и 10 и более вариантов ответа, то лучшим решением будет группировка ответов по темам, а затем создание отдельного проекта для каждой группы ответов. Объемные процессы. Если задача включает сложные механизмы контроля качества и отложенную проверку, необходимо создать отдельный проект, в котором одна группа исполнителей будет проверять другую. Есть ли случаи, когда декомпозировать задачу не нужно? Да. Нет необходимости разбивать задачу на части, если соблюдаются два критерия: инструкции к задаче помещаются на половине листа бумаги формата А4, или задача выполнена с помощью одного действия, например, выбора из нескольких категорий."
            }
        ]
    },
    {
        "id": "q_0416",
        "question": "Какие обязательные пункты должны быть включены в инструкцию для микрозадачи?",
        "answers": [
            "Обязательными пунктами инструкции являются: описание задачи, условия входа в задание (обучение, экзамен, ценообразование), технические нюансы (устройство, настройки), краткое описание интерфейса задания, пошаговое описание частых сценариев выполнения с примерами, справочные материалы (глоссарий, FAQ) и информация о том, куда направлять вопросы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "После декомпозиции нашего проекта нам необходимо создать для него инструкцию. Инструкция потребуется для каждой микрозадачи. В нашем случае нам необходимо создать три инструкции. Какие пункты мы обязательно в них укажем? Первым пунктом инструкции станет описание задачи. В нем мы объясним участнику, что предстоит сделать и где будет использован результат этой работы. Например: Вашему вниманию представлен проект, результаты которого помогут сделать беспилотные автомобили безопасным транспортом. Ваша задача — определить, есть ли дорожные знаки на изображении. Выберите ответ «Да», если изображение содержит дорожные знаки. Выберите ответ «Нет», если на изображении дорожных знаков нет. На изображении, представленном ниже, есть несколько дорожных знаков. Значит, правильный ответ — «Да». Далее, мы подробно опишем условия входа в задание: расскажем, будет ли обучение и экзамен, с каким качеством его нужно пройти, есть ли в проекте повторный экзамен для тех, кто не прошел испытание с первого раза. Также опишем ценообразование. Например: Чтобы выполнить это задание, вам потребуется пройти обучение на тренировочном пуле. В тренировочный пул войдут задания аналогичные тем, что будут в основном проекте. После обучения мы предложим вам пройти экзамен. В экзамен войдут 5 изображений. Следующий элемент инструкции — технические нюансы. Здесь мы расскажем, с какого устройства потребуется выполнить задание — со смартфона или с компьютера — и какие дополнительные настройки браузера будут необходимы. Этот пункт в особенности важен для второго задания в рамках нашего проекта. Разметить дорожные знаки прямоугольниками участники смогут только с компьютера: Мы рекомендуем выполнять это задание с персонального компьютера. Это необходимо, чтобы вы смогли корректно выделить все необходимые объекты на изображении. Краткое описание интерфейса задания — еще один важный пункт в инструкции. Для большей наглядности мы сделаем скриншот с комментариями о том, для чего нужны те или иные блоки и кнопки. Если в задании простой интерфейс, эту часть можно пропустить. Например: Используйте желтый квадрат («полигон») в левой части экрана, чтобы выделять дорожные знаки на изображении. Теперь о самом задании. Чтобы избежать ошибок, мы пошагово опишем все частые сценарии, которые могут случиться при выполнении наших задач. Также мы укажем, что делать с нестандартными случаями. Добавим примеры: несколько кейсов сделают теорию намного понятнее. Справочные материалы — глоссарий, faq — важное дополнение к этим сценариям. Наконец, мы расскажем, куда направлять вопросы по заданию или проекту в целом. На что мы обратим внимание при написании текста? Первое, за чем стоит проследить — сам язык, которым написана инструкция. Мы откажемся от профессионального сленга и не будем использовать терминологию. Некоторые термины, например, «полигоны», мы объясним или заменим синонимами — «прямоугольники». Наша задача — сделать инструкцию простой и понятной для большого числа участников. Следуя этой же задаче, мы упростим стиль и синтаксис (одна мысль = одно предложение; одна тема = один абзац), не будем использовать пояснения в скобках и сделаем форматирование единообразным. Готовый текст инструкции мы обязательно проверим, выполнив некоторое количество заданий. Такое упражнение быстро покажет, какие случаи еще не описаны в инструкции, а какие описаны мало. Кроме того, оно позволит проверить как выглядит наше задание на разных устройствах: умещаются ли все картинки и скриншоты на экранах мобильного телефона, планшета и компьютера. В итоге каждая инструкция не займет больше двух экранов. Это максимальное количество пространства для инструкции, за пределы которого лучше не выходить. Если инструкция все же не вписывается в такой объем, вероятно, задача слишком многосоставная и ее нужно декомпозировать."
            }
        ]
    },
    {
        "id": "q_0417",
        "question": "Какой метод агрегации данных основан на предположении, что правильный ответ — это тот, который выбирает большинство исполнителей?",
        "answers": [
            "Это метод «Мнение большинства». Он предполагает, что самый популярный ответ среди исполнителей является верным и становится финальным ответом."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
                "text": "Представим, что мы запустили наш проект и получили необходимые данные. В краудсорсинговых проектах данные обычно собираются в перекрытии (мнения большинства) — это один из распространенных механизмов контроля качества исполнителей и улучшения качества итогового набора данных. Но как выбрать из нескольких оценок финальную? В данном случае нам помогут механизмы агрегации данных. Что они делают? Они обрабатывают файлы с ответами исполнителей и выбирают из нескольких ответов тот, который с наибольшей вероятностью окажется верным. Рассмотрим принцип работы механизмов агрегации данных на примере первого пула с заданиями (см. рис. 4). У нас есть набор изображений, и наша цель — отнести каждое изображение к группе «изображения с дорожными знаками» или к группе «изображения без дорожных знаков». В соответствии с принципом краудсорсинга задание должно быть распределено между несколькими исполнителями, каждый из которых размечает некое подмножество изображений. В результате для каждого изображения у нас есть несколько результатов разметки. Цель метода агрегации — объединить эти результаты в один качественный ответ. Алгоритм агрегации данных «Мнение большинства» основан на предположении, что правильный ответ — этот тот, который выбирают большинство исполнителей (рис. 5). Самый популярный ответ становится финальным ответом. Практика показывает, что при помощи метода, основанного на мнении большинства, можно получить достойные результаты. Поэтому этот метод с успехом применяется во многих проектах. Также одно из преимуществ этого метода заключается в том, что он весьма нагляден и логика его работы понятна. Однако в проектах краудсорсинга существуют определенные временные и бюджетные ограничения. Наша цель в том, чтобы собрать минимальный объем данных, необходимый для достижения желаемой точности. С этой точки зрения, метод, основанный на мнении большинства, далеко не всегда будет оптимальным выбором. Чтобы осознать слабые стороны метода, рассмотрим его модель. Модель, лежащая в основе метода, проста. Есть N изображений и M исполнителей. Каждое изображениеподразумевает некий неизвестный ответ («изображения с дорожными знаками» или «изображения без дорожных знаков» в нашем случае). При использовании модели, основанной на мнении большинства, предполагается, что если исполнительразметил изображение, его ответ является правильным с некоторой вероятностью При этом вероятность правильного ответа полагается одинаковой для каждого исполнителя и вопроса. Допущение, чтоучитывает, что для каждого исполнителя вероятность правильного ответа выше, чем неправильного. В таком случае, поскольку число разметок для каждого изображения достаточно велико, мнение большинства с высокой вероятностью даст истинные ответы. В силу своей простоты, метод основанный на мнении большинства имеет ряд ограничений: **Однородность исполнителей.**Во-первых, данный метод предполагает, что все исполнители обладают одинаковыми способностями. Иными словами,для каждого конкретного вопроса вероятность того, что исполнитель правильно ответит на вопрос, одинакова для всех исполнителей.Однако на практике пул исполнителей на краудсорсинговых платформах чрезвычайно разнообразен: кто-то из них очень аккуратно и скрупулезно выполняет задачи, а кто-то небрежен и чаще допускает ошибки. Таким образом, одно из направлений совершенствования модели, основанной на мнении большинства, — это учет различия в способностях исполнителей в рамках модели. **Однородность вопросов.**Во-вторых, модель, основанная на мнении большинства, предполагает, что вопросы имеют одинаковую сложность. Другими словами,вероятность того, что исполнитель правильно ответит на вопрос, одинакова для всех вопросов.Однако некоторые вопросы в рамках проекта могут быть сложнее других. Таким образом, еще одно направление по улучшению модели на основании мнения большинства — это учесть в модели разную степень сложности вопросов. Далее мы рассмотрим оба направления развития модели и расскажем о других алгоритмах, учитывающих особенности краудсорсинговых заданий. Рассмотрим модель, которая учитывает неоднородность исполнителей при агрегации ответов. Естественный способ учесть различия в способностях исполнителей — ввести параметр качества для каждого исполнителя. Если естьисполнителей, то мы можем связать каждого исполнителяс неизвестным параметром качества. Чем выше параметр качества исполнителя, тем больше вероятность того, что исполнитель ответит на вопрос правильно: Другими словами, вероятность того, что исполнитель правильно ответит на вопрос, своя для каждого исполнителя (но от вопроса она все еще не зависит). В ситуации, когда у исполнителей разные способности, логично присваивать больший вес ответам более сильных исполнителей и меньший вес — ответам более слабых. Однако проблема в том, что параметры качества для исполнителей априори нам не известны. Основная идея двух методов модели агрегации данных с учетом способностей исполнителей заключается том, чтобы одновременно оценить параметры качества для исполнителей и ответы на поставленные вопросы. Рассмотрим каждый их них. Контрольные вопросы (такжеhoneypots,golden sets) — это задания, на которые заказчик заранее знает правильные ответы. На практике мы часто добавляем в набор данных определенное количество контрольных вопросов, чтобы контролировать качество работы исполнителей. Когда этих вопросов достаточно много, мы можем использовать их для оценки качества работы. Предположим, что у нас естьконтрольных вопросов и некий исполнитель, который правильно ответил навопросов изконтрольных вопросов. Тогда мы можем оценить параметр качества для исполнителя следующим образом: Теперь, когда у нас есть оценка параметра качества, мы можем оценить ответ каждого исполнителя по-разному. Эта идея подводит нас к концепции взвешенного мнения большинства (от англ.Weighted majority vote). Идея этого метода проиллюстрирована на рисунке ниже (рис. 6). Предположим, что у нас есть нестандартное изображение, на котором столб похож на дорожный знак. В этом случае модель, основанная на простом мнении большинства, не делает отличия между ответами исполнителей с меньшими способностями (первых двух исполнителей) и ответами исполнителя-эксперта (последнего исполнителя) и допускает ошибку. Напротив, модель взвешенного мнения большинства дополнительно взвешивает каждый ответ полученным коэффициентом качества исполнителя. Такая модель приводит к правильному ответу, поскольку мнение исполнителя-эксперта в таком случае перевешивает мнения двух других исполнителей. Метод взвешенного мнения большинства подходит для тех случаев, когда в проекте есть достаточное количество контрольных заданий, необходимых для оценки качества работы исполнителя. Однако зачастую контрольных заданий в проекте не хватает, в связи с чем оценки могут быть довольно неточными. Кроме того, исполнители могут коллективно выявить контрольные вопросы и начать обманывать систему, давая правильные ответы на контрольные вопросы и случайные ответы на другие. В этом случае, чтобы оценить параметры качества исполнителей при ответе на неизвестные вопросы, мы можем использовать метод Дэвида — Скина: Метод Дэвида-Скинаодновременно находит значения качества исполнителей и ответы на вопросы, которые согласуются с наблюдаемыми данными в наибольшей степени.Мы имеем в качестве данных— количество раз, при которых разметчикпоставил классобъекту(возможно, разметчик видел этот объект несколько раз). Обозначим через это наши латентные величины. В качестве параметров имеем — вероятность того, что разметчикпоставил классвместо правильного класса. — вероятность класса. Примем также обозначения: , , . Поймём, какой будет функция неполного правдоподобия в этой задаче. Прежде всего, Если– номер класса-го объекта, то (значенияоднозначно определяются номером истинного класса, поэтому справапропадает). Далее, мы считаем, что разметчики действуют независимо, поэтому Разберёмся с величиной. Она отвечает за то, какие классы-й разметчик ставил-му объекту. Мы считаем, что встречи разметчика с объектом упорядочены по времени, тогда Эту вероятность можно переписать в виде а итоговое неполное правдоподобие предстаёт в виде Его нам нужно максимизировать пои Пояснение к формуле: Вне больших скобок фиксируются объект и его класс, сама скобка возводится в степень 1, если рассматривается правильный класс объекта, и в степень 0 иначе. Внутри сначала записана вероятность того, что объект имеет данный класс, а затем — перебор по всем пользователям и всем классам, которые мог поставить данный пользователь. Наконец, записывается вероятность того, что пользователь нашему объекту поставил некоторый класс, которая возводится в степень того, сколько раз он поставил этот класс. Например, если пользователь видел изображение котика 5 раз, при этом 3 раза он сказал, что котик, а два раза — песик, то вероятностьдля данного котика учтется 3 раза, а вероятность— 2 раза. Рассмотрим концепцию метода Дэвида-Скина на простом примере (рис. 7).Предположим, что у нас есть тольковопросов иисполнителей. Каждый исполнитель отвечает на все вопросы. В этом случае наблюдаемые данные — это ответы исполнителей на вопросы. Давайте разберемся в том, каким образом метод Дэвида — Скина позволяет найти параметры качества для исполнителей и те ответы на вопросы, которые лучше всего соответствуют наблюдаемым данным. Для этого рассмотрим два варианта, показанные на картинках ниже (см. рис. 7.1). Каждая картинка предполагает свой набор параметров. Посмотрим, какой из предложенных вариантов лучше соответствует наблюдаемым данным. Во-первых, обратите внимание, что на обоих изображениях предложенные ответы согласуются с ответами исполнителя, у которого, по оценкам, высокий параметр качества. Но какой выбор параметров подходит данным лучше всего? Чтобы ответить на этот вопрос, обратите внимание, что ответы второго и третьего исполнителей полностью совпадают. Если параметры качества для этих исполнителей соответствуют первой картинке, тогда, если верить этой модели, эти два исполнителя отвечают наугад. В таком случае высокая степень согласия между исполнителями нас бы скорее удивила, поскольку отвечая наугад, они должны время от времени расходиться в своих ответах. Напротив, если исполнители 2 и 3 — эксперты, как на втором изображении, тогда мы ожидаем, что у них будет высокая степень согласия, и это то, что мы видим в данных. Интуитивно, второй набор параметров лучше согласуется с наблюдаемыми данными. Приведенный простой пример показывает, что концепция согласованности между потенциальными параметрами и наблюдаемыми данными позволяет нам исключить те варианты, которые плохо согласуются с наблюдаемыми данными. Оба метода — взвешенное мнение большинства и агрегация по методу Дэвида — Скина — входят в стандартный функционал Толоки. В двух наших пулах, в первом и третьем, мы будем использовать метод Дэвида — Скина. Он позволит нам получить наиболее точные данные для нашего проекта. Подробнее узнать о том, как получить агрегированные результаты из размеченного пула, можно вдокументации. Метод Дэвида-Скина и метод, основанный на мнении взвешенного большинства, — основа современного краудсорсинга. Многие создатели проектов повышают качество данных, используя эти методы агрегации. Однако существуют и другие современные подходы. Например, есть группа подходов, которые учитывают сложность вопроса при агрегировании ответов. Аналогично тому, как мы замеряли качество для каждого исполнителя, вводя параметр качества, точно так же для каждого исполнителя мы можем ввести параметр сложностидля каждого вопроса. Тем не менее, главная проблема заключается в том, как описать взаимодействие между качеством исполнителя и сложностью вопроса, и в результате рассчитать вероятность того, что конкретный исполнитель правильно ответит на выбранный вопрос. В работе Уайтхилла с соавторами (2009) предлагается следующее решение. Во-первых, параметр качества для исполнителя, который раньше мерился в диапазоне, теперь задается в интервале. В частности, возможно нулевое качество, которое соответствует ситуации, когда исполнитель отвечает на все вопросы наугад. Положительные значения качества подразумевают, что работник с большей вероятностью даст правильный ответ, а отрицательные значения означают, что исполнитель настроен враждебно и с большей вероятностью даст неправильный ответ. Во-вторых, для параметра сложности каждого вопросатакже может быть дана интуитивная интерпретация: низкая сложность вопросаозначает что вопрос настолько прост, что любой исполнитель ответит на него правильно с вероятностью, близкой к 1. Чем выше уровень сложности, тем меньше вероятность того, что конкретный исполнитель ответит на вопрос правильно. Объединив эти параметры, модель предполагает, что вероятность для конкретного исполнителяпри ответе на конкретный вопросможет быть корректно описана следующим параметрическим выражением: Следует заметить, что в таком случае вероятность является функцией и самого исполнителя, и вопроса, на который исполнитель отвечает. Как только мы выбрали параметрическое уравнение для описания взаимосвязи между уровнем качества исполнителя и сложностью вопроса, с одной стороны, и вероятностью правильного ответа, с другой, мы можем применять все те же принципы, что и для расчета параметров по модели Дэвида – Скина. Таким образом мы можем оценить не только параметры модели, но и полученные ответы на вопросы. Более подробно об этом можно почитать встатье. Несмотря на то, что параметрические модели позволяют делать весьма эффективные выводы, в них неизбежно заложены сильные допущения о когнитивных процессах, присущих исполнителям при ответе на вопросы. Эти допущения обычно невозможно проверить, поэтому неясно, насколько хорошо они согласуются с реальностью. Соответственно, если допущения параметрической модели неверны, то и методы, используемые такой моделью, могут дать неожиданные результаты. Это подводит нас к идее непараметрического подхода, где можно попробовать избежать сильных допущений о мыслительных процессах. Непараметрический подход предложил Нихар Б. Шах с коллегами в 2016 году. Вместо моделирования вероятностей, что исполнительверно ответит на вопрос, считается, что между этими вероятностями есть взаимосвязь. При этом модель использует два ключевых допущения: Во-первых, предполагается, что исполнителей можно выстроить в ряд в порядке возрастания способностей. Если исполнительзанимает в этом ряду более высокую позицию, чем исполнитель, то при ответе на каждый вопрос исполнительс большей вероятностью даст правильный ответ, чем исполнитель. Во-вторых, предполагается, что вопросы можно выстроить в ряд в зависимости от их сложности. Если вопроссложнее вопроса, то любой исполнитель совершит ошибку при ответе на вопросс не меньшей вероятностью, что и отвечая на вопрос. Стоит заметить, что эти допущения гораздо слабее, чем в параметрической модели. В самом деле, параметрическая модель не только предполагает существование таких упорядоченных рядов, но и задает все вероятности. С другой стороны, непараметрический подход делает всего лишь естественное предположение о существовании последовательных рядов, но не ограничивает набор когнитивных механизмов, характерных для исполнителей. Было показано, что в некоторых случаях непараметрическая модель позволяет лучше делать выводы. Более подробно об этом можно почитать вполном тексте статьи. Как мы уже говорили, эти подходы еще достаточно новые и не успели стать классикой краудсорсинга. Если сложность вопросов в вашем проекте существенно варьируется, мы рекомендуем более основательно изучить упомянутые методы и лежащие в их основе допущения, а затем опробовать их на практике. Использованная литература Jeff Howe,The Rise of Crowdsourcing, The Wired, 2006. Джефф Хау, Краудсорсинг: Коллективный разум как инструмент развития бизнеса, Альпина Паблишер, 2012. Omar Alonso, The Practice of Crowdsourcing, 2019. «Cамая богатая часть планеты работает бесплатно во время перерывов на кофе»: редактор Wired Джефф Хау о краудсорсинге, T &P, 2012. Р. А. Долженко, А. В. Бакаленко, Краудсорсинг как инструмент мобилизации интеллектуальных ресурсов: опыт использования в Сбербанке России, Российский журнал менеджмента, Том 14, №3, 2016, С. 77–102. Беспилотные автомобили Яндекса на CES 2020: 7 тысяч км без водителя за рулём по улицам Лас-Вегаса, Новости Яндекса, 2020. Метод Дэвида и Скина"
            }
        ]
    },
    {
        "id": "q_0418",
        "question": "Какой язык программирования доминирует в индустрии машинного обучения и почему?",
        "answers": [
            "Доминирует Python, благодаря большому количеству специализированных библиотек и фреймворков для машинного обучения, таких как TensorFlow и PyTorch."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
                "text": "Грубо говоря, оно делится на две большие категории: Железо и вычислительные ресурсы для обучения моделей; Программы и библиотеки для работы с данными. Начнём со второй категории. Чтобы начать работу, нужно установить Python — именно этот язык программирования доминирует в индустрии, благодаря большому количеству библиотек и фреймворкам, предназначенным именно для машинного обучения — TensorFlow или PyTorch. Фреймворк — слой абстракции над языком программирования, который облегчает разработку. Например — нам нужно сделать отверстие в доске. Эту задачу можно решить разными способами: закрутить и выкрутить шуруп, забить и вытащить гвоздь и так далее. А можно взять дрель и сверло. Дрель в этом примере и есть фреймворк. PyTorch чаще выбирают для академических исследований — он более гибкий и больше подходит для экспериментов. TensorFlow — для продакшен-решений, поскольку он более подходит для масштабирования моделей. Далее нужно установить библиотеки для Python. Продолжая строительную аналогию: библиотека — это насадка для дрели. То есть инструмент для конкретной задачи: можно установить сверло для дерева, для бетона, для металла, а можно коронку или щётку — зависит от задачи. Чаще всего применяют: Scikit-learn — библиотека машинного обучения для классических алгоритмов: классификации, регрессии, ансамблей и других. О них мы подробнее поговорим далее в этом хендбуке. Pandas — библиотека для предварительной обработки данных, и работы с данными вообще. С её помощью можно загрузить датасет, обработать недостающие значения, закодировать категориальные переменные и многое другое. Matplotlib и Seaborn — библиотеки для создания визуализаций и графиков в Python. После этого — выбрать IDE, то есть текстовый редактор для кода: Visual Studio Code, Jupyter, Sublime, PyCharm, и так далее. Теоретически, всё это можно установить на домашний компьютер или ноутбук — именно так и делали ещё 15-20 лет назад. Но вам не хватит вычислительных ресурсов для обучения моделей, в первую очередь — объёма памяти GPU (видеокарты). Даже для файнтюнинга небольших языковых моделей, таких как BERT, необходим графический процессор с минимум 16 Гб видеопамяти. Мало кто может позволить себе дома оборудование для обучения более сложных моделей. Сейчас исследователи и студенты чаще берут вычислительные мощности в аренду. Тут есть два способа: арендовать устройство «в облаке» (эта модель называется IaaS), воспользоваться специальной платформой для ML (эта модель называется SaaS). IaaS-сервис, грубо говоря, — очень мощный удалённый компьютер. Это значит, что прежде чем решать задачу на такой машине, её всё равно необходимо настроить: развернуть IDE, установить Python, фреймворки и библиотеки и многое другое. Это не всегда удобно: иногда хочется, чтобы всё работало «из коробки». «Из коробки», как вы могли догадаться, работают SaaS-сервисы: они предоставляют полностью настроенные среды, готовые к немедленному использованию в решении задач. Эти платформы обычно включают в себя: IDE или другие среды программирования, часто представленные в формате ноутбуков. Заранее настроенные рабочие окружения, оптимизированные для конкретной системы. Возможности для загрузки и хранения данных и файлов. Интеграцию с известными сервисами, такими как GitHub. О них мы и поговорим далее. Но если вам ближе путь самурая — то вот несколькоIaaSпровайдеров. По ссылкам можно узнать, как развернуть окружение для ML в IaaS-сервисе."
            }
        ]
    },
    {
        "id": "q_0419",
        "question": "Какие платформы относятся к популярным SaaS-решениям для работы с ML-задачами?",
        "answers": [
            "К популярным SaaS-платформам относят Google Colab, Kaggle Notebooks, AWS SageMaker, Azure ML Studio и Yandex DataSphere."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
                "text": "Как мы уже выяснили, главное преимущество SaaS – это простота входа: вы получаете доступ к необходимым ресурсам без забот о их настройке и оптимизации, что позволяет быстро приступить к работе над ML-задачами. К популярным SaaS-платформам относят: Google Colab Kaggle Notebooks AWS SageMaker Azure ML Studio Yandex DataSphere Ниже мы собрали в таблицу их возможности, плюсы и минусы. Далее мы расскажем, как решать ML-задачи на примере Yandex DataSphere. Но если вас заинтересовали другие платформы, то в конце параграфа будет список ссылок на руководства по работе с ними."
            }
        ]
    },
    {
        "id": "q_0420",
        "question": "Как студенты могут получить бесплатный доступ к DataSphere?",
        "answers": [
            "Студенты могут получить доступ через тестовый грант или специальный грант для учебных программ. Для учебного гранта преподаватель должен заполнить форму, что откроет доступ для всей группы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
                "text": "Прежде чем мы начнём настройку — несколько важных моментов. DataSphere — это платный сервис, но вы можете начать работу бесплатно, с помощьютестового гранта. Также у сервиса есть специальные гранты для учебных программ. Чтобы воспользоваться грантом, нужно попросить своего преподавателя заполнитьформу, — это откроет доступ к сервису для всех студентов группы. Отлично, теперь можем приступить к настройке. Для этого: Перейдите на сайтDataSphere Нажмите большую синюю кнопку и авторизуйтесь в Яндекс ID Создайте сообщество и нажмите «Привязать платежный аккаунт»на появившемся красном дисклеймере. В созданном сообществе вы сможете взаимодействовать со всеми важными сущностями в DataSphere. Теперь можно создать проект на вкладке «Проект». В созданном проекте вы можете запустить JupyterLab: После незначительного ожидания откроется выбор среды исполнения. Там вы можете выбрать любой из примеров ноутбуков с различными снипеттами кода под разные задачи. Создадим новый пустой ноутбук, нажав “DataSphere Kernel”. Теперь, в появившемся новом ноутбуке, если мы запустим любой код в одной из ячеек, вам будет предложено выбрать конфигурацию виртуального рабочего места (более подробно о доступных конфигурациях можно почитатьтут). После выделения ресурсов, которое тоже займет небольшое количество времени, все последующие выполнения ячеек будут происходить без выбора конфигурации. Теперь, когда у нас всё готово — DataSphere настроена, ресурсы выделены, можем выполнить тестовую лабораторную работу!"
            }
        ]
    },
    {
        "id": "q_0421",
        "question": "В какой среде выполняется работа по обучению генеративной трансформерной модели?",
        "answers": [
            "Работа выполняется в среде DataSphere."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
                "text": "В ней мы будем обучать генеративную трансформерную модель с помощью библиотекиtransformers. Сама работа находится в DataSphere — переходите поссылке, чтобы ознакомиться с заданием. А как закончите — возвращайтесь, чтобы завершить урок. Вот и всё! Если вы читаете эти строки, и у вас всё получилось — вы большой молодец. Если не получилось — ничего страшного, с первого раза мало у кого всё получается. Советуем вступить всообщество хендбукаи попросить помощи или совета."
            }
        ]
    },
    {
        "id": "q_0422",
        "question": "Какие облачные платформы для работы с данными и машинным обучением рассматриваются в материалах?",
        "answers": [
            "В материалах рассматриваются Google Colab, Kaggle Notebooks, AWS SageMaker, Azure ML Studio и DataSphere."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
                "text": "Руководствопо работе с Google Colab. Гайддля новичков по Kaggle Notebooks. Руководстводля AWS SageMaker. Документацияпо настройке Azure ML Studio Статьяпро то, как используется DataSphere в образовании КакDataSphere помогает изучать снежных барсов"
            }
        ]
    },
    {
        "id": "q_0423",
        "question": "Какие типы рекомендательных систем выделяют в зависимости от используемой информации?",
        "answers": [
            "Выделяют три типа: контентные, коллаборативные и гибридные системы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
                "text": "Все рекомендательные системы можно поделить на три типа в зависимости от того, какую информацию они используют для построения рекомендаций: Контентные; Коллаборативые; Гибридные. В данном разделе мы подробнее рассмотрим основные алгоритмы построения контентных рекомендаций. Основная идея контентных рекомендаций состоит в том, что для их построения будут использоваться атрибуты объектов и пользователей. На основе данных атрибутов мы можем найти релевантные данному пользователю объекты и рекомендовать их. Представим, например, что мы работаем в музыкальном онлайн-сервисе и хотим подбирать наиболее релевантную музыку нашим пользователям. Допустим у нас есть пользователь Иван, который интересуется русским роком. Тогда наша система может рекомендовать Ивану музыку этого или подобных жанров. Можно придумать много различных атрибутов трека: жанр, автор, год выхода, продолжительность и так далее. Также можно использовать дополнительную информацию о пользователе: возраст, уровень дохода и тому подобные. Допустим, мы работаем в музыкальном сервисе. Тогда в качестве признаков объектов можно использовать: Стандартные статистики объекта: количество лайков, кликов, полных прослушиваний; Признаки автора: количество слушателей, жанр; Неструктурированные данные: названия треков, обложки альбомов или даже предобученные эмбеддинги треков целиком. В качестве признаков пользователей можно использовать: Информацию про пользователя, если она нам доступна: возраст, пол, язык, насколько долго пользуется сервисом; Информацию про контекст запроса: с какого устройства был сделан, в какое время. Информацию про друзей пользователя и их взаимодействия. Например, усреднённый эмбеддинг всех треков, которые слушал каждый из друзей. Или же можно обучить RNN или Transformer на истории и результат конкатенировать к остальным признакам."
            }
        ]
    },
    {
        "id": "q_0424",
        "question": "Как можно снизить количество параметров в модели, учитывающей попарные взаимодействия пользователей и объектов?",
        "answers": [
            "Для этого используется трюк: каждому признаку сопоставляется вектор размерности k, а симметричная матрица коэффициентов заменяется на её низкоранговое приближение. Это позволяет снизить число параметров до O(kn)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
                "text": "Начнём с постановки задачи. Пусть I – множество объектов (айтемов), U - множество пользователей. Для каждой пары объект-пользователь построим вектор размерностивзаимодействия этой пары, в котором единицы стоят на месте соответствующих пользователя и объекта: Предсказывать будем пользовательские рейтинги объектов. Можно рассмотреть простейшую регрессионную модель: Заметим, что к этой модели легко добавить любые фичи объектов, пользователей или пар объект-пользователь: Дальше будем обозначать черезобщее число фичей. Модель можно обогатить признаками, отвечающими за взаимодействия второго порядка: Матрицуможно считать симметричной: в любом случае, мы используем только её верхний треугольник. Из-за использования попарных взаимодействий пользователей и объектов в полученной модели будетпараметр, и так какможет быть очень большим, работать с такой моделью может оказаться непросто. Для решения этой проблемы можно использовать следующий трюк. Сопоставим каждому признакувектордля некоторого не очень большогои представим модель в виде: Таким образом, мы заменяем симметричную матрицу коэффициентовна её низкоранговое приближение, где– матрицас векторамипо столбцам. Число параметров модели при этом можно снизить до. На практике матрицаразреженная, и, как правило, даже при небольшомполучается её неплохо приблизить. В то же время, при небольшихмодель обладает лучшей обобщающей способностью. Вычислитьпо можно за: Итоговая модель имеет вид Данная модель и называетсяфакторизационной машиной. Первоначально факторизационные машины использовали только коллаборативный сигнал, но, как мы уже видели, в такую модель можно естественным образом добавить и контентную информацию. Факторизацонную машину можно обучать для решения разных задач. Например: Предсказание рейтинга. Ответ моделиможно интерпретировать, как вещественный рейтинг, и решать задачу регрессии. Бинарную классификацию рекомендовать/не рекомендовать. Тогдаимеет смысл логита, и мы можем оптимизировать оптимизировать log loss или hinge loss. Ранжирование объектов. Тогда– это ранжирующая функция. Модель обычно обучается градиентным спуском. Оригинальная статья Статья про практическое применение Как следующий этап развития факториационных машин, появилась идея иметь несколько различных латентных представлений для каждой из фичей. Пример: есть три разных по своей природе признака: год выпуска, цвет и марка автомобиля. В факторизационной машине для учёта взаимодействия год-цвет и год-марка используется один и тот же вектор для года. Но так как эти признаки разные по смыслу, то и характер их взаимодействия может отличаться. Идея: использовать 2 разных вектора для признака «год выпуска» при учёте взаимодействий год-цвет и год-марка. Таким образом, модель принимает вид: Авторы статьи выложилиисходный код своей библиотеки libffm, с помощью которой они смогли войти в топ-3 сразу в трёх соревнованиях на kaggle (Criteo, Avazu, Outbrain). Подробнее об этом можно почитатьвот тут."
            }
        ]
    },
    {
        "id": "q_0425",
        "question": "Какую функцию потерь предлагается использовать для задачи ранжирования в DSSM, чтобы положительные примеры оказывались выше отрицательных?",
        "answers": [
            "Для задачи ранжирования в DSSM можно использовать попарный лосс, например, функцию потерь вида max(0, -s(u, i⁺) + s(u, i⁻) + margin), где s — мера близости, u — пользователь, i⁺ — релевантный объект, i⁻ — нерелевантный объект. Это заставляет модель ранжировать положительные примеры выше отрицательных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
                "text": "Теперь рассмотрим ещё одну популярную модель, которая использует контентную информацию для построения рекомендаций –DSSM. Оригинальная статья В оригинальной статье DSSM была использована для нахождения «схожести» между поисковым запросом и документом. Для этого она использовала текст запроса и текст документа. DSSM представляет из себя «двуногую» (two-tower) нейронную сеть. В исходной постановке на первый вход подаётся текст запроса, а на второй – текст документа. Далее, независимо для текста запроса и текста документа строятся эмбеддинги. Итоговая «схожесть» вычисляется, как косинусная мера близости между ними. На схеме ниже Q – это запрос (query), а D – документ (document). Некоторые авторы пытались в качестве меры близости рассматривать вместо косинусной меры обучаемый MLP, но это оказалось гиблой идеей. Эта архитектура оказалась крайне удобной при использовании на практике, так как эмбеддинги пользователя и объекта можно предподсчитать независимо и дальше хранить сразу готовые представления для них, а при запросе к рекомендациям просто пересчитывать меру близости, что ускоряет применение модели. Данная идея хорошо обобщается на построение рекомендаций. Поиск релевантных объектов можно представить, как задачу ранжирования, где вместо текстов запроса и документа мы будем иметь некоторую контентную информацию о пользователе и объекте. Давайте считать, что мы для каждого запросапредсказываем один релевантный документ. Обозначим черезипостроенные моделью эмбеддинги запросаи документасоответственно. Будем вычислять условную вероятность клика по документупри условии запросаследующим образом: где Здесь– коэффициент сглаживания, который подбирается эмпирически, а– число всех документов. Если в качестве функции потерь мы выбираем кросс-энтропию, то на паре запрос-кликнутый документона принимает вид Но вычислять градиент такого функционала для каждого примера дорого, ведь для этого придётся для каждого запроса находить вероятность клика по всем документам. Что же делать? На помощь приходитnegative sampling. Заметим, что среди документовв знаменателеесть лишь один кликнутый, а остальные тысячи и миллионы являются отрицательными примерами. Есть смысл на каждом шаге оптимизации рассматривать не все из них, а только небольшую выборку, вместо полной суммы беря где– подобранные для запросанегативные примеры. Генерировать их можно по-разному; на практике чаще всего используют одну из следующих стратегий: Равновероятно выбирать подмножество документов из некликнутых. В оригинальной статье предлагают брать позитивные и негативные в соотношении. С большей вероятностью выбирать те из некликнутых документов, популярность которых выше. На каждой эпохе обучения выбирать некликнутые документы, получившие максимальный скор для этого запроса на предыдущей эпохе. Задачу построения рекомендаций можно решать, как задачу ранжирования. Например, это можно делать с помощью попарного лосса. А именно, рассмотрим пару объектов, в которой– релевантный, ане релевантный для пользователя. Тогда мы можем использовать один из двух вариантов функции потерь: . Тем самым модель будет учиться ранжировать положительные примеры выше отрицательных. (triplet loss). При этом модель обучается так, чтобы положительный и отрицательный примеры как можно больше отличались. Эта функция потерь довольно популярна не только в DSSM сетках, но и в целом в задачах, где нужно обучить парные представленияобъектовиз разных доменов так, чтобы для релевантных друг другуиэмбеддинги оказывались близкими, а для не релевантных далёкими. Рассмотрим батчразмера, где– пользователь,– пользователю, а– таргет, степень релевантности объекта пользователю. Построим по ним: матрицу эмбеддингов пользователей; матрицу эмбеддингов объектов; вектор таргетов. Рассмотрим матрицу где softmax берётся по строкам Рассмотрим функцию потерь вид Эта функция потерь старается сделать так, чтобы для релевантных друг другу (с) парскалярное произведение эмбеддинговбыло максимальным."
            }
        ]
    },
    {
        "id": "q_0426",
        "question": "Какую задачу решает модель Behaviour Sequence Transformer, представленная исследователями из Alibaba?",
        "answers": [
            "Модель решает задачу предсказания вероятности клика по объекту (Click Through Rate prediction)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
                "text": "В 2018 году появилась архитектура трансформеров на основе механизма внимания. Модели на основе трансформеров показали state-of-the-art результаты на большом числе NLP задач, а впоследствии оказалось, что они отлично подходят и для задач компьютерного зрения. С их помощью можно решать и задачи рекомендаций. Аналогия заключается в следующем: если в NLP трансформеры работают с последовательностями токенов, то в рекомендациях в качестве последовательности можно взять историю событий пользователя. Каждый элемент последовательности – это взаимодействие пользователя с объектом, например, клик на объект. Классические модели рекомендаций часто игнорируют тот факт, что история пользователя – это направленная последовательность, в которой порядок событий имеет значение. Трансформеры позволяют учитывать как порядок событий, так и сложные паттерны в поведении и интересах пользователя. Например, исследователи из Alibaba представили модель, которую назвали Behaviour Sequence Transformer. Авторы заявляют, что модель используется в продакшене. Модель решает задачу Click Through Rate (CTR) prediction – предсказание вероятности клика по объекту. На вход модели подается история кликов пользователя, на основе которой нужно предсказать вероятность клика по заданному объекту. Роль архитектуры трансформера здесь в том, чтобы качественно закодировать представление пользователя, после чего применяется обычный multi layer perceptron (MLP) для предсказания вероятности. Помимо архитектур, которые специально разрабатываются под задачи рекомендаций, трансформеры можно использовать и как обособленные предобученные модели для построения векторых представлений текстов или изображений, которые затем подаются как признаки для решения downstream задач в домене рекомендаций. Несмотря на очевидные преимущества трансформеров с точки зрения качества, их использование в продакшене часто ограничивается имеющимися вычислительными ресурсами. Это особенно актуально для рекомендаций, где модели важно применять непосредственно в момент запроса пользователя."
            }
        ]
    },
    {
        "id": "q_0427",
        "question": "Какие примеры онлайн-метрик приводятся для оценки работающей системы?",
        "answers": [
            "В качестве примеров онлайн-метрик приводятся медианная длина сессии в онлайн-игре и среднее количество бананов на полках во всех магазинах торговой сети в конце дня."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mashinnoye-obucheniye",
                "text": "По обучающей выборке мы хотим построить модель, предсказания которой достаточно хороши. Что вообще значит «достаточно хороши»? Не понимая, чего мы хотим добиться, мы не предложим хорошего решения, поэтому нужно внимательно отнестись к выборуметрик качества. Возможно, вы уже участвовали в соревнованиях по анализу данных. На таких соревнованиях метрику организатор выбирает за вас, и она, как правило, непосредственным образом связана с результатами предсказаний. Но на практике всё бывает намного сложнее. Например, мы хотим: решить, сколько коробок с бананами нужно завтра привезти в конкретный магазин, чтобы минимизировать количество товара, который не будет выкуплен, и минимизировать вероятность того, что покупатель к концу дня не найдёт желаемый продукт на полке; увеличить счастье пользователей от работы с нашим сервисом, чтобы пользователи стали лояльнее, а сервис мог получать стабильный прогнозируемый доход; решить, нужно ли направить пациента на дополнительное медицинское обследование. В каждом конкретном случае может возникать целая иерархия метрик. Самый верхний уровень – этобизнес-метрики, например, будущий доход сервиса. Их трудно измерить в моменте, они сложным образом зависят от совокупности всех наших усилий, не только связанных с машинным обучением. Онлайн(online)метрики– это характеристики работающей системы, с помощью которых мы надеемся оценить, что будет с бизнес-метриками. Например, это может быть:– Медианная длина сессии в онлайн-игре. Можно предположить, что пользователь, который долго сидит в игре – это довольный пользователь.– Среднее количество бананов на полках во всех магазинах торговой сети в конце дня. Не всегда плоды наших трудов оцениваются числами. Многое может зависеть от субъективного восприятия людей, и для того, чтобы оценить их реакцию до выпуска в продакшен, применяется оценка специально нанятыми людьми – асессорами. Например, так можно оценивать, получилось ли у нас улучшить качество машинного перевода или релевантность выдачи в поисковой системе. Офлайн(offline)метрикимогут быть измерены до введения модели в эксплуатацию, например, по историческим данным. В задачах, в которых нужно предсказывать какой-то конкретный таргет, офлайн метрики обычно оценивают отклонение предсказаний модели от истинных значений таргета. Например, это может быть точность предсказания, то есть число верно угаданных значений, или среднеквадратичное отклонение. Асессорскую оценку тоже можно считать офлайн-метрикой В этой книге речь в основном пойдёт об офлайновых метриках и о функциях потерь. И прежде, чем вы начнёте знакомиться с методами решения задач обучения с учителем, полезно посмотреть, какими бывают метрики качества. Вот несколько примеров: для задачи постановки диагноза хорошими метриками могут быть, например, доля правильно поставленных диагнозов или доля больных, которым удалось поставить правильный диагноз (а вы поняли разницу?); для задачи предсказания цены квартиры метрикой качества может быть доля квартир, для которых разница между предсказанным и истинным значением цены не превысила какого-то порога, или средний модуль разницы между предсказанным и истинным значением; для задачи ранжирования поисковых документов по запросу — доля пар документов, которые мы упорядочили неправильно. Цель обычно в том, чтобы найти модель, для которой значение метрики будет оптимальным. Вопрос на подумать.Важно помнить, что разные нужды заказчика могут диктовать самые разные метрики. Вернёмся к задаче постановки диагноза пациентам больницы. Какие метрики вы предложили бы использовать в каждом из следующих случаев: обычный год в обычном терапевтическом отделении обычной больницы; определение очень неприятной болезни, которая жутким клеймом падёт на каждого, кому поставили такой диагноз; определение опасной и очень заразной болезни. Вопрос на подумать.Рассмотрим задачу детектирования людей на изображении. Чаще всего под детектированием понимают указание местоположения человека на картинке. Например, модель пытается выделить прямоугольник, в котором, по её мнению, есть человеческая фигура. Подумайте, какие метрики можно было бы использовать в различных ситуациях для измерения качества решения этой задачи. Не забудьте, что метрики — это способ численно измерить то, насколько модель помогает нам в жизни, так что важно думать о том, зачем нам вообще детектировать людей. Критерии качества не всегда сводятся к метрикам. Бизнес или общество могут накладывать и другие требования, например: Модель может выдавать предсказания в режиме реального времени. Заметим, что это требование не только к модели, но и к её реализации, а также к тому железу или к тем серверам, на которых она работает. Модель достаточно компактна, чтобы помещаться на мобильном телефоне или другом устройстве. Можно объяснить, на основании чего модель сделала то или иное предсказание для конкретного объекта. Это может быть важным в случае, если модель решает что-то важное в жизни человека, например, дадут ли кредит или будет ли согласовано дорогостоящее лечение. Такое требование является частным случаем более общего понятия интерпретируемости модели. Предсказания модели не дискриминируют какую-либо категорию пользователей. Например, если двум людям с одинаковой и достаточно длинной историей просмотров онлайн-кинотеатр рекомендует разные фильмы только из-за того, что у них разный пол, то это не здорово."
            }
        ]
    },
    {
        "id": "q_0428",
        "question": "Как обычно записывают градиент скалярной функции относительно формы её аргумента?",
        "answers": [
            "Градиент скалярной функции записывают в той же форме, что и сам аргумент: если аргумент — вектор-строка, то градиент записывают вектор-строкой, а если аргумент — матрица, то градиент будет матрицей того же размера."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
                "text": "Вспомним определение производной для функции. Функциядифференцируема в точке, если где—дифференциалфункции: линейное отображение из мира-ов в мир значений. Грубо говоря, он превращает «малое приращение» в «малое приращение» («малые» в том смысле, что на о-малое можно плюнуть): Отметим, что дифференциал зависит от точки, в которой он берётся:. Подподразумевается норма вектора, например корень из суммы квадратов координат (обычная евклидова длина). Давайте рассмотрим несколько примеров и заодно разберёмся, какой вид может принимать выражениев зависимости от формы. Начнём со случаев, когда— скалярная функция. В примерах выше нам дважды пришлось столкнуться с давним знакомцем из матанализа:градиентомскалярной функции (у нескалярных функций градиента не бывает). Напомним, что градиентфункции в точкесостоит из частных производных этой функции по всем координатам аргумента. При этом его обычно упаковывают в ту же форму, что и сам аргумент: если— вектор-строка, то и градиент записывается вектор-строкой, а если— матрица, то и градиент тоже будет матрицей того же размера. Это важно, потому что для осуществления градиентного спуска мы должны уметь прибавлять градиент к точке, в которой он посчитан. Как мы уже имели возможность убедиться, для градиента скалярной функциивыполнено равенство где скалярное произведение — это сумма попарных произведений соответствующих координат (да-да, самое обыкновенное). Посмотрим теперь, как выглядит дифференцирование для функций, которые на выходе выдают не скаляр, а что-то более сложное."
            }
        ]
    },
    {
        "id": "q_0429",
        "question": "Что представляет собой производная скалярной линейной функции?",
        "answers": [
            "Производная скалярной линейной функции, представленной в виде f(x) = a^T x для некоторого вектора a, является самим этим вектором a, который выступает в роли градиента."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
                "text": "Производная константы.Пусть. Тогдато есть— это нулевое отображение. А если— скалярная функция, то и Производная линейного отображения.Пусть— линейное отображение. ТогдаПоскольку справа линейное отображение, то по определению оно и является дифференциалом. Мы уже видели примеры таких ситуаций выше, когда рассматривали отображения умножения на матрицу слева или справа. Если— (скалярная) линейная функция, то она представляется в видедля некоторого вектора— он и будет градиентом. Линейность производной.Пусть, где— скаляры, а— некоторые отображения, тогда Производная произведения.Пусть, где— некоторые отображения, тогда Это же правило сработает и для скалярного произведения: В этом нетрудно убедиться, повторив доказательство или заметив, что в доказательстве мы пользовались лишь дистрибутивностью (= билинейностью) умножения. Производная сложной функции.Пусть. ТогдаЗдесь— дифференциалв точке, а— это применение отображенияк тому, что в скобках. Итого получаем: Важный частный случай:дифференцирование перестановочно с линейным отображением. Пусть, где— линейное отображение. Тогдасовпадает с самими формула упрощается:"
            }
        ]
    },
    {
        "id": "q_0430",
        "question": "Как вычислить градиент определителя квадратной матрицы?",
        "answers": [
            "Градиент определителя квадратной матрицы вычисляется как производная определителя по элементам матрицы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
                "text": "Вычислим дифференциал и градиент функции, где— вектор-столбец,— постоянный вектор. Вычислим производную и градиент, где— вектор-столбец,— постоянная матрица. Вычислим производную обратной матрицы:, где— квадратная матрица. Вычислим градиент определителя:, где— квадратная матрица. Вычислим градиент функции. С этой функцией мы ещё встретимся, когда будем обсуждать задачу линейной регрессии."
            }
        ]
    },
    {
        "id": "q_0431",
        "question": "Что необходимо вычислить для функции?",
        "answers": [
            "Необходимо вычислить градиент функции."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
                "text": "Вычислим градиент функции. Вычислим градиент функции. Вычислим градиент функции."
            }
        ]
    },
    {
        "id": "q_0432",
        "question": "При каких условиях квадратичная форма второго дифференциала указывает на точку минимума функции?",
        "answers": [
            "Точка является точкой минимума функции, если квадратичная форма второго дифференциала положительно определена, то есть когда она принимает положительные значения для всех ненулевых векторов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
                "text": "Рассмотрим теперь не первые два, а первые три члена ряда Тейлора: где— второй дифференциал, квадратичная форма, в которую мы объединили все члены второй степени. Вопрос на подумать.Докажите, что второй дифференциал является дифференциалом первого, то есть Зависит ли выражение справа от порядкаи? Этот факт позволяет вычислять второй дифференциал не с помощью приращений, а повторным дифференцированием производной. Вторая производная может оказаться полезной при реализации методов второго порядка или же для проверки того, является ли критическая точка (то есть точка, в которой градиент обращается в ноль) точкой минимума или точкой максимума. Напомним, что квадратичная форманазывается положительно определённой (соответственно, отрицательно определённой), если(соответственно,) для всех, причёмтолько при. Теорема.Пусть функцияимеет непрерывные частные производные второго порядкав окрестности точки, причём. Тогда точкаявляется точкой минимума функции, если квадратичная формаположительно определена, и точкой максимума, если она отрицательно определена. Если мы смогли записать матрицу квадратичной формы второго дифференциала, то мы можем проверить её на положительную или отрицательную определённость с помощьюкритерия Сильвестра."
            }
        ]
    },
    {
        "id": "q_0433",
        "question": "При каком условии на матрицу A обратная матрица (A^T A)^{-1} существует?",
        "answers": [
            "Обратная матрица (A^T A)^{-1} существует, когда столбцы матрицы A линейно независимы, так как в этом случае ранг A^T A равен размеру этой матрицы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
                "text": "Рассмотрим задачу минимизациипо переменной, где— матрица с линейно независимыми столбцами. Выше мы уже нашли градиент этой функции; он был равен. Мы можем заподозрить, что минимум достигается в точке, где градиент обращается в ноль:. Отметим, что обратная матрица существует, так как, а столбцыпо условию линейно независимы и, следовательно,равен размеру этой матрицы. Но действительно ли эта точка является точкой минимума? Давайте оставим в стороне другие соображения (например, геометрические, о которых мы упомянем в параграфе пролинейные модели) и проверим аналитически. Для этого мы должны вычислить второй дифференциал функции. Мы нашли квадратичную форму второго дифференциала; она, оказывается, не зависит от точки (впрочем, логично: исходная функция была второй степени по, так что вторая производная должна быть константой). Чтобы показать, чтодействительно является точкой минимума, достаточно проверить, что эта квадратичная форма положительно определена. Докажем, что функцияявляется выпуклой вверх на множестве симметричных, положительно определённых матриц. Для этого мы должны проверить, что в любой точке квадратичная форма её дифференциала отрицательно определена. Для начала вычислим эту квадратичную форму. Чтобы доказать требуемое в условии, мы должны проверить следующее: что для любой симметричной матрицыи для любого симметричного (чтобы не выйти из пространства симметричных матриц) приращенияимеем Покажем это явно.Так как— симметричная, положительно определённая матрица, у неё есть симметричный и положительно определённый квадратный корень:Тогда что, конечно, меньше нуля для любой ненулевой."
            }
        ]
    },
    {
        "id": "q_0434",
        "question": "Что такое локальный минимум в контексте критических точек?",
        "answers": [
            "Локальный минимум — это критическая точка, в которой гессиан положительно определён."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
                "text": "ОпределениеКритической точкой гладкой функцииназывается точка, для которой В выпуклой оптимизации такая точка обязательно будет точкой глобального минимума. В невыпуклой оптимизации все сильно сложнее: Бывает много локальных минимумов Бывают седловые точки Локальный минимум — это критическая точка, в которой Гессианположительно определён. Отметим, что часто в методах глобальной оптимизации рассматривается так называемая «локальная выпуклость», для которой требуется, чтобы функциябыла выпуклой внутри некоторого шара радиусас центром в точке. Критические точки, в которых гессиан не является знакоопределённым, называются седловыми. Пример: функцияимеет седловую точку. Гессиан в точке 0 Обратите внимание: во многих современных статьях про сходимость методов оптимизации первого порядка на невыпуклых функциях (пример) в качестве критерия сходимости рассматривают сходимость по норме градиента:при некотором заранее фиксированном. В выпуклой оптимизации этот критерий сходимости эквивалентен двум другим: сходимости по расстоянию до оптимума в пространстве параметров:; сходимости по расстоянию до оптимума по значениям функции. В невыпуклой оптимизации всё не так просто и поиск глобального минимума является в общем случае NP-трудной задачей. Критерийдаёт возможность исследовать сходимость к любой критической точке, но если речь об обучении нейронных сетях, то остается лишь надеяться, что эта критическая точка будет хорошим локальным минимумом."
            }
        ]
    },
    {
        "id": "q_0435",
        "question": "Какие два нововведения представлены в работе по методам RMSProp и AdaGrad с логарифмическими границами сожаления?",
        "answers": [
            "В работе представлены: 1) Переформулировка метода RMSprop с сохранением экспоненциального скользящего среднего, устранением проблем с отрицательными регуляризаторами и взрывающимися learning rate, обеспечением совместимости с AdaGrad и хорошей эмпирической работой на глубоких моделях. 2) Формулировка новых алгоритмов оптимизации SC-AdaGrad и SC-RMSprop для сильно выпуклых функций с логарифмическими гарантиями на regret."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
                "text": "Особняком стоит метод, описанный в статьеVariants of RMSProp and Adagrad with Logarithmic Regret Bounds. Авторы не придумывали очередной хотфикс, а аккуратно заново выводили формулы. Также важно, что данный метод является строгим обобщением метода AdaGrad. В работе есть два нововведения: Переформулировка метода RMSprop так, чтобы:— Осталось экспоненциальное скользящее среднее;— Не было проблемы с отрицательными регуляризаторами и взрывающимися learning rate;— Метод AdaGrad являлся частным случаем нового метода;— Чтобы все эмпирически хорошо работало в т.ч. на глубоких моделях Формулировка новых алгоритмов оптимизации SC-AdaGrad и SC-RMSprop для сильно выпуклых функций с логарифмическими гарантиями на regret. SC в названии — Strongly Convex. Пока рассмотрим только первый пункт. Авторы вводят следующий общий метод: Нововведение здесь в том, что вместо фиксированногомы будем рассматривать последовательность. Авторы доказывают сублинейный regret для любых последовательностей, удовлетворяющих Докажем, что метод Adagrad — это метод OnlineRMSprop с. Аналогично выводам momentum в FTRL, перепишем рекуррентное выражение для: Подставив, получим Далее, подставляя это в формулу, получаем Докажем, что OnlineRMSprop не может сломать регуляризаторы в regret. Для этого преобразуем неравенство Из условияполучаем, что правая часть неравенства неположительна, а левая неотрицательно. Значит, последнее неравенство невозможно, то есть все. Таким образом, регуляризаторы не сломаются, сходимость будет иметь место и данный метод можно использовать в выпуклых задачах. Строгое доказательство сходимости и оценки на Regret можно прочитать в исходной статье. Как и ранее в методе AdaGrad, допустим, что. Тогда Привыполнено Докажем, что все элементы предела <1. Из этого, в частности, будет следовать, что learning rate у OnlineRMSprop не меньше, чем learning rate в AdaGrad. Если все все, то итерационный процесс OnlineRMSprop превращается в Предположим, что. Тогда: По индукции разворачиваем вплоть до, получаем противоречие. Полное доказательство предела оставляем читателям. Надо бы чем-нибудь снизу подпереть, что тоже к 1 сходится. Автор сдавал матан почти 10 лет назад и ему было очень неохота откапывать все эти прекрасные пределы, поэтому ответ был получен с помощью wolfram. Вывод: learning rate у OnlineRMSprop убывает со скоростью. Мы исправили ошибку предыдущего RMSprop, изменивтолькоперевзвешивание, но не асимптотику в. Такой RMSprop можно пробовать использовать в выпуклых задачах"
            }
        ]
    },
    {
        "id": "q_0436",
        "question": "Какой метод использует правильную обработку Nesterov Momentum и показал отличные результаты в 2022 году?",
        "answers": [
            "Метод Adan (2022) нашел способ правильной обработки Nesterov Momentum, показал отличные результаты и обновил SOTA метрики на широком спектре задач."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
                "text": "Попробуем расписать классический momentum с константным learning rate в стиле FTRL: Всё, что нам нужно сделать — это взять все рекурсивные зависимости от предыдущей итерации и «размотать» их, получив явное выражение. Зависимостьотпереписать довольно просто, мы это уже делали для обычного градиентного спуска: Теперь надо размотать Теперь будет чуть сложнее. Подставим это и попробуем расписать, как суммус определенными коэффициентами: Множительсразу выносим за сумму и пока забываем. Отлично, а теперь нам нужно получить последовательность функций. В линеаризованной задаче это фактически эквивалентно получению зависимостиот, где, напомним,— это сумма градиентов. Теперь мы можем записать функцию, градиент которой равени онлайн-оптимизация которой эквивалентна процедуре с моментумом: Получаем, что для онлайн-обучения мы на самом деле каждую итерацию скармливаем экспоненциально взвешенную последовательность всех предыдущих функций исходной последовательности. В принципе, нечто такое мы и ожидали увидеть. Функции, очевидно, выпуклы, так что для данной измененной последовательности функций будет сублинейный regret. Рассмотрим классический SGD с momentum, для всех adaptive методов рассуждения аналогичны. Градиент функциипосчитан в предыдущей точке. Идея nesterov momentum в том, чтобы применить momentum на параметрыдо вычисления градиента: У метода много всяких «интуитивных объяснений», но изначально Nesterov Momentum был выведен сугубо аналитическими методами. Увы, попытки добавлять его в стохастическую оптимизацию «в лоб» обычно улучшением качества не заканчиваются. Анализ того, почему так нельзя и делать и как можно сделать правильно, проводится в работахKatyusha: The First Direct Acceleration of Stochastic Gradient MethodsиNatasha-2(мотивация их автора Zeyuan Allen-Zhu для выбора таких наименований доподлинно неизвестна). Katuysha правильным образом использует nesterov momentum для выпуклого случая, Natasha — для невыпуклого. Данные методы используют подход SVRG для улучшения сходимости и ускорение оптимизации происходиттолько при приближении к точке оптимума. До недавнего времени громких историй успеха для nesterov momentum в глубоком обучении не было. Метод Natasha распространения не нашел. Наконец, авторы статьиAdan(2022) нашли способ правильной обработки Nesterov Momentum. Метод показал отличные результаты и обновил SOTA метрики на широком спектре задач."
            }
        ]
    },
    {
        "id": "q_0437",
        "question": "Какие свойства должна формализовать хорошая рекомендательная система, помимо метрик ранжирования?",
        "answers": [
            "Хорошая рекомендательная система должна формализовать свойства, связанные с измерением «счастья пользователей», чтобы пользователи не только кликали в моменте, но и продолжали пользоваться сервисом."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
                "text": "Предположим, выдача нашей рекомендательной системы имеет высокие значения метрик ранжирования. Значит ли это, что система действительно хорошая? Не всегда просто ответить на этот вопрос. Оптимизируя определенные метрики, можно выкрутить кликбейт, и пользователи будут охотно кликать в моменте, но больше не станут пользоваться таким сервисом. Соответственно, нужно как-то измерять «счастье пользователей», попытаться формализовать свойства, которыми должна обладать хорошая рекомендательная система. Однозначного ответа на этот вопрос нет, всё зависит от контекста применения рекомендательной системы. В этом разделе мы поговорим о наиболее распространённых критериях, которые довольно часто оказываются важными."
            }
        ]
    },
    {
        "id": "q_0438",
        "question": "Какой фактор может привести к более быстрому росту полноты в рекомендациях фильмов по сравнению с рекомендациями музыки?",
        "answers": [
            "В рекомендациях фильмов полнота растёт быстрее из-за отсутствия повторов, так как пользователи редко хотят пересматривать фильмы в отличие от музыкальных треков, которые могут рекомендоваться повторно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
                "text": "Под полнотой в данном контексте понимается доля рекомендованных объектовсреди всех объектов. Эта метрика была предложена в статье Ge, M., Delgado-Battenfeld, C., Jannach, D. (2010, September). Beyond accuracy: evaluating recommender systems by coverage and serendipity. In Proceedings of the fourth ACM conference on Recommender systems (pp. 257-260). Данную метрику имеет смысл оценивать в разных временных интервалах, при этом принимая во внимание возможные ограничения, связанные с объемом данных. Например, нас может интересовать значение полноты за первый день работы рекомендательной системы, а может – за неделю. Целевое поведение полноты будет различаться в зависимости от доменных областей и бизнес деталей конкретного случая. Например, в рекомендациях музыки может быть полезно периодически повторно рекомендовать треки, которые пользователю в наибольшей степени нравятся, так как пользователь может захотеть послушать их еще раз. В то же время в рекомендациях фильмов это реже оказывается осмысленным: обычно проходит много времени, прежде чем пользователь захочет пересмотреть фильм. Таким образом, во втором случае полнота будет расти быстрее за счет отсутствия повторов. Еще одним фактором, влияющим на полноту, является алгоритм холодного старта, который может использоваться для того чтобы найти подходящие объекты для нового пользователя или подходящих пользователей для нового объекта. Часто пользователям на этапе холодного старта показывают самые популярные объекты. Из-за этого свежедобавленные объекты (например, музыкальные треки) могут неявно пессимизироваться алгоритмом. Один из способов решения проблемы – бустить свежие объекты в течение определённого времени, чтобы они показывались чаще. Настройки логики холодного старта могут сильно повлиять на метрику полноты. Среди других актуальных вопросов, которыми стоит задаваться: Cколько нужно дней, чтобы полнота достигала заданного значения? Возможно ли достичь такого значения в принципе, используя текущий алгоритм? Чтобы ответить на эти вопросы, нужно принимать во внимание ряд факторов: Какой объём трафика у системы рекомендаций? Есть ли у бизнеса ограничения, влияющие на конечный список рекомендаций? Имеет ли алгоритм рекомендаций достаточную степень персонализации? Можно ли регулировать режимы exploration и exploitation во время работы рекомендательной системы? Каждый из этих факторов может по-разному влиять на динамику полноты. Бизнес ограничения и слабая степень персонализации могут сдерживать рост полноты. Напротив, если модель высокоперсонализированная и учитывает много пользовательских факторов, то она способна рекомендовать больше уникальных объектов из хвоста распределения, которые тоже могут ему понравиться, тем самым обеспечивая рост полноты."
            }
        ]
    },
    {
        "id": "q_0439",
        "question": "Как рассчитывается итоговая метрика новизны рекомендаций для конкретного пользователя?",
        "answers": [
            "Для заданного пользователя усредняют значение собственной информации по всему списку его рекомендаций. Собственная информация для каждого рекомендованного объекта рассчитывается как логарифм вероятности его рекомендации случайному пользователю, где вероятность равна отношению числа пользователей, которым был показан этот объект, к общему числу пользователей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
                "text": "Один из способов оценить новизну рекомендательной системы – использовать статистическую меру собственной информации объекта (self information), которая используется в теории информации и тесно связана с понятием энтропии. Значение собственной информации для событияравняется логарифму вероятности наступления данного события. Согласно теории, чем меньше вероятность наступления события, тем больше потенциальной информации принесет это событие при его наступлении. Единицей информации при использовании логарифма по основанииявляется бит. Теперь если переносить идею собственной информации в парадигму рекомендательных систем, то получается, что чем менее популярен объект, тем более вероятно, что он будет новым для пользователя. А значит мера информации у такого объекта будет выше. Для каждого рекомендованного объектасчитаем вероятность, с которой его порекомендуют случайному пользователю:, где– количество пользователей, которым был показан-й объект, а– общее число пользователей. Для заданного пользователя усредняем значение собственной информации по списку его рекомендацийи получаем итоговое значение метрики:"
            }
        ]
    },
    {
        "id": "q_0440",
        "question": "Какую метрику можно использовать для оценки разнообразия рекомендаций на основе попарной схожести объектов с использованием эмбеддингов?",
        "answers": [
            "Для этого используется метрика Intra List Similarity (ILS). Она рассчитывается как усреднённая попарная схожесть между рекомендованными объектами в едином векторном пространстве, где для минимизации разнообразия эту метрику нужно уменьшать."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
                "text": "Разнообразие – это способность модели рекомендовать разные по содержанию объекты. Такое свойство очень важно для долгосрочного успеха сервисов, основанных на рекомендательных системах. Действительно, если модель постоянно рекомендует похожие друг на друга объекты, то рано или поздно пользователю наскучат такие рекомендации. Разнообразие можно рассчитывать на основе комбинаций метрик полноты и новизны. Также мерой разнообразия может быть дисперсия рекомендаций за заданный промежуток времени. Помимо этого популярны подходы, использующие эмбединги объектов для оценки попарной похожести объектов и расчёта на основе неё значения разнообразия. Одна из таких метрик – Intra List Similarity (ILS). Чтобы ее посчитать, нужно иметь эмбединги объектов рекомендаций, находящиеся в едином векторном пространстве. Для расчёта разнообразия для одного пользователя нужно усреднить попарную схожестьмежду рекомендованными объектами: где– это набор рекомендованных пользователю объектов. Для того чтобы добиться большего разнообразия, метрику нужно минимизировать. Мера схожести должна бытьбольшедля более похожих объектов. Чаще всего используется косинусная близость (cosine similarity)."
            }
        ]
    },
    {
        "id": "q_0441",
        "question": "Когда следует начинать отслеживать и оптимизировать специализированные метрики рекомендательных систем?",
        "answers": [
            "Это стоит делать после того, как базовые бизнес-метрики, такие как конверсия и среднее время визита, достигнут удовлетворительного уровня."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
                "text": "В этом разделе мы рассмотрели ключевые свойства рекомендательных систем и метрики для их оценки. Рекомендательные системы – сложная область, где нет готовых рецептов оценки качества. Ключевые метрики всегда идут от продуктовых деталей применения рекомендательной системы. Полезно смотреть на несколько метрик одновременно, чтобы оценить разные свойства моделей. В какой момент нужно начинать следить за метриками из данного раздела? Несмотря на их ценность, на начальном этапе стоит концентрироваться на более простых и интуитивно понятных с точки зрения бизнеса метриках: конверсии, среднем времени визита и так далее. А вот как только базовые метрики будут на удовлетворительном уровне, стоит начинать мониторить и оптимизировать метрики, разобранные в этом разделе."
            }
        ]
    },
    {
        "id": "q_0442",
        "question": "Что такое interpolation threshold в контексте обучения нейронных сетей?",
        "answers": [
            "Interpolation threshold — это точка, в которой нейросеть приобретает достаточно параметров, чтобы почти идеально запомнить всю обучающую выборку без особых усилий. Она разделяет график double descent risk curve на две части: классический режим обучения и современный режим с огромным числом параметров."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition",
                "text": "В книжках и различных интернет-ресурсах часто можно увидеть следующую картинку: Она иллюстрирует утверждение, которое в литературе называетсяbias-variance trade-off: чем выше сложность обучаемой модели, тем меньше её смещение и тем больше разброс, и поэтому общая ошибка на тестовой выборке имеет вид-образной кривой. С падением смещения модель всё лучше запоминает обучающую выборку, поэтому слишком сложная модель будет иметь нулевую ошибку на тренировочных данных и большую ошибку на тесте. Этот график призван показать, что существует оптимальная сложность модели, при которой соблюдается баланс между переобучением и недообучением и ошибка при этом минимальна. Существует достаточное количество подтверждений bias-variance trade-off для непараметрических моделей. Например, его можно наблюдать для методаближайших соседей при ростеи для ядерной регрессии при увеличении ширины окна(Geman et al., 1992): Чем больше соседей учитывает-NN, тем менее изменчивым становится его предсказание, и аналогично для ядерной регрессии, из-за чего сложность этих моделей в некотором смысле убывает с ростоми. Поэтому традиционный график bias-variance trade-off здесь симметрично отражён по оси. Однако, как показывают последние исследования, непременное возрастание разброса при убывании смещения не является абсолютно истинным предположением. Например, для нейронных сетей с ростом их сложности может происходить снижение и разброса, и смещения. Одна из наиболее известных статей на эту тему — статьяБелкина и др. (Belkin et al., 2019), в которой, в частности, была предложена следующая иллюстрация: Слева — классический bias-variance trade-off: убывающая часть кривой соответствует недообученной модели, а возрастающая — переобученной. А на правой картинке — график, называемый в статьеdouble descent risk curve. На нём изображена эмпирически наблюдаемая авторами зависимость тестовой ошибки нейросетей от мощности множества входящих в них параметров (). Этот график разделён на две части пунктирной линией, которую авторы называют interpolation threshold. Эта линия соответствует точке, в которой в нейросети стало достаточно параметров, чтобы без особых усилий почти идеально запомнить всю обучающую выборку. Часть до достижения interpolation threshold соответствует «классическому» режиму обучения моделей: когда у модели недостаточно параметров, чтобы сохранить обобщающую способность при почти полном запоминании обучающей выборки. А часть после достижения interpolation threshold соответствует «современным» возможностям обучения моделей с огромным числом параметров. На этой части графика ошибка монотонно убывает с ростом количества параметров у нейросети. Авторы также наблюдают похожее поведение и для «древесных» моделей: Random Forest и бустинга над решающими деревьями. Для них эффект проявляется при одновременном росте глубины и числа входящих в ансамбль деревьев. В качестве вывода к этому разделу хочется сформулировать два основных тезиса: Bias-variance trade-off нельзя считать непреложной истиной, выполняющейся для всех моделей и обучающих данных. Разложение на смещение и разброс не влечёт немедленного выполнения bias-variance trade-off и остаётся верным и для случая, когда все компоненты ошибки (кроме неустранимого шума) убывают одновременно. Этот факт может оказаться незамеченным из-за того, что в учебных пособиях часто разговор о разложении дополняется иллюстрацией с-образной кривой, благодаря чему в сознании эти два факта могут слиться в один."
            }
        ]
    },
    {
        "id": "q_0443",
        "question": "Какие авторы предлагали обобщённые формы декомпозиции bias-variance?",
        "answers": [
            "Обобщённые формы декомпозиции bias-variance были предложены Домингосом в 2000 году и Джеймсом в 2003 году."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition",
                "text": "Блог-постпро bias-variance отЙоргоса Папахристудиса Блог-постпро bias-variance от Скотта Фортмана-Роу Статьи отДомингоса (2000)иДжеймса (2003)про обобщённые формы bias-variance decomposition Блог-постот Брейди Нила про необходимость пересмотра традиционного взгляда на bias-variance trade-off СтатьяГемана и др. (1992), в которой была впервые предложена концепция bias-variance trade-off СтатьяБелкина и др. (2019), в которой был предложен double-descent curve"
            }
        ]
    },
    {
        "id": "q_0444",
        "question": "Какой метод подбора гиперпараметров предполагает фиксацию нескольких значений для каждого параметра и перебор всех их комбинаций?",
        "answers": [
            "Это метод перебора по сетке (Grid Search), при котором для каждого гиперпараметра задаётся несколько значений, затем последовательно проверяются все возможные комбинации этих значений, и выбирается комбинация с наилучшим качеством модели."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "Самый естественный способ организовать перебор наборов гиперпараметров — сделать перебор по сетке (Grid Search): для каждого гиперпараметра фиксируется несколько значений; перебираются все комбинации значений различных гиперпараметров, на каждой из этих комбинаций модель обучается и тестируется; выбирается комбинация, на которой модель показывает лучшее качество. Примеры: для метода ближайших соседей можно, например, перебирать по сетке число соседей (например, от 1 до 20) и метрику, по которой будет измеряться расстояние между объектами выборки (евклидова, манхэттенская и так далее); для решающих деревьев можно перебирать по сетке сочетания значений максимальной глубины дерева и различные критерии ветвления (критерий Джини, энтропийный критерий). Перебор некоторых значений гиперпараметров можно вести по логарифмической шкале, так как это позволяет быстрее определить правильный порядок параметра и в то же время значительно уменьшить время поиска. Так можно подбирать, например, значение learning rate для градиентного спуска, значение константы регуляризации для линейной регрессии или метода SVM. Сразу же видно естественное ограничение данного метода: если комбинаций параметров слишком много либо каждое обучение / тест длится долго, алгоритм не завершится за разумное время."
            }
        ]
    },
    {
        "id": "q_0445",
        "question": "Какие существуют способы борьбы с большим количеством комбинаций гиперпараметров при настройке модели?",
        "answers": [
            "Можно взять меньше значений каждого гиперпараметра, уменьшить число фолдов в кросс-валидации, оптимизировать параметры последовательно или перебирать только случайное подмножество комбинаций (Random Search)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "Если у вас возникает очень большое количество комбинаций параметров, вы можете какими-то способами пытаться справляться с этой проблемой: можно взять меньше значений каждого гиперпараметра, но тогда есть шансы пропустить наилучшую комбинацию; можно уменьшить число фолдов в кросс-валидации, но оценка параметров станет более шумной; можно оптимизировать параметры последовательно, а не перебирать их комбинации, но снова есть шанс получить неоптимальное решение; можно перебирать не все комбинации гиперпараметров, а только случайное подмножество. Последний способ называетсяRandom Search. Для каждого гиперпараметра задаётся распределение, из которого выбирается его значение, и комбинация гиперпараметров составляется семплированием из этих распределений (хорошие советы по поводу выбора распределений можно найти вдокументации sklearn). Таким образом, благодаря случайному выбору очередной комбинации гиперпараметров вы можете найти оптимальную комбинацию за меньшее число итераций. Вот это изображение хорошо иллюстрирует отличия поиска по сетке от случайного поиска: То есть: качество нашей модели в зависимости от гиперпараметров — это функция многих переменных с некоторой нетривиальной поверхностью. Но эта поверхностьможет зависетьот одной из своих переменных сильно меньше, чем от другой. Если бы мы знали, какой гиперпараметр важнее для перформанса модели, мы бы рассмотрели больше его возможных значений, но часто у нас нет такой информации, и мы рассматриваем некоторое наперёд заданное число значений для каждого гиперпараметра. Random Search может за то же число итераций, что и Grid Search, рассмотреть более разнообразные значения гиперпараметров. Тем самым он с большей вероятностью найдёт те значения, которые больше всего влияют на качество модели, а значит, с большей вероятностью найдёт наилучшую комбинацию значений гиперпараметров. Естьещё однодовольно интересное объяснение, почему Random Search работает хорошо. Рассмотрим случай, когда у нас конечная сетка гиперпараметров (каждому гиперпараметру сопоставлено конечное число значений). В этой сетке выделим группу размераот общего числа наборов гиперпараметров, на которой модель достигает лучшего качества (можно мысленно отранжировать все наборы по качеству в некоторый список и взять топэтого списка). Тогда некоторый набор гиперпараметров не попадает в эту группу с вероятностью. Если мы насемплировалинаборов, то каждый из них не попал в эту группу с вероятностью, и, соответственно, вероятность того, что хотя бы один насемплированный набор попал в лучшую группу, равна. Мы можем решить неравенство и выяснить, что примы попадём в топ 5% с вероятностью, не меньшей. Это в большинстве случаев значительно быстрее, чем перебор всех комбинаций гиперпараметров с помощью Grid Search. Если в рассуждении выше у нас некоторым гиперпараметрам соответствует непрерывное распределение, то всегда можно предположить, что мы уже насемплировали из этих распределений некоторое конечное число значений (равное числу итераций Random Search), а дальше считать, что мы работаем с конечной сеткой. Конечно, остаётся наша зависимость от самой сетки гиперпараметров, и не всякая сетка обязана содержать в себе глобальный максимум перформанса модели или даже гиперпараметры из интервала вокруг него."
            }
        ]
    },
    {
        "id": "q_0446",
        "question": "Какие две основные стратегии используются при выборе точки для следующей итерации в методах подбора гиперпараметров, учитывающих результаты предыдущих вычислений?",
        "answers": [
            "Это стратегии exploration (исследование областей с малым количеством семплов, чтобы не пропустить оптимальное значение) и exploitation (выбор большего количества семплов в хорошо изученных областях, где вероятно находится оптимум)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "В машинном обучении достаточно часто встречаются такие термины, какexplorationиexploitation. Суть этих терминов хорошо поясняет следующий пример из реальной жизни. Допустим, перед вами стоит выбор, в какой ресторан пойти сегодня. Пусть ваш любимый ресторан находится прямо за углом. Вы ходите туда каждый день и поэтому достаточно уверены в том, насколько вкусным будет ваш обед. Но при этом не рассматриваете никакие другие опции и, возможно, упускаете возможность поесть гораздо вкуснее в другом месте. Если же вы будете обедать каждый раз в новом месте, то очень часто будете не удовлетворены результатом. В описанных далее методах подбора гиперпараметров будет так или иначе происходить поиск баланса между exploration и exploitation. Одно из основных отличий всех методов, которые будут описаны далее, от Grid Search и Random Search — возможность учитывать результаты предыдущих вычислений. Одна из возможных стратегий выбора точки для следующей итерации —exploration: исследование тех областей, в которых у нас мало семплов на текущей итерации, что даёт нам возможность с меньшей вероятностью пропустить оптимальное значение. Другая стратегия —exploitation: выбирать больше семплов в областях, которые мы достаточно неплохо изучили и где, как мы считаем, с большой вероятностью находится оптимум."
            }
        ]
    },
    {
        "id": "q_0447",
        "question": "Какой метод позволяет оценить оптимум функции без её дифференцирования и указывает следующую точку для вычисления с наибольшей вероятностью улучшения оценки?",
        "answers": [
            "Это байесовская оптимизация — итерационный метод, который на каждой итерации указывает точку, где с наибольшей вероятностью можно улучшить текущую оценку оптимума, не требуя дифференцирования функции."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "Байесовская оптимизация — это итерационный метод, позволяющий оценить оптимум функции, не дифференцируя её. Кроме того, на каждой итерации метод указывает, в какой следующей точке мы с наибольшей вероятностью улучшим нашу текущую оценку оптимума. Это позволяет значительно сократить количество вычислений функции, каждое из которых может быть довольно затратным по времени. Подбор гиперпараметров тоже можно сформулировать в виде задачи, которая может решаться с помощью байесовской оптимизации. Пусть, например, наша функция — значение валидационных метрик в зависимости от текущего сочетания гиперпараметров. Её вычисление затратно по времени (нужно натренировать и провалидировать модель), и мы не можем вычислить градиенты этой функции по её переменным (нашим гиперпараметрам). Байесовская оптимизация имеет две основные компоненты: вероятностную модель, которая приближает распределение значений целевой функции в зависимости от имеющихся исторических данных (часто в качестве такой модели выбираютгауссовские процессы); функцию, которая позволяет по некоторым статистикам текущей вероятностной модели функцииуказать, в какой следующей точке нужно вычислить значение. Эта функция называетсяacquisition function. Она должна балансировать междуexplorationиexploitationв следующем смысле:exploration— исследовать те точки, в которых дисперсия нашей вероятностной модели велика;exploitation— исследовать те точки, где среднее нашей модели велико (и может служить оценкой максимума). exploration— исследовать те точки, в которых дисперсия нашей вероятностной модели велика; exploitation— исследовать те точки, где среднее нашей модели велико (и может служить оценкой максимума). Простой пример acquisition function — сумма среднего вероятностной модели и стандартного отклонения с некоторым весом: где— точка из пространства, в котором мы оптимизируем целевую функцию (в нашем контексте это вектор значений гиперпараметров). На картинке ниже изображены обе компоненты, из которых складывается данная acquisition function, — среднее вероятностной модели(синий график) и доверительный интервал, ширина которого в каждой точке пропорциональна стандартному отклонению вероятностной модели (жёлтая область). Среднее моделистремится приблизить искомую функциюи в точности равнов тех точках, где значенияизвестны. Доверительный интервал имеет переменную ширину, так как чем дальше находится некоторая точка от тех, значения в которых известны, тем более модель не уверена в том, какое значение функции в этой точке, и тем шире доверительный интервал. Наоборот, в точках, где значения известны, доверительный интервал имеет нулевой радиус. Байесовская оптимизация в общем случае представляет из себя следующий алгоритм. Пусть— множество предыдущих наблюдений целевой функции:, а— некоторая acquisition function. На итерациивычисляется точка, в которой нужно провести следующее вычисление целевой функции: Вычисляется значение, и обновляется множество наблюдений. Обновляется статистическая модель. Чтобы такой алгоритм работал эффективно,должна быть легко вычислимой и дифференцируемой. На рисунке ниже изображены три итерации этого алгоритма. Здесь пунктирная линия — это целевая функция, сплошная линия — график среднего вероятностной модели, жёлтым цветом обозначен доверительный интервал модели. Серый график снизу — это график acquisition function. Её значения велики там, где вероятностная модель предсказывает большие значения целевой функции (exploitation), и там, где велика неуверенность вероятностной модели (exploration). На каждой итерации находится точка максимума acquisition function (чёрный крестик), и следующая итерация произойдёт в этой точке (серый кружок на графике функции). На нижнем графике побеждает exploitation, так как acquisition function верно предсказала, что наблюдения из неизвестных областей слабо повлияют на нашу текущую оценку максимума. Байесовская оптимизация хорошо работает, когда нужно оптимизировать небольшое число гиперпараметров, так как в наивной реализации алгоритм не поддаётся распараллеливанию. При большой размерности пространства гиперпараметров скорость сходимости не лучше, чем у обычного Random Search (как утверждается в этой статье). Байесовская оптимизация в изначальной постановке предполагалась для работы с непрерывными гиперпараметрами, а для работы с категориальными гиперпараметрами ей нужны некоторые трюки: Если нужно найти оптимальное значение только одного гиперпараметра и этот параметр категориальный, то можно, например, использовать Thompson sampling (как тут вразделе «Bernoulli bandit»). Вообще, проблему выбора наилучшего значения категориального гиперпараметра можно переформулировать какmulti-armed bandit problemи использовать любой известный способ решения этой задачи. Если категориальных гиперпараметров больше одного и кроме них есть некатегориальные, то: можно попробовать использовать специальные виды ядер в гауссовских процессах,как, например, сделано здесь; можно заменить гауссовские процессы на Random Forest (подробнее можно посмотреть здесь вразделе «Random Forests»)."
            }
        ]
    },
    {
        "id": "q_0448",
        "question": "Какой процесс происходит в алгоритме TPE после того, как модель с выбранными гиперпараметрами была провалидирована?",
        "answers": [
            "Алгоритм поднимается из листа дерева наверх, обновляя распределения во всех вершинах вдоль пройденного пути. В каждой вершине для каждого гиперпараметра имеющиеся значения переранжируются по качеству с учётом нового результата, по топ 10-25% оценивается распределение лучших наблюдений, по остальным — распределение всех остальных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "Алгоритм TPE, как и алгоритм байесовской оптимизации, итерационный: на каждой итерации принимается решение о том, какие следующие значения гиперпараметров нужно выбрать, исходя из результатов предыдущих итераций. Но идейно имеет довольно сильные отличия. Предположим сначала, что мы хотим сделать поиск оптимального значения дляодногогиперпараметра. На нескольких первых итерациях алгоритму требуется «разогрев»: нужно иметь некоторую группу значений данного гиперпараметра, на которой известно качество модели. Самый простой способ собрать такие наблюдения — провести несколько итераций Random Search (количество итераций определяется пользователем). Следующим шагом будет разделение собранных во время разогрева данных на две группы. В первой группе будут те наблюдения, для которых модель продемонстрировала лучшее качество, а во второй — все остальные. Размер доли лучших наблюдений задаётся пользователем: чаще всего это 10-25% от всех наблюдений. Картинка ниже иллюстрирует такое разбиение: Далее некоторым образом строятся оценки распределениялучших наблюдений и распределениявсех остальных в пространстве значений рассматриваемого гиперпараметра. На следующем шаге алгоритма мы семплируем несколько значений-кандидатов из распределения(количество таких семплирований тоже задаётся пользователем, можно задать их число равным, например, 1000). Из насемплированных кандидатов мы хотим найти тех, кто с большей вероятностью окажется в первой группе (состоящей из лучших наблюдений), чем во второй. Для этого для каждого кандидатавычисляетсяExpected Improvement: Замечание: На самом деле стоит отметить, что воригинальной статьевеличинаимеет более общее определение. Но там же доказывается, что максимизацияв исходном определении эквивалентна максимизации отношения выше. Кандидат с наибольшим значениембудет включён в множество рассматриваемых гиперпараметров на следующей итерации: После того как было выбрано значение-кандидат, максимизирующее, обучается модель с этим значением гиперпараметра. После обучения мы замеряем её качество на валидационной выборке и в соответствии с этим результатом обновляем распределенияи: снова ранжируем всех имеющихся кандидатов по качеству модели с учётом последнего, из топ 10-25% формируется обновлённое, из остальных —. Так происходит столько раз, сколько итераций алгоритма мы задали. Теперь опишем, как алгоритм работает в общем случае, когда гиперпараметровболее одного. Алгоритм работает с гиперпараметрами, представляя их в форме дерева (отсюда «tree» в названии). Например, в документацииHyperoptможно увидеть такой пример: Скопировать код1from hyperopt import hp23space = hp.choice('classifier_type', [4{5'type': 'naive_bayes',6},7{8'type': 'svm',9'C': hp.lognormal('svm_C', 0, 1),10'kernel': hp.choice('svm_kernel', [11{'ktype': 'linear'},12{'ktype': 'RBF', 'width': hp.lognormal('svm_rbf_width', 0, 1)},13]),14},15{16'type': 'dtree',17'criterion': hp.choice('dtree_criterion', ['gini', 'entropy']),18'max_depth': hp.choice('dtree_max_depth',19[None, hp.qlognormal('dtree_max_depth_int', 3, 1, 1)]),20'min_samples_split': hp.qlognormal('dtree_min_samples_split', 2, 1, 1),21},22]) На рисунке ниже изображено дерево, соответствующее данному примеру: Корень дерева— фиктивная вершина, введённая для удобства. Здесь первый уровень дерева — выбор классификатора (наивный байес, SVM, решающее дерево). Дальнейшие уровни — гиперпараметры самих классификаторов и зависящие уже от них гиперпараметры (например, SVMkernelRBFwidth). Движение по дереву во время итераций алгоритма происходит по некоторому пути от корня к листу и обратно вдоль пройденного пути (этот процесс подробнее описан ниже). Под некоторыми вершинами записан набор гиперпараметров в скобках (например,kernelиCпод SVM). Это означает, что при приходе в эту вершину значения всех гиперпараметров, перечисленных в скобках, должны так или иначе быть выбраны. Каждой вершине дерева, в которой будет происходить семплирование значений, сопоставляется своя параис учётом значений, насемплированных на этапе «разогрева». Каждому гиперпараметру, перечисленному в скобках, соответствует своя собственная пара. Если из названия гиперпараметра не идут стрелки (например,Cу SVM иmin_samples_splitу Decision Tree), то это означает, что от его значения не зависят значения никаких других гиперпараметров. Поэтому либо будет выбрано его значение, максимизирующеедля соответствующих емуи, либо уже ничего не нужно семплировать (как, например, в вершинахlinearилиgini). Если же из гиперпараметра идут стрелки на следующий уровень, то с помощью максимизациибудет выбрано, в каком направлении сделать переход. Например, из корнявыбирается, какой классификатор рассмотреть на следующем этапе, а из параметраkernelможно перейти либо кRBF, либо кlinear. Теперь опишем сам алгоритм. Сначала так же, как и в одномерном случае, происходит «разогрев»: проводится некоторое количество итераций Random Search с теми изначальными распределениями, которые были заданы для гиперпараметров (в примере из Hyperopt эти распределения задаются какhp.qlognormal,hp.lognormalи так далее). Затем начинается итерационное обновление дерева гиперпараметров. Обновление дерева на каждой итерации происходит в два этапа: Сначала алгоритм идёт из корня дерева до некоторого листа. В каждой вершине для каждого соответствующего ей гиперпараметра он находит значение, максимизирующее. Если выбор значения для некоторого гиперпараметра означает переход на следующий уровень дерева, он идёт в ту вершину, которая соответствует максимизации. Так он идёт до тех пор, пока не упрётся в какой-то лист. Пройденный путь от корня до листа задаёт полный набор значений гиперпараметров для модели, и её с этими значениями можно провалидировать. После того как модель, полученная на предыдущем этапе, была провалидирована, распределения в вершинах дерева нужно обновить в соответствии с информацией о полученном качестве. Для этого алгоритм поднимается из листа наверх, обновляя распределения во всех вершинах дерева вдоль своего пути. В каждой вершине для каждого гиперпараметра процедура обновления та же, что была описана для одного гиперпараметра: имеющиеся значения гиперпараметров переранжируются по качеству с учётом результата последнего кандидата (этот результат общий для всех вершин вдоль пути), по топ 10-25% оценивается, по остальным —. В качестве окончательного ответа алгоритм выдаёт набор гиперпараметров (или, как в примере выше, не только гиперпараметры, но даже саму модель), на котором было получено лучшее качество за все итерации. Число итераций алгоритма задаётся пользователем. За дальнейшими деталями о процедуре обновления дерева для алгоритма TPE можно обратиться кэтой статьеи кисходному кодуалгоритма TPE из библиотеки Hyperopt. Стоит заметить, что если гиперпараметры не лежат вместе ни в одном пути в дереве, то TPE считает их независимыми. Это — недостаток данного алгоритма, так как некоторые гиперпараметры, находящиеся по смыслу в разных путях в дереве, зависят от друг от друга. Например, с регуляризацией мы можем тренировать нейросеть большее число эпох, чем без регуляризации, потому что без регуляризации сеть на большом числе эпох может начать переобучаться. В этом конкретном примере можно использовать такой трюк: Скопировать код1hp.choice('training_parameters', [2{3'regularization': True,4'n_epochs': hp.quniform('n_epochs', 500, 1000, q=1),5}, {6'regularization': False,7'n_epochs': hp.quniform('n_epochs', 20, 300, q=1),8},9]) Но если внутренние зависимости между гиперпараметрами вам неизвестны, то алгоритм не сможет найти их сам. Критерийпозволяет методу TPE балансировать междуexplorationиexploitation. Семплирование из распределения— это, с одной стороны, exploitation, так как гиперпараметры, семплируемые из него, близки к оптимуму, но это же привносит элемент exploration, так как семплируемые гиперпараметры не равны оптимуму в точности."
            }
        ]
    },
    {
        "id": "q_0449",
        "question": "Какие процедуры выполняются в алгоритме PBT при обновлении модели, достигшей порога «созревания»?",
        "answers": [
            "Выполняются две процедуры: exploit() — замена весов модели с низким качеством на веса более успешной модели из популяции, и explore() — добавление случайного шума в параметры модели после перезаписи весов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "Этот метод использует идеи из теорииэволюционных стратегийи с самого начала включает в себя параллельные вычисления. Методы, описанные выше, имеют свои сильные и слабые стороны. Grid Search и Random Search:отлично параллелизуются;не используют результаты предыдущих итераций. отлично параллелизуются; не используют результаты предыдущих итераций. БО и TPE:трудно параллелизуются;используют результаты предыдущих итераций, при сходимости результаты лучше, чем у Random Search и Grid Search. трудно параллелизуются; используют результаты предыдущих итераций, при сходимости результаты лучше, чем у Random Search и Grid Search. В алгоритме PBT была сделана попытка объединить сильные стороны обеих групп, что проиллюстрировано на картинке ниже: В процессе работы алгоритм обучает не одну модель, а целуюпопуляциюмоделей — набор моделей одинакового типа, отличающихся только набором гиперпараметров: гдеи— веса и гиперпараметры моделисоответственно. Предполагается также, что модели обучаются как-то итерационно, например градиентным спуском (но могут использоваться и безградиентные методы, такие как эволюционные стратегии). Изначально каждая модель в популяции имеет случайные веса и гиперпараметры. Каждая модель из популяции тренируется параллельно с остальными, и периодически качество каждой модели замеряется независимо от остальных. Как только какая-то модель считается «созревшей» для обновления (например, прошла достаточное число шагов градиентного спуска или преодолела некоторый порог по качеству), у неё появляется шанс быть обновлённой относительно всей остальной популяции: процедураexploit(): если у модели низкое качество относительно популяции, то её веса заменяются на веса модели с более высоким качеством; процедураexplore(): если веса модели были перезаписаны, шагexploreдобавляет случайный шум в параметры модели. При таком подходе только лучшие пары моделей и гиперпараметров выживут и будут обновляться, что позволяет добиться более высокой утилизации ресурсов. Стоит отметить, что наиболее оптимальный размер популяции, выявленный авторами в результате экспериментов, — от 20 до 40, что довольно много и не реализуется на обычном ноутбуке. Красивая гифка с демонстрацией работы алгоритма:"
            }
        ]
    },
    {
        "id": "q_0450",
        "question": "Какие методы оптимизации гиперпараметров реализованы в библиотеке Hyperopt?",
        "answers": [
            "В библиотеке Hyperopt реализованы три метода оптимизации: Random Search, TPE и Adaptive TPE."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "В библиотекеScikit-learnесть реализации Grid Search и Random Search, что очень удобно, если вы используете модели из sklearn. Примеры их использования можно найтиздесь. В библиотекеHyperoptреализованы три метода оптимизации гиперпараметров: Random Search TPE Adaptive TPE У них есть небольшойтуториалпо тому, как начать пользоваться библиотекой. Кроме того, у них есть обёртка над sklearn, позволяющая работать с моделями оттуда:Hyperopt-sklearn. В библиотекеOptunaреализованы те же методы оптимизации, что и в Hyperopt, но по многим параметрам она оказывается удобнее. Хорошее сравнение Optuna и Hyperopt можно найтиздесь. В библиотекеScikit-Optimizeреализованы алгоритмы байесовской оптимизации и Random Search. Кроме самих методов оптимизации библиотека предоставляет отличный инструментарий для различныхвизуализаций. Хорошее описание возможностей библиотеки можно найтитут. БиблиотекаKeras Tunerпозволяет подбирать гиперпараметры для нейросеток, написанных на TensorFlow 2.0, и для обычных моделей из Scikit-learn. Доступные методы оптимизации — Random Search иHyperband. Хороший гайд по использованию данной библиотеки можно найтитут."
            }
        ]
    },
    {
        "id": "q_0451",
        "question": "Какие методы оптимизации гиперпараметров, помимо Grid Search и Random Search, упоминаются в доступных материалах?",
        "answers": [
            "В материалах упоминаются Population Based Training, эволюционные стратегии, байесовская оптимизация (включая метод TPE - Tree-structured Parzen Estimator), а также квазислучайные распределения для усиления Random Search."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
                "text": "Примерыиспользования Grid Search от sklearn. Примерыиспользования Random Search от sklearn. Хороший блог-пост о гиперпараметрах, в первом разделе которого есть интересные рассуждения про усиление Random Search с помощью квазислучайных распределений. Блог-постот DeepMind про предложенный ими алгоритм Population Based Training. Оригинальная статья, где был предложен алгоритм. Блог-постпро эволюционные стратегии. А если вам интересно как следует разобраться в байесовской оптимизации (в частности, рассмотреть больше примеров вероятностных моделей и разных acquisition function), то вот полезный контент: Отличный туториалпо различным методам оптимизации гиперпараметров, в частности по байесовской оптимизации. Статья-обзор, подробно объясняющая математические детали методов байесовской оптимизации и содержащая примеры их применения в ресёрче и индустрии. ВидеолекцияЕвгения Бурнаева на летней школе Deep | Bayes. Оригинальная статья, в которой были предложены методы TPE и байесовская оптимизация. Пример использования skopt (Scikit-Optimize)— нахождение лучших параметров для SVM с помощью байесовской оптимизации. Реализацияалгоритма байесовской оптимизации и примеры использования библиотечных реализаций. Про гауссовские процессыс хорошими визуализациями. Более формально про гауссовские процессы, но с хорошими примерами на питоне. Для дальнейшего изучения метода TPE можно использовать следующие источники: Оригинальная статья, в которой были предложены методы TPE и байесовская оптимизация. Блог-постпро TPE и остальные методы тюнинга гиперпараметров от NeuPy. Там же можно найти пример применения TPE изHyperopt. Отличное объяснениетого, что такое Parzen window density estimation. Отличный туториалпо различным методам оптимизации гиперпараметров (который уже был упомянут выше в разделе про байесовскую оптимизацию)."
            }
        ]
    },
    {
        "id": "q_0452",
        "question": "Как называется пара случайных величин, совместное распределение которых задаётся матрицей вероятностей?",
        "answers": [
            "Такую пару случайных величин называют случайным вектором."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "Пусть, например, эксперимент состоит из двух фаз: сначала подбрасывается монетка, а затем кубик. Тогда вероятностная масса сосредоточена в точках,,. Вероятность каждого исхода можно записать в виде таблицы Результат подбрасывания монеты моделирует бернуллиевская случайная величина, а результат броска кубика — равномерно распределённая на множествеслучайная величина. Содержимое таблицы вероятностей каждого исхода можно также представить матрицей которая задаётсовместное распределениеслучайных величини:. Пару случайных величинв таком контексте называют такжеслучайным вектором. Элементы матрицыне обязаны совпадать; например, монета может быть несимметричной с вероятностью «успеха», и тогда таблица вероятностей примет вид Контрольный вопрос. Какая таблица вероятностей соответствует эксперименту, в котором результат подбрасывания монеты «портит» кубик следующим образом: на нём могут равновероятно выпасть только значенияилив случае «неудачи» и,илив случае «успеха»? В общем случае дискретное-мерное распределение задаётся многомерным тензором из неотрицательных чисел, суммирующихся в единицу. Такие тензоры используются для задания совместного распределения вероятностей случайного вектораиз дискретных случайных величин:"
            }
        ]
    },
    {
        "id": "q_0453",
        "question": "Как определяется вероятность события для непрерывного распределения на плоскости?",
        "answers": [
            "Вероятность события для непрерывного распределения на плоскости определяется как двойной интеграл от плотности распределения по соответствующей области, при условии что этот интеграл имеет смысл."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "Непрерывное распределение на плоскости задаётся плотностью; при этом вероятность событияравна при условии, что этот интеграл имеет смысл. Простейший пример — равномерное распределение на единичном квадрате: его плотность равна, и Именно так на единичном квадрате формально определяется геометрическая вероятность. Плотность непрерывного распределения вявляется неотрицательной функцией видасо свойством Говорят, что случайный векторимеетсовместную плотность, если для всех достаточно «хороших» (измеримых по Лебегу) множеств."
            }
        ]
    },
    {
        "id": "q_0454",
        "question": "Как получить маргинальное распределение из совместного распределения случайных величин?",
        "answers": [
            "Маргинальное распределение получается путём суммирования или интегрирования по части переменных совместного распределения. Например, для дискретного случая суммируют вероятности по ненужным переменным, а для непрерывного — интегрируют совместную плотность."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "Из совместного распределения можно получить распределение в пространстве меньшей размерности путём суммирования или интегрирования по части переменных. Например, если матрицазадаёт совместное распределение случайных величини,, то каждый из наборов чисел неотрицателен и суммируется в единицу: Таким образом, числаизадают некоторые распределения вероятностей, называемыемаргинальными. Упражнение. Найдите маргинальные распределения, если совместное распределение задано матрицей В непрерывном случае ситуация похожая: если случайный вектор имеет совместную плотность, то функции являются плотностями маргинальных распределений. Для-мерных распределений можно находить маргинальные распределения, суммируя или интегрируя по любым наборам переменных с индексами; в результате получится маргинальное распределение по оставшимсяпеременным."
            }
        ]
    },
    {
        "id": "q_0455",
        "question": "При каком условии дискретные случайные величины X и Y считаются независимыми?",
        "answers": [
            "Дискретные случайные величины X и Y независимы, если для всех возможных значений x и y выполняется равенство P(X=x, Y=y) = P(X=x) * P(Y=y)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "Случайные величиныиназываютсянезависимыми, если совместное распределение случайного векторараспадается на произведение одномерных. Точнее говоря, дискретные случайные величиныинезависимы, еслидля всех возможныхи; непрерывные случайные величиныинезависимы, если их совместная плотность. Если случайные величиныинезависимы, то распределение каждой из них является маргинальным распределением их совместного распределения, поскольку и Случайные величинынезависимы в совокупности, если их совместное распределение (совместная плотность) распадается в произведение одномерных распределений (плотностей). Пример. Рассмотримгауссовских случайных величинс плотностями Совместную плотность случайного вектораопределим как произведение плотностей его компонент: Случайный векторс такой плотностью имеетмногомерное нормальное (гауссовское) распределениеc независимыми в совокупности компонентами. Любое маргинальное распределение случайного вектораобладает плотностью того же вида, и поэтому также является гауссовским."
            }
        ]
    },
    {
        "id": "q_0456",
        "question": "Как связаны ковариационные матрицы случайных векторов, если один получен из другого линейным преобразованием?",
        "answers": [
            "Если случайный вектор Y получен из случайного вектора X линейным преобразованием Y = AX, то ковариационная матрица вектора Y равна A * Cov(X) * A^T, где Cov(X) — ковариационная матрица вектора X, а A^T — транспонированная матрица A."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "Математическое ожидание случайного вектораявляется вектором той же размерности и вычисляется покомпонентно: Каждая компонента случайного вектора — это обычная случайная величина, и её среднее можно вычислить стандартными методами: в дискретном случае; в непрерывном случае. Математическое ожидание перестановочно с линейным преобразованием случайного вектора:, где— фиксированная матрица. Вместо дисперсии у случайного вектораестьматрица ковариаций: Матрица ковариаций симметрична и состоит из попарных ковариаций компонент случайного вектора: Упражнение. Докажите, что ковариационная матрица любого случайного вектора неотрицательно определена. Если случайные величинынезависимы в совокупности, то, и ковариационая матрица случайного векторадиагональна: Например, матрица ковариации гауссовского случайного векторас плотностью равна, поскольку компоненты векторанезависимы в совокупности и имеют нормальное распределение. Аналогом ковариации в многомерном случае служит матрица ковариаций между случайными векторамии: Матрицу ковариаций можно также вычислить по формуле Упражнение. Пусть случайный векторполучен из случайного векторалинейным преобразованием:. Как связаны между собой их ковариационные матрицы?"
            }
        ]
    },
    {
        "id": "q_0457",
        "question": "Как найти плотность случайного вектора Y = a + BX, если известна плотность случайного вектора X, где a — постоянный вектор, а B — постоянная обратимая матрица?",
        "answers": [
            "Плотность случайного вектора Y вычисляется по формуле f_Y(y) = f_X(B^{-1}(y - a)) * |det(B^{-1})|, где f_X — плотность исходного вектора X, B^{-1} — обратная матрица к B, а |det(B^{-1})| — модуль определителя обратной матрицы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "Нередко приходится иметь дело не с самими случайными векторами, а с функциями от них. Но как найти плотность случайного вектора, зная плотность? Предположим, что— гладкая обратимая функция. Тогда для измеримогоимеем Чтобы перейти к интегралу по, сделаем замену переменной. По формуле замены координат в кратном интеграле получаем где– якобиан преобразования, т.е. определитель матрицы Якоби.Таким образом, Упражнение. Пусть– случайный вектор с плотностью. Какова плотность случайного вектора, где– постоянный вектор, а– постоянная обратимая матрица?"
            }
        ]
    },
    {
        "id": "q_0458",
        "question": "Как называется формула для нахождения распределения суммы двух независимых непрерывных случайных величин через их плотности?",
        "answers": [
            "Эта формула называется формулой свёртки. Она позволяет вычислить плотность распределения суммы через интеграл от произведения плотностей исходных величин."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "В дискретном случае найти распределение суммы двух независимых случайных величин несложно. В самом деле, В силу независимости случайных величинипоследняя сумма равна Полученная формула называетсяформулой свёртки. Пусть теперьи– независимые непрерывные случайные величины с плотностямиисоответственно. Сам собой напрашивается аналог формулы свёртки с плотностями вместо вероятностей, но чтобы достаточно строго вывести его и не запутаться, мы немного схитрим. А именно, мы рассмотрим случайный вектори его (обратимое!) преобразование Обратное к нему будет иметь вид Тогда по правилу преобразования плотности где в последнем равенстве мы воспользовались независимостьюи. Распределение случайной величины– это маргинальное распределение, которое вычисляется следующим образом: Эта формула также называетсяформулой свёртки."
            }
        ]
    },
    {
        "id": "q_0459",
        "question": "Какое распределение моделирует случайный выбор одного из нескольких классов с заданными вероятностями?",
        "answers": [
            "Категориальное распределение (также известное как multinoulli) моделирует случайный выбор одного из нескольких классов с заданными вероятностями."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
                "text": "Рассмотрим несколько популярных распределений случайных векторов. Биномиальное распределениемоделирует-кратное подбрасывание монеты с вероятностями «успеха»и «неудачи».Мультиномиальное распределениеобобщает этот эксперимент: теперь подбрасывается кубик сгранями, и вероятность выпадения-й грани равна,. Обозначим черезколичество выпадений-й грани в серии избросков. Тогда случайный векторимеет мультиномиальное распределение, при котором Примультиномиальное распределение превращается вкатегориальное, известное также под названиемmultinoulli. Категориальное распределение моделирует случайный выбор одного изклассов с заданными вероятностями. Многомерное нормальное (гауссовское) распределениезадаётся функцией плотности где,— невырожденная симметричная матрица размера. Такое распределение обозначается. Если случайный вектор, то,; таким образом, параметры гауссовского распределения — это его среднее и матрица ковариаций. Упражнение.Пустьи. Докажите, что. Важный частный случай случайного гауссовского вектора с независимыми компонентами был рассмотрен в примере из секции пронезависимость случайных величин. Такое распределение получается, если матрицадиагональна,. Тогда,, и поэтому Отсюда снова получаем формулу совместной плотности которую можно переписать в виде откуда следует независимость в совокупности компонент вектора. Если ковариационная матрицане является диагональной, то отдельные компоненты случайного векторазависимы. Тем не менее, всегда найдётся линейное (и даже ортогональное) преобразование, которое превратит векторв гауссовский вектор с независимыми компонентами. Для этого достаточно найти ортогональную матрицусо свойством и далее воспользоваться формулой плотности линейного преобразования гауссовского вектора. По тем же соображениям облако точек, сгенерированных из распределения, будет напоминать эллипсоид с полуосями, пропорциональными вектору. Линии уровня плотностизадаются уравнениями вида, а такое равенство эквивалентно квадратичной форме гдеи– некоторые константы. С помощью описанной выше ортогональной замены эта квадратичная форма может быть приведена к главным осям: в координатах это выглядит как Мы получили практически каноническое уравнение-мерного эллипсоида. Вэто будут эллипсы, сплюснутые тем сильнее, чем дальше от единицы отношениесобственных значений матрицы. Нормальным будет и всякое маргинальное распределение многомерного гауссовского вектора. Упражнение. Пусть случайный векторимеет гауссовское распределение с параметрами где,,,,.Докажите, что случайный вектор, полученный маргинализацией по компонентам вектора, является гауссовским с параметрамии. Распределение Дирихлесосредоточено на-мерном симплексе Плотность распределения Дирихлеравна где– вектор положительных параметров, а– многомерная бета-функция. Если,то"
            }
        ]
    },
    {
        "id": "q_0460",
        "question": "Какой параметр в функции train_test_split из библиотеки sklearn позволяет сохранить соотношение классов при разделении данных?",
        "answers": [
            "Для сохранения соотношения классов при разделении данных в функции train_test_split используется параметр stratify, который принимает значения меток классов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
                "text": "Методhold-outпредставляет из себя простое разделение на train и test: Такое разделение очень легко реализовать с помощью библиотекиsklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimporttrain_test_split34X, y = np.arange(1000).reshape((500,2)), np.arange(500)5X_train, X_test, y_train, y_test = train_test_split(6X, y,7test_size=0.2,8random_state=429) Чтобы оценить модель, вы обучаете её на тренировочном множестве, а результаты измеряете на тестовом. У sklearn по дефолту выставлен параметрshuffle=True, то есть перед разделением на тренировочное и тестовое множества происходит перемешивание семплов (и для воспроизводимости такого разбиения нужно фиксироватьrandom_state). А что будет, если не перемешать данные? Если обучение модели не зависит от порядка подачи в неё примеров (что верно, например, для k-NN или решающего дерева), то перемешивание данных влияет только на то, кто в итоге окажется в train и test. Если данные шли какими-то группами, например сначала 800 картинок с кошками, а за ними 200 картинок с собаками, аtrain_test_splitбыл совершён в пропорции 0.8, то модель просто не увидит собак в трейне. А в случае когда модель обучается с помощью градиентного спуска или его вариации (про различные модификации SGD подробно рассказывается впараграфео нейросетях), отсутствие перемешивания данных может влиять более интересным образом. Вот пример из практики Yandex.Research — как вы думаете, что не так с графиком обучения данной модели? Продолжим. Если у вас достаточно данных, лучше всегда предусматривать также валидационное множество: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimporttrain_test_split34X, y = np.arange(1000).reshape((500,2)), np.arange(500)5X_train, X_test, y_train, y_test = train_test_split(6X, y,7test_size=0.2,8random_state=429)10X_train, X_val, y_train, y_val = train_test_split(11X_train, y_train,12test_size=0.1,13random_state=4214) Если вы перебираете какие-то модели для вашей задачи, то оптимизировать их качества стоит на валидационном множестве, а окончательное сравнение моделей проводить на тестовом множестве. Оптимизация качеств модели может включать в себя подбор гиперпараметров, подбор архитектуры (в случае нейросетей) или подбор оптимального трешхолда для максимизации значений целевой метрики (например, вы делаете двуклассовую классификацию, а модель выдаёт непрерывные значения от 0 до 1, которые нужно бинаризовать так, чтобы получить максимальный скор по F1) и так далее. Если же оптимизировать качества моделей и проводить их сравнение на одном и том же множестве, то можно неявно заложить в модели информацию о тестовом множестве и получить результаты хуже ожидаемых на новых данных. Немного прервёмся например— к чему может привести неявное использование моделью тестового множества Представьте, что вы хотите обучить модель одномерной линейной регрессии для предсказания ваших данных: гдеи— искомые параметры вашей модели. Однако представьте, что параметрвам кто-то запретил обучать на тренировочном множестве и для вас у этой модели всего один параметр. Пусть на первой итерации у вас задано какое-то фиксированное, вы с ним подобрали на трейне лучшеепри данноми замерили качество получившейся модели на тестовом множестве. На следующей итерации вы взяли новое значение, повторили с ним предыдущий шаг и так далее. Теперь пришло время выбирать модель, и из всех них вы выбрали ту, которая показала лучший результат на тестовом множестве. Вам может показаться, что ваша модель содним параметромобучена на трейне и всё хорошо, но на самом деле вы использовали оба множества, чтобы обучить модель сдвумя параметрами, и теперь ваша тестовая оценка качества модели завышена. Может показаться, что этот пример довольно искусственный, но он на самом деле легко переносится на модели любой сложности. Просто представьте себе, что часть обучаемых весов вашей сложной модели вам запретили обучать на трейне и вы начинаете так же, как и выше, оценивать их на тесте, то есть по фактуучитьна тесте. А чем такая ситуация отличается от подборагиперпараметровмодели (которые вы уже действительно не можете обучить на трейне) сразу на тестовом множестве? Вообще говоря, ничем. Продолжим. Для окончательного применения найденную лучшую модель можно обучить на всех имеющихся данных. Правда, вы не сможете оценить качество получившейся модели, так как у вас уже не будет тестового множества. Чтобы примерно оценить, как будет вести себя модель при добавлении новых данных, вы можете построитькривые обучения: графики качества модели на трейне и на тесте в зависимости от числа поданных семплов на вход. Кривые обучения могут выглядеть следующим образом (код для отрисовки таких кривых можнонайтив документации библиотеки sklearn): Если графики подсказывают, что качество модели по валидационным метрикам продолжает расти, имеет смысл добавить новые данные. На картинке выше приведены кривые обучения двух моделей на одном и том же датасете. Модель слева показала итоговые результаты явно хуже модели справа — плюс график качества на валидации у неё близок к плато, хотя и продолжает расти, — а качество модели справа могло бы ещё вырасти при добавлении дополнительных семплов (качество на трейне константно высокое, а на валидации возрастает). При простом случайном разделении на тренировочное и тестовое множества (как в примерах выше) может случиться так, что их распределения окажутся не такими, как у всего исходного множества. Проиллюстрируем такую ситуацию на примере случайного разбиения датасетаIrisна трейн и тест. Распределение классов в данном датасете равномерное: Setosa Versicolor Virginica Случайное разбиение, в котором две трети цветов (100) отправились в трейн, а оставшаяся треть (50) отправилась в тест, может выглядеть, например, так: трейн: 38Setosa, 28Versicolor, 34Virginica (распределение) тест: 12Setosa, 22Versicolor, 16Virginica (распределение) Если распределение цветов в исходном датасете отражает то, что в природе они встречаются одинаково часто, то мы только что получили два новых датасета, не соответствующих распределению цветов в природе. Распределения обоих датасетов вышли не только несбалансированными, но ещё и разными: самый частый класс в трейне соответствует наименее частому классу в тесте. На помощь в такой ситуации может прийтистратификация: разбиение на трейн и тест, сохраняющее соотношение классов, представленное в исходном датасете. В библиотеке sklearn такое разбиение можно получить с помощью параметраstratify: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimporttrain_test_split34X, y = np.arange(1000).reshape((500,2)), np.random.choice(4, size=500, p=[0.1,0.2,0.3,0.4])5X_train, X_test, y_train, y_test = train_test_split(6X, y,7test_size=0.2,8random_state=42,9stratify=y10) В целом на достаточно больших датасетах (порядка хотя бы 10 тысяч семплов) со сбалансированными классами можно не очень сильно беспокоиться об описанной выше проблеме и использовать обычный random split. Но если у вас очень несбалансированные данные, в которых один класс встречается сильно чаще другого (как, например, в задачах фильтрации спама или сегментации осадков на спутниковых снимках), стратификация может довольно сильно помочь."
            }
        ]
    },
    {
        "id": "q_0461",
        "question": "Какой алгоритм кросс-валидации является частным случаем метода k-Fold, где каждый фолд состоит из одного семпла?",
        "answers": [
            "Это метод leave-one-out (LOO), который является частным случаем k-Fold кросс-валидации. При его использовании каждый фолд содержит ровно один семпл, а количество итераций равно количеству семплов в данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
                "text": "Методk-Foldчаще всего имеют в виду, когда говорят о кросс-валидации. Он является обобщением метода hold-out и представляет из себя следующий алгоритм: Фиксируется некоторое целое число(обычно от 5 до 10), меньшее числа семплов в датасете. Датасет разбивается наодинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называютсяфолдами. Далее происходититераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится нафолде и тестируется на оставшемся. Финальный скор модели получается либо усреднениемполучившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации. Этот метод есть в sklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportKFold34X = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])5y = np.array([1,2,3,4])6kf = KFold(n_splits=2)78fortrain_index, test_indexinkf.split(X):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]12'''13result:14TRAIN: [2 3] TEST: [0 1]15TRAIN: [0 1] TEST: [2 3]16''' В коде выше получилось два фолда: в первый вошли объекты с индексами 2 и 3, во второй — объекты с индексами 0 и 1. На первой итерации алгоритма фолд с индексами 2 и 3 будет тренировочным, а на второй — фолд с индексами 0 и 1. В sklearn есть также методcross_val_score, принимающий на вход классификатор, данные и способ разбиения данных (либо число фолдов) и возвращающий результаты кросс-валидации: Скопировать код1fromsklearn.model_selectionimportcross_val_score23clf = svm.SVC(kernel='linear', C=1, random_state=42)4scores = cross_val_score(clf, X, y, cv=5)5print(scores)6'''7result:8array([0.96..., 1. , 0.96..., 0.96..., 1. ])9''' Интересный вопрос состоит в том, какую модель брать для сравнения с остальными на отложенном тестовом множестве (если оно у вас есть) либо для окончательного применения в задаче. После применения k-Fold для одной модели у вас на руках останетсяэкземпляров (инстансов) этой модели, обученных на разных подмножествах трейна. Возможные варианты: делать предсказание с помощью усреднения предсказаний этихинстансов; из этихинстансов выбрать тот, который набрал лучший скор на своём тестовом фолде, и применять дальше его; заново обучить модель уже на всехфолдах и делать предсказания уже этой моделью. Выбирать, какой способ лучше, нужно в зависимости от конкретной задачи и имеющихся вычислительных возможностей. Метод k-Fold даёт более надёжную оценку качества модели, чем hold-out, так как обучение и тест модели происходят на разных подмножествах исходного датасета. Однако проведениеитераций обучения и теста может быть вычислительно затратным, и поэтому метод обычно применяют либо когда данных достаточно мало, либо при наличии большого количества вычислительных ресурсов, позволяющих проводить всеитераций параллельно. В реальных задачах данных зачастую достаточно много для того, чтобы hold-out давал хорошую оценку качества модели, поэтому k-Fold в больших задачах применяется не очень часто. Методleave-one-out (LOO)— частный случай метода k-Fold: в нём каждый фолд состоит ровно из одного семпла. LOO тоже есть в библиотеке sklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportLeaveOneOut34X = np.array([[1,2], [3,4], [5,6]])5y = np.array([1,2,3])6loo = LeaveOneOut()78fortrain_index, test_indexinloo.split(X):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]12'''13result:14TRAIN: [1 2] TEST: [0]15TRAIN: [0 2] TEST: [1]16TRAIN: [0 1] TEST: [2]17''' Этот метод может понадобиться в случае, если у вас очень мало данных, — например, в задаче сегментации клеток на изображениях с оптического микроскопа, — и вы хотите использовать максимальное их количество для обучения модели. Для валидации на каждой итерации методу требуется всего один семпл, однако и итераций будет столько, сколько семплов в данных, поэтому метод неприменим для средних и больших задач. Методstratified k-Fold— это метод k-Fold, использующий стратификацию при разбиении на фолды: каждый фолд содержит примерно такое же соотношение классов, как и всё исходное множество. Такой подход может потребоваться в случае, например, очень несбалансированного соотношения классов, когда при обычном random split некоторые фолды могут либо вообще не содержать семплов каких-то классов, либо содержать их слишком мало. Этот метод также представлен в sklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportStratifiedKFold34X = np.array([[1,2], [3,4], [1,2], [3,4]])5y = np.array([0,0,1,1])6skf = StratifiedKFold(n_splits=2)78fortrain_index, test_indexinskf.split(X, y):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]12'''13result:14TRAIN: [1 3] TEST: [0 2]15TRAIN: [0 2] TEST: [1 3]16''' Существует такая задача, как прогнозирование временных рядов. На практике она часто возникает в форме «Что будет с показателями нашего продукта в ближайший день / месяц / год?». При этом имеются какие-то исторические данные этих показателей за предыдущее время, которые можно визуализировать в виде некоторого графика по времени: Этот график — пример графика временного ряда, и наша задача — спрогнозировать, как будет выглядеть данный график в будущие моменты времени. Кросс-валидация моделей для такой задачи осложняется тем, что данные не должны пересекаться по времени: тренировочные данные должны идти до валидационных, а валидационные — до тестовых. С учётом этих особенностей фолды в кросс-валидации для временных рядов располагаются вдоль временной оси так, как показано на следующей картинке: В sklearn реализована такая схема кросс-валидации: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportTimeSeriesSplit3X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])4y = np.array([1,2,3,4,5,6])5tscv = TimeSeriesSplit()6print(tscv)78fortrain_index, test_indexintscv.split(X):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]1213'''14result:15TRAIN: [0] TEST: [1]16TRAIN: [0 1] TEST: [2]17TRAIN: [0 1 2] TEST: [3]18TRAIN: [0 1 2 3] TEST: [4]19TRAIN: [0 1 2 3 4] TEST: [5]20'''"
            }
        ]
    },
    {
        "id": "q_0462",
        "question": "Какие проблемы могут возникнуть при использовании случайного разбиения данных на тренировочное и тестовое множество для задачи классификации новостных статей по темам?",
        "answers": [
            "Случайное разбиение может привести к тому, что тренировочное и тестовое множества будут содержать статьи на одни и те же темы, поскольку новостные статьи одной тематики часто публикуются кластерами во времени. Это не соответствует реальному применению модели, где на вход будут поступать новые кластеры тем, которых может не быть в тренировочных данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
                "text": "Ваша модель показала очень высокое качество на тестовых данных, вы радостно откидываетесь на спинку кресла и достаёте шампанское... Или пока рано? Перед тем как информировать коллег о своих высоких результатах, проверьте, что вы не допустили какую-то из следующих ошибок: ваши данные не были перемешаны (вспоминаем пример выше с тензорбордом курильщика); вы подбирали гиперпараметры на тестовом множестве и на нём же оценивали качество модели; у вас в данных есть фича, которая в некотором смысле является «прокси» к таргету (proxy for the target). Это такая фича, которая почти равна таргету, хотя формально им не является и так же, как и таргет, не будет доступна на момент реального применения модели; вы проводили feature engineering на всём датасете, а не только на трейне. Например, вы строилиtf-idfфичи илиbag-of-wordsна всех данных, а не только на трейне, тем самым заложив в свои тренировочные данные информацию о тестовых данных; вы применялистандартизациюданных на всём датасете, а не только на трейне. Например, в случаеStandardScalerтестовое множество повлияет на используемые этим методом оценки среднего и стандартного отклонения; вы смешали трейн с тестом. Последний пункт может звучать очень банально, но на практике часто оказывается, что правильно разделить данные на тренировочные и тестовые не так просто даже с учётом всех описанных выше техник. Об этом в следующих разделах. Ваши данные зависят от времени, а вы при разбиении на трейн и тест это не учли. Например, вы применили обычный random split при работе с временными рядами, передав тем самым вашей модели информацию из будущего. Или вы предсказываете погоду на несколько часов вперёд, а у вас данные из одного и того же дня находятся и в трейне, и в тесте. У вас есть датасет с картинками, и вы решили увеличить количество семплов в нём с помощьюаугментаций(примерами аугментаций могут служить симметричные отражения, повороты, растяжения). При этом вы взяли весь датасет, применили к нему аугментации и только после этого разделили на трейн и тест. В таком случае преобразования какой-то одной картинки могут попасть в оба множества, и вы получите пересечение трейна и теста. Вы решаете задачу рекомендации статей или постов пользователям на основании их комментариев и прочтений, при этом в трейне и тесте у вас одни и те же пользователи. Вы решаете какую-то задачу, где происходит работа с видеоданными. Например, распознаёте движение по видео или предсказываете фамилию актёра, попавшего в кадр. При этом в трейн и тест у вас попадают различные кадры из одного и того же видео. У вас есть спутниковые снимки, и вы хотите по ним предсказывать рельеф местности. При этом у вас в трейне и тесте есть кропы снимков над одними и теми же географическими координатами (хоть и в разное время). Вы обучаете голосового ассистента в звуковом потоке распознавать момент, когда к нему обращаются (например, «Слушай, Алиса», «Ok, Google»). При этом у вас в трейне и тесте одни и те же люди. Это, на первый взгляд, не очень страшная проблема, но на самом деле достаточно большая нейронка может запомнить интонации и манеру речи конкретного человека и будет использовать эти сведения для тестовых записей с этим человеком. При этом на новых людях распознавание будет работать сильно хуже. Вы хотите расширить тренировочный датасет какими-то дополнительными данными из другого датасета, но при этом оказывается, что другой датасет содержит в себе часть тестового множества вашего исходного датасета. Например, есть два публичных датасета:ImageNet LSVRC 2015, в котором 1000 классов и чуть больше миллиона изображений, иImageNet, в котором 21 тысяча классов и чуть больше 14 миллионов изображений. При этом первый полностью содержится во втором, поэтому использование ImageNet для расширения обучающей выборки из ImageNet LSVRC 2015 может закончиться тем, что в трейне окажутся примеры из тестового множества, сформированного из ImageNet LSVRC 2015. Пример заимствованотсюда. Допустим, что вы должны обучить модель, предсказывающую тему новостной статьи по её тексту. Если отсортировать статьи по дате их публикации, то ваши данные могут выглядеть, например, так: Здесь форма и цвет фигуры соответствуют новости, которой посвящена статья. Почему случайное разбиение данных на трейн и тест может привести к проблемам в этой задаче? На самом деле новостные статьи с одной и той же тематикой появляются кластерами во времени, так как статьи о новом событии выходят, как правило, порциями в то же время, когда произошло событие. Если разбить данные случайно, то тренировочное и тестовое множества с большой вероятностью будут содержать статьи на одни и те же наборы тем: Такое разбиение не соответствует тому, как потом модель будет применяться в реальной задаче: при нём модель будет ожидать равномерного распределения тем, предложенных ей в трейне, тогда как в реальности ей на вход будут приходить всё те же кластеры, и они, вообще говоря, не обязаны были быть в её тренировочном множестве. Простым решением будет при разбиении на трейн и тест учитывать время, когда была опубликована статья: Тут нужно, однако, учитывать, что в реальности кластеры историй по времени выражены не столь чётко и могут пересекаться. Поэтому если трейн и тест расположены слишком близко друг от друга по времени, то они могут пересечься. В принципе, это не так плохо с учётом того, что новости о каких-то событиях могут продолжать выходить в течение некоторого растянутого промежутка времени. Но если хочется избежать такой ситуации, то можно оставить между трейном и тестом некоторый временной зазор: тренироваться, например, на апрельских публикациях, а тестироваться на второй неделе мая, оставив, таким образом, недельный промежуток между двумя множествами."
            }
        ]
    },
    {
        "id": "q_0463",
        "question": "Какие дополнительные возможности предоставляет библиотека Prophet для работы с кросс-валидацией?",
        "answers": [
            "Библиотека Prophet от Facebook включает собственную имплементацию кросс-валидации, которая предоставляет таблицы с результатами и визуализацию в виде графиков."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
                "text": "Оригинальный текстописанного выше примера. Ещё один классный пример, когда случайное разбиение данных может испортить ML-модель. Отличный блог-постот Neptune про различные методы кросс-валидации. Раздел нашего учебника, посвящённый сравнению и оценке качества моделей. Большая статья-обзорпро методы сравнения моделей и оценки их качества. Секция Model Selectionот sklearn. Блог-постпро различные «умные» способы получить завышенные оценки качества моделей. Отличныйгайдо том, как читать графики обучающих кривых в разных случаях. Статья про временные рядыиз курса «Открытый курс машинного обучения» от ODS Библиотека Prophet от Facebookдля прогнозирования временных рядов, у которой есть свояимплементация кросс-валидациис дополнительными фичами (таблицы с результатами кросс-валидации, красивые графики). Здесьможно почитать статью с теоретическим обоснованием метода Prophet. Отличное видео про лики в данныхот DataRobot. Блог-постна эту же тему от них же. Статьяпро методики разбиения данных в рекомендательных системах."
            }
        ]
    },
    {
        "id": "q_0464",
        "question": "Какая особенность автокорреляционной функции характерна для модели скользящего среднего?",
        "answers": [
            "Автокорреляционная функция модели скользящего среднего равна нулю для лагов, превышающих порядок модели."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель скользящего среднего порядкаили просто MA() предполагает следующую зависимость данных: где— стационарный ряд со средним, а— гауссовский белый шум, то естьи независимы. По сути наш рядвыражается через сумму некоторого фиксированного среднего, значения белого шума в текущий момент времении не болеепредыдущих значений белого шума, домноженных на некоторые коэффициенты, которые являются параметрами модели. Рассмотрим некоторые свойства модели MA(). Как уже было упомянуто выше, рядбудет являтьcя стационарным со средним. Найдем также. Воспользовавшись свойством независимости для, можем заключить, что Посчитаем автоковариационную функцию для ряда, то есть найдем значение. Легко понять, что если, то= 0, т.к.независимы. Если же, то тогда Записав более компактно, можем получить: где. Из посчитанных значений для дисперсии и ковариационной функции, можете попробовать получить выражение и для автокорреляционной функции. Ее особенностью будет как раз равенство нулю на лаге, превосходящим. Посмотрим на визуализацию:"
            }
        ]
    },
    {
        "id": "q_0465",
        "question": "При каких условиях на комплексные корни характеристического полинома модель AR(p) задаёт стационарный временной ряд?",
        "answers": [
            "Модель AR(p) задаёт стационарный временной ряд, если все комплексные корни характеристического полинома лежат вне единичного круга."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель авторегрессии для временного ряда можно записать следующим образом: где— стационарный ряд, а— гауссовский белый шум, то естьи независимы. Отметим, что, вообще говоря, для стационарности нужны некоторые условия на коэффициенты. По сути наш рядвыражается через сумму некоторого фиксированного числа, значения белого шума в текущий момент времении не болеепредыдущих значений этого же ряда, домноженных на некоторые коэффициенты, которые являются параметрами модели. Другими словами, модель AR() — это модельдля которой Таргет:— значение ряда в момент времени Признаки:— значения ряда в предыдущие моменты времени Введем— оператор сдвига, обладающий следующими свойствами: применениек ряду дает предыдущее значение этого же ряда: применениек белому шуму дает предыдущее значение шума: применениек константе — это константа: Операториногда называют такжелаговымоператором. Можно рассматривать функции от оператора сдвига, например, кратное применение оператора:или. Для записей некоторых моделей временных рядов будет удобно использовать лаговый многочлен: Обратным к операторуназывают оператортакой, что: Так, например, дляможно заключить, что: Рассмотрим модель AR(): С помощью оператора сдвига ее можно представить в следующем виде: где— характеристический полином. Сформулируем пару важных утверждений: Любой стационарный (в широком смысле) процесс представим в виде, то есть в виде модели скользящего среднего с неограниченным количеством слагаемых (конечное или бесконечное число). Этот результат так же известен кактеорема Волдао декомпозиции временного ряда. Модельзадает стационарный временной рядвсе комплексные корнилежат вне единичного круга. Приведем пояснение второго утверждения. В самом деле, пусть— все его комплексные корни (их ровнос учетом кратности), тогда справедливо представление: Тогда при представлении временного ряда в виде и дальнейшего его разложения на простые дроби возникнут слагаемые вида Если при этомлежит внутри единичного круга или на его границе, то соответствующий ряд будет расходящимся. На самом деле, случаймы в дальнейшем учтем. В качестве примера рассмотрим подробнее модель.Зависимость имеет вид, где. Для данного ряда можно выписать следующие свойства: Уравнение, имеет корень. Тем самым,стационарен. Кроме того, чем меньше, тем предыдущее значение ряда вносит меньший вклад в текущее значение. Если ряд стационарен, то:. . Разберем первое равенство, остальные получаются аналогично. Возьмем математическое ожидание в уравнении ряда Поскольку ряд стационарен, то его математическое ожидание не меняется во времени, а для белого шума математическое ожидание равно нулю. Тем самым мы получаем уравнение на, откуда следует доказываемая формула. Таким образом, в зависимости от значениямы можем получить следующие результаты: Если, то— представление ряда в виде MA(). Если, то— это случайное блуждание. Если, то— экспоненциально растущий процесс. Посмотрим на визуализацию. В первом случае мы имеем модель, отрицательный коэффициент является следствием больших колебаний ряда. Во втором случае модель, большой положительный коэффициент делает ряд менее шумным. В третьем случае показано несколько рядов вида случайного блуждания, что соответствует случаю. В четвертом случае показан экспоненциальный процесс, на графике шум уже не заметен из-за масштаба. На немного вернемся к модели MA(). Чуть выше мы выяснили, что при некоторых условиях на коэффицентывременной ряд модели AR() будет стационарным, а значит имеет представление в виде MA(). На самом деле, модель скользящего среднего порядкатоже можно представить с помощью оператораследующим образом: где—характеристический многочлен. Для простоты изложения пусть. Важным при такой записи оказывается понятие обратимости, то есть представления в виде которое означает, что ряд можно представить в виде бесконечной авторегрессионной модели.Здесь, как и в рассуждениях выше, можно заключить, что временной рядобратим, если все комплексные корнилежат вне единичного круга."
            }
        ]
    },
    {
        "id": "q_0466",
        "question": "Что определяет стационарность ряда в модели ARMA?",
        "answers": [
            "Стационарность ряда в модели ARMA определяется только его AR-компонентой, то есть значениями коэффициентов авторегрессии, поскольку MA-компонента всегда стационарна."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель ARMA() по сути является суммой моделейи, иначе говоря, модель есть сумма нескольких предыдущих значений ряда и нескольких предыдущих значений белого шума с некоторым коэффициентами. Эквивалентную запись ряда в терминах оператора сдвига можно получить, рассмотрев два многочлена или гдеи.Заметим, что во втором представлении константазаменена на. На самом деле, стационарность такого ряда будет определяться только его AR() компонентой, то есть значениями коэффициентов, так ряд в модели MA() всегда является стационарным."
            }
        ]
    },
    {
        "id": "q_0467",
        "question": "Каким образом модель ARIMA учитывает нестационарность временного ряда?",
        "answers": [
            "Модель ARIMA применяет процедуру дифференцирования временного ряда, чтобы преобразовать нестационарный ряд в стационарный. После этого к ряду разностей применяется модель ARMA. Например, для случайного блуждания дифференцирование первого порядка превращает его в стационарный ряд белого шума."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Модель ARIMA() — это расширение моделей типа ARMA на нестационарные временные ряды, которые однако могут стать стационарным после применениея процедуры дифференцирования ряда. Модель ARIMA() для рядаопределяется как модель ARMA() для ряда разностей порядкаряда. Разность порядка 1:. Разность порядка 2:. Получаем формулу модели ARIMA: или То есть многочленимеетединичных корней.Тем самым такая модель позволяет учесть нестационарности, в частности, тренд. В качестве примера рассмотрим процесс случайного блуждания: где— белый шум. Как уже упомяналось ранее, такой ряд не является стационарным. Однако, если мы применим операцию дифференцирования, то можем перейти к новому, уже стационарном ряду, который можно записать в виде:"
            }
        ]
    },
    {
        "id": "q_0468",
        "question": "Какую функцию используют для определения порядка модели авторегрессии?",
        "answers": [
            "Для определения порядка модели авторегрессии (AR) используют частичную (частную) автокорреляционную функцию (PACF). Значения PACF для модели AR(p) будут ненулевыми для лагов до p и равны нулю для лагов больше p."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Для модели скользящего среднего порядкамы выяснили, что значения автокорреляционной функции для такого ряда оказывается равной нулю после лага. Эта особенность позволяет использовать автокорреляционную функцию для определения порядка модели скользящего среднего. Возникает разумный вопрос, как оценить порядокдля модели AR()? Здесь оказывается полезным понятие частичной (частной) автокорреляционной функции. Частичная автокорреляция (PACF)— корреляция ряда с собой после снятия линеной зависимости от промежуточных значений ряда. Иначе говоря, мы хотим как-то учесть опосредованного влияние промежуточных значений ряда и оценить непосредственное влияниена. Чуть более формально частичную автокорреляцию можно записать следующим образом: где— линейная регрессия на: Пример для: где— МНК-оценка в модели. Можно показать, что значение частиной автокорреляции для модели авторегресии AR() будет ненулевой для лагови равняться нулю для лагов. Имеет место быть полная аналогия с автокорреляционной функцией и моделью MA(). Таким образом, исследование поведения автокорреляционной и частичной автокорреляционной функции может быть использовано для определения порядкамодели скользящего среднего и порядкамодели авторегрессии соответсвтенно."
            }
        ]
    },
    {
        "id": "q_0469",
        "question": "Как выбираются начальные приближения для параметров p и q в модели ARIMA?",
        "answers": [
            "Начальное приближение для параметра p выбирается по последнему значимому пику у частичной автокорреляционной функции (PACF), а для параметра q — по последнему значимому пику у автокорреляционной функции (ACF)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
                "text": "Пусть гиперпараметрыфиксированы.&tab;В предположении, что— гауссовский белый шум, в нашей модели мы можем выписать функцию правдоподобиягде— соместная плотность. Из-за того, чтоимеют нормальное распределение, она будет иметь разумный вид. Соответственно, в качестве оценок параметров берется оценка максимального правдоподобия. Для поиска начальных приближение для параметровивоспользуемся автокорреляционной и частичной автокорреляционной функцией. Начальное приближение: последний значимый пик у PACF. Начальное приближение: последний значимый пик у ACF. Далее обычно используется поиск по сетке вокруг подобранных значений, минимизируя информационный критерий: — критерий Акаике; — критерий Акаике (короткие ряды); — Байесовский информационный критерий или критерий Шварца, где— логарифм функции правдоподобия,— длина временного ряда. Приведем некоторый план при применению модели ARIMA для прогнозирования временных рядов. Анализ выбросов: замена нерелевантых выбросов наNAили усреднение по соседним элементам. Стабилизация дисперсии (преобразования). Дифференцирование, если ряд не стационарен. Выбор пилотныхипо PACF и ACF. Вокруг этих параметров подбираем оптим. модель по/. Пошаговое построение прогноза:— для:;— для:;— для:. Построение предсказательного интервала:— если остатки модели нормальны и гомоскедастичны (дисперсия постоянна), то строится теоретический предсказательный интервалгде— горизонт прогнозирования,— оценка на дисперсию шума,— коэф. для ряда при его представлении в виде бесконечного процесса скользящего среднего. И, имогут быть выражены через оценки на параметрыи.— иначе интервалы строятся с помощью бутстрепа."
            }
        ]
    },
    {
        "id": "q_0470",
        "question": "В каких двух типах задач машинного обучения, помимо предсказанной метки, могут быть важны вероятности?",
        "answers": [
            "Вероятности могут быть важны как в задаче классификации, так и в задаче регрессии."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Раз уж мы начали говорить о распределении на веса, то почему бы не пойти дальше. Решая задачу классификации, мы уже столкнулись с тем, что может быть важна не только предсказанная метка класса, но и вероятности. Аналогичное верно и для задачи регрессии. Давайте рассмотрим две следующих ситуации, в каждой из которых мы пытаемся построить регрессию: Несмотря на то, что в каждом из случаев «точная формула» или градиентный спуск выдадут нам что-то, степень нашей уверенности в ответе совершенно различная. Один из способов выразить (не)уверенность — оценить распределение параметров. Так, для примеров выше распределения на параметрмогли бы иметь какой-то такой вид: Дальше мы постараемся формализовать процесс получения таких оценок."
            }
        ]
    },
    {
        "id": "q_0471",
        "question": "Как изменяется распределение вероятности параметра монеты после получения данных о результатах её подбрасываний?",
        "answers": [
            "После получения данных о результатах подбрасываний монеты априорное равномерное распределение вероятности параметра обновляется до апостериорного бета-распределения, параметры которого зависят от количества выпавших орлов и решек. Пик этого распределения смещается в сторону более вероятных значений параметра, а его ширина уменьшается с увеличением количества данных, отражая рост уверенности в оценке."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Давайте ненадолго забудем про линейную регрессию и представим, что мы подобрали с пола монету, которая выпадает орлом с некоторой неизвестной пока вероятностью. До тех пор, пока мы не начали её подкидывать, мы совершенно ничего не знаем о, эта вероятность может быть совершенно любой — то есть априорное распределение наявляется равномерным (на отрезке): Теперь представим, что мы подкинули еёраз, получив результаты(— решка,— орёл), среди которыхрешек иорлов. Определённо наши познания о числестали точнее: так, еслимало, то можно заподозрить, что иневелико (уже чувствуете, запахло распределением!). Распределение мы посчитаем с помощью формулы Байеса: в нашем случае: В этом выражении нетрудно узнать бета-распределение:. Давайте нарисует графики его плотности для нескольких конкретных значенийи: Как можно заметить, с ростоммы всё лучше понимаем, каким может быть, при этом если орёл выпадал редко, то пик оказывается ближе к нулю, и наоборот. Ширина пика в каком-то смысле отражает нашу уверенность в том, какими могут быть значения параметра, и не случайно чем больше у нас данных — тем уже будет пик, то есть тем больше уверенности. Распределениепараметра, полученное с учётом данных, называетсяапостериорным. Переход от априорного распределения к апостериорному отражает обновление нашего представления о параметрах распределения с учётом полученной информации, и этот процесс является сердцем байесовского подхода. Отметим, что если нам придут новые данные, в которыхрешек иорлов, мы сможем ещё раз обновить распределение по той же формуле Байеса: Вопрос на подумать. Пусть— нормальное распределение с фиксированной дисперсией, а для параметрав качестве априорного выбрано также нормальное распределение. Каким будет апостериорное распределение при условии данных?"
            }
        ]
    },
    {
        "id": "q_0472",
        "question": "Какие пары распределений являются сопряжёнными согласно распространённым примерам?",
        "answers": [
            "Сопряжёнными парами являются: распределение Бернулли с бета-распределением; нормальное распределение с фиксированной дисперсией с нормальным; показательное распределение с гамма-распределением; пуассоновское распределение с гамма-распределением; равномерное распределение на отрезке с распределением Парето."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "В двух предыдущих примерах нам очень сильно повезло, что апостериорные распределения оказались нашими добрыми знакомыми. Если же взять случайную пару распределенийи, результат может оказаться совсем не таким приятным. В самом деле, нет никакой проблемы в том, чтобы посчитать числитель формулы Байеса, но вот интеграл в знаменателе может и не найтись. Поэтому выбирать распределения нужно с умом. Более того, поскольку апостериорное распределение само станет априорным, когда придут новые данные, хочется, чтобы априорное и апостериорное распределения были из одного семейства; пары (семейств) распределенийи, для которых это выполняется, называютсясопряжённыминазываетсясопряжённымк. Полезно помнить несколько наиболее распространённых пар сопряжённых распределений: — распределение Бернулли с вероятностью успеха,— бета распределение; — нормальное с матожиданиеми фиксированной дисперсией,также нормальное; — показательное с параметром,— гамма распределение; — пуассоновское с параметром,— гамма распределение; — равномерное на отрезке,— Парето; Возможно, вы заметили, что почти все указанные выше семейства распределений (кроме равномерного и Парето) относятся к экспоненциальному классу. И это не случайность! Экспоненциальный класс и тут лучше всех: оказывается, что дляиз экспоненциального класса можно легко подобрать сопряжённое. Давайте же это сделаем. Пустьимеет вид Положим где— множитель, обеспечивающий равенство единице интеграла от этой функции. Найдём апостериорное распределение: Это распределение действительно из того же семейства, что и, только с новыми параметрами: Пример. Пустьподчиняется распределению Бернулли. Напомним, что оно следующим образом представляется в привычном для экспоненциального класса виде: Предлагается брать априорное распределение вида Тогда апостериорное распределение будет иметь вид (проверьте, посчитав по формуле Байеса!) Превратив логарифм частного в сумму, а экспоненту суммы в произведение, легко убедиться, что получается то самое бета распределение, которое мы уже получали выше."
            }
        ]
    },
    {
        "id": "q_0473",
        "question": "Что такое MAP-оценка и как она связана с априорным знанием?",
        "answers": [
            "MAP-оценка — это оценка апостериорного максимума, которая представляет собой самое вероятное значение параметра. Она использует априорное знание через параметры, которые работают как память о воображаемых испытаниях, учитывая успехи и неудачи до получения данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Апостериорное распределение — это очень тонкий инструмент анализа данных, но иногда надо просто сказать число (или же интеграл в знаменателе не берётся и мы не можем толком посчитать распределение). В качестве точечной оценки логично выдать самое вероятное значение(интеграл в знаменателе отне зависит, поэтому на максимизацию не влияет): Это число называетсяоценкой апостериорного максимума (MAP). Если же в формуле выше перейти к логарифмам, то мы получим кое-что, до боли напоминающее старую добрую регуляризацию (и не просто так, как мы вскоре убедимся!): Пример. Рассмотрим снова распределение Бернуллии априорное распределение. Тогда MAP-оценка будет равна Дифференцируя пои приравнивая производную к нулю, мы получаем В отличие от оценки максимального правдоподобиямы здесь используем априорное знание: параметрыиработают как «память о воображаемых испытаниях», как будто бы до того, как получить данные, мы уже имелиуспехов инеудач."
            }
        ]
    },
    {
        "id": "q_0474",
        "question": "При каком условии оценка максимального правдоподобия становится частным случаем апостериорной оценки?",
        "answers": [
            "Это происходит, когда априорное распределение является равномерным, то есть не зависит от параметров."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Оценка максимального правдоподобия является частным случаем апостериорной оценки. В самом деле, если априорное распределение является равномерным, то естьне зависит(если весавещественные, могут потребоваться дополнительные усилия, чтобы понять, как такое вообще получается), и тогда"
            }
        ]
    },
    {
        "id": "q_0475",
        "question": "Как уточняется представление о распределении весов в байесовском подходе после получения данных?",
        "answers": [
            "Изначальное априорное представление о распределении весов уточняется на основе данных, что приводит к формированию апостериорного представления о распределении весов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "В предыдущих разделах мы разобрали, как байесовский подход работает для обычных, не условных распределений. Теперь вернёмся к чему-то более близкому к машинному обучению, а именно к распределениям вида, и убедимся, что для них байесовских подход работает точно так же, как и для обычных распределений. Имея некоторое распределение, мы подбираем для него априорное распределение на веса(и да, оно не зависит от: ведь априорное распределение существует ещё до появления данных) и вычисляем апостериорное распределение на веса: Вычислять его мы будем по уже привычной формуле Байеса: Повторим ещё разок, в чём суть байесовского подхода: у нас было некоторое априорное представлениео распределении весов, а теперь, посмотрев на данные, мы уточняем своё понимание, формулируя апостериорное представление. Если же нам нужна только точечная оценка, мы можем ограничиться оценкой апостериорного максимума (MAP): что уже до неприличия напоминает регуляризованную модель"
            }
        ]
    },
    {
        "id": "q_0476",
        "question": "Как изменяется апостериорное распределение весов линейной регрессии с ростом размера обучающей выборки?",
        "answers": [
            "С увеличением размера обучающей выборки мода апостериорного распределения приближается к истинному значению весов, а дисперсия распределения постепенно уменьшается."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "В модели линейной регрессии,введём априорное распределение на веса вида Тогда— точка минимума следующего выражения: Получается, что а это же функция потерь для линейной регрессии с-регуляризацией! Напомним на всякий случай, что у этой задачи есть «точное» решение Для этого примера мы можем вычислить и апостериорное распределение. В самом деле, из написанного выше мы можем заключить, что Таким образом,— это квадратичная функция от, откуда следует, что апостериорное распределение является нормальным. Чтобы найти его параметры, нужно немного преобразовать полученное выражение: Таким образом, Как видим, от априорного распределения оно отличается корректировкой как матожидания, так и ковариационной матрицы. Отметим, что— это, с точностью до численного множителя, оценка ковариационной матрицы признаков нашего датасета (элементы матрицы— это скалярные произведения столбцов, то есть столбцов значений признаков). Иллюстрация. Давайте на простом примере (датасет с двумя признаками) посмотрим, как меняется апостериорное распределениес ростом размера обучающей выборки: Как видим, не только мода распределения, то естьприближается к своему истинному значению, но и дисперсия распределения постепенно уменьшается. Ещё иллюстрация. Теперь рассмотрим задачу аппроксимации неизвестной функции одной переменной (чьи значения в обучающей выборке искажены нормальным шумом) многочленом третьей степени. Её, разумеется, тоже можно решать, как задачу линейной регрессии на коэффициенты многочлена. Давайте нарисуем, как будут выглядеть функции, сгенерированные из распределениядля разного объёма обучающей выборки: Тут тоже видим, что функции не только становятся ближе к истинной, но и разброс их уменьшается."
            }
        ]
    },
    {
        "id": "q_0477",
        "question": "Какая функция потерь получается при использовании распределения Лапласа в качестве априорного распределения на веса в линейной регрессии?",
        "answers": [
            "Получается функция потерь для линейной регрессии с L1-регуляризацией."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Другое распределение, которое тоже может кодировать наше желание, чтобы небольшие по модулю значениябыли правдоподобными, а большие не очень, — распределение Лапласа. Посмотрим, что будет, если его взять в качестве априорного распределения на веса. Проводя такое же вычисление, получаем, что а это же функция потерь для линейной регрессии с-регуляризацией!"
            }
        ]
    },
    {
        "id": "q_0478",
        "question": "Как предлагается предсказывать распределение для нового объекта в вероятностной модели?",
        "answers": [
            "Для нового объекта предлагается предсказывать распределение, вычисляя интеграл, который учитывает апостериорное распределение параметров модели. Если вычисление интеграла затруднительно, используется приближение с помощью дельта-функции, заменяющей сложное апостериорное распределение на точечную оценку."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Все изложенные выше рассуждения проводились в ситуации, когда— обучающая выборка. Для неё мы можем посчитать и точечную апостериорную оценку. А теперь пусть нам дан новый объект. Какой таргетмы для него предскажем? Было бы естественным, раз уж мы предсказываем распределение для, и длятоже предсказывать распределение. Делается это следующим образом: Надо признать, что вычисление этого интеграла не всегда посильная задача, поэтому зачастую приходится «просто подставлять». В вероятностных терминах это можно описать так: вместо сложного апостериорного распределениямы берём самое грубое на свете приближение где— дельта-функция, которая не является честной функцией (а является тем, что математики называют обобщёнными функциями), которая определяется тем свойством, чтодля достаточно разумных функций. Если не мудрствовать лукаво, то это всё значит, что Пример. Пусть,— модель линейной регрессии с априорным распределениемна параметры. Тогда, как мы уже видели раньше, Попробуем для новой точкипосчитать распределение на. Рекомендуем читателю попробовать самостоятельно посчитать интеграл или же обратиться к пункту 7.6.2 книжки «Machine Learning A Probabilistic Perspective» автора Kevin P. Murphy, убедившись, что что, очевидно, более содержательно, чем оценка, полученная с помощью приближения: Собственно, видно, что в этом случае Пример в примере. Рассмотрим полюбившуюся уже нам задачу приближения функции многочленом степени не выше(в которой мы строим модели с). Длямы получали такую картинку: Если оценить по приведённым выше формуламдля разных, то можно убедиться, что модель в большей степени уверена в предсказаниях для точек из областей, где было больше точек из обучающей выборки:"
            }
        ]
    },
    {
        "id": "q_0479",
        "question": "Какие ограничения имеют обычные вероятностные модели при поступлении новых данных для обучения?",
        "answers": [
            "Обычные небайесовские вероятностные модели не предоставляют инструментов для дообучения на новых данных. Оценку максимального правдоподобия приходится пересчитывать заново, хотя можно использовать старое значение как начальное приближение при оптимизации."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "До сих пор мы в основном рассуждали о моделях машинного обучения как о чём-то, что один раз обучается и дальше навсегда застывает в таком виде, но в жизни такое скорее редкость. Мы пока не будем обсуждать изменчивость истинных зависимостей во времени, но даже если истина неизменна, к нам могут поступать новые данные, которые очень хотелось бы использовать для дообучения модели. Обычные, не байесовские вероятностные модели не предоставляют таких инструментов. Оценку максимального правдоподобия придётся пересчитывать заново (хотя, конечно, можно схитрить, использовав старое значение в качестве начального приближения при итеративной оптимизации). Байесовский же подход позволяет оформить дообучения в виде простой и элегантной формулы: при добавлении новых данныхимеем"
            }
        ]
    },
    {
        "id": "q_0480",
        "question": "Какие недостатки у модели, объясняющей опоздание Василия открытием портала в другой мир и его участием в битве орков с эльфами?",
        "answers": [
            "Во-первых, эта модель допускает множество маловероятных исходов, среди которых наблюдаемый исход (Василий вернулся вовремя) крайне маловероятен. Во-вторых, её невозможно провалидировать, так как в мире с порталами и орочьими принцессами возможно всё, и отсутствие повторения ситуации не опровергает модель."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Нам часто приходится выбирать: дерево или случайный лес, линейная модель или метод ближайших соседей; да, собственно, и внутри наших вероятностных моделей есть параметры (скажем, дисперсия шумаи), которые надо бы подбирать. Но как? В обычной ситуации мы выбираем модель, обученную на выборкев зависимости от того, как она себя ведёт на валидационной выборке(сравниваем правдоподобие или более сложные метрики) — или же делаем кросс-валидацию. Но как сравнивать модели, выдающие распределение? Ответим вопросом на вопрос: а как вообще сравнивать модели? Назначение любой модели — объяснять мир вокруг нас, и её качество определяется именно тем, насколько хорошо она справляется с этой задачей. Тестовая выборка — это хороший способ оценки, потому что она показывает, насколько вписываются в модель новые данные. Но могут быть и другие соображения, помогающие оценить качество модели. Аналитик Василий опоздал на работу. Своему руководителю он может предложить самые разные объяснения — и это будет выработанная на одном обучающем примере модель, описывающая причины опоздания и потенциально позволяющая руководителю принять решение о том, карать ли Василия. Конечно, руководитель мог бы принять изложенную Василием модель к сведению, подождать, пока появятся другие опоздавшие, и оценить её, так скажем, на тестовой выборке, но стоит ли? Давайте рассмотрим несколько конкретных примеров: Модель «Василий опоздал, потому что так получилось», то есть факт опоздания — это просто ни от чего не зависящая случайная величина. Такая модель плоха тем, что (а) не предлагает, на самом деле, никакого объяснения тому факту, что Василий опоздал, а его коллега Надежда не опоздала и (б) совершенно не помогает решить, наказывать ли за опоздание. Наверное, такое не удовлетворит руководителя. Модель «Василий опоздал, потому что рядом с его домом открылся портал в другой мир, где шла великая битва орков с эльфами, и он почувствовал, что просто обязан принять в ней участие на стороне орков, которых привёл к победе, завоевав руку и сердце орочьей принцессы, после чего был перенесён обратно в наш скучный мир завистливым шаманом». Чем же она плоха? Битва с эльфами — это, безусловно, важное и нужное дело, и на месте руководителя мы бы дружно согласились, что причина уважительная. Но заметим, что в рамках этой модели можно объяснить множество потенциальных исходов, среди которых довольно маловероятным представляется наблюдаемый: тот, в котором Василий не погиб в бою, не остался со своей принцессой и не был порабощён каким-нибудь завистливым шаманом. Отметим и другой недостаток этой модели: её невозможно провалидировать. Если в совершенно случайной модели можно оценить вероятность опоздания и впоследствии, когда накопятся ещё примеры, проверить, правильно ли мы её посчитали, то в мире, где открываются порталы и любой аналитик может завоевать сердце орочьей принцессы, возможно всё, и даже если больше никто не попадёт в такую ситуацию, Василий всё равно сможет бить себя в грудь кулаком и говорить, что он избранный. Так что, наверное, это тоже не очень хорошая модель. Модель «Василий опоздал, потому что проспал» достаточно проста, чтобы в неё поверить, и в то же время даёт руководителю возможность принять решение, что делать с Василием. Обратимся к примеру из машинного обучения. Сравним три модели линейной регрессии: Даже и не запрашивая тестовую выборку, мы можем сделать определённые выводы о качестве этих моделей. Средняя (квадратичная) явно лучше левой (линейной), потому что она лучше объясняет то, что мы видим: тот факт, что облако точек обучающей выборки выглядит вогнутым вниз. А что с правым, почему мы можем утверждать, что он хуже? Есть много причин критиковать его. Остановимся вот на какой. На средней картинке у нас приближение квадратичной функцией, а на правой — многочленом довольно большой степени (на самом деле, десятой). А ради интереса: как выглядит график квадратичной функции и как — многочлена десятой степени со случайно сгенерированными коэффициентами? Давайте сгенерируем несколько и отметим их значения в точках обучающей выборки: Обратите внимание на масштаб на графиках справа. И какова вероятность, что нам достался именно тот многочлен десятой степени, у которого значения в обучающих точках по модулю в пределах сотни? Очевидно, она очень мала. Поэтому мы можем сказать, что выбор в качестве модели многочлена десятой степени не очень обоснован. Слишком простая модель плохо объясняет наблюдаемые нами данные, тогда как слишком сложная делает это хорошо, но при этом описывает слишком многообразный мир, в котором имеющиеся у нас данные оказываются уже слишком частным случаем. В каком-то смысле наш способ выбора модели оказывается переформулировкойбритвы Оккама: из моделей, пристойно описывающих наблюдаемые явления, следует выбирать наиболее минималистичную."
            }
        ]
    },
    {
        "id": "q_0481",
        "question": "Какая модель считается наиболее обоснованной при регрессии по двум точкам в задаче аппроксимации функции многочленом?",
        "answers": [
            "При регрессии по двум точкам наиболее обоснованной является линейная модель."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Пусть у нас есть некоторое семейство моделейи для каждогозадана какая-то своя вероятностная модель. В духе байесовского подхода было бы оценить условное распределение моделей и в качестве наилучшей модели взять её моду. Если же считать все модели равновероятными, то мы сводим всё к максимизации только лишь: Величинаназываетсяобоснованностью(evidence, marginal likelihood) модели. Отметим, что такое определение вполне согласуется с мотивацией из предыдущего подраздела. Слишком простая модель плохо описывает наблюдаемые данные, и потому будет отвергнута. В свою очередь, слишком сложная модель способна описывать гораздо большее многообразие явлений, чем нам было бы достаточно. Таким образом, компромисс между качеством описания и сложностью и даёт нам оптимальную модель. Вернёмся к нашей любимой задаче аппроксимации функции одной переменной многочленом небольшой степени по нескольким точкам, значение в которых было искажено нормальным шумом. Построим несколько моделей, приближающих многочленом степени не выше некоторого(будет принимать значения 1, 3 и 6), положив в вероятностной модели. Мы не будем приводить полный вывод обоснованности для задачи регрессии, а сразу выпишем ответ: Посмотрим, какой будет обоснованность для разного числа обучающих точек: Можно убедиться, что для регрессии по двум точкам наиболее обоснованная — линейная модель (и неудивительно), тогда как с ростом числа точек более обоснованной становится модель с многочленом третьей степени; слишком сложная же модель шестой степени всегда плетётся в хвосте. Точно вычислить обоснованность может быть трудной задачей (попробуйте проделать это сами хотя бы для линейной регрессии!). Есть разные способы посчитать её приближённо; мы рассмотрим самый простой. Напомним, что Воспользуемсяприближением Лапласа, то есть разложим(как функцию от) вблизи своего максимума, то есть вблизив ряд Тейлора: где линейный член отсутствует, поскольку разложение делается в точке локального экстремума, а— знакомая нам матрица Фишера. Далее,мы можем с точностью до второго порядка приблизить. Получается, что Несмотря на то, чтои, сгруппированные нами во «всякие штуки», существенным образом зависят от модели, при большихони вносят в показатель гораздо меньше вклада, чем первые два слагаемых. Таким образом, мы можем себе позволить вместо трудновычисляемыхиспользовать для сравнения модели"
            }
        ]
    },
    {
        "id": "q_0482",
        "question": "Какие два подхода к оцениванию рассматриваются в контексте анализа данных?",
        "answers": [
            "Рассматриваются фреквентистский (частотный) подход, где данные считаются случайной выборкой из фиксированного распределения, и байесовский подход, где данные используются для обновления априорных представлений о распределении параметров."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
                "text": "Мы с вами познакомились с двумя парадигмами оценивания: фреквентистской(frequentist, от слова \"frequency\", частота) — в которой считается, что данные являются случайным (настоящая случайность!) семплом из некоторого фиксированного распределения, которое мы стараемся оценить по этому семплу, и байесовской— в которой данные считаются данностью и в которой мы используем данные для обновления наших априорных представлений о распределении параметров (здесь случайности нет, а есть лишь нехватка знания). У обеих есть свои достоинства и недостатки, поборники и гонители. К недостаткам байесовской относится, безусловно, её вычислительная сложность: возможно, вы помните, в пучину вычислений сколь мрачных нас низвергла банальная задача линейной регрессии, и дальше становится только ещё трудней. Если мы захотим байесовский подход применять к более сложным моделям, например, нейросетям, нам придётся прибегать к упрощениям, огрублениям, приближениям, что, разумеется, ухудшает наши оценки. Но, если простить ему эту вынужденную неточность, он логичнее и честней, и мы продемонстрируем это на следующем примере. Одно известное свойство оценки максимального правдоподобия —асимптотическая нормальность. Если оценивать наши весапо различным наборам изобучающих примеров, причём считать, что наборы выбираются случайно (не будем уточнять, как именно), то оценкатоже превращается в случайную величину, которая как-то распределена. Теория утверждает, что при где— истинное значение весов, а— матрица информации Фишера, которая определяется как что при некоторых не слишком обременительных ограничениях равно При этом поскольку, матрица тоже распадается в сумму, и получается, что, то есть с ростомковариацияоценки максимального правдоподобия стремится к нулю. На интуитивном уровне можно сказать, что матрица информации Фишера показывает, сколько информации о весахсодержится в. Поговорим о проблемах. В реальной ситуации мы не знаеми тем более не можем посчитать матрицу Фишера, то есть мы с самого начала вынуждены лукавить. Ясно, что вместоможно взять просто, а вместо— матрицу, которую можно даже при желании определить как безо всякого математического ожидания. Итак, хотя мы можем теперь построить доверительный интервал для оцениваемых параметров, по ходу нами было сделано много упрощений: мы предположили, что асимптотическая оценка распределения уже достигнута, отперешли к, а для полноты чувств ещё и избавились от математического ожидания. В байесовском подходе мы такого себе не позволяем."
            }
        ]
    },
    {
        "id": "q_0483",
        "question": "Какие проблемы возникают при инициализации весов нейронной сети нулями или другими константами?",
        "answers": [
            "Константная инициализация приводит к симметрии между нейронами, что не позволяет алгоритму обучения обновлять их по-разному. Это может полностью заблокировать обучение, хотя в некоторых случаях численные ошибки позволяют сети сдвинуться с мёртвой точки."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/tonkosti-obucheniya",
                "text": "Как вы уже успели заметить, нейронные сети — достаточно сложные модели, чувствительные к изменениям архитектуры, гиперпараметров, распределения данных и другим вещам. Поэтому значительную роль играет начальная инициализация весов вашей сети. Стоит отметить, что здесь речь идет именно о начальной инициализации параметров сети, вопрос дообучения (и использования предобученных сетей в качестве backbone) в данном параграфе рассматриваться не будет. Нейронные сети включают в себя различные преобразования, и инициализация по-хорошему также должна зависеть от типа используемого преобразования. На практике вопрос часто остается без внимания, так как в большинстве современных фреймворков уже реализованы методы инициализации, зависящие от используемой функции активации и гиперпараметров слоя, и пользователь может не задумываться об этом. Но всё же важно понимать, какие соображения привели к появлению тех или иных стратегий инициализации. Давайте разберём несколько методов инициализации и обсудим их свойства. Казалось бы, инициализация параметров слоя нулями — это достаточно просто и лаконично. Но инициализация нулём (как и любой другой константой) ведёт к катастрофе! Вот пример того, что может получиться: Стоит, впрочем, отметить, что из-за численных ошибок значения параметров могут всё-таки сдвинуться с мёртвой точки, и тогда нейросеть что-нибудь выучит: Здесь также стоит привести цитату из замечательной Deep Learning book (страница 301): Скопировать код1Perhaps the only property known with complete certainty is that the initial parameters need to “break symmetry” between different units. If two hidden units with the same activation function are connected to the same inputs, then these units must have different initial parameters. If they have the same initial parameters, then a deterministic learning algorithm applied to a deterministic cost and model will constantly update both of these units in the same way. Если константная инициализация не подходит, можно инициализировать нейросеть случайными числами. Допустим, веса пришли из распределения с нулевым средним и дисперсией, например, из нормального распределения. Пусть теперь на вход линейному слою с весамиразмерностипришел вектораналогичной размерности. Замечание. Можем считать, что мы рассматриваем лишь одну компоненту следующего промежуточного представления. Все компонентыраспределены одинаковым образом и обладают нулевым средним. Тогда дисперсия ихпроизведенияимеет вид: Первое и второе слагаемые равны нулю так как математические ожидание и весов, и значенийравны нулю. Замечание. Стоит заметить, что это будет верно и для промежуточных слоев в случае использования симметричной относительно нуля функции активации, например,tanh. Поскольку все веса пришли из одного распределения, можно выразить дисперсию результата следующим образом: где— это дисперсия любой компоненты(как было оговорено ранее, они распределены одинаково), а— дисперсия компоненты. Следовательно, дисперсия результата линейно зависит от дисперсии входных данных с коэффициентом. Увеличение дисперсии промежуточных представлений с каждым новым преобразованием (слоем) может вызвать численные ошибки или насыщение функций активации (таких какtanhиsigmoid), что не лучшим образом скажется на обучении сети. Снижение дисперсии может привести к почти нулевым промежуточным представлениям (плюс «линейному» поведениюtanhиsigmoidв непосредственной близости от нуля), что тоже негативно повлияет на результаты обучения. Поэтому для начальной инициализации весов имеет смысл использовать распределение, дисперсия которого позволила бы сохранить дисперсию результата. Например,или же в общем случае Данный подход часто упоминается какcalibrated random numbers initialization. Если обратиться к предыдущему подходу, можно обнаружить, что все выкладки верны как для «прямого» прохода (forward propagation), так и для обратного (backward propagation). Дисперсия градиента при этом меняется враз, где— размерность следующего запромежуточного представления. И если мы хотим, чтобы сохранялись дисперсии и промежуточных представлений, и градиентов, у нас возникают сразу два ограничения: и Легко заметить, что оба этих ограничения могут быть выполнены только в случае, когда размерность пространства не меняется при отображении, что случается далеко не всегда. ВработеUnderstanding the difficulty of training deep feedforward neural networks за авторством Xavier Glorot и Yoshua Bengio в качестве компромисса предлагается использовать параметры из распределения с дисперсией Подробный вывод данного результата можно найти в оригинальной статье в формулах 2-12. Обратите внимание: эта инициализация хорошо подходит именно дляtanh, так как в выводе явно учитывается симметричность функции активации относительно нуля. В случае использования равномерного распределениядля инициализации весов с учетом описанных выше ограничений мы получимnormalized Xavier initialization: Замечание. Здесь используется тот факт, что дисперсия непрерывного равномерного распределения. Сравнение подобной инициализации для поведения промежуточных представлений (сверху) и градиентов (снизу) проиллюстрированы ниже (иллюстрации изоригинальной статьи): Вы могли обратить внимание, что Xavier initialization во многом опиралась на поведение функции активацииtanh. Данный тип инициализации и впрямь лучше подходит для нее, но само использование гиперболического тангенса приводит к некоторым сложностям (например, к затуханию градиентов). В 2015 году вработеDelving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification за авторством Kaiming He, Xiangyu Zhang, Shaoqing Ren и Jian Sun были рассмотрены особые свойства функции активацииReLU, в частности, существенно смещенная относительно нуля область значений. Пусть представление на входе было получено после применения данной функции активации к предыдущему представлению: где, в свою очередь, — это выход предыдущего линейного слоя с нулевым средним для каждой компоненты весов, то есть, в частности, В таком случае дисперсия выхода следующего линейного слоя примет вид: В данном случае первый член не может быть проигнорирован, так какReLUимеет ассиметричную область значений, а значит, распределениябудут смещёнными. С учетом того, что, выражение выше примет итоговый вид: С учётом поведенияReLUи того, что, можно сказать, что то есть Получается, что использованиеReLUприводит к необходимости инициализировать веса из распределения, чья дисперсия удовлетворяет следующему ограничению: Например, подходит нормальное распределение. Данный способ инициализации (и его сравнение с Xavier initialization) проиллюстрирован ниже: Рассмотренные способы инициализации используют достаточно много предположений, но все-таки они работают и позволяют нейронным сетям в некоторых случаях значительно быстрее сходиться. Понимание принципов работы даже таких небольших механизмов – ключ к глубокому освоению области глубокого обучения 😃"
            }
        ]
    },
    {
        "id": "q_0484",
        "question": "Какие методы оптимизации подходят для настройки нейросетей, если они рассматриваются как параметризованные дифференцируемые функции?",
        "answers": [
            "Нейросети можно настраивать с помощью градиентных методов, таких как стохастический градиентный спуск на батчах, а также с использованием различных модификаций и эвристик, ускоряющих сходимость."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/tonkosti-obucheniya",
                "text": "Так как мы договорились, что нейросети представляют собой параметризованные дифференцируемые функции и для каждого параметра мы можем посчитать градиент, то, так же как и линейные модели, их можно настраивать с помощью градиентных методов. Впараграфепро линейные модели мы под этим подразумевали обычно стохастический градиентный спуск на батчах, и это совершенно подходящий способ и для нейросетей тоже. Но существует множество модификаций и эвристик, позволяющих ускорить его сходимость, познакомиться с которыми вы можете в специальномпараграфе, посвящённом методам оптимизации."
            }
        ]
    },
    {
        "id": "q_0485",
        "question": "В чём заключается ключевое отличие задачи рекомендаций от задачи поиска?",
        "answers": [
            "В задаче поиска есть явный, сформулированный пользователем запрос, а в задаче рекомендаций явного запроса нет — система опирается на историю взаимодействий пользователя с объектами и пытается распознать его скрытые предпочтения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
                "text": "С рекомендательными системами можно столкнуться там, где есть большое множество товаров и пользователей, которые хотят найти нужные для себя товары. Рекомендательные системы помогают отобрать наиболее релевантные для пользователя объекты, тем самым экономя его время. Приведём несколько примеров: YouTube рекомендует пользователям видео; На сайтах интернет-магазинов можно встретить блоки с рекомендациями товаров; Музыкальные сервисы наподобие Spotify или Яндекс.Музыки рекомендуют музыкальные треки. Что такое «релевантные для пользователя товары» – это нетривиальный вопрос, который решается отдельно для каждой задачи исходя из бизнес-логики. Отметим, что, хотя задачи поиска и рекомендаций кажутся похожими и, как мы увидим, могут использовать схожие методы, у них есть одно важное отличие: в задаче поиска есть сформулированный запрос от пользователя, а в задаче рекомендаций явного запроса нет, есть только история взаимодействий пользователя с объектами и наша надежда на то, что мы верно распознали его скрытые желания. Это различие объясняет некоторые особенности дизайна рекомендательных систем, которые мы подробнее обсудим в конце этого параграфа, при разборе классического пайплайна рекомендательной системы."
            }
        ]
    },
    {
        "id": "q_0486",
        "question": "Какие примеры действий пользователя относятся к явному фидбеку в рекомендательных системах?",
        "answers": [
            "К явному фидбеку относятся действия, которые прямо выражают отношение пользователя к объекту: например, поставленная оценка фильму, лайк или дизлайк к видео, а также написанная рецензия на товар."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
                "text": "Введём ряд обозначений. Пусть у нас есть множество пользователейи множество объектов. Для каждого пользователяесть множество объектов, с которыми он взаимодействовал и которым поставил рейтинги. Рейтинг (его также называют фидбеком) – это некоторая характеристика взаимодействия пользователя с объектом; про него можно думать, как про некоторый таргет, который мы выбрали для оптимизации рекомендательной системы. Таким образом, задачу рекомендательных систем можно переформулировать в следующем виде: для каждого пользователянеобходимо оценить значениедляи выбрать несколько товаров с наибольшим. Иными словами, надо научиться среди непоказанных пользователю товаров находить те, которые заинтересовали бы его больше всего. Приведем несколько примеров фидбека: Для товара – факт добавления в корзину; Для музыки – дослушали ли трек до конца; Для статьи – лайк/дизлайк; Для видео – время его просмотра или факт просмотра, например, наполовину. Как правило, фидбек разделяют на два типа – explicit и implicit. Из-за различия для каждого фидбека есть разные техники обработки и использования, которые будут обсуждаться в параграфе проматричные факторизации. Explicit, или явный фидбек– это такие действия пользователя, по которым точно можно понять, понравился ли ему объект. Это может быть оценка, поставленная, фильму, лайк/дизлайк к видео или рецензия на купленный товар. Такого фидбека очень мало, но он наиболее точно характеризует отношение пользователя к товару. Implicit, или неявный фидбек– это любая другая информация о действиях пользователя на сайте. Он выступает в качестве прокси к явному фидбеку. Например, факт того, что пользователь досмотрел видео до конца, не говорит о том, понравилось ли оно ему, однако можно сделать предположение, что большинству досмотревших видео до конца оно понравилось. Приведем основные примеры неявного фидбека: клик на статью, время просмотра видео, покупка товара. Обычно такого сигнала в разы больше, чем явного, однако он более шумный, и не стоит доверять ему так же, как явному. Например, при оптимизации кликов на статью может получиться так, что рекомендательная система научится находить кликбейт, а не интересные пользователю статьи – это может плохо отразиться на сервисе в долгосрочной перспективе. Задачу построения рекомендательной системы можно формулировать в качестве задачи классификации (клик/не клик) или регрессию (сколько звёзд пользователь поставит объекту), но это не самые распространённые стратегии. Обратим внимание, что нам на самом деле не обязательно уметь точно оценивать рейтинги. Достаточно уметь для пользователя и набора объектов генерировать перестановку этих объектов в порядке убывания рейтинга. Модель, решающую данную задачу, называютранжирующей. Опишем классический пайплайн применения ранжирующей модели для одного пользователя. На вход подаются признаки пользователя и объекта, и для пары пользователь-объект на основе этих признаков выдается некоторое число, ответ модели. Далее мы сортируем объекты в порядке его убывания. Из полученной перестановки обычно берут несколько первых объектов для показа пользователю. Более подробно о том, как решается задача ранжирования, вы можете прочитать в соответствующем параграфе."
            }
        ]
    },
    {
        "id": "q_0487",
        "question": "Какой объект можно порекомендовать Кате на основе сходства её взаимодействий с Петей?",
        "answers": [
            "Кате можно порекомендовать объект 3, поскольку он понравился Пете, а взаимодействия Кати и Пети похожи (оба лайкали объекты 1 и 8)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
                "text": "Рассмотрим матрицу взамодействий пользователя, приведённую выше. Что можно порекомендовать Кате, исходя из исторических данных? Можно заметить, что взаимодействия Кати похожи на взамодействия Пети (так как они оба лайкали объекты 1 и 8). Иными словами, их интересы в чём-то похожи, поэтому Кате можно порекомендовать, например, объект 3 (так как он понравился Пете). Можно проделать аналогичное упражнение с Петей и сделать вывод, что ему не стоит рекомендовать объект 10. Можно решать и транспонированную задачу: для лайкнутого пользователем объекта искать похожие, то есть те, которые пользователи достаточно часто лайкали вместе с ним. Например, объекты 1 и 8 похожи друг на друга, так как их лайкали одни и те же пользователи, и точно так же похожи 1 и 3. Проиллюстрированный выше подход называютколлаборативной фильтрацией. Он объединяет семейство методов рекомендаций, использующих сходство по истории взаимодействия между пользователем и товаром. Рассмотрим конкретные простые методы коллаборативной фильтрации. Введём меру похожести двух пользователей, которая тем больше, чем выше сходство междуи. Для пользователярассмотрим множество похожих на него пользователейгде– настраиваемый гиперпараметр, в чём-то аналогичный порогу бинарного классификатора. Допустим, мы хотим теперь оценить рейтинг, который пользовательпоставил бы объекту. Сделаем это, опираясь на рейтинги, которые ставили похожие напользователи. Например, можно взять взвешенное среднее: Модуль добавляется для того, чтобы корректно обработать непохожих пользователей, то есть пары с отрицательной похожестью, которая может возникнуть, если при построениивзять достаточно маленькое. Можно пойти дальше и усовершенствовать метод оценивания. У пользователей могут быть разные диапазоны оценок: кто-то ставит почти всегда в диапазоне 1-3, а кто-то предпочитает ставить 4-5. Иными словами, для разных пользователей оценка «нормально» (и соответственно, оценки «хорошо» и «плохо») могут соответствовать разным значениям рейтинга. Для устранения этой проблемы, можно брать не сырой рейтинг пользователя, а его отклонение от среднего всех оценок пользователя:. Таким образом, мы учитываем только разброс вокруг среднего и итоговая оценка будет выглядеть так: Можно пойти еще дальше и учесть дисперсию оценок пользователей: где– множество объектов, с которыми взаимодействовал пользователь. В заключение приведём несколько вариантов оценки схожести пользователей: Мера Жаккара:где– множество понравившихсяайтемов; Скалярное произведение общих рейтингов:; Корреляция Пирсона: Дисконтированная корреляция Пирсона. Так как айтемов в пересечениив действительности не всегда может быть достаточно много, можно дисконтировать похожести, посчитанные по небольшому множеству айтемов, домножая корреляцию на. Теперь попробуем решать транспонированную задачу. Введем меру похожести объектов. Если нам нужно оценить рейтинг, который пользовательпоставил бы ещё не виденному им объекту, то мы можем рассмотреть множествоблизких кобъектов и оценитьаналогично user2user подходу: Меру схожести объектов можно задать как adjusted cosine: где– множество пользователей, оценивших товар. Обратите внимание, что– это средняя оценка пользователя, а не объекта, то есть это не корреляция Пирсона – на практике данный подход обычно работает лучше. Выделим ключевые особенности методов, основанных на коллаборативной фильтрации, о которых следует помнить при разработке рекомендательных систем: Они не опираются ни на какую дополнительную информацию кроме матрицы оценок, предполагая, что этого должно быть достаточно для улавливания качественного сигнала о схожести пользователей и товаров; Предложенные методы не применимы для новых объектов и пользователей – для них просто нет истории или она недостаточно информативна для того, чтобы методы могли давать более-менее точные оценки; Так как методы коллаборативной фильтрации основаны только на истории прошлых взаимодействий, рекомендательная система, построенная исключительно на их основе будет постепенно вгонять пользователя в информационный пузырь: эти методы не предполагают открытия новых интересов у пользователя, они способны только эксплуатировать уже имеющиеся."
            }
        ]
    },
    {
        "id": "q_0488",
        "question": "Какой подход к рекомендательным системам использует только статичную контентную информацию о товарах и не учитывает взаимодействия пользователей?",
        "answers": [
            "Это content-based подход, который строит рекомендации на основе измерения похожести объектов по их содержанию (текст, время публикации, картинки), преобразуя их в числовые представления (эмбеддинги). Такие модели не используют коллаборативную информацию о других пользователях."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
                "text": "Также помимо коллаборативной фильтрации существует content-based подход для построения рекомендаций: измерение похожести между объектами на основе их содержания. Например, две статьи про то, как заменить колесо на велосипеде можно считать похожими с точки зрения содержания. Иными словами, входом для content-based модели являются разные контентные признаки и характеристики товара (например, текст статьи, время публикации, картинки), а выходом является некоторое числовое представление объекта (эмбеддинг). Отметим, что никакую коллаборативную информацию такие модели не используют, они ничего не знают про других пользователей и про их взаимодействие с объектами. Например, Bert является чисто контентной моделью – он переводит текст в эмбеддинг. Пусть у нас есть некоторый контентные эмбеддингидля каждого товара – например, мы применили обученный Bert для получения векторных представлений статей. Тогда мы можем посчитать скалярное произведение (или косинусное расстояние) до оценённых пользователем объектов и оценить рейтинги, как: где– скалярное произведение или косинусное расстояние между двумя векторами,– множество оценённых пользователем объектов, а– гиперпараметр. Таким образом, высокие рейтинги получат объекты, похожие на те, что понравились пользователю – мы получили простую ранжирующую модель. Плюс контентного подхода в том, что, в отличие от чисто коллаборативного подхода, он одинаково хорошо работает на новых и старых айтемах, так как контентные модели основаны только на статичной контентной информации, которая всегда доступна. Из минусов можно отметить, что похожесть по контенту может ещё больше загонять пользователя в информационный пузырь: например, контентная модель вряд ли сможет к кофемашине порекомендовать кофейные зерна, в то время как коллаборативный подход получит сигнал о том, что товары являются дополняющими напрямую из действий других пользователей. Отметим, что существуют гибридные модели, совмещающие в себе коллаборативный и контентный сигналы. Например, такой моделью является DSSM. Подробнее о контентных моделях вы узнаете в соответствующем параграфе."
            }
        ]
    },
    {
        "id": "q_0489",
        "question": "Какие два основных требования предъявляются к этапу отбора кандидатов в рекомендательной системе?",
        "answers": [
            "Отбор кандидатов должен быть быстрым и обладать хорошей полнотой поиска, то есть в полученном подмножестве должно в избытке находиться интересное пользователю содержимое."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
                "text": "Мы разобрали несколько классических подходов к построению рекомендаций, теперь нужно обсудить, как это скомпоновать в единую рекомендательную систему. Для начала сформулируем ряд свойств, которыми должна обладать хорошая рекомендательная система: При ранжировании товаров в порядке убываниянам хотелось бы учитывать как можно больше сигналов/фичей (как пользователя, так и объекта); Рекомендательная система должна работать достаточно быстро; Должен быть несложный механизм, позволяющий понятно учитывать «бизнес-логику» (например, если при прочих равных мы больше хотим показывать свежие статьи). Для соблюдения первого пункта, очевидно, нужна ранжирующая модель. В качестве самой модели часто применяют бустинг – на табличных данных он, как правило, cправляется лучше, плюс он быстрее нейронных сетей с точки зрения времени применения. Здесь не будет лишним упомянуть про feedback loop. Для обучения ранжирующей модели мы обычно берем прошлую историю взаимодействия пользователей с показанными ему объектами, считаеми составляем на основе этих оценок обучающий датасет. Таким образом, обучая новую модель, мы с некоторыми оговорками будем учиться предсказывать старую модель. Поэтому есть риск, что она застрянет в локальном оптимуме, из которого сложно выбраться. В качестве решения этой проблемы можно, например, подмешивать в выдачу случайные объекты и давать им больший вес в функции потерь. Таким образом, у нас появляется некоторое подмножество объектов, которые не были смоделированы нашей моделью. В качестве дополнительного плюса такого подхода мы в какой-то степени будем выбивать пользователя из его информационного пузыря, показывая объекты из категорий, которыми он еще не интересовался. В реальной рекомендательной системе обычно от нескольких миллионов товаров и хотя бы несколько сотен тысяч пользователей в день (а чаще несколько миллионов). Обученная CatBoost модель на 5000 объектов отрабатывает где-то за 100-125ms на CPU. Фичи пользователей и объектов постоянно меняются, поэтому на каждый запрос пользователя мы должны заново скорить все объекты. Но тогда только на скоринг мы будем тратить порядка 25 секунд, а если это не CatBoost, а, например, нейронная сеть, то, скорее всего, ещё больше. Это очень существенные и необоснованные затраты. В действительности, пользователю наверняка интересна лишь небольшая часть имеющихся у нас товаров. Можно попытаться сузить множество до потенциально интересных пользователю объектов и уже для них применить «тяжёлую» ранжирующую модель, которая определит финальную выдачу. Этот подход называетсяотбором кандидатов. К отбору кандидатов предъявляют два требования: он должен быть быстрым; он должен иметь хорошую полноту поиска подходящих пользователю объектов, то есть в полученной после отбора кандидатов подмножестве должны в избытке находиться интересные пользователю статьи/фильмы/продукты; Приведем несколько подходов к отбору кандидатов: Эвристики: самые популярные товары, популярные запоследних дней, популярные среди жителей этого города, недавно опубликованные; Коллаборативные: item2item или user2user рекомендации. Мы можем в оффлайне предподсчитывать все необходимые статистики и строить таблички из пользователя в множество подходящих айтемов или из айтема в айтемы. Также есть более сложные подходы на основе матричных разложений, о которых будет рассказано в соответствующем параграфе; Контентные методы: берём content-based эмбеддинги объектов и строим быстрый индекс для поиска ближайших объектов (например, HNSW). Подробнее о быстром поиске ближайших соседей вы можете почитать в параграфе про метрические методы. Далее, можем взять понравившиеся пользователю товары и найти похожие на них. Обычно отбор кандидатов состоит из набора разных источников кандидатов, где каждый источник по смыслу пытается покрыть какой-то пользовательский аспект. Двухступенчатая рекомендательная система уже обладает двумя хорошими свойствами, осталось предложить механизм, который позволит учитывать бизнес-логику. Под бизнес-логикой здесь понимается некоторое качество рекомендательной системы, которое хотелось бы иметь, но которое достаточно нетривиально, чтобы мы не стали зашивать его в саму ранжирующую модель. Приведем примеры возможных пожеланий: Реже показывать старые видео в ленте; Реже показывать слишком длинные видео или видео, снятые в плохом качестве; Обеспечить разнообразную для пользователя выдачу. Например, если пользователь интересуется кошками и машинами, А ранжирующая модель всем видео про кошек дала большую оценку, чем любому видео про машины, то получится, что лента пользователя будет состоять только из кошек, хотя ему также интересны и машины. Все эти свойства подразумевают под собой небольшое переупорядочивание объектов после применения ранжирующей формулы. Этот механизм называетсяпереранжированием(реранкингом)."
            }
        ]
    },
    {
        "id": "q_0490",
        "question": "Какой класс генеративных моделей обучается одновременно с другой сетью, старающейся отличить сгенерированные объекты от настоящих?",
        "answers": [
            "Это генеративно-состязательные сети (Generative Adversarial Networks, GAN). Они представляют собой большой класс генеративных моделей, где обучение происходит одновременно с сетью-дискриминатором."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
                "text": "Генеративно-состязательные сети (Generative Adversarial Networks, GAN) – это большой класс генеративных моделей, общая черта которых заключается в том, что они обучаются одновременно с другой сетью, которая старается отличить сгенерированные объекты от настоящих. В этом параграфе мы рассмотрим основы основ GAN-ов, интуитивное объясним принципы их работы, а также детально погрузимся в многочисленные приёмы и модификации оригинального подхода, которые применяются в наиболее успешных моделях. Мы также приведём примеры нескольких типов практических задач, в которых применяются генеративно-состязательные сети. Генеративно-состязательные сети — это неявная генеративная модель. То есть она не восстанавливает плотность данных в явном виде, но умеет сэмплировать из распределения данных. Самый простой и эффективный дизайн генеративных моделей, которые умеют только сэмплировать, но не умеют оценивать плотность, – это отображение одних случайных величин в другие. Подобного вида модель после обучения работает следующим образом: пусть– случайная величина, обозначающая сэмпл из распределения нужных нам данных (например, картинок с нарисованными цифрами), а– сэмпл из какого-то распределения, который нам легко получить (например, каждая его компонента берётся из стандартного нормального). Тогда, если у нас есть обученная функция, которая переводит сэмплы изв сэмплы из, то процесс генерации происходит в два этапа: сначала мы случайным образом получаем вектор, а затем отображаем его в: Ключевым вопросом в таких моделях является соотношение размерностейи. Есть генеративные модели, где. Примером таких подходов являются, например, нормализующие потоки. В случае генеративных состязательных сетей (как и другого класса популярных генеративных моделей, вариационных автоэнкодеров),. Поэтому работу этих моделей можно рассматривать как поиск многообразия размерностисреди всех случайных примеров из домена, на котором определяется. Например, в случае генерации цифр это соответствует поиску в домене, где– это ширина картинки, а– её высота, подмножества, в котором каждый элемент изображает какую-либо цифру. Таким образом, задача обучения генеративных состязательных сетей может рассматриваться как задача компрессии данных в низкоразмерное представление."
            }
        ]
    },
    {
        "id": "q_0491",
        "question": "Какую аналогию используют для объяснения принципа обучения генеративно-состязательных сетей?",
        "answers": [
            "Используется аналогия с фальшивомонетчиком и полицейским, где фальшивомонетчик создаёт поддельные купюры, а полицейский учится их отличать от настоящих."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
                "text": "Классическая аналогия того, как учатся GANы — это фальшивомонетчик и полицейский. Задача фальшивомонетчика — научиться создавать купюры, которые полицейский не сможет отличить от реальных. Задача полицейского — научиться отличать купюры фальшивомонетчика от настоящих. Чтобы понять, как обучаются GANы, надо представить себе следующий мысленный эксперимент. Допустим, фальшивомонетчик и полицейский — друзья, которые решили поучиться друг у друга. Фальшивомонетчик создаёт несколько фальшивых купюр и показывает полицейскому. Полицейский говорит фальшивомонетчику, какие из его купюр, по его мнению, поддельные, а какие — настоящие. Фальшивомонетчик запоминает отзыв полицейского и в следующий раз улучшит свои купюры на основе отзыва от полицейского. Сам полицейский при этом тоже учится: он запоминает, что купюры, которые он видел — поддельные. В нашем мысленном эксперименте представим, что фальшивомонетчик взаимодействует с полицейским много раз. Что получается в результате? С каждым разом купюры фальшивомонетчика всё труднее отличить от настоящих. И с каждым разом умение выявлять поддельные купюры у полицейского выше. Важный вопрос для понимания работы GANов: в какой момент мы можем утверждать, что фальшивомонетчик хорошо подделывает купюры? Ответ:Когда фальшивомонетчик сможет обманывать сильного полицейского. В начале нашего эксперимента полицейский плохо отличает подделку от оригинала. Поэтому обмануть его можно купюрами плохого качества. Нам же интересно получить фальшивомонетчика, который будет выдавать купюры, неотличимые от оригинала даже профессионалом. Рассмотрим задачу обучения более формально. Пусть у нас есть генератор(фальшивомонетчик) с параметрами, и дискриминатор(полицейский) с параметрами. Генератор отображает векторыв, распределение которых приближает реальное распределение данных. Дискриминатор каждому реальному сэмплуи фейковомуставит в соответствие вероятность, которая оценивает степень принадлежностик реальным данным, т.е. он решает задачу бинарной классификации. Самый простой способ это сделать – при помощи минимизации бинарной кросс-энтропии: Учитывая обозначение, и то, что мы пытаемся максимизировать вероятность принадлежности к реальным данным, как её оценивает дискриминатор, задачу, которую решает генератор, можно расписать следующим образом (используя свойство выпуклости логарифма): Это равенство позволяет записать задачи, которые решают генератор и дискриминатор, вместе. (Мы также избавимся от лишних минусов, сделав так, чтобы дискриминатор решал задачу максимизации.) Получается, что на самом деле генератор и дискриминатор пытаются оптимизировать одну функцию: генератор её минимизирует, а дискриминатор максимизирует. Обозначим эту функцию (минус бинарную кросс-энтропию) как. Тогда эту задачу оптимизации можно записать в сокращённом виде: По параметрам дискриминатора минимум бинарной кросс-энтропии (или минимумпо) достигается на следующей функции – оптимальном дискриминаторе для фиксированного генератора: Её оптимальность нетрудно проверить, используя выпуклость логарифма. Учитывая это, и формулу для, интуицию работы метода обучения GANов со стороны генератора можно сформулировать следующим образом: Мы замеряем, насколько реалистичными являются сгенерированные сэмплы, используя для этого оптимальный дискриминатор. Мы хотим увеличить отклик дискриминатора на каждом сэмпле, т.е. пытаемся модифицировать каждый предсказанный элементтак, чтобы на нём стало выше значение. Ещё более простую интуицию для этой задачу можно сформулировать следующим образом. Как нужно модифицировать плотность, чтобы она стала ближе к, если к плотности распределения мы имеем доступ только через сэмплы из него? Визуализацию желаемых градиентов по случайным сэмплам для задачи сопоставления двух гауссиан можно видеть на графике ниже, где. Направленные вниз стрелки показывают, насколько нужно уменьшить координаты точек из распределения, чтобы получилось нечто максимально похожее на. То есть на самом деле точки будут сдвигаться на то же самое расстояние влево. Формализуем эту интуицию, и заодно поймём, почему вообще такой метод должен работать. Подставив выражение для оптимального дискриминатора в, мы можем избавиться от внутренней максимизации в исходной задаче и оставить только внешнюю минимизацию по параметрам генератора. Тем самым, мы получим в явном виде функцию потерь, которую минимизирует генератор (обозначим её за). Для неё мы распишем математическое ожидание через интеграл и упростим дроби: Упростим выражение дляещё раз, прибавив и отняв константу, а также учитывая, чтои: Здесьозначает, как обычно, KL-дивергенцию которая показывает, насколько два распределения отличаются друг от друга. Черезобозначает ещё один вид дивергенции (её называют дивергенцией Йенсена-Шеннона). Получается, что при оптимальном дискриминаторе генератор, решая внешнюю задачу оптимизации, уменьшает расстояние между распределениями реальных и фейковых данных, действительно приближая их друг к другу! Исходя из этого, и в предположении достаточной capacity генератора и дискриминатора (т.е. предполагая, что их параметризация позволяет достичь оптимума), мы можем сформулировать первый, наивный алгоритм обучения генеративно-состязательных сетей. Решить внутреннюю задачу максимизации по, повторяя шаги ниже до сходимости по параметрам дискриминаторак оптимальному значению:— Составить мини-батч сэмплов шумаиз.— Составить мини-батч сэмплов данныхиз.— Обновить дикриминатор, сделав шаг вверх по его градиенту: Сделать шаг SGD для внешней задачи минимизации по:— Составить мини-батч сэмплов шумаиз.— Обновить генератор, сделав шаг вниз по его градиенту:где черезмы для краткости обозначили. Какие у этого наивного подхода могут быть недостатки? Во-первых, он очень медленный, потому что необходимо обучать дискриминатор до сходимости, чтобы сделать всего один шаг по градиенту генератора. Но вторая проблема намного серьёзнее: функция потерь генератора может насыщаться и выдавать близкие к нулю градиенты. Проиллюстрируем это на примере обучения простой модели, которая будет сэмплировать из одномерной гауссианы с заданными параметрами. Распределениев этом случае известно, а распределениемы можем получить с помощью методов оценки плотности по сэмплам. Визуализируем эти плотности, а также градиент по сэмплам из генератора (a). Видно, что в случае, когда пики распределений плохо пересекаются друг с другом, градиент будет равен нулю на большинстве сэмплов, которые выдаёт генератор, т.е. они никак не будут использоваться для обучения. Чтобы понять причину происходящего, давайте посмотрим на градиент функции потерь генератора. На точках, далёких от основной «массы», дискриминатор выдаёт что-то близкое к нулю, то есть знаменатель градиента практически не будет ни на что влиять, а в числителе тоже будет практически ноль: ведь если мы немного поменяем параметры генератора, то «плохие» точки по-прежнему будут далеки от, так что изменение лосса будет пренебрежимо малым, и градиент тоже. Это приводит к тому, что обучение происходит недостаточно эффективно: мы тратим время на вычисление сэмплов, которые не делают никакой вклад в обновление параметров генератора. Но более существенная проблема возникает в вырожденном случае: если изначально два распределения практически не пересекаются своими плотностями (b): в этом случае процесс обучения практически не идёт. Часто ли встречается такая вырожденная ситуация на практике? Довольно часто! Достаточно представить себе ситуацию, когда мы хотим генерировать реалистичные изображения лиц, а генератор в начале обучения вместо этого выдаёт случайный шум. Из-за наличия такой проблемы описанная выше функция потерь генератора называется «сатурирующей». В оригинальном подходе по обучению генеративно-состязательных сетей было предложено два решения этой проблемы. Во-первых, мы можем обучать дискриминатор на каждой итерации не до сходимости, а с небольшим фиксированным числом шагов(на практике чаще всего используется). Это позволяет существенно улучшить исходную ситуацию с переобучением дискриминатора. Также мы могли бы улучшить функцию потерь для генератора, сделав так, чтобы она сглаживала выходы дискриминатора около нуля. В качестве такой функции изначально был предложен логарифм. Нетрудно видеть, что оптимум улучшенной функции потерь («несатурирующий лосс») совпадает с исходной, что позволяет сохранить все описанные выше теоретические гарантии: Точка минимума у новой функции потерь та же, что у исходной, а градиенты оказываются ненулевыми на всех сгенерированных сэмплах. Помимо этого, на практике вместо обычного метода стохастического градиентного спуска используются его модификации, которые учитывают и первые, и вторые моменты градиентов например, Adam. Вообще, GAN-ы – довольно капризные модели, и настоятельно рекомендуется использовать готовые реализации с GitHub, оставляя большую часть гиперпараметров без изменений. Наиболее критичными среди них являются learning rate и расписание (то есть количество обновлений дискриминатора на одно обновление генератора)."
            }
        ]
    },
    {
        "id": "q_0492",
        "question": "Какие типовые ошибки может совершать GAN при генерации изображений?",
        "answers": [
            "Основные ошибки включают плохое качество или наличие артефактов из-за ограничений capacity генератора, а также mode collapse — когда генератор выдаёт реалистичные картинки, но не покрывает всё разнообразие распределения (например, генерирует только часто встречающиеся виды животных или вариации одной картинки)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
                "text": "После успешного обучения генератора хотелось бы также понять, насколько хорошо он работает. Для этого рассмотрим на примере задачи генерации изображений типовые ошибки, которые может совершать GAN. Наиболее частая проблема – плохое качество или наличие артефактов – вызвана ограничениями, связанными с capacity генератора и несовершенством самих методов обучения. Здесь всё просто: наша генеративная модель плохо работает, и мы это видим на сгенерированных сэмплах. Более скрытым видом ошибок является так называемыйmode collapse: обученный генератор выдаёт реалистично выглядящие картинки, но они не покрывают всё разнообразие распределения. Например, если наша модель учится генерировать изображения с животными, то она может проигнорировать более редкие виды, а научиться генерировать только наиболее часто встречающиеся. Более экстремальная форма подобного поведения – это когда модель вообще выдаёт вариацию одной картинки. Иногда в литературе общее качество результатов работы нейросети, по аналогии с задачей классификации, измеряется точностью метода (precision), а отсутствие mode collapse измеряется полнотой (recall). Самый простой и действенный способ измерить как precision, так и recall – сгенерировать данные и посмотреть на них, дав экспертную оценку уровня их реализма. Не стоит им пренебрегать! Формализовать этот подход в метрику можно в виде эксперимента, который в литературе называется user study. Например, мы можем сделать опрос экспертов, которым будем показывать два примера, настоящий и сгенерированный, и попросить их угадать, где фейк. Тогда процент неправильных ответов будет являться метрикой качества для нашего метода. Такой опрос в основном показывает степень реализма полученных результатов: есть ли в них какие-то заметные артефакты, соответствуют ли они реальным примерам по своей структуре, и так далее. Отчасти он также замеряет разнообразие примеров: то, насколько они хорошо покрывают носитель распределения. Если обученная модель генерирует очень похожие друг на друга примеры (то есть имеет место существенный mode collapse), то эксперт через несколько примеров научится определять ненастоящие. С другой стороны, если сэмплы в целом разнообразные, но всё равно не полностью покрывают основу целевого распределения, то user study не позволит обнаружить эту проблему. Есть метрики, с помощью которых можно автоматически проводить тестирование, похожее на user study. Для изображений наиболее используемой является Frechet Inception Distance (FID). Чтобы её посчитать, нам в идеале понадобится нейросеть, предобученная на датасете, который мы генерируем, но на практике во всех случаях используется модель Inception v3, предобученная на датасете ImageNet (отсюда слово Inception в названии метрики). Для того, чтобы понять идею этой метрики, рассмотрим следующий пример: если выходом нейросети является класс (число), то его вероятность можно смоделировать мультиномиальным распределением. Гипотетически, чтобы сравнить два распределения картиноки, нам достаточно измерить расстояние между двумя мультиномиальными распределениями, построенными на выходах предобученного классификатора после прогона датасетов реальных и сгенерированных данных. Если в распределениипримеров из каких-то классов будет меньше или больше, чем в, то такая метрика будет отличная от нуля. Понятно, что это слишком грубое приближение расстояния между двумя распределениями, т.к. оно практически никак не учитывает реализм получаемых картинок. Поэтому вместо выходов нейросети в FID было предложено использовать признаки с её глубоких слоёв. Они кодируют высокоуровневую семантику изображений, потому что по этим признакам модель предсказывает вероятность принадлежности картинки к тому или иному классу. При этом в них остаётся довольно много информации об исходном изображении и свойств локальных признаков (текстур), которые могут помочь распознать артефакты. Метрика FID работает таким образом, что сравнивает два распределения высокоуровневых признаков для реальных и сгенерированных картинок, используя в качестве их приближения многомерные гауссианы (каждая размерность соответствует одному каналу). Для измерения расстояния между этими двумя распределениями используется метрика Вассерштейна: гдеи– это среднее и матрица ковариаций глубоких признаков, которые считаются по выборке изреальных картинок. При этом как средние, так и матрицы ковариаций считаются по объединению всех признаков со всех картинок без учёта пространственной размерности, т.е. по второй размерности матрицы. То же самое делается для сгенерированных картинок, для них средние и ковариации обозначены каки. Минимум этой метрики равен нулю, и достигается в случае, когда статистики, посчитанные по двум распределениям, совпадают. На практике эта метрика используется как для измерения реализма изображений, так и для детектирования mode collapse. Ещё один способ измерения качества, который мы рассмотрим, напрямую связан с тем, что генеративно-состязательные модели эффективно занимаются кодированием потенциально высокоразмерных данных в низкоразмерное представление. Но как для нейросети с большим числом параметров проверить, занимается ли она реальным кодированием или простым запоминанием выборки? Рассмотрим следующий пример. Пусть наша генеративная модель к случайным векторамприменяет их функцию распределения и отображает векторы в равномерно распределённые на отрезкечисла. Упорядочим наш датасет. В качестве случайного сэмпла пусть наша модель выдаёт ту картинку, чей индекс, поделённый на размер датасета, ближе всего к. Другими словами, наша генеративная модель будет выдавать случайные картинки из датасета вместо генерации новых картинок. Методы оценки качества, которые мы описали выше, пропустят эту проблему: ведь «сгенерированные» картинки будут в точности совпадать с настоящими. Поэтому для полной проверки качества работы генеративной модели важно понимать, действительно ли она производит сжатие выборки в низкоразмерное представление или просто запоминает обучающие примеры. Одним из тестов на подобное поведение является интерполяция между сгенерированными примерами. Возьмём два случайных вектораииз. Рассмотрим все векторы, которые лежат между ними. К каждому такому векторуприменим наш генератор и получимдля промежуточных векторов идляи. Для правильно обученного GANа мы должны увидеть следующую картинку: при изменении коэффициентаизображениедолжно плавно меняться и перетекать изв. При этом каждая промежуточная картинка должна быть так же реалистичным сэмплом. Качество такой интерполяции сложно измерить численно, но если мы видим, что промежуточные результаты меняются случайно без какой-либо связи с семантикой интерполируемых примеров, то это говорит о плохом качестве генератора. Стоит упомянуть, что для сэмплов из нормального распределения, которое обычно имеют векторы, намного лучше работаетинтерполяция по сфере (Slerp), потому что в многомерном пространстве векторыпрактически всегда будут лежать в объёме вокруг сферы диаметра, где– размерность вектора. Интерполяция в скрытом пространстве с недавних пор стала использоваться для генерации анимаций и видео. Ведь анимация — это последовательность кадров, плавно переходящих друг в друга. И если у нас есть обученный GAN для генерации картинок, то нам нужно лишь найти путь в скрытом пространстве таким образом, чтобы набор сгенерированных картинок складывался в анимацию. Более того, в скрытом пространстве можно находить различные интерпретируемые пути. Например, путь, при движении по которому размывается задний фон или меняется причёска. Почитать подробнее про это можнотут. Ещё одним способом проверить, не запомнил ли генератор датасет, является поиск ближайших соседей по датасету. Для этого следует сгенерировать несколько изображений. Для каждого изображения нужно найти несколько ближайших соседей из датасета. В качестве признаков для картинок можно взять признаки с последних слоёв сети Inception. На соседей стоит посмотреть глазами. Если мы увидим, что ближайшие соседи из датасета визуально совпадают со сгенерированными сэмплами, то это значит, что генератор запомнил сэмплы из датасета."
            }
        ]
    },
    {
        "id": "q_0493",
        "question": "Какой метод предлагается для условной генерации изображений, когда условием является метка класса?",
        "answers": [
            "Основной метод — конкатенация условия с вектором шума на вход генератора. Если условие — метка класса, её следует закодировать с помощью one-hot encoding. В статье Conditional GAN 2014 года также рекомендовалось подавать это условие и в дискриминатор."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
                "text": "Чтобы лучше понимать современные модели, давайте сначала рассмотрим более базовые модели. Хотя они редко используются напрямую, многие идеи из них легли в основу современных моделей. Наиболее простая версия генеративной модели для изображений — это DCGAN (Deep Convolutional GAN, 2015 год). Её до сих пор можно иногда встретить как в литературе, так и на практике. В основе DCGAN лежит простая идея: нейросети, основанные на свёртках, отлично подходят для распознавания изображений, а значит вполне могут подойти и для их генерации. Единственное отличие, которое требуется – это постепенно увеличивать внутри нейросети пространственный размер признаков, а не уменьшать. Для этого в современных нейросетях делается операцияnearest upsampling, очень похожая на max pooling. В nearest upsampling пространственное разрешение карты признаков увеличивается за счёт того, что каждый вектор повторяетсяраз по горизонтали и по вертикали. К примеру, после увеличения таким образом карты признаков, состоящей из одной единицы, мы получим квадрат размераиз единиц. На практике увеличение размерности происходит по аналогии с размерами пулинга в свёрточных дискриминативных сетях и почти всегда равно. Таким образом, генератор в случае DCGAN является последовательностью свёрток, слоёв батч нормализации, нелинейностей и слоёв upsampling, а дискриминатор – обычной классификационной нейросетью. При этом первым слоем в генераторе является линейный слой, который отображает вектор шумав карту признаков с начальным разрешением (как правило, размера). Хотя результаты работы DCGAN довольно смазанные, эта модель показала большие перспективы генеративных нейросетей для изображений. Допустим, что в нашем датасете есть изображения, относящиеся к разным классам, и мы хотели бы уметь генерировать изображение заданного класса. В этом случае речь идёт обусловной генерации. В качестве условия может выступать не только метка класса, но и объект любой природы. Например, когда вы можете захотеть сгенерировать изображение по текстовому описанию. Далее будем обозначать условие как. Наша задача — построить генератор, который бы моделировал. Самый основной метод условной генерации — конкатенация условия с вектором шума, который генератор принимает на вход. Встатье Conditional GAN2014 года, где предложили этот метод, рекомендовалось подавать условие не только в генератор, но и в дискриминатор. Если мы генерируем векторные данные, то вектор на вход дискриминатора подаётся конкатенированным с. При этом если если— это метка класса, то стоит её закодировать с помощью one-hot encoding. Если же мы работаем с изображениями, то нам из вектора условия следует сделать изображение. Например, если картинки из датасета имеют размер, то следует размножить вектор, создав из него тензор размера, где— размерность вектора. Далее полученное «изображение» конкатенируется с входным изображением."
            }
        ]
    },
    {
        "id": "q_0494",
        "question": "Какой метод используется в StyleGAN для постепенного увеличения разрешения генерируемых изображений?",
        "answers": [
            "В StyleGAN используется техника progressive growing, при которой обучение начинается с низкого разрешения (например, 4x4), а затем к генератору и дискриминатору поэтапно добавляются блоки, увеличивающие разрешение до целевого (например, 1024x1024)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
                "text": "Теперь на примере наиболее успешных моделей мы расскажем об улучшениях, которые во многом отходят от оригинального подхода к обучению GAN-ов и при этом значительно улучшают практические результаты, а значит расширяют практическую применимость. В этом разделе мы рассмотрим state-of-the-art систему генерации изображений StyleGAN, методы еёобращения(т.е., поиска векторов шума, соответствующих произвольной картинке), а также методы манипуляции семантикой изображений. После этого мы рассмотрим несколько примеров условных генеративных моделей, которые вместо шума принимают на вход изображения. Такие модели используются как для задачи повышения разрешения (super resolution), так и стилизации (например, превращение пейзажей в картины Моне). Мы сфокусируемся на изображениях, так как в этой области сконцентрирован как основной прогресс, так и наиболее впечатляющие применения генеративных моделей. Самой известной генеративно-состязательной моделью, работающей с изображениями, по праву считается StyleGAN, который до сих пор активно развивается и имеет большое количество расширений (например, существуют разнообразные методы его обращения). Архитектура StyleGAN переняла progressive growing из моделиProgressive Growing of GANs. Суть данной техники заключается в том, чтобы не сразу генерировать изображение высокого разрешения, а постепенно. Давайте рассмотрим это подробнее. Мы хотим получить генератор, который генерирует изображения размера 1024x1024. Обучить такой генератор очень сложно. Поэтому мы начинаем с разрешения 4x4. У генератора мы оставляем только первый блок слоёв, который позволяет из шума получить изображение размера 4x4. У дискриминатора мы оставим, наоборот, только последний, который принимает на вход изображение размером 4x4. Такой GAN мы обучаем на изображениях из датасета (предварительно уменьшив их в размере). Спустя сколько-то итераций мы понимаем, что сеть уже умеет генерировать маленькие изображения. В этот момент мы добавляем к генератору один блок, чтобы на выходе у неё получалось изображение размера 8x8. Так же мы добавляем один блок в начало дискриминатора, чтобы он на вход принимал изображения размера 8x8. Теперь генератор и дискриминатор состоят из двух блоков, которые мы и обучаем. Такой процесс мы повторяем несколько раз, пока в итоге не дойдём до нужного нам разрешения 1024x1024. Эта схема в итоге показала себя действенным способом генерации реалистичных изображений высокого разрешения. Ключевой частью StyleGAN является используемый в нём способ подачи шумав нейросеть, и именно из-за него метод и получил своё название. Для того чтобы понять, что конкретно в нём особенного, давайте подробнее посмотрим на архитектуру сети (рисунок из предыдущего раздела, модель StyleGAN справа). Во-первых, вместо того, чтобы подавать вектор шуматолько в самом начале генератора, нейросеть обуславливают на него много раз на разных разрешениях признаков. Исторически, впервые похожим методом решалась задача переноса стиля одной картинки на другую, отсюда и название: a style-based generator. В качестве метода обуславливания используются так называемые адаптивные слои. Это модификация обычных слоёв нейросетей, в которых часть параметров предсказывается другой нейросетью. Вообще говоря, адаптивным можно сделать любой вид нормализации, включая батч нормализацию, но наиболее известным примером такого слоя являетсяадаптивная инстанс нормализация(adaptive instance normalization), и именно она использовалась в первой версии StyleGAN. Вспомним, как именно работает неадаптивная версия этого слоя. Пусть у нас есть батч, элементы которого будем обозначать как. Здесьобозначает размер мини-батча,– количество признаков, аи– высоту и ширину. Тогда внутри слоя инстанс нормализации выполняется следующая операция: Здесьиобозначают матрицы средних и стандартных отклонений, которые считаются отдельно для каждого элемента мини-батча и для каждого признака: При этомиявляются параметрами слоя, которые настраиваются в процессе обучения. Особенностью этого слоя является то, что, в отличие от батч нормализации, он применяется одинаковым образом как при обучении, так и во время инференса. То есть вместо того, что приближать средние и стандартные отклонения по батчу при помощи скользящих средних, как это делается в батч нормализации, мы честно каждый раз считаем эти статистики для каждой новой картинки отдельно от всех остальных. Это делает инстанс нормализацию очень популярной в области обработки и генерации изображений, где зачастую бывает невозможным обучение с большим размером мини-батча, а значит и использование батч нормализации. Адаптивной инстанс нормализацией (AdaIN) называется слой, гдеиявляются не обучаемыми параметрами, а нейросетями, которые предсказывают эти векторы из какого-то общего для всех слоёв адаптивной инстанс нормализации входа (обозначим его через): Это означает, что вместо оптимизации по векторамибудет происходить оптимизация по параметрам этих двух нейросетей. Также это означает, что у адаптивной инстанс нормализации добавляется ещё один вход помимо набора признаков, который определяет её поведение: некоторый вектор, который также называют вектором стиля. Как правило, в качествеииспользуется нейросеть с одним линейным слоем или неглубокий персептрон. Нетрудно видеть, что если в качестве вектораподавать сгенерированный шум, то это будет хорошим способом многократного обуславливания нашего генератора на вектор шума. Это позволило бы глубоким слоям нейросети выучивать лишь часть той информации о выходном изображении, которая содержится в векторе, например, глобальные признаки картинки. А информация о локальных признаках выходного изображения (текстурах) может появляться уже ближе к последним слоям на более высоком разрешении промежуточных признаков. Таким образом, у генератора нет необходимости хранить во всех своих картах признаков всю информацию о сгенерированной картинке, как это происходит в случае DCGAN: он может декодировать её напрямую из вектора шума по мере необходимости, что существенно облегчает обучение таких моделей и улучшает качество результатов. Авторы StyleGAN пошли даже дальше: в качестве дополнительной регуляризации они специально заставляли нейросеть использовать информацию из вектора шума частями. А именно, во время обучения все слои адаптивной нормализации случайным образом делятся на две последовательно идущие группы: первая группа обуславливается при помощи одной части вектора шума, а вторая – при помощи другой части. На практике это приводит к следующему эффекту: нейросеть учиться декодировать часть признаков изображения, используя вектор, а часть – используя. Это позволяет после обучения напрямую манипулировать выходами нейросети, смешивая разные векторы стилей. Второе ключевое открытие авторов StyleGAN связано с задачей поиска семантически значимого редактирования векторов из выученного низкоразмерного многообразия. Зачем это нужно на практике мы уже упоминали ранее: на этом низкоразмером многообразии значительно проще семантически редактировать изображения, чем на уровне пикселей. Например, для задачи генерации лиц на многообразииза изменение возраста или гендера может отвечать простой аддитивный сдвиг векторана. Если же мы попытаемся приблизить такую операцию в пространстве пикселей, то для этого уже понадобится большая нейросеть с сотнями тысяч или даже миллионами параметров. При этом, как правило, мы хотим использовать наиболее простые операции редактирования. В идеале, мы бы хотели ограничить класс преобразований редактирования (а) сдвигами на какой-то вектор и (б) линейной (или сферически-линейной) интерполяцией двух векторов. С одной стороны, кажется, что так задача редактирования векторов существенно усложняется: этот класс преобразований даже менее выразителен, чем линейные операции. Но, с другой стороны, для таких простых преобразований легче гарантировать, что они не выведут нас за пределы многообразия, в котором у распределениябольшая «масса», т.е. того множества векторов, которые генератор чаще всего видел во время обучения. Для нормального распределения, как было сказано ранее, это многообразие можно приблизить сферой радиуса. Но будет ли легко найти хорошо работающие преобразования на многообразии случайных векторов, взятых из нормального распределения? Авторы StyleGAN обнаружили, что если сначала пропустить векторычерез многослойный персептрон, и подавать на вход свёрточного генератора его выходы, то редактировать латентные векторы на выученном многообразиистанет намного проще. Это объясняется тем, что функцияимеет возможность выучить достаточно сложное распределение для переменной, которое упростило бы задачу генерации картинки для свёрточной части генератора. И на практике оказывается, что такое выученное представлениеулучшает не только качество генерируемых картинок, но и качество результатов для семантического редактирования векторов. Последняя важная деталь, которая тем не менее очень сильно помогла авторам StyleGAN получить настолько хорошие результаты – это так называемый truncation trick. Он был впервые предложен в более ранних работах и продолжает оказывает огромное влияние на качество результатов. Его суть состоит в том, чтобы после обучения сэмплировать те примеры из латентного пространства, которые чаще всего видел генератор во время обучения. Например, если мы во время обучения брали векториз нормального распределения, то при использовании truncation trick после обучения мы бы его сэмплировали из нормального распределения с обрезанными хвостами. Тем самым, интуитивно, мы убираем из сгенерированной выборки те примеры входных векторов, которые генератор реже видел во время обучения. Однако, нетрудно заметить что такая процедура приводит к потере разнообразия в выходных картинках. Например, если мы обрежем нормальное распределение вплоть до его среднего значения, то тогда нейросеть сможет выдавать лишь один пример. При всём при этом потеря разнообразия выходов – не такая большая проблема, т.к. обученный генератор всё ещё может часто ошибаться и выдавать маргинальные примеры. Фильтрация таких плохих примеров по какому-то выставленному порогу – в этом и есть суть применения truncation trick. В случае StyleGAN, авторам хотелось бы применять этот трюк непосредственно на распределении в выученном латентном пространстве. Для этого они применяют простой трюк: сначала считают центр масс, усредняя векторыдля большой выборки сэмплов: а затем сдвигают каждый сгенерированный векторпо направлению к этому центру: где– это параметр, который задаёт trade-off между качеством результатов и их разнообразием. Хотя работа StyleGAN показала довольно хорошие результаты, авторы статьи про StyleGAN-2Analyzing and Improving the Image Quality of StyleGANзаметили, что в некоторых случаях она может выдавать некачественные изображения. В частности, StyleGAN в некоторых случая может выдавать изображения с артефактами. Основной причиной этих артефактов оказалась адаптивная нормализация. Изначально, адаптивная нормализация состояла из двух частей: нормализация (на рисунке обозначена как Norm) и модуляция (на рисунке обозначена как Mod). В нормализации мы вычитали среднее и делили на стандартное отклонение. В модуляции мы умножали на новое выученное стандартное отклонение и прибавляли новое выученное среднее. Авторы StyleGAN2 предложили несколько модификаций для этапа нормализации. Каждое изменение в статье добавляли последовательно, следя за изменением общего качества генерации. Как из нормализации, так и из модуляции убрали вычитание/прибавление среднего. Нормализация и модуляция теперь выполняются независимо друг от друга и были перемещены в начало/конец стилевых блоков (см рисунок ниже, (c) Revised architecture). Нормализацию из предыдущего пункта заменили на демодуляцию весов. По сути это та же нормализация, только теперь нормализуются веса свёрток, а не входные данные (см рисунок ниже, (d) Weight demodulation. Обратите внимание на). В StyleGAN используется техникаprogressive growing(см раздел про StyleGAN). Из-за этого StyleGAN появляются артефакты, возникающие при исследовании латентного пространства с помощью интерполяций. Некоторые объекты лиц (глаза, зубы), которые должны вращаться при вращении головы, оставались на месте. Чтобы побороть эти артефакты, вместо progressive growing в StyleGAN2 стали использовать residual connections. Эти изменения позволили улучшить качество генерируемых изображений и избавиться от артефактов StyleGAN. Вот, например, некоторые примеры сгенерированных изображений модели StyleGAN2: Следующий шаг в развитии архитектуры StyleGAN — это статьяStyleGAN-ADA. ADA расшифровывается какAdaptiveDiscriminatorAugmentation. В данной статье авторы предложили механизм аугментации данных, который позволяет стабилизировать обучение и избежать переобучения дискриминатора. Всего в статье использовали 18 разных аугментаций. В статье также предложили некоторую эвристику того, как понимать, насколько переобучился дискриминатор. Эвристика нужна для того, чтобы адаптивно контролировать параметр аугментациив зависимости от степени переобучения. Основная идея алгоритма контроляв процессе обучения следующая. Изначально этот параметр равен нулю. Его значение изменяется на фиксированную величину каждые четыре мини-батча (авторы пишут, что частота обновлений не влияет на результат). Если наблюдается, что дискриминатор слишком переобучился, то параметрувеличивается. И наоборот, при низкой степени переобучении дискриминатора значениеуменьшается. Аугментация, как показали авторы, действительно помогает стабилизировать обучение при маленьком количестве данных. Однако, большой набор реальных данных всегда будет выигрывать у аугментации. Большинство современных моделей, которые показали впечатляющие результаты для генерации изображений, работают по схеме text to image. То есть текст является входом для нейросети, изображение — выходом. Обычно текст на входе называют prompt. По такой схеме работают модели Stable Diffusion, DALLE 2, Midjourney. Все эти модели являются диффузионными. Однако, пока что списывать GANы со счетов не стоит. Хотя качество у GANов не такое высокое, как у диффузионных моделей, а обучать их сложнее, у них есть неоспоримое преимущество — быстрая генерация изображений. На момент написания этого параграфа самая свежая статья про генерацию изображений с помощью GANов —StyleGAN-T. Её авторы решили на основе StyleGAN сделать модель для генерации изображений из текста. Архитектура модели StyleGAN-T очень похожа на архитектуру модели StyleGAN (за основу авторы взялиStyleGAN-XL— версию StyleGAN для больших обучающих выборок). В качестве кодировщика текста была использована предобученная модельCLIP. На что стоит обратить внимание в данной архитектуре: Текст, закодированный CLIP text encoder, подаётся на вход как генератору, так и дискриминатору. Дискриминатор в данном случае классифицирует не отдельное изображение, а пару текст/изображение. Сгенерированное изображение пропускается через фиксированный кодировщик изображений, также взятый из модели CLIP (CLIP image encoder на рисунке архитектуры). Полученное представление изображения должно быть близко с представлением текста, полученным с помощью CLIP text encoder. Это достигается за счёт добавление CLIP guidance loss в общую функцию потерь. Для разрешения выше 64x64 авторы берут случайные кропы размера 64x64 на изображении, чтобы посчитать CLIP guidance loss. Основное новшество модели StyleGAN-T — это лучшая GAN-модель для генерации изображений из текста. До этого большинство хорошо работающих моделей позволяли генерировать изображения для заданного класса или вообще без условий. Связать текст с изображением — гораздо более сложная задача. Поскольку на вход модель принимает не только шум, но и закодированный текст, она позволяет делать интерполяции по пространству текста. Примеры сгенерированных изображений и интерполяций по текстовому пространству вы можете видеть на рисунке ниже. Качество изображений StyleGAN-T отстаёт от диффузионных моделей, таких как Stable Diffusion или DALLE 2, о чём пишут сами авторы. Однако данная модель сильно выигрывает по скорости: на одной и той же видеокарте Stable Diffusion генерирует изображение за 3.7 секунды, в то время как StyleGAN-T за 0.02 секунды. Выше были перечислены лишь основные особенности данного класса генеративных моделей, на которые стоит обратить внимание. Эти соображения нашли применение в других задачах помимо генерации картинок из шума. На самом деле, список трюков и нюансов, необходимых для успешного обучения такой модели, намного обширнее. На практике для генеративных моделей настоятельно рекомендуется отталкиваться от готовых кодовых баз, внося минимальные и контролируемые изменения в процесс обучения. Особенно чувствительны генеративные модели бывают к архитектуре генератора и дискриминатора, к параметрам оптимизации (learning rate, количество обновлений весов дискриминатора на одно обновление генератора, и т.д.), а также к значениям весов лоссов (например, к весу R1 регуляризации, которую мы тут не обсуждали)."
            }
        ]
    },
    {
        "id": "q_0495",
        "question": "Как называется задача восстановления части изображения, выделенной маской, с помощью нейросетей?",
        "answers": [
            "Эта задача называется инпеинтинг (inpainting). Она заключается в восстановлении выделенных маской участков изображения чем-то подходящим для конкретной фотографии."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
                "text": "До этого мы рассмотрели основные особенности генеративных состязательных нейросетей, а также их применение в задаче генерации изображений. В этом разделе мы рассмотрим, какие ещё задачи можно решать с помощью таких моделей. Отметим, что задачи, которые мы рассмотрим ниже, можно решать и другими способами без ГАНов. Зачастую диффузионные модели (MidJourney, Stable Diffusion) показывают лучшие результаты в этих задачах. Тем не менее в данном же разделе мы рассмотрим именно методы на основе генеративных состязательных нейросетей. Представьте, что вы хотите удалить с фотографии людей на заднем плане. Встаёт вопрос, чем их заменить? Для этого существует задача инпеинтинга (inpainting). Она заключается в том, чтобы восстановить часть изображения, которая была выделена маской. Если выделить людей или объекты на фотографии маской, то нейросеть для инпеинтинга будет способна зарисовать эти участки чем-то подходящим для конкретной фотографии. Обычно генератор модели GANs для инпеинтинга представляют собой image-to-image модели. То есть изображение подаётся как на вход, так и на выход. То, что происходит внутри генератора, зависит от архитектуры модели. Как правило, используются U-Net-подобные архитектуры с какими-то дополнениями. Так, например, в одной из последних работ по инпеинтигу на основе GANsResolution-robust Large Mask Inpainting with Fourier Convolutionsиспользуются Fast Fourier Convolutions. Чтобы обучить модель инпеинтинга, нужно подготовить данные в формате пар <изображение с маской, изображение без маски >. Сделать это не сложно. Достаточно на существующем наборе изображений случайным образом выделить участки для удаления, после чего обучать нейросеть их восстанавливать. Задачу inpainting можно так же превратить в задачу outpainting, то есть дорисовки изображения по краям. Для этого нужно в качестве маски подать пиксели, которые находятся за рамками изображения. При этом само исходное изображение можно уменьшить, если того требуют размерности нейросети. Задача outpainting может быть полезна, когда хочется расширить изображение, например, чтобы увеличить его разрешение. До этого мы рассматривали, как можно редактировать латентное пространство обученной состязательной модели, чтобы это отражалось на сгенерированных изображениях. В 2023 году вышла работаDrag Your GAN, которая основана на этом принципе, и позволяет редактировать изображения перетаскиванием одной точки в другую. Пример работы Drag Your GAN.cсылка на источник изображения Метод Drag Your GAN основан на модели StyleGAN2. Ему на вход подаётся набор изначальных точек и набор конечных точек. Внутри метода поочерёдно выполняются следующие два шага: Обновление латентного пространства и обновления изображения с помощью оптимизации; Обновление координат точек (трекинг точек). Изначально метод работает только со сгенерированным изображениями. Однако, нет проблем в том, чтобы добавить кодировщик, который бы переводил реальные изображения в латентное пространство модели. В таком случае можно будет редактировать и реальные изображения. Демо Drag Your GAN доступно поссылке."
            }
        ]
    },
    {
        "id": "q_0496",
        "question": "Какое условие является достаточным для сходимости в глобальный минимум на обучающей выборке при интегрировании динамики предсказаний?",
        "answers": [
            "Достаточным условием является положительная определённость матрицы Грама ядра. В этом случае градиентный спуск гарантированно сходится к глобальному минимуму."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
                "text": "Нам удалось проинтегрировать динамику предсказаний в явном виде. Что это даёт? Во-первых, мы получаем достаточное условие на сходимость в глобальный минимум на обучающей выборке. Таким условием является положительная определённость матрицы Грама ядра:для некоторого. В самом деле, в этом случае, что даёт Во-вторых, раз явное решение известно, можно написать оценку на обобщающую способность. Оба этих результата опираются на то, что ядро постоянно. Как мы покажем ниже, постоянство нейрокасательного ядра нейронной сети можно гарантировать лишь в пределе бесконечной ширины. Тем не менее, если сеть конечна, но достаточно широка, можно показать, что её ядро достаточно близко к предельному, и оценки сохраняют силу. Например, для обоснования сходимости в глобальный минимум достаточно показать, что наименьшее собственное значение эмпирического ядра с высокой вероятностью остаётся отделённым от нуля в течение обучения:с вероятностьюдля. В самом деле, из этого следует, что а значит, Формальное доказательство вы можете найти в работеGradient Descent Provably Optimizes Over-parameterized Neural Networks, а также вконспекте лекцийавтора этого параграфа. Вот ещё несколько результатов, полученных в этом направлении: улучшенные оценки на минимальную ширину в работеQuadratic suffices for over-parametrization via matrix chernoff bound; оценки для случая глубоких сетей в работеGradient descent finds global minima of deep neural networks; оценки на обобщающую способность, полученные через близость ядра к предельному, в работеFine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks. Как мы увидим позже, NTK реальных, стандартно параметризованных, имеющих конечную ширину сетей может меняться за время обучения существенным образом: см. эмпирическую работуDeep learning versus kernel learningи теоретический анализ для сетей с одним скрытым слоемDynamically Stable Infinite-Width Limits of Neural Classifiers. Тем не менее, ядро в инициализации может выявить определённые патологии соответствующей нейронной сети. Рассмотрим один из примеров применения. В некоторых состоящих из однородных блоков архитектурах (скажем, ResNet) можно увеличивать (и даже устремлять к бесконечности) число слоёв или блоков, и логично задаться вопросом о том, как при этом будет вести себя процесс обучения. Необходимым условием обучаемости является хороший первый шаг обучения. Если он исчезающе мал, то сеть не обучится ни на первом, ни на каком-либо другом шаге. Если он слишком велик, то обучение разойдётся на первом же шаге. Как мы увидим ниже, индикатором проблем является плохая обусловленность NTK в инициализации. Например, его собственные значения могут с ростом глубины стремиться к нулю или, наоборот, к бесконечности. В первом случае какие-то из компонент выборки никогда не выучатся, во втором обучение невозможно ни при каком конечном темпе обучения. Чтобы в этом убедиться, рассмотрим разложение матрицы Грама ядра по собственным векторами: где, а векторыобразуют ортонормированный базис. Разложим предсказание сети по этому базису:. Так как базис ортонормированный, каждая из компонент эволюционирует независимо от других. В самом деле, для дискретного градиентного спуска с шагомимеем Таким образом, если, тоникогда не сойдётся к. Кроме того, для того, чтобы процесс сходился, шагдолжен убывать обратно пропорционально наибольшему собственному числу. Если последнее стремится к бесконечности, тостремится к нулю, а значит,будем мало для всех, для которыхконечен; соответствующие компоненты также никогда не сойдутся. Подробности см. в работеRapid training of deep neural networks without skip connections or normalization layers using Deep Kernel Shaping, а также в более ранних работахExponential expressivity in deep neural networks through transient chaos,Deep information propagation,Resurrecting the sigmoid in deep learning through dynamical isometry,Dynamical isometry and a mean field theory of cnns, в которых использовалась похожая идея, но не использовалось понятие NTK явно. См. также главу про инициализацию вконспекте лекций."
            }
        ]
    },
    {
        "id": "q_0497",
        "question": "Какая основная проблема использования ядровых методов на больших наборах данных?",
        "answers": [
            "Основная проблема заключается в необходимости вычисления матрицы Грама ядра на обучающем наборе, размер которой квадратично зависит от размера выборки (N²), что сильно усложняет применение методов на больших данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
                "text": "Предельное NTK нейронной сети можно использовать в любом ядровом методе, например, в SVM. Обсудим это поподробнее и заодно разберёмся, почему NTK вообще называют ядром. Рассмотрим задачу линейной регрессии: Эту же задачу можно эквивалентно переписать следующим образом: где– пространство линейных отображенийс некоторой нормойна нём. Сделаем линейное пространствоевклидовым, введя на нём следующее скалярное произведение. Дляиопределим Это скалярное произведение порождает норму, что и делает формулировку (5) эквивалентной формулировке (4). Пространство линейных моделей слишком узко, однако ничто не мешает нам рассмотреть задачу вида (5), в которойбудет произвольным нормированным пространством функций. Наиболее хорошо изучен случай, когда функции изявляются линейными моделями в некотором (возможно, бесконечномерном) гильбертовом пространстве признаков:, гдеотображаетв это пространство. Если последнее всё же конечномерно, то мы можем использовать матричную запись; элементыв этой записи обычно называют первичными переменными (primal variables). Пространство функцийтакже оказывается гильбертовым: соответствующее скалярное произведение имеет вид Таким образом,, если. Любому отображениюможно сопоставить симметричную положительно-определённую функцию; функции такого вида называются ядрами. В силуфундаментальной теоремы о представителелюбое решение задачи (4) принимает вид В отличие от, векторвсегда конечномерен: его размерность равна размеру обучающей выборки. Элементыназывают двойственными (dual) переменными. Упомянутый результат позволяет перейти от минимизациив бесконечномерном пространстве функций (или, что то же самое, минимизациив бесконечномерном пространстве признаков), к минимизации в конечномерном пространстве двойственных переменных: Если в качестве функции потерь взять квадратичную, то получим ядровую регрессию; если же взять hinge loss, то SVM. Заметим, что двойственная задача полностью сформулирована в терминах ядра: отображение в потенциально бесконечное пространство признаковболее нигде не возникает. Поэтому мы можем использовать в качествелюбую симметричную положительно определённую функцию двух переменных, не думая о том, для какого пространства признаков оно будет ядром (есть теорема, что такие функции всегда являются ядрами). Это может быть очень полезно. Так, если для эмпирического NTK в инициализацииимеем, но совершенно неочевидно, какое отображениесоответствует предельному NTK:. Таким образом, мы можем использоватьв качестве ядрав двойственной задаче (6) наряду с линейнымили гауссовским ядром. Такой подход привлекателен тем, что обучение ядровых методов более устойчиво и имеет меньше гиперпараметров. При этом можно надеяться, что результат обучения ядрового метода с NTK в качестве ядра будет близок к результату обучения соответствующей нейронной сети. Основная проблема ядровых методов в том, что они требуют вычисления матрицы Грама ядра на обучающем наборе данных. Её размер(где– размер выборки), так что применение ядровых методов на больших данных сильно усложняется. Более того, наивное вычисление динамикииз формулы (3) требует обращения матрицы Грама, которое занимаетвремени. Тем не менее, определённые оптимизации существуют. Так например, в работеKernel methods through the roofпредлагается способ приближённого вычисления () запамяти и времени. Другие подходы см. в работахFast Finite Width Neural Tangent KernelиNeural tangents: Fast and easy infinite neural networks in python. Так или иначе, на малых наборах данных выражение (3) можно вычислить точно, см. результаты в работеHarnessing the power of infinitely wide deep nets on small-data tasks. Существуют также примеры задач, в которых матрицу Грама ядра достаточно посчитать только для малых, см., например,Simple, Fast, and Flexible Framework for Matrix Completion with Infinite Width Neural Networks. Ещё одна проблема использования NTK в ядровых методах состоит в том, что явный подсчёт предельного NTK доступен только для сетей, состоящих из слоёв из определённого класса. В этот класс входят полносвязные и свёрточные слои, average pooling, ряд нелинейностей с одним аргументом (включая, например, ReLU и erf), layer norm, но не входят max pooling и batch norm, часто используемые в реальных архитектурах. Явный подсчёт предельного NTK для «хороших» сетей реализован вбиблиотеке NeuralTangents; часть явных формул для подсчёта можно найти в статьеOn exact computation with an infinitely wide neural net. Тем не менее, даже в тех случаях, когда посчитать предельное NTK не представляется возможным, в качестве ядра для ядрового метода можно использовать эмпирическое NTK в инициализации Такое ядро можно рассматривать как шумную и смещённую оценку предельного; для уменьшения шума можно использовать Монте-Карло оценку матожидания. Некоторые оптимизации подсчёта эмпирического ядра см. в работеNeural tangents: Fast and easy infinite neural networks in python. NTK не единственное ядро, которое можно сопоставить нейронной сети. Так, NNGP-ядро– это ядро гауссовского процесса, реализуемого сетью в пределе бесконечной ширины. Подробнее можно почитать в работахDeep Neural Networks as Gaussian Processes,Wide neural networks of any depth evolve as linear models under gradient descent,Random neural networks in the infinite width limit as Gaussian processesили вконспекте лекций. Можно показать, что оно соответствует NTK-ядру для сети, в которой учится лишь выходной слой. Так как, в отличие от NTK, для подсчёта NNGP-ядра не требуется обратный проход (backward pass), последнее более вычислительно эффективно;Towards nngp-guided neural architecture search– пример работы, в которой предпочтение отдаётся NNGP-ядру именно по этой причине."
            }
        ]
    },
    {
        "id": "q_0498",
        "question": "Какая параметризация обеспечивает независимость эмпирического NTK от времени и инициализации?",
        "answers": [
            "NTK-параметризация обеспечивает независимость эмпирического NTK от времени и инициализации, в отличие от стандартной параметризации, где эмпирическое NTK расходится с шириной сети."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
                "text": "Вы этом параграфе мы покажем, что при определённой параметризации эмпирическое NTK не зависит ни от времени, ни от инициализации. Мы начнём с иллюстративного примера, прежде чем формулировать строгую теорему. Рассмотрим сеть с одним скрытым слоем, скалярным выходом и гауссовской инициализацией весов; вход для простоты тоже положим скалярным: Здесь– ширина скрытого слоя. Следуя одной из стандартных схем инициализации из статьиDelving deep into rectifiers: Surpassing human-level performance on imagenet classification, дисперсия каждого слоя выбирается обратно пропорционально числу входных нейронов (подробнее см. в параграфе протонкости обучения нейросетей). Назовём описанную выше параметризацию стандартной. Для сходимости ядра нам придётся несколько её видоизменить: Назовём новую параметризацию NTK-параметризацией. Отметим, что распределение выходов нейронов в инициализации остаётся неизменным при переходе от стандартной к NTK-параметризации. Что меняется – это динамика градиентного спуска: Приприращения весов для такой параметризации имеют порядок, в то время как сами веса имеют порядокпри. Поэтомуипридля любого данногои. Другими словами, с ростом размера скрытого слоя градиент будет стремиться к нулю, и каждый из весов в пределе останется в начальной точке. Сравним с градиентным спуском в стандартной параметризации: В этом случае веса выходного слоя имеют порядокпри, но получают приращения порядкав этот момент времени, в то время как веса входного слоя имеют порядокпри, но получают в этот момент времени приращения порядка. В новой параметризации эмпирическое NTK выглядит следующим образом: Так какипридля любых заданныхи, выражение выше асимптотически эквивалентно а значит, сходится к прив силу закона больших чисел. Предельное ядроне зависит ни от времени, ни от инициализации. Мы будем называть это ядронейрокасательнымили простоNTK(его не стоит путать с эмпирическим NTK). Ещё раз подчеркнём, что это работает для NTK-параметризации, но не для стандартной. Для стандартной параметризации эмпирическое NTK в инициализации расходится с шириной: Подробнее мы поговорим об этом в одном из следующих параграфов. Для NTK-параметризации сходимость эмпирического ядра выполняется не только для сетей с одним скрытым слоем. Так, рассмотрим полносвязную сеть сслоями: Здесь,идля всех остальных. Положим, что веса инициализируются из стандартного нормального распределения. Поставим задачу оптимизации дифференцируемой функции потерь: где– объединение всех весовсети. Теорема ниже доказана воригинальной работе по NTK: Теорема. В предположениях выше, еслиизи липшицева иизи липшицева, тосходится кпо вероятности припоследовательно. Оказывается, что эта теорема верна не только для полносвязных сетей с гладкими активациями. Определимтензорную программукак начальный набор переменных определённых типов и последовательность команд. Каждая команда порождает новую переменную, действуя на уже имеющиеся. Переменные бывают трёх типов: :матрицы с независимыми элементами из; : вектора размерас асимптотически независимыми нормальными элементами; : образы-переменных относительно поэлементных нелинейностей. Для переменнойзаписьбудет означать, чтоимеет тип. Команды бывают следующие: trspop:(перевести переменную типасо значениемв переменную типасо значением); matmul:; lincomb:; nonlin:(здесь мы несколько выходных векторовагрегируем в один с помощью покоординатной, возможно, нелинейной функции). Формализм тензорных программ позволяет представить прямой и обратный проход широкого класса нейронных архитектур, который включает свёрточные сети, рекуррентные сети, сети с residual слоями. Хотя и ни одна из операций выше не может порождать новые-переменные (веса), любое наперёд заданное число шагов градиентного спуска можно представить в рамках одной тензорной программы (посредством «развёртывания» шагов градиентного спуска). Назовём величинушириной тензорной программы.Основная «предельная» теорема тензорных программ представлена ниже: Master theorem(G. Yang,Tensor programs III: Neural matrix laws). Рассмотрим тензорную программу с-величинами, удовлетворяющую определённым начальным условиям. Пусть все нелинейностии функцияполиномиально ограничены. Тогда почти наверное при, гдеимогут быть вычислены по некоторым рекурентным правилам. Оказывается, что если тензорная программа выражает прямой и обратной проход в некоторой нейронной сети, то NTK сети в инициализации всегда можно представить в видедля некоторой функции, см.Tensor programs II: Neural tangent kernel for any architecture.Таким образом, теорема выше доказывает существование и детерминированность предельного ядра в инициализации, а также даёт способ его вычисления. Более того, это верно и для ядра в любой фиксированный момент времени, см.Tensor Programs IIb. В качестве иллюстрации обратимся вновь к сети с одним скрытым слоем. Рассмотрим тензорную программу, вычисляющую прямой и обратный проходы на входахи. Такая программа порождает следующие-величины:,,и. Напомним, что эмпирическое NTK равно Положив получим выражение как раз в виде, требуемом Master Theorem."
            }
        ]
    },
    {
        "id": "q_0499",
        "question": "Почему расходящееся ядро при стандартной параметризации не является проблемой для задач классификации?",
        "answers": [
            "Для бинарной классификации важен только знак предсказания, а для многоклассовой — индекс максимального логита, поэтому величина предсказаний не играет роли. Это позволяет пределу при бесконечной ширине сохранять смысл, несмотря на расходящееся ядро."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
                "text": "Как было отмечено в предыдущем параграфе, эмпирическое NTK двухслойной сети расходится с шириной при стандартной параметризации. При, так какнезависимы и имеют порядок, сумма расходится пропорционально.Так как для квадратичной функции потерь, предсказание модели в любой точкеполучает приращение порядкана первом же шаге обучения; для задачи регрессии такая модель теряет смысл. Однако для классификации величина предсказаний не играет роли: для бинарной классификации важен лишь знак, а для многоклассовой – индекс максимального логита. Таким образом, в этом случае, несмотря на расходящееся ядро, предел при бесконечной ширине имеет смысл, см.Dynamically Stable Infinite-Width Limits of Neural Classifiers. Рассмотрим нормализованное эмпирическое NTK. Его предел в инициализации равен. Назовём этот предел нормализованным NTK и обозначим. В отличие от ядра в NTK-параметризации, нормализованное NTK при стандартной параметризации зависит от времени: Напомним, как выглядит градиентный спуск в стандартной параметризации: При,, в то время как. Так каки, для любого, не зависящего от,,,и. Наивная оценка сумм даётдля любого, не зависящего от. Таким образом, нормализованное ядро зависит от времени даже в пределе бесконечной ширины. Экспериментальный анализ эволюции ядра реальной нейронной сети в стандартной параметризации см. в работеDeep learning versus kernel learning. Преимущество нейронных сетей над ядровыми методами, в том числе с NTK, может быть связано, в частности, с зависимостью предельного ядра от времени. В самом деле, ядро измеряет «похожесть» в некотором пространстве признаков. Для NTK это пространство фиксировано, в то время как нейронная сеть меняет своё ядро по ходу обучения, возможно, делая его более подходящим для задачи."
            }
        ]
    },
    {
        "id": "q_0500",
        "question": "Как можно интерпретировать мягкую кластеризацию с использованием смеси распределений?",
        "answers": [
            "Мягкую кластеризацию можно интерпретировать через смесь распределений, где каждое распределение компоненты задаёт отдельный кластер, а априорные вероятности компонент соответствуют вероятностям принадлежности объектов к этим кластерам."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
                "text": "Говорят, что распределениеявляетсясмесью распределений, если его плотность имеет вид где: — число компонент; — вероятности компонент; — функции правдоподобия, то есть функции вероятности компонент (в дискретном случае) или их плотности (в абсолютно непрерывном случае). Проиллюстрируем это понятие на примере с банком. Будем считать, что распределения компонент смеси принадлежат некоторому параметрическому семейству:(например, гауссовскому с параметром). Мы можем говорить, что каждое из распределенийзадаёт свой кластер, причём каждый кластер имеет некоторую априорную вероятность. Если у нас нет дополнительных данных, разумно положить. Если же нам, к примеру, известно, что какой-нибудь кластер описывает сравнительно малочисленную группу людей, эти вероятности окажутся различными. Таким образом, мы проинтерпретировали нашумягкую кластеризациюв терминах смеси распределений."
            }
        ]
    },
    {
        "id": "q_0501",
        "question": "Какой эксперимент описывает процесс генерации значения из смеси распределений с использованием скрытой переменной?",
        "answers": [
            "Эксперимент состоит из двух этапов: сначала из дискретного распределения выбирается номер компоненты смеси, который кодируется бинарным вектором с одной единицей, а затем из соответствующего распределения генерируется значение. Скрытая переменная определяет, к какой компоненте смеси будет относиться каждое сгенерированное значение."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
                "text": "Рассмотрим следующий эксперимент: сначала из дискретного распределениявыбирается номер, а затем из распределениявыбирается значение. Покажем, что распределение переменнойбудет представлять собой смесь. Введемскрытую переменную, отвечающую за то, к какой компоненте смеси будет относиться очередной. Пусть она представляет собой-мерный бинарный случайный вектор, ровно одна компонента которого равна единице: Вероятность того, что единице будет равна-я компонента, положим равной: Запишем распределение сразу всего вектора: Теперь, когда номер компоненты смеси известен, сгенерируемиз распределения: или, что то же самое, Проверим, чтоимеет нужное нам распределение. Запишем совместное распределение переменныхи: Чтобы найти распределение переменной, нужно избавиться от скрытой переменной: Суммирование здесь ведется по всем возможным значениям, то есть по всем-мерным бинарным векторам с одной единицей: Мы получили, что распределение сгенерированной переменнойв описанном эксперименте представляет собой смеськомпонент."
            }
        ]
    },
    {
        "id": "q_0502",
        "question": "Какие два типа правдоподобия рассматриваются в вероятностных моделях со скрытыми переменными и как они связаны?",
        "answers": [
            "В моделях со скрытыми переменными различают неполное правдоподобие (для наблюдаемых переменных) и полное правдоподобие (для наблюдаемых и скрытых переменных). Они связаны соотношением, где неполное правдоподобие получается суммированием полного правдоподобия по всем возможным значениям скрытых переменных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
                "text": "Рассмотрим вероятностную модель с наблюдаемыми переменнымии параметрами, для которой задано правдоподобие. Предположим, что в модели также существуютскрытые переменные, описывающие её внутреннее состояние и, возможно, недоступные для непосредственного наблюдения (как то, к какому из кластеров относится клиент). Тогда правдоподобиеназываетсянеполным, а правдоподобие—полным. Они связаны соотношением Нашей основной целью будет создать хорошую модель, то есть оценить параметры. И оказывается, что с помощью введения скрытых переменных нередко удаётся существенно упростить правдоподобие и эффективно решить задачу. Рассмотрим пример со смесями распределений. В качестве наблюдаемых переменных здесь выступает выборка, в качестве скрытых переменных— номера компонент, из которых сгенерированы объекты (здесь каждый из—-мерный вектор), в качестве параметров — априорные вероятности и параметры компонент. Неполное правдоподобие выглядит так: Правдоподобие здесь имеет видлогарифма суммы. Если приравнять нулю его градиент, то получатся сложные уравнения, не имеющие аналитического решения. Данное правдоподобие сложно вычислять: оно не является выпуклым (а точнее, вогнутым) и может иметь много локальных экстремумов, поэтому применение обычных итерационных методов для его непосредственной максимизации приводит к медленной сходимости. Рассмотрим теперь полное правдоподобие: Оно имеет видсуммы логарифмов, и это позволяет аналитически найти оценки максимального правдоподобия на параметрыпри известных переменныхи. В общем случаетакже стараются выбирать таким способом, чтобы распределениеоказалось «лучше» исходного. В каком именно смысле, мы увидим дальше. Проблема, впрочем, заключается в том, что нам не известны скрытые переменные, поэтому их необходимо оценивать одновременно с параметрами, что никак не легче максимизации неполного правдоподобия. Осуществить это позволяетEM-алгоритм."
            }
        ]
    },
    {
        "id": "q_0503",
        "question": "В чём заключается основное отличие жёсткого EM-алгоритма от стандартного?",
        "answers": [
            "Жёсткий EM-алгоритм вместо апостериорного распределения на скрытых переменных использует точечную оценку, то есть работает с семейством дельта-функций, а не с полным распределением."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
                "text": "EM-алгоритм решает задачу максимизации полного правдоподобия путём попеременной оптимизации по параметрам и по скрытым переменным. Опишем сначаланаивныйспособ оптимизации. Зафиксируем некоторое начальное приближение для параметров. При известных наблюдаемых переменныхи параметрахмы можем оценить скрытые переменные, найдя их наиболее правдоподобные значения: Зная скрытые переменные, мы можем теперь найти следующее приближение для параметров: Повторяя итерации до сходимости, мы получим некоторый итоговый вектор параметров. Данная процедура, однако, далека от идеальной — и ниже мы предложим решение, которое приводит к более качественным результатам. Воспользуемся байесовским подходом. Точечные оценки параметров несут меньше информации, чем их распределение; учтём это и будем оптимизировать не, а условное распределение. Как и прежде, зафиксируем вектор параметров, но вместо точечной оценки вычислим апостериорное распределение на скрытых переменных, которое будет в некотором смысле оптимальным образом описывать распределениепри известныхи. В этом заключаетсяE-шагEM-алгоритма. Отметим, что вычислитьаналитически возможно не для всех распределений, и скрытые переменные стоит подбирать так, чтобы это всё-таки получилось. Теперь мы должны произвести оптимизацию по. Для этого возьмём логарифм полного правдоподобияи усредним его по всем возможным значениям скрытых переменных: Формально говоря, мы нашли матожидание логарифма полного правдоподобия по апостериорному распределению на скрытых переменных. НаM-шагеновый вектор параметров находится как максимизатор данного матожидания: EM-алгоритм состоит в чередовании E-шага и M-шага. Можно показать, что такой итерационной процесс всегда не уменьшает правдоподобие и сходится. Не всегда получается подобрать латентные переменныетак, чтобыможно было выразить аналитически, то есть на E-шаге не удаётся минимизироватьпо. В такой ситуации иногда приходится брать оптимум не по всему пространству распределений, а только по некоторому семейству — например, параметрическому, в котором оптимизацию можно проводить градиентными методами. В максимально упрощённой ситуации мы возьмём семейство дельта-функций, то есть вместо распределения набудем брать просто точечную оценку. Такая модификация EM-алгоритма называетсяжёстким EM-алгоритмом. В начале параграфа мы упоминали кластеризацию методом K-средних и отмечали, что EM-алгоритм даёт «мягкую» версию алгоритма: на E-шаге мы не приписываем однозначно точку к какому-то из кластеров (то есть не берём точечную оценку скрытой переменной «номер кластера, к которому принадлежит точка»), а сопоставляем ей вероятности принадлежности каждому из кластеров (то есть распределение на скрытые переменные). Настоящий метод K-средних как раз таки соответствует жёсткому EM-алгоритму."
            }
        ]
    },
    {
        "id": "q_0504",
        "question": "Как найти апостериорную вероятность принадлежности объекта к определённой компоненте смеси гауссиан, если известны начальные приближения параметров распределений?",
        "answers": [
            "Апостериорная вероятность вычисляется по формуле Байеса, где используется априорная вероятность (на первом шаге обычно равная 1/K для всех гауссиан) и правдоподобие объекта для нормального распределения с текущими параметрами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
                "text": "Пусть теперь нам известно, чтоточек были семплированы из Kразныхгауссовских распределений и нам неизвестно, какая точка из какого распределения пришла в выборку. Нам нужно оценить параметры (,) для первого распределения, (,) для второго и, соответственно, (,) для-го распределения. Если мы знаем, что точкапришла из распределения, то её правдоподобие в равно: Напомним, что— это латентная переменная, обозначающая номер гауссианы (от 1 до), из которой была просемплирована точка. Например, если точкапросемплирована из распределения с номером 3, то в формулу вместо (,) нужно подставлять. Воспользуемся EM-алгоритмом для нахождения параметров (,). Сначала инициализируем их: Зная, выполним E-шаг: нужно найтиили что то же самое, для каждого объектанайти распределение на вероятности. Как найти апостериорную вероятность, если мы знаеми у нас есть приближение? Ответ — по формуле Байеса: где— априорная вероятность того, что объектаполучен из распределения с номером. На первом шаге априорную вероятность можно положить равнойдля всех гауссиан. Введём обозначение — правдоподобие того, что объектпришел из нормального распределения с параметрами. Тогда по формуле Байеса: Вот так для каждого объектапо начальному приближениюмы посчитаем распределение— с какими вероятностями объектприходит из той или иной компоненты смеси. Теперь выведем формулы для М-шага. Запишем производную и приравняем к, чтобы найти экстремум: Отсюда Мы получили конечную формулу для пересчетапои предыдущему значению. Причем у этой формулы есть простая интерпретация — каждый объект мы взвешиваем с его вероятностью принадлежности к этому классу. Теперь посчитаем производную по(обратите внимание, что именно по квадрату): Стало быть, Мы снова получили интерпретируемый результат: подсчитывая дисперсию для-ой гауссианы, мы учитываем вес каждого объекта при подсчете среднеквадратичноого отклонения. То есть веса — вероятности происхождения из той или иной компоненты смеси. Сравните эту формулу с формулой для подсчета выборочной дисперсии, где каждый изобъектов вносит одинаковый вклад в дисперсию с весом: Вы можете «пощупать» EM-алгоритм в задаче разделения вероятностной смеси с помощью интерактивной визуализации — попробуйте сделать E и M шаги и последить за изменениями параметров: после одной итераций алгоритма можно выбрать точку на графике и наблюдать за вероятностью её принадлежности к разным кластерам."
            }
        ]
    },
    {
        "id": "q_0505",
        "question": "Какие преимущества вероятностного PCA по сравнению с обычным методом выделяются в тексте?",
        "answers": [
            "Вероятностный PCA может служить частью более сложных вероятностных моделей, легко обобщается на данные с пропусками через добавление скрытых переменных и может быть вычислительно эффективнее благодаря использованию EM-алгоритма без работы с полной матрицей данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
                "text": "Теперь давайте рассмотрим простой пример того, как введение латентных переменных может помочь выделять новые информативные признаки в данных. Предположим, что мы имеем выборку данных(вектор-строку), где каждый объект имеетпризнаков (предположим, что числоочень большое). Это достаточно типичная ситуация, например, при работе с текстами или изображениями. Теперь введём следующую вероятностную модель, где— латентный вектор-строка меньшей размерности, а, где— единичная матрица размером,— скаляр больший 0. Что означает эта модель? Она означает, что наши сложные многоразмерные данныемогут иметь более простое малоразмерное представление, а отображениелинейно с точностью до нормально распределенного шума. Заметим, что так как, отсюда следует, что. Зададим априорное распределение накак стандартное нормальноеи распишем совместное распределениечерез условное и априорное: Чтобы восстановить параметры,и латентные переменные, снова воспользуемся EM-алгоритмом. На E-шагемы оцениваем распределение напри фиксированныхи: По формуле Байеса распределение напри условии: С точностью до констант и слагаемых, которые не зависят от, логарифм правдоподобия равен: Обозначим, тогда Если теперь взять от этого экспоненту, увидим, что. M-шаг. Теперь мы оптимизировать пои: Приравняв производные к, можно найти: Вероятностный PCA хорош тем, что: как любая байесовская модель, может служить промежуточным участком в более сложной вероятностной модели; если в данных есть пропуски, то вероятностный PCA легко обобщается и на этот случай с добавлением дополнительных скрытых переменных; так как параметрыи оценки наполучаются через итерационный EM-алгоритм, то вероятностный PCA может быть вычислительно эффективнее. Так, в вычислениях и промежуточных формулах нигде не используется матрица, и все рассматриваемые матрицы имеют меньший размер. Связь с обычным PCA Как вероятностный PCA связан с обычным, который мы изучили в теме про разложение матриц? Напомним, что в обычном SVD-разложении мы полагали, что. Давайте опять положим, что разница междуиесть гауссовский шум с нулевым средним: или Если зададим априорное распределение накак стандартное нормальное, тогдаи соответственно. Теперь сделаем обратную заменуи убедимся, что оценка максимального правдоподобия в точности равна. (напомним, чтоиэто вектор-строки). Заметим, что число есть след матрицы, состоящей из этого числа, поэтому можно преобразовать вторую часть, как Отсюда следует, что Приравняв производную пок нулю, найдем: Оценка максимума правдоподобия на: Эту оценку можно интерпретировать как среднюю потерю дисперсии по всем проигнорированным сингулярным направлениям. Если же— константа, то приполучаем обычный PCA. Другой способ получить обычный PCA — это вместо обычного EM-алгоритма воспользоваться его жёсткой модификацией. Теперь предлагаем вам потренировать изученный материал на практике. Предлагаем вам выполнить лабораторную работу, которая покрывает большинство тем главы “Вероятностные модели”. Скачайтеноутбукс лабораторной работой. В нём вы найдете описания заданий и дополнительные материалы. Задания из лабораторной прикреплены к этому параграфу в виде задач в системе Яндекс Контест. Чтобы проверить себя, отправляйте решения по соответствующим задачам в систему. Успехов в практике!"
            }
        ]
    },
    {
        "id": "q_0506",
        "question": "Какой принцип используется для выбора модели машинного обучения, когда распределение должно удовлетворять только явно заданным ограничениям и не отражать дополнительного знания?",
        "answers": [
            "Это принцип максимальной энтропии. Согласно ему, искомое распределение должно обладать максимальной неопределённостью при заданных ограничениях, то есть иметь максимально возможную энтропию."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/entropiya-i-semejstvo-eksponencialnyh-raspredelenij",
                "text": "Впараграфе про оценки параметровбыли описаны различные свойства параметрических оценок и методы их получения, например, метод моментов или метод максимального правдоподобия. В принципе, если мы уже выбрали для наших данныхнекоторое параметрическое семейство, моделирующее их распределение, восстановить его параметры чаще всего можно по выборочному среднемуи/или выборочной дисперсии. А теперь представим, что мы посчитали эти (или какие-то другие) статистики, а семейство распределений пока не выбрали. Как же совершить этот судьбоносный выбор? Давайте посмотрим на следующие три семейства и подумаем, в каком из них мы бы стали искать распределение, зная его истинные матожидание и дисперсию? Почему-то хочется сказать, что в первом. Почему? Второе не симметрично – но что нас может заставить подозревать, что интересующее нас распределение не симметрично? С третьим проблема в том, что, выбирая его, мы добавляем дополнительную информацию как минимум о том, что у распределения конечный носитель. А с чего бы? У нас такой инфомации вроде бы нет. Общая идея такова: мы будем искать распределение, которое удовлетворяет только явно заданным нами ограничениям и не отражает никакого дополнительного знания о нём. Таким образом, искомое распределение должно обладать максимальной неопределённостью при заданных ограничениях, или, говоря более научно, иметь максимально возможную энтропию. В самом деле, энтропия выражает нашу меру незнания о том, как ведёт себя распределение, и чем она больше – тем более «‎произвольное» распределение, по крайней мере, в теории. В этом и заключаетсяпринцип максимальной энтропиидля выбора модели машинного обучения. Как мы уже видели выше, среди распределений с конечным носителем максимальную энтропию имеет равномерное распределение. Примеры геометрического и нормального распределения показывают, что энтропия распределений с бесконечным носителем (счётным или континуальным) может быть сколь угодно большой, и среди них нет какого-то одного распределения с максимальной энтропией. Однако в более узком классе распределений с фиксированным средним и/или дисперсией найти распределение с максимальной энтропией, как правило, можно. Пример. Покажем, что среди распределений на множестве натуральных чисели математическим ожиданиеммаксимальную энтропию имеет геометрическое распределение. Для минимизации энтропиис учётом ограничений воспользуемсяметодом множителей Лагранжа, согласно которому требуется минимизировать функцию Лагранжа Приравняем к нулю частные производные по: Отсюда следует, что, так что распределение действительно получается геометрическое. Параметрыинайдём из уравнений Деля первое уравнение на второе, получаем, или. Далее из первого уравнения находим. Итак, а это и есть геометрическое распределение с параметром. У непрерывных распределений возможны более интересные комбинации из ограничений на носитель и параметры. И конечно же, первую скрипку среди распределений с максимальной энтропией играет гауссовское распределение. Пример. Докажем, что среди распределений наc математическим ожиданиеми дисперсиейнаибольшую энтропию имеет нормальное распределение. Пусть– некоторое распределение со средними дисперсией,. Как было показано выше,. Запишем дивергенцию Кульбака-Лейблера: Так как KL-дивергенция всегда неотрицательна, получаем, чтопри любом распределении, удовлетворяющем заданным ограничениям. Можно показать, что максимальную энтропию среди многомерных распределений с вектором среднихи матрицей ковариацийимеет также гауссовское распределение. Упражнение. Докажите, что среди распределений на отрезкемаксимальную энтропию имеет равномерное распределение. Упражнение. Докажите, что среди распределений на промежуткес математическим ожиданиеммаксимальную энтропию имеет показательное распределение. Как выяснилось, многие классические распределения имеют максимальную энтропию при весьма естественных ограничениях. Но как быть, если даны не эти конкретные, а какие-то другие ограничения? Есть ли какой-нибудь надёжный алгоритм вывода распределения с максимальной энтропией, позволяющий избежать случайных озарений и гаданий на кофейной гуще? Оказывается, что при некоторых не очень обременительных ограничениях ответ можно записать с помощью распределений экспоненциального класса."
            }
        ]
    },
    {
        "id": "q_0507",
        "question": "Как изменяются свойства активаций в свёрточной нейронной сети по мере увеличения глубины слоёв?",
        "answers": [
            "Активации первых слоёв имеют маленький receptive field и реагируют на низкоуровневые детали изображения. С увеличением глубины receptive field растёт, и активации начинают реагировать на более высокоуровневые абстракции, такие как формы, части объектов, а на последних слоях — на целые объекты и их группы."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
                "text": "Нейронные сети можно рассматривать, как механизм автоматического выучивания представлений, поэтому современные методы выучивания представлений существенно сконцентрированы на использовании нейросетей. Напомним, что нейронная сеть состоит из набора дифференцируемых преобразований, примененных друг за другом к объектудля получения предсказания целевой переменной. Обычно преобразования содержат обучаемые параметры, которые настраиваются в процессе обучения по данным. Преобразования в литературе часто называют слоями. Результат применения преобразования к его входу мы будем называть скрытыми представлениями или активациями. Активации любого слоя можно использовать как представления объекта. Представления с разной глубины нейронной сети будут обладать разными свойствами. Рассмотрим свёрточные нейронные сети для изображений. Активации первых слоёв обычно видят только маленькие части исходной картинки, другими словами, имеют маленькийreceptive field. Такие активации могут реагировать — принимать большие значения — только на низкоуровневые детали, маленькие фрагменты изображения. По мере увеличения глубины receptive field становится больше, а активации начинают реагировать на более высокоуровневые абстракции, такие как формы и части объектов. Активации последних слоёв имеют большой receptive field и реагируют на уже на объекты и группы объектов. На изображении ниже показаны части картинок (патчи), каждая группа из 9 изображений максимизирует значение определенной активации в обученной нейронной сети. Размер патча зависит от receptive field активации, а максимизация ведется по датасету реальных изображений: выбираем топ-9 патчей из датасета по значению активации. Для активаций, взятых с ранних слоев, нейроны реагируют на низкоуровневые детали. По мере увеличения глубины нейроны начинают реагировать на более высокоуровневые объекты. Большая часть методов, которые мы рассмотрим ниже, за исключением матричной факторизации (в зависимости от того, как на это взглянуть), будут использовать активации нейросети в качестве представлений. Поэтому, обучить представления и обучить нейросеть это почти синонимы. Большинство отличий будет состоять в том, как эти нейронные сети обучаются и какую архитектуру имеют. Нейронные сети можно обучать из случайной инициализации, а можно стартовать с вектора весов, обученного на внешнем датасете. К примеру, если вы решаете задачу классификации изображений, часто инициализация части вашей нейронной сети весами, предобученными на популярном датасете ImageNet, ускорит и улучшит обучение. Такой процесс называется fine-tuning («дообучение» / «файнтюнинг»): Как можно усложнять эту схему: Добавлять в модель много новых, обучающихся с нуля слоёв (на картинке мы добавляем один, но можно и больше); Не обязательно копировать все слои, можно копировать только сколько-то первых. Дообучать как все веса модели, так и какую-то часть. К примеру, можно заморозить скопированные слои и дообучать только новые части модели. Для файнтюнинга часто используют постепенное увеличение (warm-up) learning rate на первых эпохах обучения. Это позволяет сетке «привыкнуть» к новой задаче и архитектуре. Пример: В некотором смысле хорошая инициализация работает как праер на функции, которые могут быть выучены после дообучения. Поэтому дообучение часто требует в разы меньше данных, чем обучение со случайной инициализации."
            }
        ]
    },
    {
        "id": "q_0508",
        "question": "Какие три важные темы были затронуты в параграфе о представлениях сложных объектов в глубинном обучении?",
        "answers": [
            "В параграфе были затронуты supervised предобучение, self-supervised предобучение и metric learning."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
                "text": "Глубинное обучение — в существенной степени наука о представлениях сложных объектов. В этом параграфе мы лишь слегка затронули несколько важных тем: supervised предобучение, self-supervised предобучение, и metric learning. Self-supervised предобучение — это важный новый раздел глубинного обучения, который, вероятно, поможет серьезно сократить количество необходимой разметки во многих приложениях. Генеративные модели VAE/inverse-GANs также широко используются для получения и обработки представлений. О них вы сможете прочитать в следующих параграфах."
            }
        ]
    },
    {
        "id": "q_0509",
        "question": "Какие авторы и организации публиковали материалы по теме самообучения (self-supervision) в 2020 году?",
        "answers": [
            "В 2020 году материалы по этой теме публиковали Александр Дьяконов (июнь), Yann LeCun от ICLR (май), Aravind Srinivas от UC Berkeley в курсе CS294-158 (весна), а также DeepMind совместно с UCL."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
                "text": "Contrastive Representation Learning, Lilian Weng, May 2021. Self-Supervised Representation Learning, Lilian Weng, Nov 2019. Самообучение (Self-Supervision), Александр Дьяконов, Июнь 2020. Self-Supervised Learning | ICLR, Yann LeCun, May 2020. Self-Supervised Learning | UC Berkeley, CS294-158 Deep Unsupervised Learning, Aravind Srinivas, Spring 2020. Unsupervised Representation Learning | DeepMind x UCL."
            }
        ]
    },
    {
        "id": "q_0510",
        "question": "Какие две основные особенности метода Ньютона выделяются при сравнении с градиентным спуском?",
        "answers": [
            "Первая особенность — квадратичная скорость сходимости в окрестности решения. Вторая — устойчивость к плохой обусловленности задачи благодаря инвариантности к линейным преобразованиям."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka",
                "text": "Итак, наша задача – безусловная оптимизация гладкой функции Как и при оптимизации методом градиентного спуска, мы будем искать направление уменьшения функционала. Но в этот раз мы будем использовать не линейное приближение, а квадратичное: Формула Тейлора говорит нам брать. Приравняв к нулю градиент этой квадратичной аппроксимации, мы получаем направление спуска для метода Ньютона: Обозначим. В таком случае мы можем записать итеративный алгоритм спуска: В литературе методом Ньютона называется такой метод при, при другом размере шагеэтот метод называютдэмпированным(damped) методом Ньютона. Обсудим, в чем главная особенность метода Ньютона и в чем заключается выигрыш по сравнению с классическим градиентным спуском. Таких особенностей две. Первая связана со скоростью его сходимости. А именно – в окрестности решения он сходитсяквадратично. Теорема. Пусть функцияимеет достаточно гладкий гессиан и сильно выпукла в точке оптимума. Тогда, что для всякогодля метода Ньютона свернодля константызависящей только от. Второе приятное свойство заключается в устойчивости метода Ньютона к плохой обусловленности задачи (в отличие от метода градиентного спуска). Разберёмся, что это значит. Когда мы говорим о плохой обусловленности задачи, мы имеем в виду, что гессиан в точке оптимума плохо обусловлен, то есть отношение максимального и минимального собственных чисел является большим числом. Геометрически это значит, что линии уровня функции вблизи оптимума похожи на очень вытянутые эллипсоиды; мы уже обсуждали, что в такой ситуации градиентный спуск может работать медленно. А как справится метод Ньютона? Оказывается, намного лучше. И связано это с его инвариантностью к линейным преобразованиям. А именно, рассмотрим функциюдля некоторой невырожденной матрицы. Обозначим. Посмотрим, как связаны градиент и гессиан новой функции с градиентом и гессианом старой. Воспользуемся производной сложной функции: Рассмотрим теперь траекториюметода Ньютона, запущенного из точкидля поиска минимума функции, и траекториюметода Ньютона, запущенного для поиска минимума функции. Если, то для всехбудет верно, то есть траектории получаются одна из другой при помощи этого линейного преобразования, другими словами, траектории исходной и новой функции подобны. Вернёмся теперь к плохо обусловленной задаче минимизации функции. Рассмотрим линейное преобразованиеи функцию. Тогда для функциичисло обусловленности гессиана в точке оптимума равно в точность единице (проверьте это!), а траектории для этой новой, хорошо обусловленной функции, и старой, плохо обусловленной, подобны. В частности, метод Ньютона не будет, как градиентный спуск, долго метаться где-то на задворках вытянутой эллиптической «ямки» вокруг оптимума, а быстро ринется к центру. Можно сказать, что метод Ньютона правильно улавливает кривизну линий уровня функции и это позволяет ему быстрее сходиться к оптимуму. Эту идею стоит запомнить, она появляется в некоторых вдохновлённых методами второго порядка модификациях SGD. Также еще можно заметить, что свойства, которые мы требуем от функции в теореме о квадратичной сходимости, вообще говоря, не сохраняются при линейных преобразованиях: могут поменяться константы липшицевости и сильной выпуклости. Это простое замечание побудило исследователей ввести класс самосогласованных функций, более широкий и линейно инвариантный, для которого метод Ньютона также сходится. Подробнее об этом можно узнать вразделе 9.6 книги S. Boyd &L. Vandenberghe, Convex Optimization. От хорошего переходим к плохому: к слабостям метода Ньютона. Во-первых, мы имеем квадратичную скорость сходимости только вокрестностиоптимума. А если мы стартуем из произвольно удалённой точки, то нам, как и в случае градиентного спуска, требуется подбор шагапри помощи линейного поиска (что нам вряд ли по карману). Если подбирать шаг не хочется, можно прибегнуть к интересному теоретическому методу получения гарантий на глобальную сходимость – добавлению кубической регуляризации. Другая проблема кроется в формуле пересчета следующей итерации:вычисление и обращение гессиана. Конечно, вместо обращения гессиана можно честно решать систему линейных уравнений, но асимптотика остается прежней:, а от затрат памяти на хранение матрицывообще некуда деться. А это значит, что, например, решать линейную регрессию с ~10000 признаками методом Ньютона попросту невозможно. Есть и третья, малозаметная проблема: дословно метод Ньютона не работает для невыпуклых задач, посколькуне будет положительно опредленной иперестанет быть направлением спуска. Для решения этой проблемы можно немного «подпортить» нашу аппроксимацию и рассмотреть матрицу вида, такую чтостанет положительно определенной, и уже её подставлять в нашу квадратичную модель. Идея подмены гессиана на что-то более подходящее – это главная идея квазиньютоновских методов, обсуждаемых далее. Итак, общие выводы: Метод Ньютона – теоретически оптимальный метод, который автоматически улавливает кривизну функции в окрестности оптимума. Для размерностион уже не является эффективным, поскольку требует вычисления и хранения гессиана, а также решения системы линейных уравнений с его участием (что может быть в общем случае очень дорого)."
            }
        ]
    },
    {
        "id": "q_0511",
        "question": "Какие два основных способа существуют для хранения матриц дешевле, чем «по-честному»?",
        "answers": [
            "Первый способ — пользоваться разреженностью матрицы, второй — использовать низкоранговые разложения или что-то близкое к ним."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka",
                "text": "Чтобы придумать, как бороться с проблемами метода Ньютона, нужно посмотреть на него с другой стороны, а для этого мы обратимся ненадолго к решению задачи нахождения нуля векторной функции. Итак, рассмотрим совершенно новую задачу. Пусть дана функцияи нужно найти её ноль, то есть такое, что. Связь с оптимизацией (по крайней мере в выпуклом случае) довольно проста: если взять, то корень уравненияи будет точкой оптимума. Сначала рассмотрим одномерный случай. Как найти ноль функции с помощью итеративной процедуры? Логично поступить следующим образом: проводим касательнуюк графику функции и находим точку, в которой линейная аппроксимация обнуляется: откуда получаем формулу пересчета Известно, что этот метод обладает квадратичной скоростью сходимости в одномерном мире, что очень перекликается с методом Ньютона для оптимизации – и не просто так. Если рассмотреть многомерный случай, то вычисление производной заменяется на вычисление якобиана векторнозначной функции. В случаенаш якобиан становится гессианом и получаем в точности обычный метод Ньютона для оптимизации: Пусть мы хотим найти такую точку, что. В одномерном случае мы можем подменить вычислениевычислением её приближения. Откуда получаем формулу пересчета: Графически, этот метод выглядит следующим образом: Скорость сходимости этого метода несколько ниже, чем у метода Ньютона (линейная, а не квадратичная), но зато мы теперь не должны вычислять производную! В текущем виде, используя просто подмену градиента на его конечно-разностную аппроксимацию, не очевидно, как обобщить этот метод на произвольную размерность. Но, если посмотреть на название метода и на картинку, как он работает, мы видим, что мы по сути проводим через два предыдущих приближения секущую, а затем выбираем ноль этой секущей в качестве следующей точки. В многомерном случае мы можем выписать соответствующее ей уравнение, где– матрица размера, которая должна удовлетворять так называемомууравнению секущей(secant equation): Теперь, чтобы выбрать следующую точку, нужно найти ноль секущей, то есть А теперь рассмотрими добавим в итеративную схему выше размер шага. Тогда мы получаем общую итеративную схему квазиньютоновских методов: При этом необходимо выбирать такие, чтобы они (а) были симметричными и положительно определенными и (б) удовлетворяли уравнению секущей Первое требование восходит к двум соображениям. Первое –должно приближать гессиан, а он в идеале в окрестности точки минимума как раз является симметричным и положительно определенным. Второе соображение проще: в противном случаепопросту не будет направлением спуска. Несмотря на эти два свойства, выбор по прежнему остается достаточно широким, откуда возникает большое разнообразие квазиньютоновских методов. Мы рассмотрим один классический и широко известный метод BFGS (Broyden, Fletcher, Goldfarb, Shanno). Сначала заметим, что в самом алгоритме в первую очередь используется обратная матрица к, которую мы обозначим. Тогда выбирать– это тоже самое, что выбирать. Введем еще два стандартных обозначения, чтобы можно было проще записывать все последующие формулы:и. В их терминах уравнение секущей длявыглядит максимально просто:. Теперь введем некоторое искусственное требование, которое гарантирует единственность– выберем ближайшую подходящую матрицу к, удовлетворяющую описанным выше условиям: Вообще говоря, при выборе разных норммы будем получать разные квазиньютоновские алгоритмы. Рассмотрим один достаточно общий класс норм (аналог взвешенныхнорм в матричном мире): где– это Фробениусова норма а– некоторая симметричная и положительно определенная матрица весов, которую мы выберем таким образом, что она будет сама по себе удовлетворять уравнению секущей. Сразу уточним, что матрица весов в таком случае меняется на каждой итерации и, по сути, на каждой итерации мы имеем разные задачи оптимизации, само же предположение задает дополнительную похожесть на обратный гессиан, поскольку можно взять в качестве весов усредненый гессиан Решив описанную выше оптимизационную задачу, мы получаем матрицу, не зависящую явным образом от матрицы весов: Эта формула как раз является ключевой в алгоритме BFGS. Чтобы заметить одно крайне важное свойство этой формулы, раскроем скобки: Отсюда мы видим, что нам в этой формуле достаточно умножать матрицу на вектор и складывать матрицы, что можно делать заопераций! То есть мы победили один из самых страшных минусов метода Ньютона. Воспользовавшись тем, чтои– числа, перепишем формулу в более computational friendly стиле: Общие выводы: Итерации BFGS вычислительно проще итераций метода Ньютона и не требуют вычисления гессиана; По скорости сходимости BFGS уступает методу Ньютона, но все равно является достаточно быстрым; По прежнему требуетсяпамяти, что по-прежнему вызывает проблемы при большой размерности (). Время выполнения итерациигораздо лучше, чемметода Ньютона, но всё ещё оставляет желать лучшего. Казалось бы, избавиться отнельзя принципиально, ведь нужно как-то взаимодействовать с матрицейразмера, а она не факт что разреженная. Но и в этом случае можно добиться улучшения до линейной сложности (как у градиентных методов!). При взаимодействии с матрицами существует два основных способа хранить их дешевле, чем «по-честному». Первый способ – пользоваться разреженностью матрицы, а второй – низкоранговыми разложениями или чем-то близким. Поскольку сейчас мы не хотим добавлять предположений на задачу, которую мы решаем, то единственный выход – это пользоваться структурой, возникающей в BFGS. Если внимательно взглянуть на формулы обновления, то их можно переписать в следующем виде: Для того, чтобы перейти отк, можно хранить не матрицу, а набор пар из k пари начальное приближение(например,для некоторого), чтобы «восстановить». Пользуясь такой структурой, мы можем хранить матрицупри помощи лишьчисел, а не. К сожалению, такая структура имеет довольно простую проблему: призатраты памяти становятся только выше. Возникает простая идея – а давайте хранить только последниеобновлений! Таким образом, мы получаем алгоритм L-BFGS, который имеет уже линейныезатраты памяти и, что немаловажно, такие же линейные затратына итерацию, ведь умножение матрицина вектор может осуществляться за линейное время. Общие выводы: L-BFGS обладает линеной сложностью итерации, линейными требованиями по дополнительной памяти и к тому же требует вычислять только градиенты! Производительность сильно зависит от константы, отвечающей за точность аппроксимации гессиана; Как и все методы из этого раздела, требует точного, а не стохастического вычисления градиентов."
            }
        ]
    },
    {
        "id": "q_0512",
        "question": "В каких случаях метод L-BFGS может быть неэффективным и какой метод тогда следует использовать?",
        "answers": [
            "Метод L-BFGS может быть неэффективным при больших размерах датасета, когда вычисление честного градиента и значения для функционалов вида суммы занимает неразумное время. В такой ситуации рекомендуется вернуться к использованию стохастического градиентного спуска (SGD)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka",
                "text": "Из всех перечисленных в этом разделе методов важнее всего отметить L-BFGS как самый практичный. Он реализован в любой* библиотеке, которая имеет дело с оптимизацией чего-либо и может быть эффективным, если удаётся вычислить градиенты (и значения функций для линейного поиска размера шага). К сожалению, это получается не всегда: при больших размерах датасета вычисление честного градиента и значения для функционалов вида суммы не представляется возможным за разумное время. В таком случае мы вынуждены вернуться в мир стохастического градиентного спуска. Общая идея более тонкого учёта геометрии линий уровня функции потерь, в чём-то напоминающая происходящее в методе Ньютона, находит применение и в ряде вариаций SGD, но, конечно, порождает совершенно другие методы. Что же касается самого метода Ньютона, его можно несколько оптимизировать, если смириться с тем, что всё вычисляется неточно. Во-первых, обратную матрицу к гессиану матрицу на самом деле не нужно ни хранить, ни даже вычислять. Давайте разберёмся, почему. Умножитьна вектор– это то же самое, что решить систему с левой частьюи правой частью, а для решения систем уравнений существуют эффективные итеративные методы, не меняющие левой части системы, а требующие лишь уметь умножать её на разные векторы. При этом умножать гессиан на вектор можно при помощи автоматического дифференцирования. Кроме того, можно на кажом шаге неточно решать систему, получая таким образом неточный метод Ньютона. Теория предписывает решать систему все точнее с ростом номера итерации, но на практике нередко используют фиксированное и небольшое число шагов итеративных методов решения систем линейных уравнений."
            }
        ]
    },
    {
        "id": "q_0513",
        "question": "Какой численный метод решения ОДУ более стабилен, чем обычная схема Эйлера?",
        "answers": [
            "Более стабильным численным методом решения обыкновенных дифференциальных уравнений является обратная схема Эйлера (backward Euler scheme)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/proksimalnye-metody",
                "text": "Для того, чтобы подступиться к проксимальным методам, посмотрим на градиентный спуск с другой стороны. Для простоты рассмотрим константный размер шага. Перепишем шаг градиентного спуска следующим образом: Посмотрим на это уравнение по-другому. Рассмотрим функцию, равнуюпри(мы будем воспринимать, как некоторый временной параметр). Тогда при: Теперь слева не что иное, как аппроксимация производной! Если мы устремимк нулю, то получится так называемоеуравнение градиентного потока: Эта динамика в случае выпуклой функциисходится к точке минимумаиз любой начальной точки при. Сравнение между динамикой градиентного спуска и градиентного потока можно увидеть на следующем изображении: Первый состоит из дискретных шагов, второй же представляет из себя непрерывный процесс. Нетрудно осознать физический смысл динамики: маленькое тело скатывается по склону графика функции так, что в любой момент её скорость совпадает с антиградиентом, то есть оно катится по направлению наискорейшего спуска. Теперь представим, что мы сейчас занимается не машинным обучением, а численными методами. Перед нами есть обыкновенное дифференциальное уравнение (ОДУ), и его надо решить. Одним из численных методов решения ОДУ (более стабильным, чем обычная схема Эйлера) является обратная схема Эйлера (backward Euler scheme): В обратной схеме Эйлера мы делаем градиентный спуск, только градиент смотрим не в текущей точке (как было бы в обычной схеме Эйлера), абуквальнов будущей. Занятная идея, только вот напрямую выразитьиз этого уравнения не получится. Нужно поступить чуть хитрее. Заметим, что Это позволяет нам сказать, что весь векторявляется градиентом функции, посчитанном в точке. Тогда получаем, чтоудовлетворяет следующему условию: Если функциявыпуклая, тотоже выпуклая, и её стационарная точка будет точкой минимума. Стало быть,можно высчитывать по формуле Определимпрокс-операторследующим образом: Тогда, поскольку умножение навнутри арг-минимума не влияет на саму точку минимума, получаем следующую итеративную схему: Итеративный процессназываетсяметодом проксимальной минимизации. Вы можете спросить себя: зачем он нужен? Ведь теперь на каждом шаге мы должны решать задачу оптимизации: Есливыпуклая, нам есть, что ответить: наличие второго слагаемого гарантирует сильную выпуклость задачи, то есть она решается достаточно эффективно. Но еслине является выпуклой, то мы ничего не достигли этой модификацией. Чтобы понять, зачем нам понадобилась проксимальная оптимизация, рассмотрим оптимизацию функций вида где– это гладкая функция, а– это функция, для которой прокс-оператор считается аналитически. Воспользуемся следующим трюком: помы совершим градиентный шаг, а по– проксимальный. Получаем следующую итеративную процедуру: Эта процедура определяет так называемый проксимальный градиентный метод (Proximal Gradient Method, PGM), который может использоваться, например, для решения задачи регрессии с-регуляризацией. Теперь решим конкретную задачу-регрессии. Она выглядит следующим образом: Мы хотим применить PGM к этой задаче, для этого нужно научиться вычислять прокс-оператор для-нормы. Проделаем эту операцию: Заметим, что каждое слагаемое зависиттолько от одной координаты. Это значит, что каждую координату мы можем прооптимизировать отдельно и получитьодномерных задач минимизации вида Решение такой одномерной задачи записывается в виде функцииsoft thresholding: Тогда мы получаем следующий алгоритм для-регрессии, которые называются Iterative Shrinkage-Thresholding Algorithm (ISTA): Скопировать код1w = normal(0,1)# инициализация2repeat S times:# другой вариант: while abs(err) >tolerance3f = X.dot(w)# посчитать предсказание4delta = f - y# посчитать отклонение предсказания5grad =2* X.T.dot(delta) / n# посчитать градиент6w_prime = w - alpha * grad# считаем веса, которые отправим в прокс7foriinrange(d):8w[i] = soft_threshold(w_prime[i], alpha * llambda)# вычисляем прокс Заметим одну крутую особенность этого алгоритма -- мы явно видим, что решение получается разреженное, ведь какие-то координаты будут явно зануляться при применении soft threshold! Причем чем больше размер и шага, и параметра регуляризации, тем больше прореживается координат. Конкретно этот метод не применяется на практике, но используются его вариации. Например,статья, которая указана в параграфе пролинейные моделио том, как работало предсказание CTR в google в 2012 году, также базируется на вычислении soft threshold как прокс-оператора. Подытожим все вышесказанное: Проксимальные методы – теоретически интересная идея для выпуклой оптимизации, которая должна давать более численно стабильные алгоритмы. Проксимальные методы позволяют достаточно эффективно решать задачи композитной оптимизации, в частности,-регуляризованную задачу регрессии. Более того, используемые на практике решения задачи-регуляризованной регрессии так или иначе базируются на идее ISTA. Также есть попытки использовать проксимальные методы для более сложных моделей. Например,статья о применении их в нейросетях. Кроме того, имеются применения проксимальных методов для построения распределенных алгоритмов. Все подробности можно найти вмонографии Neal Parikh и Stephen Boyd, мы же только привели применение этих идей в машинном обучении."
            }
        ]
    },
    {
        "id": "q_0514",
        "question": "Какие основные проблемы возникают при безграничном увеличении размеров моделей машинного обучения?",
        "answers": [
            "Безграничный рост моделей приводит к увеличению времени обучения, повышенным требованиям к размерам и качеству обучающей выборки, необходимости более дорогого вычислительного оборудования для обработки запросов, а также делает невозможным применение в сценариях реального времени или на мобильных устройствах."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/distillyaciya-znanij",
                "text": "Задача сжатия моделей проистекает из следующего наблюдения. Неоднократно было замечено, что в широком диапазоне практически значимых задач машинного обучения точность предсказания модели существенно зависит от её размера. При этом зачастую данная зависимость выглядит достаточно тривиально: последовательное увеличение размеров модели позволяет последовательно улучшать точность её предсказаний. Однако такой безграничный рост приводит к ряду проблем, связанных с практическим применением итоговых моделей. Сюда относятся рост времени обучения больших моделей и повышенные аппетиты таких моделей к размерам и качеству обучающей выборки. Кроме того, большие модели нередко требуют более дорогостоящего вычислительного оборудования для эффективного применения, особенно если мы говорим об обработке большого количества запросов в сжатые сроки. А для некоторых сценариев, таких как предсказание в реальном времени и/или на мобильных устройствах, применение большой модели может оказаться вовсе невозможным. Эти проблемы породили каждая свою ветвь исследований. Так в последние годы де-факто стандартным способом обучения даже относительно компактных моделей стало использование mixed-precision training, которое позволяет ускорить обучение более или менее любых сетей на современных графических процессорах, при этом практически без потерь в итоговом качестве. Для борьбы с недостатком обучающих данных была предложена целая плеяда методов self-supervised pretraining, и новые появляются до сих пор. Сжатие моделей же концентрируется на решении проблем, связанных с этапом применения уже обученных моделей. Как можно догадаться из названия, задача сжатия моделей заключается в том, чтобы взять большую модель, и сжать её в как можно более компактную модель при этом по возможности минимально пожертвовав качеством предсказания. Исторически задачу сжатия моделей пытались решать множеством разных способов. Классическим примером здесь может служить прунинг, где модель обучается специальным образом (например, с использованием L2 регуляризации) так, чтобы часть весов в итоге можно было занулить и исключить из итоговой модели. Однако методы данного семейства, как правило, страдают от двух основных проблем. Во-первых, простое удаление части весов каждого из слоёв обычно показывает лишь незначительное ускорение в применении итоговой модели за исключением случаев использования специализированной аппаратуры Во-вторых, наивный прунинг нередко приводит к существенной просадке в качестве предсказания сжатой модели, причём соотношение степени сжатия и качества итоговой модели едва ли возможно контролировать. Чтобы обойти данные ограничения, и была предложена техника дистилляции знаний."
            }
        ]
    },
    {
        "id": "q_0515",
        "question": "Какие сложности возникают при использовании выходов промежуточных слоев для дистилляции знаний?",
        "answers": [
            "Возникают две основные сложности: необходимость заранее выбирать пары слоев между учителем и учеником, а также проблема несовпадения размеров выходов выбранных слоев, что требует дополнительных преобразований для выравнивания размерностей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/distillyaciya-znanij",
                "text": "Несмотря на широкий успех хинтоновского подхода, дистилляция знаний им не ограничивается. Одно из наиболее очевидных направлений улучшения предложенного метода — это использование дополнительных способов передачи знаний от модели-учителя к модели-ученику. Действительно, в хинтоновской постановке единственный канал передачи знаний — это выходы с последнего слоя модели-учителя. Однако в случае нейронных сетей это отнюдь не единственный доступный нам источник информации. Например, можно использовать веса модели-учителя для умной инициализации, как при обучении DistilBERT. К сожалению, поскольку дистилляция знаний практически всегда сопряжена со сжатием модели, не всегда получается непосредственно использовать веса учителя, и в каждом отдельном случае приходится изобретать специализированные трюки. По этой причине DistilBERT — это единственная известная автору этого параграфа модель, в которой удалось добиться улучшения результатов благодаря использованию весов модели-учителя для умной инициализации. Тем не менее, в нейронных сетях можно найти и другие источники информации. Хинтоновская дистилляция использует только выходы с последнего слоя сети. Почему бы нам дополнительно не использовать выходы промежуточных слоев? И действительно,исследования показывают, что использование выходов промежуточных слоев позволяет улучшить результаты дистилляции знаний. Для получения прироста качества авторы предлагают выбрать один или несколько промежуточных слоев модели-учителя, сопоставить каждому из них промежуточный слой модели-ученика, после чего использовать квадрат нормы разности выходов итоговых пар слоев в качестве дополнительного слагаемого к хинтоновской функции потерь. К сожалению, несмотря на кажущуюся прямолинейность данного подхода, здесь возникают две сложности. Мы явным образом предполагаем наличие заранее выбранных пар слоёв, оставляя за бортом вопрос о том, каким образом их собственно стоит выбирать. Поскольку дополнительные слагаемые функции потерь по сути обучают модель-ученика повторять промежуточные представления модели-учителя, разумным кажется сохранять порядок слоёв: слои из середины модели-учителя сопоставлять со слоями из середины модели-ученика, а слои, находящиеся ближе к концу модели-учителя, — со слоями, находящимися ближе к концу модели-ученика. В частности, авторы оригинальной статьи просто берут средний слой в каждой из моделей и используют их в качестве своей единственной пары, однако это в большей степени связано с тем, что статья была написана в 2014 году и рассматривала достаточно маленькие по современным меркам модели. Более свежие статьи, как правило, работают с более глубокими сетями, а потому используют большее количество пар слоёв. Так, авторы следующей работырассматриваютглубокие сверточные сети с промежуточными связями (residual connections) и предлагают разбивать каждую из моделей на группы блоков с промежуточной связью таким образом, чтобы итоговое количество групп совпало. Пример такой разбивки можно видеть на картинке ниже. Здесь к каждой группе относится по три блока в модели-учителе и по два блока в модели-ученике. После этого выходы каждой такой группы можно сопоставить друг другу и использовать для дистилляции знаний. После того, как пары слоёв были выбраны, перед нами может возникнуть и второе препятствие. Что, если выходы выбранных слоёв различаются по размерам? Такая ситуация запросто может случиться, ведь мы хотим, чтобы модель-ученик была поменьше, а один из способов сжатия — как раз уменьшение количества нейронов в полносвязных слоях. В таком случае авторы оригинальной статьипредлагаютиспользовать дополнительное преобразование, чтобы придать выходам модели-ученика нужные размеры (например, линейный слой). Такие слои обучаются совместно с моделью-учеником, а после исключаются из сети при применении. В более поздних работах встречаются и другие, более продвинутые преобразования. Несмотря на кажущуюся интуитивность дистилляции промежуточных выходов, практическое применение это метода, к сожалению, осложняется необходимостью выбора целого ряда гиперпараметров. Скажем, оптимальные тактики выбора пар слоёв для дистилляции или дополнительных преобразований для выравнивания размерностей выходов до сих пор являются предметами активных исследований, точно так же, как и функции потерь для оптимизации."
            }
        ]
    },
    {
        "id": "q_0516",
        "question": "Какое теоретическое обоснование позволяет использовать выборочное среднее в качестве оценки неизвестного параметра распределения?",
        "answers": [
            "Закон больших чисел утверждает, что при увеличении размера выборки выборочное среднее сходится к истинному математическому ожиданию, что делает его обоснованной оценкой параметра."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/parametricheskie-ocenki",
                "text": "Как правило, чем больше размер выборки, тем более информативны параметрические оценки вида. Теоретические свойства таких оценок приустанавливаются с помощью предельных теорем теории вероятностей. Внимательный читатель мог обратить внимание, что в ряде примеров из предыдущих параграфов параметры некоторых распределений почему-то молчаливо подменялись средними значениями. Так мы поступили в задаче о показе рекламы, взяв в качестве параметра пуассоновского распределение среднее количество кликов пользователей. Фактически мы оценили неизвестный параметрасредним по выборке: В общем-то это кажется логичным, поскольку, если. Однако у такой оценки есть также мощное теоретическое обоснование. Теорема (Закон больших чисел, ЗБЧ). Пусть– последовательность попарно независимых одинаково распределенных случайных величин с конечным математическим ожиданием. Тогда для любого Таким образом, чем больше размер выборки, тем менее вероятно отклонениевыборочного среднегоот истинного среднегона любое число. Закон больших чисел особенно легко обосновать для случая конечных дисперсий:. Имеем Отсюда видно, что, поэтому при большихраспределение случайной величинывсё больше похоже на распределение, сосредоточенное в одной лишь точке. Формально же утверждение ЗБЧ получается с помощью неравенства Чебышева: Закон больших чисел допускает следующее усиление. Теорема (Усиленный закон больших чисел, УЗБЧ). Пусть– последовательность попарно независимых одинаково распределенных случайных величин с конечным математическим ожиданием. Тогда выборочное среднеепочти наверноесходится к, т.е.. Доска Гальтонаиллюстрирует биномиальное распределение. До поворота на ее дне лежит множество маленьких шариков. Сразу после переворота шарики проходят через 10 рядов гладких круглых препятствий. Преодоление каждого препятствия можно рассматривать как испытание Бернулли: с равными вероятностями шарик может пойти как налево, так и направо. Поэтому финальное положение шарика в одной из 10 корзин является приблизительной реализацией биномиального распределения. Уже прибиномиальное распределение напоминает нормальное. И действительно, чем больше, тем лучше дискретная случайная величинааппроксимируется непрерывной гауссианой. Теорема Муавра-Лапласа. Пусть,, тогда Из теоремы Муавра-Лапласа вытекает, что при большихвероятность попадания биномиальной случайной величиныв заданный интервал можно оценить как где— функция распределения стандартного нормального распределения. При выводе закона больших чисел мы видели, что выборочное среднееимеет среднееи дисперсию. Но как именно выглядит распределение случайной величиныпри увеличении? Оказывается, что оно становится всё больше похоже на. Вот как, например, выглядят нормализованные гистограммывыборочных средних, построенных по i.i.d. выборкамдля разных значений: Эти гистограммы и впрямь очень напоминают гауссианы, и это прямое следствие следующей теоремы. Центральная предельная теорема, ЦПТ. Пусть– последовательность попарно независимых одинаково распределенных случайных величин с конечным математическим ожиданиеми дисперсией. Тогда Точнее говоря,. Таким образом, случайная величинасходится по распределениюк:. Если применить центральную предельную теорему к бернуллиевским случайным величинам с вероятностью успеха, то вновь получим теорему Муавра-Лапласа."
            }
        ]
    },
    {
        "id": "q_0517",
        "question": "Какой метод оценки параметров заключается в приравнивании выборочных моментов к теоретическим?",
        "answers": [
            "Это метод моментов. Он состоит в решении системы уравнений, полученной из приравнивания выборочных моментов к теоретическим, что позволяет найти оценки параметров распределения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/parametricheskie-ocenki",
                "text": "До этого мы обсуждали разные приятные свойства оценок, а теперь рассмотрим некоторые методы, позволяющие систематически получать по выборке оценки параметров с нужными свойствами. Пусть выборкаполучена сэмплированием из некоторого семейства распределенийс параметрами.Метод моментовдля оценки этих параметров заключается в приравнивании выборочных моментов к теоретическим Решая полученную систему уравнений,, находим оценки параметров. Пример. Оценим параметры нормального распределенияс помощью метода моментов. Упражнение. Оцените по методу моментов параметрыидля выборкииз. При некоторых условиях на регулярность семейства распределенийоценка по методу моментов получается состоятельной и асимптотически нормальной. Пусть, как обычно, выборка.Правдоподобие(функция правдоподобия,likelihood) выборки— это просто её совместная pmf или pdf. Вне зависимости от типа распределения будем обозначать правдоподобие как Если выборка i.i.d., то функция правдоподобия распадается в произведение одномерных функций: Оценка максимального правдоподобия(maximum likelihood estimation,MLE) максимизирует правдоподобие: Поскольку максимизировать сумму проще, чем произведение, обычно переходят к логарифму правдоподобия (log-likelihood). Это особенно удобно в случае i.i.d. выборки, тогда Пример. В результатеподбрасываний монеты выпало«орлов» и«решек».Оценим вероятность выпадения «орла» методом максимального правдоподобия. Пусть— вероятность выпадения «орла», тогда правдоподобие равно Дифференцируя логарифм правдоподобия и приравнивая к нулю производную, находим Нетрудно убедиться, что это точка максимума. Итак, оценка максимального правдоподобиявероятности «успеха» в схеме Бернулли вполне ожидаемо оказалась равна доле «успехов» в серии изиспытаний. Упражнение. Пусть i.i.d. выборкавзята из пуассоновского распределения с параметром. Найдите его оценку максимального правдоподобия. Методом максимального правдоподобия можно оценить сразу несколько параметров. Пример. Найдём MLE-оценки параметров распределенияпо i.i.d. выборке. Запишем правдоподобие: Перейдём к log-likelihood: Приравняем частные производные поик нулю: откуда– выборочное среднее,– выборочная дисперсия. Упражнение. Пусть i.i.d. выборка. Найдите оценки максимального правдоподобия для параметрови. Свойства оценки максимального правдоподобия состоятельность:; инвариантность относительно параметризации: если— MLE-оценка для, то— MLE-оценка для; асимптотическая нормальность:; асимптотическая оптимальность: при достаточно большихоценкаимеет минимальную дисперсию."
            }
        ]
    },
    {
        "id": "q_0518",
        "question": "При каких условиях все локальные минимумы функции потерь для нейронной сети с одним скрытым слоем являются глобальными минимумами?",
        "answers": [
            "Это выполняется, если функция активации аналитична, ограничена и не тождественно равна нулю, ширина скрытого слоя не меньше размера набора данных, и все столбцы матрицы входных данных различны."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/landshaft-funkcii-poter",
                "text": "Рассмотрим нейронную сеть с одним скрытым слоем: где функция активацииприменяется поэлементно. Рассмотрим набор данныхразмера, где, а. Применяя соотношения выше к этому набору, получим следующие значения выходов слоёв: Поставим задачу оптимизации квадратичной функции потерь где– норма Фробениуса. Теорема 1(On the local minima free condition of backpropagation learning) Еслианалитична, ограничена и не тождественно равна нулю, ширина скрытого слояне меньшеи все столбцы матрицыразличны, то все локальные минимумыглобальны. Доказательство. Пусть– локальный минимум, и пусть,– соответствующие ему скрытые представления. Тогда– локальный минимум. Задача оптимизациивыпуклая, поэтому– глобальный минимум. Если, то система, где– неизвестная матрица, гарантировано имеет решение для каждого. Следовательно, а значит,– глобальный минимум. Заметим, что для выполнения равенстванеобходимо. Пусть теперь. Если тем не менее, то– по-прежнему глобальный минимум. Пусть Докажем, чтоне может быть локальным минимумомдо тех пор, пока выполнены условия следующей леммы, которую мы докажем позже: Лемма 1. Если, функцияаналитична, ограничена и не тождественно равна нулю, а все столбцы матрицыразличны, то лебегова мера множестваравна нулю. Так каки– непрерывна как функция от, существует, для которого где черезмы обозначили-окрестность точкив пространстве весов. Из леммы 1 следует, что для любогонайдётся, для которого. Возьмём. Для соответствующегоимеем; при этом. Как было отмечено выше, задача минимизациивыпуклая, и оптимум её равен нулю, так как. Поэтому градиентный спуск, применённый ки стартующий в, сойдётся в некоторую точку, для которой. Мы знаем, что в нашей эпсилон-окрестности функция потерь положительна, значит, найденная точка находится вне её:. Таким образом, найдётсятакое, что для любыхсуществует паратакая, что градиентный спуск, примененный к, стартующий ви действующий только на, сходится в точку. Очевидно, что если «для любых» заменить на «для любых», утверждение выше останется верным. Это означает, что динамика градиентного спуска, действующего только на, не устойчива по Ляпунову в точке. Следовательно,не может быть точкой минимума (иначе градиентный спуск был бы устойчив), а значит, условиеневыполнимо в условиях леммы 1. Таким образом, все локальные минимумыглобальны.Теорема 1 доказана. Доказательство леммы 1. Пусть– наборов индексов издлины. Рассмотрим– подматрицу матрицы, состоящую из строк, проиндексированных набором. В терминахусловиеэквивалентно. Так каканалитична, а определитель – аналитическая функция элементов матрицы,– аналитическая функция отдля любого. Нам понадобится следующая лемма, доказательство которой вы можете найти вThe loss surface of deep and wide neural networks(лемма 4.3): Лемма 2.В условиях леммы 1, найдётся, для которого. Из леммы 2 и эквивалентности выше следует, что найдётся, такой что для некоторогоимеет место неравенство. Так как определитель– аналитическая функция, а всякая не тождественно нулевая аналитическая функция принимает значение ноль лишь на множестве меры ноль по Лебегу, то лебегова мера множестваравна нулю. Таким образом,лемма 1 доказана."
            }
        ]
    },
    {
        "id": "q_0519",
        "question": "Какие условия необходимы для того, чтобы локальный минимум функции потерь нейронной сети был глобальным минимумом?",
        "answers": [
            "Для этого должны выполняться следующие условия: функция активации аналитична, ограничена и не тождественно равна нулю; её производная нигде не обращается в ноль; самый широкий слой сети имеет ширину не меньше числа различных обучающих примеров; после самого широкого слоя сеть сужается; гессиан функции потерь в локальном минимуме невырожден."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/landshaft-funkcii-poter",
                "text": "При доказательстве теоремы 1 мы воспользовались следующими условиями: Все обучающие примеры (столбцы матрицы) различны; Число скрытых слоёвравно одному; Ширина (последнего) скрытого слоя не меньше числа примеров:; Функция активациианалитична, ограничена и не тождественно равна нулю; Функция ошибки квадратична. Можем ли мы ослабить какие-то из них? Если какие-то из примеров совпадают и соответствующие метки также одинаковы, теорема обобщается тривиально. Если же метки не совпадают, то нулевая ошибка, вообще говоря, недостижима. Тем не менее, доказательство меняется по большому счёту лишь в том, что вместобудет фигурировать число различных примеров. Рассмотрим сеть сскрытыми слоями, действующую на набор данныхразмера: Для обобщения теоремы 1 на глубокие сети с широким последним скрытым слоем, достаточно обобщить лемму 1. Например, можно воспользоваться следующим результатом (лемма 4.4 изThe loss surface of deep and wide neural networks) Лемма 3. Пустьаналитична, ограничена и не тождественно равна нулю, и пусть. Тогда еслии все строки матрицыразличны, то лебегова мера множестваравна нулю. Третье предположение можно попытаться ослабить с двух сторон. Во-первых, можно требовать меньшего числа нейронов в скрытом слое. В общем случае этот подход не работает: в статьеA note on connectivity of sublevel sets in deep learningдоказывается, что– это наименьшая ширина, при которой теорема выполняется для набора данных общего вида с различными примерами. Тем не менее, для реальных нейронных сетей градиентный спуск нередко находит глобальный минимум, хотя их ширина часто гораздо меньше размера набора данных, на которых они обучаются. Возможно, оценки на минимальную ширину удастся улучшить, если учесть структуру данных: например, если все примеры разбиваются на подмножества с элементами, находящимися близко друг к другу и имеющими одинаковые метки. Во-вторых, можно предположить, что самым широким является не последний скрытый слой, а один из промежуточных:для некоторого. Но тогда задачане выпукла, а значит, изне следует, что, и градиентный спуск, действующий на, не обязан сходиться в точку, в которой(он может застрять в локальном минимуме). Тем не менее, поставив ряд дополнительных условий, теорему 1 можно обобщить: Теорема 2. Пусть– локальный минимуми выполнены следующие условия: аналитична, ограничена, не тождественно равна нулю; производнаянигде не обращается в ноль; ; ; . Тогда– глобальный минимум. Условие 4 необходимо, чтобы изследовало. Отметим, что из условия 4 также следует, что, то есть нейронная сеть должна сужаться, начиная со следующего после самого широкого слоя. Условие 5 необходимо, чтобы в случаепостроить малое возмущение минимума, которое снова является минимумом, но для которого; невырожденный гессиан позволяет применить для этого теорему об обратной функции. Если функция активациине аналитична, то лемма 3 неверна. В самом деле, для однородной(например, для ReLU или leaky ReLU) паттерны активаций,, не меняются при малом возмущении весов. Значит, мы, вообще говоря, не можем найти такое малое возмущение, для которого рангбудет полным. Вместо малого возмущения в работеOn Connected Sublevel Sets in Deep Learningявно строятся пути в пространстве весов, на которых функция потерь не возрастает и достигает нуля. Если такой путь можно построить из произвольной точки, то все (строгие) локальные минимумы глобальны. Оказывается, что для построения такого пути аналитичность функции активации не требуется. Более того, при определённых условиях можно доказать, что из любых двух точек в пространстве весов можно построить соответствующие пути так, чтобы они сходились в одной точке. Это значит, чтомножество подуровнясвязно при любом– эффект, впервые эмпирически обнаруженный в работахLoss surfaces, mode connectivity, and fast ensembling of DNNsиEssentially No Barriers in Neural Network Energy Landscape. Связность множеств подуровня сильнее глобальности всех строгих минимумов. В самом деле, если бы существовал строгий локальный минимум уровня, то для достаточно малогоему бы соответствовала отдельная связная компонента множества подуровня. С другой стороны, если все локальные минимумы глобальны, но изолированы, то множество подуровнянесвязно для достаточно малого. Вместо того, чтобы строить пути, на которых функция потерь достигает нуля, можно строить пути, на которых функция потерь достигает сколь угодно малого значения. Это позволяет обобщить результат на функции потерь, для которых минимум по второму аргументу, ответу сети, не достигается. Пример такой функции – кросс-энтропия. Так мы приходим к следующей теореме: Теорема(On Connected Sublevel Sets in Deep Learning). Пусть выполнены следующие условия: ,строго монотонна и не найдётся ненулевыхс, таких что; выпукла по второму аргументу идля любого; Существует, для которогоидля всех. Тогда если, то Для каждогонайдутся веса, для которых; Множество подуровнясвязно для каждого."
            }
        ]
    },
    {
        "id": "q_0520",
        "question": "Какие две задачи не могут быть одновременно решены авторегрессионными моделями и вариационными автокодировщиками?",
        "answers": [
            "Авторегрессионные модели и вариационные автокодировщики не позволяют одновременно получать скрытые представления для объектов и точно вычислять функцию правдоподобия."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
                "text": "В главеГенеративный подход к классификациимы уже познакомились с типом моделей, которые оценивают совместное распределение. Такие модели называютгенеративными. Для простоты предположим, что мы имеем всего один класс, тогда задача моделированиясводится к задаче моделирования. Научившись моделировать это распределение, мы сможем: генерировать объекты, где– параметры модели; оценивать вероятность встретить данный объектсреди набора наблюдаемых данных; выучивать скрытые представления для объекта. Известными примерами генеративных моделей являются: Авторегрессионные модели: Вариационные автокодировщики: Но оба эти метода не позволяют одновременно: получать скрытые представления для объектов точно вычислять функцию правдоподобия Нормализующие потокиспособны решить обе эти задачи."
            }
        ]
    },
    {
        "id": "q_0521",
        "question": "Как можно сгенерировать сложный объект из простого скрытой переменной?",
        "answers": [
            "Сначала сэмплируют простой объект (скрытую переменную) из распределения p_z, затем применяют к нему генератор — отображение f, которое преобразует базовую функцию плотности к более сложной."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
                "text": "Пусть, гденеизвестно, а. Мы хотим найти отображение, для которогои. Отображениепреобразует базовую функцию плотностик более сложной. С его помощью мы можем генерировать сложный объект путем сэмплинга простого объекта(скрытой переменной) из распределенияи применения «генератора». Обратное отображение«нормализует» сложное распределение, приводя его к простому. Найдя такое отображение, мы сможем генерировать новые объекты, а оценить плотностьпоможет формула преобразования плотности случайной величины. Давайте её вспомним. Пусть,, при этом отображениедифференцируемо, обратимо и. Тогда: где– якобиан отображения."
            }
        ]
    },
    {
        "id": "q_0522",
        "question": "Какой метод обучения используется для модели нормализующего потока, если известна функция правдоподобия?",
        "answers": [
            "Модель обучается методом максимума правдоподобия (ММП), где максимизируется функция правдоподобия на выборке наблюдаемых данных из распределения."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
                "text": "Итак,нормализующий поток– это обратимое дифференцируемое отображение, которое переводит исходные представления объектов в скрытые:и. При этом функция правдоподобиявычисляется по формуле: Умея вычислять функцию правдоподобия, мы можем обучать нашу модельметодом максимума правдоподобия (ММП): где– выборка наблюдаемых данных из распределения. Обычно модель нормализующего потока составляет композицию изне очень сложных отображений, чтобы она была, с одной стороны, достаточно контролируемой, а с другой – достаточно выразительной: Тогда якобиан вычисляется по формуле: Но вычисление якобиана является очень затратной операцией. Для того, чтобы мы могли обучать модели эффективно на высокоразмерных данных (аудио, изображения), необходимо использовать такое отображение, подсчет якобиана которого был бы эффективен! Примером такого отображения являетсяпланарный поток(Planar Flow), где отображениепринадлежит следующему семейству функций: где– обучаемые параметры, а– гладкая нелинейная функция, например,. Якобиан такого отображения можно будет посчитать за. Обозначим Тогда"
            }
        ]
    },
    {
        "id": "q_0523",
        "question": "Какую проблему в задаче детекции аномалий с помощью нормализующих потоков выявили в работе Serrà et al.?",
        "answers": [
            "Проблема связана с чрезмерным влиянием сложности входных данных на значение функции правдоподобия, что ухудшает качество детекции аномалий."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
                "text": "Может показаться, что способность точно и эффективно вычислять функцию правдоподобия может позволить без труда обнаруживать аномалии в данных, что может пригодиться во многих приложениях. Однако в работеKirichenko et al.на примере задачи генерации изображений было показано, что нормализующие потоки выучивают отображение картинок в латентное пространство, основываясь на локальных корреляциях пикселей и графических деталях, а не на семантическом контенте. Из-за этого правдоподобие OOD-объектов может быть выше, чем правдоподобие in-distribution сэмплов. Однако позже было предложено использовать ряд эвристик для того, чтобы улучшить способность к детекции аномалий за счет подсчета значения функции правдоподобия: Использовать значение правдоподобия второй модели потока, обученного на отличном от исходного датасете (например, ImageNet при исходном CelebA). А затем вычислять отношенение этих двух значений для вынесения вердикта об аномальности объекта.Schirrmeister et al. В работеSerrà et al.показали, что проблема качества нормализующих потоков в задаче детекции аномалий связана с чрезмерным влиянием сложности входных данных на значение функции правдоподобия. Поэтому авторы предложили использовать в качестве поправки размер сжатого изображения с помощью одного из алгоритмов компрессии (JPEG2000/PNG)."
            }
        ]
    },
    {
        "id": "q_0524",
        "question": "Какие два ключевых свойства выделяют нормализующие потоки среди других семейств генеративных моделей?",
        "answers": [
            "Нормализующие потоки выделяются обратимостью и способностью вычислять правдоподобие объекта."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
                "text": "Обратимся к статьеBond-Taylor et al., в которой приводится количественный анализ всех существующих семейств генеративных моделей в задаче генерации изображений из датасета CIFAR-10. В таблице выше указано, насколько представители каждого из популярных семейств генеративных моделей эффективны в следующих аспектах решения задачи: скорость обучения; скорость генерации; число обучаемых параметров; разрешение генерируемого изображения; ограничение на форму якобиана; возможность вычислять правдоподобие объекта; FID (Fréchet Inception Distance) тестовой выборки; Отрицательный логарифм правдоподобия тестовой выборки. За расшифровкой обратимся к таблице ниже: Подведя итог, можно сказать, что нормализующие потоки: требуют очень много времени на обучение, так как при обучении проводятся нетривиальные неоптимизированные вычисления; имеют скорость генерации, сравнимую с GAN-ами; менее эффективны по соотношению качество/число параметров, чем GAN-ы и диффузионные модели; позволяютбыстровычислять точное значение функции правдоподобия объекта; обладают сравнительно неплохим качеством генерации, проигрывающим GAN-ам и диффузионным моделям. Итак, нормализующие потоки явно выделяются среди других семейств генеративных моделей своими свойствами – обратимостью и способностью вычислять правдоподобие объекта. Но если для решения задачи они не требуются, то имеет смысл попробовать другие модели – в первую очередь, GAN-ы и диффузионные модели."
            }
        ]
    },
    {
        "id": "q_0525",
        "question": "Какие два основных типа пользовательского фидбека различают при построении рекомендательных систем?",
        "answers": [
            "Различают явный и неявный фидбек. Явный фидбек отражает степень интереса пользователя к объекту (например, рейтинги, лайки), а неявный — косвенные действия (просмотры, клики, добавление в закладки)."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Допустим, мы работаем в сервисе рекомендаций фильмов и перед нами стоит задача подобрать для каждого пользователя набор наиболее релевантных фильмов. Пользователь может разными способами провзаимодействовать с фильмом: посмотреть его, оставить отзыв, поставить оценку (например, от 1 до 5). В этом параграфе мы будем строить рекомендации на основе матрицы оценок user-item. Её строки соответствуют объектам, а столбцы – пользователям. На-й позиции матрицы мы ставим либо пропуск, либо оценку, выставленную-му объекту-м пользователем. Разумеется, не все оценки нам известны: вряд ли каждый пользователь имел возможность ознакомиться с каждым объектом. В процессе решения задачи мы будем пытаться восстановить оценки на местах пропусков. Сделав это, мы сможем, например, порекомендовать пользователю те объекты, которые он ещё не смотрел, но предсказанная оценка которых для этого пользователя максимальна. Все типы взаимодействия пользователей с объектами мы можем рассматривать как пользовательский фидбек. Обычно различаютявный(explicit) инеявный(implicit) виды фидбека. Фидбек называется явным, если он отражает степень интереса пользователя к объекту. Например, к этому типу относят рейтинги, лайки и дизлайки. Такого фидбека обычно мало, он поступает только от тех пользователей, которые соглашаются нам его дать. Обычно гораздо больше информации имеется о неявных предпочтениях – просмотры, клики, добавление в закладки. Но если пользователь, например, посмотрел фильм, мы ещё не можем сделать вывод, что он ему понравился. Мы можем лишь утверждать, что до просмотра этот фильм казался ему достаточно интересным. Поэтому обычно неявная обратная связь более шумная, чем явная. Для начала научимся работать с явным фидбеком."
            }
        ]
    },
    {
        "id": "q_0526",
        "question": "Какой алгоритм рассматривается как более эффективная альтернатива SVD и градиентному спуску для восстановления латентных векторов в разреженной матрице оценок?",
        "answers": [
            "В тексте рассматривается алгоритм Alternating Least Squares (ALS) как более эффективный подход по сравнению с SVD и стохастическим градиентным спуском для решения задачи матричной факторизации при разреженных данных."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Вернёмся к задаче восстановления матрицы оценок и предположим, что каждый пользователь и объект можно закодировать набором изскрытых признаков, а оценка-го объекта-м пользователем равна скалярному произведению соответствующих векторов скрытых представленийи. Тогда если бы наша матрица оценок была заполнена полностью, её можно было бы представить в виде произведений двух матрици, составленных по столбцам из скрытых представлений пользователей и объектов: Правда, в таком случае нам бы и не требовалось ничего решать: мы могли бы просто рекомендовать пользователю объекты с самыми высокими оценками в соответствующей строке. Но суровая реальность такова, что зачастую матрица оценок сильно разрежена. Мы можем поступить следующим образом: восстановить латентные векторы для пользователей и объектов по имеющемуся набору оценок, после чего предсказать оценки для всех отсутствующих позиций. В параграфе, посвящённомматричной факторизации, мы уже обсуждали способы решения данной задачи с помощью SVD и стохастического градиентного спуска. У SVD есть существенные недостатки: из-за большого количества пропусков в матрице полученное решение будет слишком шумным, а кроме того, его придется каждый раз рассчитывать заново при добавлении новых пользователей или объектов. Градиентный спуск не имеет данных проблем, но тоже не очень практичен. В этом параграфе мы рассмотрим более эффективный алгоритм, называемыйAlternating Least Squares(ALS)."
            }
        ]
    },
    {
        "id": "q_0527",
        "question": "Как предсказываются рейтинги в описанной модели?",
        "answers": [
            "Рейтинги предсказываются как скалярное произведение скрытых представлений пользователей и объектов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Пусть, как и раньше,– скрытые представления пользователей и объектов соответственно размерности. Запишем эти векторы по строкам в матрицыиразмераисоответственно, где– количество пользователей, а– количество объектов. Обозначим черезмножество таких парпользователей и объектов, для которых имеются явно проставленные оценки. Предсказывать рейтинги мы будем как скалярное произведение скрытых представлений: В результате мы приходим к следующей задаче оптимизации. Мы хотим научиться как можно лучше приближать известные рейтинги: Добавив регуляризацию получаем следующую функцию потерь:"
            }
        ]
    },
    {
        "id": "q_0528",
        "question": "Какой алгоритм оптимизации позволяет независимо вычислять векторы для каждого объекта, используя параллельные вычисления?",
        "answers": [
            "Это алгоритм попеременной оптимизации, где на каждом шаге фиксируются либо скрытые представления пользователей, либо объектов, а для оставшихся решается задача L2-регуляризованной регрессии с аналитическим решением. Векторы для каждого объекта вычисляются независимо, что позволяет эффективно распределять вычисления между машинами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Оптимальные параметры можно найти с помощью хорошо знакомого нам градиентного спуска, но есть более быстрые и надёжные способы. Если мысленно заморозить параметры, соответствующие латентным факторам пользователей, задача оптимизации латентных представлений объектов сведётся к задаче наименьших квадратов, для которой мы знаем точное решение. Итоговый процесс оптимизации функции потерь будет иметь следующий вид. В цикле до сходимости: Фиксируем матрицу(скрытые представления пользователей); Решаем задачу L2-регуляризованной регрессии для каждого товара и находим оптимальную матрицу; Фиксируем матрицу(скрытые представления объектов); Решаем задачу L2-регуляризованной регрессии для каждого пользователя и находим оптимальную матрицу; Решение, получаемое путём попеременного вычисления точных аналитических решений, обычно точнее тех, что получаются с помощью наивного градиентного спуска. Более того, данное решение имеет эффективную реализацию, позволяющую использовать преимущества параллельных вычислений. Для лучшего понимания распишем каждый шаг данного алгоритма оптимизации: Раскроем квадратичный член: В первой сумме константы, они уходят. Из второй и третьей возьмём только те слагаемые, в которых участвует. Из четвёртой остается только член с, так как всенезависимы. Последняя сумма пропадает, так какинезависимы: В первой сумме индексфиксирован, поэтомуможно вынести за знак суммы: Объединим второй и третий члены формулы, вынесем умножение наза скобки: Теперь воспользуемся тем, что и выпишем ответ: Таким образом, мы получили аналитическое выражение для вычисления каждогона шаге алгоритма. Отметим, что каждый вектормы можем вычислить независимо от других. Данное наблюдение позволяет нам использовать всю мощь параллельных вычислений для эффективного решения оптимизационной задачи. Распределив данные так, что на каждой вычислительной машине хранятся вседля некоторого подмножества, на одной итерации алгоритма мы можем параллельно вычислить все. На следующей итерации аналогичным образом вычисляем все."
            }
        ]
    },
    {
        "id": "q_0529",
        "question": "Как называется компонента фидбека, которая позволяет заполнить всю матрицу user-item, используя факт взаимодействия?",
        "answers": [
            "Эта компонента называется предпочтением (preference). Она позволяет поставить 1 на позициях, где пользователь положительно взаимодействовал с объектом, и 0 — где взаимодействие было негативным или отсутствовало."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Оригинальная статья Раньше мы работали с матрицейкак с матрицей рейтингов, явно проставленных пользователем. Как мы говорили выше, такого фидбека обычно довольно мало, а куда больше неявного фидбека. При этом количество данных может быть критичным при работе с такими разреженными структурами, как матрицы рейтингов, поэтому хочется научиться работать и с неявным фидбеком тоже. Неявным фидбеком является в том числе и факт взаимодействия, поэтому мы можем заполнить всю матрицу user-item целиком: на тех позициях, где пользователь положительно взаимодействовал с объектом, поставим, а на тех, где взаимодействие было негативным или его вообще не произошло, поставим. Эта компонента фидбека называется предпочтением (preference): Тем самым мы избавились от пропусков в матрице, но использовали не всю информацию. Согласитесь, если один пользователь посмотрел часовое видео польностью, а другой выключил после 5 минут, несправедливо считать, что это видео им понравилось в одинаковой степени. Введём ещё степень уверенности (confidence), отражающую уверенность в оценке пользователя: где– некоторая константа. На местах пропусков мы явно проставляем. На остальных позициях мы можем сами регулировать степень уверенности в зависимости от фидбека пользователя. Рассмотрим следующую функцию потерь: Она позволяет: Учитывать неявный фидбек, которого обычно на порядок больше, чем явного, Регулировать степень уверенности в действиях пользователей. Распишем нашу функцию потерь по аналогии с ALS и приведем к форме: Разобьём сумму на 2 части. В первой будет сумма по тем элементам, с которыми у пользователя не было положительного взаимодействия. Во второй – сумма по всем остальным элементам. Также заметим, что во втором множителе суммирование имеет смысл только по ненулевым элементам: Заметим, что в первой сумме всебудут равны 1 (так как везде). Прибавим и вычтем единицу кво второй сумме и разобьем её на две компоненты. Вторый из них будет сумма по всем, где. Объединив её с первой суммой, получимпросто: Заметим, что произведениеникак не зависит от. Мы можем посчитать его один раз для всехперед очередной итерацией. В остальном же мы точно так же, как и в случае с обычным ALS, можем распределить данные так, чтобы на одной машине содержались все, необходимые для обновления, хранящихся на этой машине, и сделать следующий шаг оптимизации нашей функции потерь."
            }
        ]
    },
    {
        "id": "q_0530",
        "question": "Какие два параметра играют роль априорных усреднённых оценок в усложнённой версии моделей ALS и Implicit ALS?",
        "answers": [
            "В усложнённой версии моделей роль априорных усреднённых оценок играют параметры для пользователя и для объекта соответственно."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Обе модели: и ALS, и Imlicit ALS – можно несколько усложнить, вместорассмотрев. В таком случаеииграют роль некоторых априорных усреднённых оценок пользователя и объекта соответственно, аявляется глобальной априорной константой. В модели IALS мы обычно полагаем элементыравнымиво всех случаях, когда имело место взаимодействие, но можем использовать и другие значения, в том числе зависящие от того, что ещё нам известно о пользователях и объектах. Для уверенностидля IALS необязательно использоватьв качестве значения по умолчанию. Например, события «пользователь не посмотрел популярный фильм» и «пользователь не посмотрел редкий фильм» могут иметь для нас разный вес."
            }
        ]
    },
    {
        "id": "q_0531",
        "question": "Какой метод оптимизации использовался в подходе, предложенном Саймоном Фанком для моделирования рейтингов?",
        "answers": [
            "В подходе Саймона Фанка оптимизация производилась с помощью стохастического градиентного спуска."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Этот подход получил широкую известность после конкурса Netflix Prize в 2006 году.Пост Саймона Фанка про участие в Netflize Prize Фанк предложил моделировать рейтинг как. Однако, в отличие от ALS, оптимизация производилась с помощью стохастического градиентного спуска. Правила обновления весов выглядели следующим образом: Этот подход не получил большой популярности, так как градиентный спуск, в отличие от ALS, намного сложнее распараллелить."
            }
        ]
    },
    {
        "id": "q_0532",
        "question": "Как можно учесть неявный фидбек в модели рекомендательной системы?",
        "answers": [
            "В модели пользователь представляется скрытым представлением и дополнительным слагаемым, которое отражает историю его неявных взаимодействий с айтемами. При этом вектора, используемые для учета неявного фидбека, не совпадают с основными векторами айтемов, а являются своего рода «неявными» векторами."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Оригинальная статья Ранее мы отдельно рассматривали факторизации для явного и неявного фидбека. Но, ограничиваясь только одним типом фидбека, мы теряем много информации. Если мы работаем над стриминговым сервисом, то в качестве неявного фидбека мы можем взять, например, историю фильмов, взятых в прокат. Такие данные не предоставляют нам явных оценок пользователей, но позволяют выявить неявные предпочтения. Учесть неявный фидбек в модели можно следующим образом: В данной модели пользователь представлен скрытым представлением, а также слагаемым, отражающим историю неявных взаимодей с айтемами:. Важно отметить, что векторане совпадают с векторами. Это своего рода «неявные» вектора айтемов."
            }
        ]
    },
    {
        "id": "q_0533",
        "question": "Как предлагается модифицировать функцию потерь для учёта изменения мнения пользователя со временем?",
        "answers": [
            "Для учёта изменения мнения пользователя со временем предлагается отсортировать взаимодействия по времени, разбить события на бакеты и на основе этого модифицировать функцию потерь."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Оригинальная статья Особенностью всех рассмотренных на данный момент разложений является отсутствие учёта порядка просмотра объектов. Однако, как показывает практика, со временем пользователь может менять своё мнение о тех или иных айтемах. Тогда, отсортировав взаимодействия по времени, мы можем разбить события на бакеты и модифицировать приведённую выше функцию потерь, в которой таргет выражается следующим образом:"
            }
        ]
    },
    {
        "id": "q_0534",
        "question": "Какой метод оптимизации используется для параметров линейной разреженной модели?",
        "answers": [
            "Для оптимизации параметров используется функция потерь MSE с L1- и L2-регуляризаторами, а сама задача решается методом покоординатного спуска."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Оригинальная статья Описанные выше методы демонстрируют хорошее качество, однако требуют больших усилий для эффективной работы в онлайн сервисах. Возникает потребность в лёгких моделях, эффективность которых значительно выше, но качество которых не сильно хуже. Для этого была предложена линейная разреженная модель. Итак, пусть– бинарная матрицаuser-item взаимодействий, например, матрица кликов/показов. Будем определять ответ алгоритмакак взвешивание событий из истории пользователя: При этом наложим ограничение. В такой постановке мы будем учить модель находить «похожие» объекты. Добавим ещё условие, которое позволит нам избежать элементарного решения – единичной матрицы.В результате весвыступает в качестве некоторой меры схожести-го и-го объектов. Осталось определиться с методом оптимизации данных параметров. Для оптимизации используется функция потерь MSE с- и-регуляризаторами: Можно заметить, что задачу можно разбить нанезависимых по строкам матрицы: Данную задачу можно решать покоординатным спуском: Фиксируем все строки, кроме одной координаты; переходим в оптимум по; переходим к следующей координате; повторять до сходимости. Применение данной модели выглядит следующим образом: Рассчитываем вектор взаимодействий пользователя; Считаемдля всех непросмотренных объектов; Отбираем топнепросмотренных объектов по. Так как в задаче оптимизации мы пользуемся-регуляризацией, матрицаполучается разреженной. Матрица просмотровтоже разреженная (по определению). Эти обстоятельства позволяют заметно улучшить эффективность применения модели."
            }
        ]
    },
    {
        "id": "q_0535",
        "question": "Какой основной недостаток методов, основанных на матричной факторизации?",
        "answers": [
            "Основной недостаток заключается в том, что эти методы используют только информацию о взаимодействии пользователей и объектов, но не учитывают атрибуты самих пользователей и объектов."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "В этом параграфе мы рассмотрели некоторые рекомендательные модели на основе матричных факторизаций. Такие модели редко используется в чистом виде для формирования рекомендательной выдачи. Обычно результаты матричной факторизации используются для генерации кандидатов в рекомендации, когда из сотен тысяч и миллионов объектов необходимо отобрать небольшое количество (например, сотни) самых релевантных. Для генерации кандидатов требуется перемножить вектор пользователя с вектором каждого из сотен тысяч объектов и отобрать топ самых релевантных. В онлайн-сервисах, когда время формирования рекомендаций составляет несколько сотен миллисекунд, нет возможности при каждом запросе рассчитывать релевантность каждого объекта для данного пользователя. Оптимизировать поиск можно с помощью инструментов для поиска ближайших соседей. Для любой функции близости, в том числе и для скалярного произведения, можно построить индекс – структуру данных, с помощью которой для любого пользователя мы сможем быстро приближённо, но зато быстро искать «ближайшие» объекты. В результате, принцип работы выглядит следующим образом: обучаются эмбеддинги объектов и пользователей; для представлений эмбеддингов строится индекс; в рантайме по вектору пользователя происходит приближённый поисксамых релевантных объектов; таким образом генерируется список кандидатов в рекомендации; дальше список кандидатов обрабатывается с помощью более хитрых методов машинного обучения. Подробнее о том, как быстро искать ближайших соседей, вы можете узнать в параграфе посвященномметрическим методам Помимо генерации кандидатов, полученные представления можно использовать в качестве признаков в более сложных моделях. Основной недостаток методов, основанных на матричной факторизации, состоит в том, что они используют лишь информацию о взаимодействии пользователей и объектов, но не о них самих. В следующем параграфе мы рассмотримконтентные методы, которые используют атрибуты объектов и пользователей."
            }
        ]
    },
    {
        "id": "q_0536",
        "question": "Какие алгоритмы и методы упоминаются в контексте рекомендательных систем?",
        "answers": [
            "В контексте рекомендательных систем упоминаются алгоритмы Implicit ALS, SVD++, TimeSVD++ и SLIM, а также участие в конкурсе Netflix Prize."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
                "text": "Статьяпро Implicit ALS Статьяпро SVD++ Статьяпро TimeSVD++ Статьяпро SLIM ПостСаймона Фанка про участие в конкурсе Netflix Prize"
            }
        ]
    },
    {
        "id": "q_0537",
        "question": "Какие проблемы возникают при использовании обычной многослойной сети для классификации изображений, если в первом слое установить слишком большое количество нейронов?",
        "answers": [
            "При слишком большом количестве нейронов в первом слое (Cout) возникает чрезмерное количество параметров, что приводит к риску переобучения и сложностям в оптимизации модели."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
                "text": "Наверное, самый простой способ построить нейронную сеть для решения задачи классификации на наших данных — это «развернуть» нашу картинку в вектор, а затем использовать обычную многослойную сеть с кросс-энтропией в качестве лосса. Однако, такой подход имеет несколько недостатков. В первом слое у нас получаетсяHxWxCxCoutпараметров, где Cout — это количество нейронов в первом слое. Если поставитьCoutслишком маленьким, мы рискуем потерять много важной информации, особенно, если рассматривать картинки размером, например, 1920x1080. Если же выставить Cout большим, рискуем получить слишком много параметров (а это только первый слой), а с этим и все вытекающие проблемы — переобучение, сложность оптимизации и так далее. Что здесь имеется в виду под «структурой»? Попробуем объяснить на примере. Для этого рассмотрим картинку щеночка: Если мы сдвинем картинку на несколько пикселей, то мы все еще будем уверены в том, что это щенок: Точно также мы останемся неизменны в своем мнении, если картинку отмасштабировать: или повернуть/развернуть: Получается, что нейронная сеть должна «сама» понять, что ее ответ должен быть инвариантен к описанным преобразованиям. Но, обычно, это достигается за счет увеличения количества нейронов в скрытых слоях (как мы можем помнить изuniversal approximation theorem), что и так для нас — головная боль из-за первого пункта. С частью этих проблем нам поможет новый «строительный блок» — свёртка. О ней в следующем разделе."
            }
        ]
    },
    {
        "id": "q_0538",
        "question": "Как выглядит градиент по весам ядра в одномерной свёртке при её представлении в виде матричного умножения?",
        "answers": [
            "Градиент по весам ядра равен произведению градиента по выходу на матрицу, которая соответствует свёртке с симметричным исходному ядром и дополнением входного вектора нулями."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
                "text": "Поговорим о том, как через свёрточный слой протекают градиенты. Нам нужно будет научиться градиент по выходу превращать в градиент по входу и в градиент по весам из ядра. Начнём с иллюстрации для одномерной свёртки с одним входным каналом, ядром длиныс дополнением по бокам нулями. Заметим, что её можно представить в виде матричного умножения: Обозначим последнюю матрицу через, а ядро свёртки через. Что происходит с градиентом при переходе через матричное умножение, мы уже отлично знаем. Градиент по весам равен Разберёмся, что из себя представляет умножение насправа. Эта матрица имеет вид Она тоже соответствует свёртке, только: с симметричным исходному ядром; с дополнением векторанулями (это как раз соответствует неполным столбцам: можно считать, что «выходящие» за границы матрицы и отсутствующие в ней элементы умножаются на нули). Вопрос на подумать. Поменяется ли что-нибудь, если исходный вектор не дополнять нулями? Рассмотрим теперь двумерную свёртку, для простоты нечётного размера и без свободного члена Продифференцируем по: Разберёмся с производной. Во всей большой сумме из определения свёртки дляэлементможет встретиться в позицияхпри,и всевозможных, причём это возможно лишь если,(для всех остальныхпроизводная понулевая). Соответствующий коэффициент прибудет равен. Таким образом, производная будет иметь вид: Легко заметить, что это тоже свёртка, но поскольку индексыви встоят с разными знаками, получаем, что Продифференцируем по: В формуле дляэлементможет встретиться в позициях, для,, с коэффициентами(для любых). Значит, производная будет иметь вид: В этой формуле тоже нетрудно узнать свёртку: Вопрос на подумать. Если всё-таки есть свободные члены, как будет выглядить градиент по?"
            }
        ]
    },
    {
        "id": "q_0539",
        "question": "Какой метод понижения разрешения карты признаков экспериментально показал наилучшие результаты в большинстве архитектур нейронных сетей?",
        "answers": [
            "Метод max pooling (взятие максимума в окне 2x2), который берёт максимум для каждого канала независимо. Этот подход увеличивает receptive field в 2 раза и позволяет сохранять информацию лучше, чем простое выкидывание пикселей."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
                "text": "Наигравшись с нашими мысленными экспериментами, давайте обратимся к опыту инженеров и исследователей, который копился с 2012 года –alexnet. Он поможет нам разобраться с тем, как эффективней всего строить картиночные нейронки. Здесь будут перечислены самые важные (на момент написания и по мнению автора) блоки. Каждая изсвёрток очередного свёрточного слоя — это новая карта признаков для нашего изображения, и нам, конечно, хотелось бы, чтобы таких карт было побольше: ведь это позволит нам выучивать больше новых закономерностей. Но для картинок в высоком разрешении это может быть затруднительно: слишком уж много будет параметров. Выходом оказалось использование следующей эвристики: сначала сделаем несколько свёрток сканалами, а затем как-нибудь уменьшим нашу карту признаков в 2 раза и одновременно увеличим количество свёрток во столько же. Посчитаем, как в таком случае изменится число параметров: было, стало, то есть, ничего не изменилось, а количество фильтров удвоилось, что приводит к выучиванию более сложных зависимостей. Осталось разобраться, как именно можно понижать разрешение картинки. Тривиальный способ — взять все пиксели с нечетными индексами. Такой подход будет работать, но, как может подсказать здравый смысл, выкидывать пиксели — значит терять информацию, а этого не хотелось бы делать. Здесь есть много вариантов: например, брать среднее/максимум по обучаемым весам в окне2x2, которое идет по карте признаков с шагом 2. Экспериментально выяснилось, что максимум — хороший выбор, и, в большинстве архитектур, используют именно его. Обратите внимание, что максимум берется для каждого канала независимо. Еще одно преимущество — увеличение receptive field. Получается, что он увеличивается в 2 раза: Операция понижения разрешения со взятием максимума в окне называетсяmax pooling, а со взятием среднего —average pooling. Вопрос на подумать. Как будет преобразовываться градиент во время error backpropagation для maxpool с окном и шагом 2x2? А для average pool? Кстати, ещё один способ уменьшать размер карт признаков по ходу применения свёрточной сети — использованиеstrided convolution, в которых ядро свёртки сдвигается на каждом шаге на некоторое большее единицы число пикселей (возможно, разное для осейHиW; обычная свёртка получается, если установить параметрstride=(1,1)). Как свёрточные слои, так и пулинг превращают картинку в «стопку» карт признаков. Но если мы решаем задачу классификации или регрессии, то в итоге нам надо получить число (или вектор логитов, если речь про многоклассовую классификацию). Один из способов добиться этого — воспользоваться тем, что свёртка без дополнения нулями и пулинг уменьшают размер карты признаков, и в итоге при должном терпении и верном расчёте мы можем получить тензор1x1xC(финальные, общие признаки изображения), к которому уже можно применить один или несколько полносвязных слоёв. Или же можно, не дождавшись, пока пространственные измерения схлопнутся, «растянуть» всё в один вектор и после этого применить полносвязные слои (именно так, как мы не хотели делать, не правда ли?). Примерно так и происходило в старых архитектурах (alexnet, vgg). Вопрос на подумать. Попробуйте соорудить конструкцию из свёточных слоёв и слоёв пулинга, превращающую изображение размера128x128x3в тензор размера1x1xC. Но у такого подхода есть как минимум один существенный недостаток: для каждого размера входящего изображения нам придётся делать новую сетку. Позднее было предложено следующее: после скольких-то свёрточных слоёв мы будем брать среднее вдоль пространственных осей нашего последнего тензора и усреднять их активации, а уже после этого строить MLP. Это и есть Global Average Pooling. У такого подхода есть несколько преимуществ: радикально меньше параметров; теперь мы можем применять нейронку к картинку любого размера; мы сохраняем «магию» инвариантности предсказаний к сдвигам. Оказывается, что, если мы будем бесконтрольно стекать наши свёртки, то, несмотря на использование relu и batch normalization, градиенты все равно будут затухать, и на первых слоях будут почти нулевыми. Интересное решение предлагают авторы архитектуры resnet: давайте будем «прокидывать» признаки на предыдущем слое мимо свёрток на следующем: Таким образом получается, что градиент доплывет даже до самых первых слоев, что существенно ускоряет сходимость и качество полученной модели. Вопрос: почему именно сумма? Может, лучше конкатенировать? Авторы densenet именно такой подход и предлагают (с оговорками), получая результаты лучше, чем у resnet. Однако, такой подход получается вычислительно сложным и редко используется на практике."
            }
        ]
    },
    {
        "id": "q_0540",
        "question": "Какая архитектура стала первой свёрточной нейронной сетью, показавшей SOTA результаты на классификации цифр MNIST?",
        "answers": [
            "Это была первая свёрточная нейронная сеть, использовавшая свёрточные слои с ядром 5x5, активацию tanh и average pool вместо max pool."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
                "text": "Дисклеймер: это мнениеодногоавтора. Приведённые в этом разделе вехи связаны преимущественно с архитектурами моделей, а не способом их оптимизации. Здесь перечислены знаковые архитектуры, заметно повлиявшие на мир свёрточных нейронных сетей в задаче классификации картинок (и не только). К каждой архитектуре указана ссылка на оригинальную статью, а также комментарий автора параграфа с указаниемключевыхнововведений. Значение метрики error rate на одном из влиятельных датасетовimagenetуказано для финального ансамбля из нейросетей, если не указано иное. Зачем это полезно изучить (вместе с чтением статей)? Основных причин две: Общее развитие. Полезно понимать, откуда взялись и чем мотивированы те или иные компоненты. Этот вопрос задают на собеседовании, когда не знают, что еще спросить 😃 Ссылка на статью 7 слоев Первая свёрточная нейронная сеть, показавшая SOTA (State Of The Art) результаты на задаче классификации изображений цифр MNIST. В архитектуре впервые успешно использовались свёрточные слои с ядром5x5. В качестве активации использовался tanh, а вместо max pool в тот момент использовался average. Ссылка на статью 11 слоев Первая CNN (Convolutional Neural Network), взявшая победу на конкурсе imagenet. Автор предложил использовать ReLU вместо сигмоид (чтобы градиенты не затухали) и популяризовал max-pool вместо average. Что самое важное, обучение модели было перенесено на несколько GPU, что позволило обучать достаточно большую модель за относительное небольшое время (6 дней на двух видеокартах того времени). Также автор обратил внимание, что глубина нейросети важна, так как выключение хотя бы одного слоя стабильно ухудшало качество на несколько процентов. Ссылка на статью В статье не привели интересных SOTA результатов, но зато ввели два очень популярных впоследствии модуля. Первый — это GAP (Global Average Pooling), который стоит после последнего свёрточного слоя и усредняет все активации вдоль пространственных осей. Второй — стекинг1x1свёрток поверх3x3, что эквивалентно тому, что вместо линейной свёртки используется полносвязный слой. Ссылка на статью 19 слоев Авторы предложили декомпозировать большие свёртки (5x5,7x7и выше) на последовательное выполнение свёрток3x3с нелинейностями между ними. Впоследствии, за нечастым исключением, свёртки3x3стали стандартом в индустрии (вместе со свёртками1x1). Ссылка на статью 22 слоя Ввели inception слой, просуществовавший довольно продолжительное время. Сейчас сам слой уже не используется, но идея лежащая в его основе, эксплуатируется. Идея следующая: будем параллельно применять свёртки с разным пространственными размерами ядер, чтобы можно было одновременно обрабатывать как low-, так и high-level признаки. Еще полезной для сообщества оказалась идея с dimensionality reduction: перед тяжелой операцией поставим свёртку 1x1, чтобы уменьшить количество каналов и кратно ускорить вычисление. Ссылка на статью Авторы внедрили вездесущую batch normalization, которая стабилизирует сходимость, позволяя увеличить шаг оптимизатора и скорость сходимости. Применив идею к архитектуре inception, они превзошли человека на imagenet. Ссылка на статью В статье предложили использовать инициализацию весов, берущую во внимание особенность активации ReLU (в предыдущих работах предполагалось, что, что, очевидно, нарушается для). Применение этой и других «свистелок» на VGG19 позволило существенно уменьшить ошибку на imagenet. Ссылка на статью 152 слоя Архитектура, которая на момент написания этого параграфа до сих пор бейзлайн и отправная точка во многих задачах. Основная идея — использование skip connections, что позволило градиенту протекать вплоть до первых слоев. Благодаря этому эффекту получилось успешно обучать очень глубокие нейронные сети, например, с 1202 слоями (впрочем, результаты на таких моделях менее впечатляющие, чем на 152-слойной). После этой статьи также стали повсеместно использоваться GAP и уменьшение размерности свёртками1x1. Ссылка на статью Очень популярная модель для быстрого инференса (на мобильных устройствах или gpu). По качеству хоть и немного проигрывает «монстрам», но в индустрии, оказывается, зачастую этого достаточно (особенно если брать последние варианты модели). Основная деталь — это использование depthwise convolutions: параллельный стекинг свёрток3x3x1x1— то есть таких, в которых вычисление для каждогоканала просходит только на основе признаков одногоканала. Чтобы скомбинировать фичи между каналами, используется классическая1x1свёртка. Ссылка на статью Одна из первых моделей, полученных при помощи NAS (Neural Architecture Search), которая взяла SOTA на imagenet. После этого, модели, где компоненты подбирались вручную, уже почти не показывали лучших результатов на классических задачах."
            }
        ]
    },
    {
        "id": "q_0541",
        "question": "Как можно адаптировать свёрточную нейронную сеть для задачи сегментации изображений?",
        "answers": [
            "Для сегментации нужно убрать в конце сети слои GlobalAveragePool или flatten, чтобы модель могла делать предсказания для каждого пикселя отдельно. При этом необходимо продумать обработку maxpool-слоев."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
                "text": "Свёрточными нейронными сетями можно решать большой спектр задач, например: Сегментация. Если убрать в конце слои GlobalAveragePool или flatten, то можно делать предсказания для каждого пикселя в отдельности (подумайте, что делать, если в сети есть maxpool) — получаем сегментацию картинки. Проблема — долгая и дорогая разметка. Детекция. Часто намного дешевле получить разметку объектов обрамляющими прямоугольниками. Здесь уже можно для каждого пикселя предсказывать размеры прямоугольника, который обрамляет объект, к которому принадлежит пиксель. Проблемы — нужен этап агрегации прямоугольников + много неоднозначностей во время разметки + много эверистик на всех этапах + данных нужно больше. Понимание видео. Добавляем в тензор новый канал — временной, считаем четырехмерные свёртки — и получаем распознавание сцен на видео. Metric learning. Часто мы не можем собрать все интересующие нас классы, например, в задаче идентификации человека по лицу (или товара на полке). В этом случае используют такой трюк: научим модель в некотором смысле (обычно по косиносному расстоянию) разделять эмбеддинги существующих классов (уникальных людей). Если на руках была репрезентативная выборка, то модель, скорее всего (а обычно — всегда), выучит генерировать дискриминативные эмбеддинги, которые уже позволят различать между собой ранее невиданные лица. и многое другое"
            }
        ]
    },
    {
        "id": "q_0542",
        "question": "Какие основные блоки присутствуют почти в каждой нейронной сети для обработки изображений?",
        "answers": [
            "В тексте упоминается, что в почти каждой картиночной нейронной сети есть определённые основные блоки, но их конкретные названия или описания не приводятся."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
                "text": "Мы разобрались, что для картинок эффективно использовать свёрточные фильтры в качестве основных операторов. Выяснили, какие основные блоки есть почти в каждой картиночной нейронной сети и зачем они там нужны. Разобрались, какие методы регуляризаторы сейчас самые популярные и какая за ними идея. И наконец — рассмотрели знаковые архитектуры в мире свёрточных нейронных сетей."
            }
        ]
    },
    {
        "id": "q_0543",
        "question": "Какие шаги включает в себя процесс построения равномерных оценок?",
        "answers": [
            "Процесс включает оценку супремумом, применение неравенства МакДайармида, оценку математического ожидания супремума с помощью симметризации и выход на сложность Радемахера."
        ],
        "ground_truth_docs": [
            {
                "url": "https://education.yandex.ru/handbook/ml/article/obobshayushaya-sposobnost-klassicheskaya-teoriya",
                "text": "Напомним, что построение равномерных оценок проходило в несколько шагов: Оценка супремумом Применение неравенства макДайармида: Оценка матожидания супремума (жёлтое слагаемое выше) с помощью симметризации с дальнейшим выходом на сложность Радемахера: На каждом шаге предыдущая величина оценивается сверху, и потенциально каждое из этих неравенств может оказаться слишком слабым и привести к бессмысленной оценке. Давайте это проиллюстрируем. Выше мы уже отмечали, что если класссодержит модель, для котороймал, авелик, то равномерная оценка становится бессмысленной. По этой причине, имеет смысл выбирать класскак можно более маленьким. Самым лучшим из возможных классов мог бы быть класс моделей, к которым сходится наш алгоритм обучения с высокой вероятностью. Рассмотрим случай, близкий к идеальному: тот, в котором существует, для которого при любыхимеем. Иными словами, предположим, что все модели классахорошо обобщают. В этом случае оценка выше близка к идеальной: Но что будет, если мы начнём честно воспроизводить процесс построения равномерных оценок? После второго шага мы получаем оценку вида которая не сильно хуже предыдущей, но в которой всё равно появилось лишнее слагаемое. Но допустим, что мы хотим честно проделать третий шаг процедуры получения равномерных оценок. Для этого нам необходимо было оценить матожидание супремума, которое после симметризации получает вот такую верхнюю оценку: Таким образом, малость истинного риска не гарантирует малость эмпирического риска на любом наборе данных. Так, авторы статьиUniform convergence may be unable to explain generalization in deep learningпредъявили пример, в котором для любогосуществует модель, такая что, но при этомималы. Иллюстрация такой ситуации приведена в начале параграфа. Тогдавелик, и оценки теряют смысл. К счастью, даже эта фундаментальная проблема не ставит крест на равномерных оценках. Так, работыUniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign OverfittingиStability and Deviation Optimal Risk Bounds with Convergence Rateрассматривают равномерную оценку в классе интерполирующих моделей, то есть, имеющих нулевой эмпирический риск: Для таких моделей контрпример выше не работает."
            }
        ]
    }
]