import asyncio
import re
import json
from typing import Any, Dict, List, Optional, Tuple, Union
from config import *
import requests
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

from langchain_openai import ChatOpenAI

from sentence_transformers import CrossEncoder

CROSS_ENCODER_MODEL = "jinaai/jina-reranker-v2-base-multilingual"
CROSS_ENCODER_TOP_K = 6  # —Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ rerank

_cross_encoder = CrossEncoder(
    CROSS_ENCODER_MODEL,
    max_length=128,
    trust_remote_code=True
)

if MODEL_SOURCE == "deepseek":
    print("deepseek")


    def _deepseek_chat(messages: List[Dict[str, str]], temperature: float) -> str:
        if not DEEPSEEK_API_KEY:
            raise RuntimeError("DEEPSEEK_API_KEY is not set")

        r = requests.post(
            f"{DEEPSEEK_BASE_URL}/chat/completions",
            headers={
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json",
            },
            json={
                "model": DEEPSEEK_MODEL,
                "messages": messages,
                "max_tokens": DEEPSEEK_MAX_TOKENS,
                "temperature": float(temperature),
            },
            timeout=DEEPSEEK_TIMEOUT,
        )
        r.raise_for_status()
        return r.json()["choices"][0]["message"]["content"].strip()


    def _invoke(prompt: ChatPromptTemplate, vars: Dict[str, Any], temperature: float) -> str:
        """Invoke DeepSeek with LangChain prompt messages."""
        lc_msgs = prompt.format_messages(**vars)
        ds_msgs: List[Dict[str, str]] = []

        for m in lc_msgs:
            if isinstance(m, SystemMessage):
                ds_msgs.append({"role": "system", "content": m.content})
            elif isinstance(m, HumanMessage):
                ds_msgs.append({"role": "user", "content": m.content})
            elif isinstance(m, AIMessage):
                ds_msgs.append({"role": "assistant", "content": m.content})
            else:
                ds_msgs.append({"role": "user", "content": str(getattr(m, "content", m))})

        return _deepseek_chat(ds_msgs, temperature=temperature)
elif MODEL_SOURCE == "openai":

    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY is not set")

    _BASE_LLM = ChatOpenAI(
        model=OPENAI_MODEL,
        api_key=OPENAI_API_KEY,
        base_url=OPENAI_BASE_URL,
        timeout=OPENAI_TIMEOUT,
        max_retries=2,
    )


    def _invoke(prompt: ChatPromptTemplate, vars: Dict[str, Any], temperature: float) -> str:
        lc_msgs = prompt.format_messages(**vars)
        llm = _BASE_LLM
        if OPENAI_MAX_TOKENS:
            llm = llm.bind(max_tokens=int(OPENAI_MAX_TOKENS))
        res = llm.invoke(lc_msgs)
        return (getattr(res, "content", str(res)) or "").strip()
else:
    raise ValueError("No correct MODEL_SOURCE")


def _extract_json(text: str) -> Optional[dict]:
    if not text:
        return None
    m = re.search(r"\{.*\}", text, flags=re.S)
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except Exception:
        return None


def _dedup(xs: List[str]) -> List[str]:
    out, seen = [], set()
    for x in xs:
        x = (x or "").strip()
        if x and x not in seen:
            out.append(x)
            seen.add(x)
    return out


def _hits_to_context(hits: List[dict]) -> str:
    print(len(hits))
    parts = []
    for i, h in enumerate(hits or [], start=1):
        chunk = (h.get("chunk") or "").strip()
        if not chunk:
            continue
        title = h.get("document_title") or ""
        sec = h.get("section_title") or ""
        url = h.get("url") or ""
        header = f"[{i}] {title} | {sec}".strip()
        if url:
            header += f" | {url}"
        parts.append(header + "\n" + chunk)

    ctx = "\n\n---\n\n".join(parts).strip()
    if len(ctx) > MAX_CONTEXT_CHARS:
        ctx = ctx[: MAX_CONTEXT_CHARS - 3] + "..."
    return ctx


def _fallback_route(text: str) -> str:
    t = (text or "").lower()
    if any(k in t for k in ("—Å–æ–±–µ—Å–µ–¥", "–∏–Ω—Ç–µ—Ä–≤", "interview", "mock", "—Ç–µ—Å—Ç", "–≤–æ–ø—Ä–æ—Å—ã")):
        return "interview"
    if any(k in t for k in ("–∫—É—Ä—Å", "–ø–ª–∞–Ω", "roadmap", "–ø–æ–¥–≥–æ—Ç–æ–≤", "—É—á–∏—Ç—å", "–ø—Ä–æ–≥—Ä–∞–º–º–∞")):
        return "course"
    return "qa"


ROUTER = ChatPromptTemplate.from_messages([
    ("system",
     "–¢—ã —Ä–æ—É—Ç–µ—Ä. –í—ã–±–µ—Ä–∏ —Å—Ü–µ–Ω–∞—Ä–∏–π: qa | interview | course.\n"
     "–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON:\n"
     '{{"route":"qa|interview|course","topic":"","n_questions":10,"weeks":2,"level":"junior|middle|senior"}}\n'
     "–ï—Å–ª–∏ —Ç–µ–º–∞ –Ω–µ –Ω—É–∂–Ω–∞ ‚Äî topic –ø—É—Å—Ç–æ–π. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∫—Ä–æ–º–µ JSON."
     ),
    ("human", "{text}")
])


def _route(text: str) -> Dict[str, Any]:
    raw = _invoke(ROUTER, {"text": text}, temperature=ROUTER_TEMP)
    data = _extract_json(raw) or {}
    route = (data.get("route") or "").strip().lower()
    if route not in ("qa", "interview", "course"):
        route = _fallback_route(text)
    return {
        "route": route,
        "topic": (data.get("topic") or "").strip(),
        "n_questions": int(data.get("n_questions") or 10),
        "weeks": int(data.get("weeks") or 2),
        "level": (data.get("level") or "middle").strip().lower(),
        "router_raw": raw,
    }


QA_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –ø–æ-—Ä—É—Å—Å–∫–∏, –∫—Ä–∞—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ.\n"
     + ("–í–ê–ñ–ù–û: –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.\n" if RAG_ONLY else
        "–û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ï—Å–ª–∏ –µ–≥–æ –º–∞–ª–æ ‚Äî –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è, –Ω–æ –ø–æ–º–µ—Ç—å –∏—Ö –∫–∞–∫ '–≤–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞'.\n")
     ),
    ("human", "–í–æ–ø—Ä–æ—Å:\n{question}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–û—Ç–≤–µ—Ç:")
])

INTERVIEW_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "–¢—ã –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –°–¥–µ–ª–∞–π —Ç–µ—Å—Ç –∏ –∑–∞—Ç–µ–º –æ—Ç–≤–µ—Ç—ã.\n"
     "–§–æ—Ä–º–∞—Ç:\n"
     "## –í–æ–ø—Ä–æ—Å—ã\n1)...\n\n"
     "## –û—Ç–≤–µ—Ç—ã –∏ —Ä–∞–∑–±–æ—Ä\n1)...\n\n"
     "–í —Ä–∞–∑–±–æ—Ä–µ —Å—Å—ã–ª–∞–π—Å—è –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ [1],[2]...\n"
     + ("–í–ê–ñ–ù–û: –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç ‚Äî –ø–∏—à–∏ '–Ω–µ—Ç –≤ –±–∞–∑–µ'.\n" if RAG_ONLY else "")
     ),
    ("human", "–¢–µ–º–∞: {topic}\n–°–¥–µ–ª–∞–π {n} –≤–æ–ø—Ä–æ—Å–æ–≤.\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n")
])

COURSE_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "–¢—ã –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫. –°–æ–±–µ—Ä–∏ –ø–ª–∞–Ω –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é.\n"
     "–ù—É–∂–Ω–æ: —Ü–µ–ª—å, –ø–ª–∞–Ω –ø–æ –Ω–µ–¥–µ–ª—è–º (—Ç–µ–º—ã/–ø—Ä–∞–∫—Ç–∏–∫–∞/—á–µ–∫-–ª–∏—Å—Ç), –º–∏–Ω–∏-–ø—Ä–æ–µ–∫—Ç –≤ –∫–æ–Ω—Ü–µ.\n"
     + ("–í–ê–ñ–ù–û: –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å—Å—ã–ª–∫–∏ –∏–∑ –Ω–µ–≥–æ.\n" if RAG_ONLY else
        "–û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ï—Å–ª–∏ —Å—Å—ã–ª–æ–∫ –Ω–µ—Ç ‚Äî —á–µ—Å—Ç–Ω–æ –ø–æ–º–µ—Ç—å —ç—Ç–æ.\n")
     ),
    ("human", "–¢–µ–º–∞: {topic}\n–£—Ä–æ–≤–µ–Ω—å: {level}\n–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {weeks} –Ω–µ–¥–µ–ª—å\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n")
])


def _rag_context(route: str, user_text: str, topic: str, search_client) -> Tuple[str, List[dict]]:
    n_queries = 3
    print(user_text)
    queries = _rewrite_queries(user_text, n=n_queries)
    print(queries)
    # 2. –ü–æ–∏—Å–∫ –ø–æ –∫–∞–∂–¥–æ–º—É –∑–∞–ø—Ä–æ—Å—É
    all_hits: List[dict] = []
    for qu in queries:
        try:
            hits = asyncio.run(search_client.search(qu, k=TOP_K))
            all_hits.extend(hits or [])
        except Exception:
            continue

    # 3. –î–µ–¥—É–ø –ø–æ chunk + url
    seen = set()
    uniq_hits = []
    for h in all_hits:
        key = (
            (h.get("chunk") or "").strip(),
            (h.get("url") or "").strip(),
        )
        if key in seen:
            continue
        seen.add(key)
        uniq_hits.append(h)
    print(user_text)
    # üîπ Cross-encoder rerank
    reranked_hits = _rerank_hits(
        query=user_text,
        hits=uniq_hits,
        top_k=CROSS_ENCODER_TOP_K,
    )

    context = _hits_to_context(reranked_hits)

    return context, reranked_hits


VALIDATOR = ChatPromptTemplate.from_messages([
    ("system",
     "–¢—ã –≤–∞–ª–∏–¥–∞—Ç–æ—Ä. –£ —Ç–µ–±—è –µ—Å—Ç—å –∑–∞–ø—Ä–æ—Å, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∏ —á–µ—Ä–Ω–æ–≤–∏–∫.\n"
     "–û—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.\n"
     "–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞."
     + ("" if RAG_ONLY else "\n–ï—Å–ª–∏ –¥–æ–±–∞–≤–ª—è–µ—à—å –æ–±—â–µ–µ –∑–Ω–∞–Ω–∏–µ ‚Äî —è–≤–Ω–æ –ø–æ–º–µ—Ç—å –∫–∞–∫ '–≤–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞'.")
     ),
    ("human", "–ó–∞–ø—Ä–æ—Å:\n{user_text}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–ß–µ—Ä–Ω–æ–≤–∏–∫:\n{draft}\n\n–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:")
])

FINALIZER = ChatPromptTemplate.from_messages([
    ("system", "–°–¥–µ–ª–∞–π –æ—Ç–≤–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —á–∏—Ç–∞–±–µ–ª—å–Ω—ã–º: –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, –∫—Ä–∞—Ç–∫–æ—Å—Ç—å. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã."),
    ("human", "{text}")
])


def _rewrite_queries(text: str, n: int = 5) -> List[str]:
    QUERY_REWRITE_PROMPT = ChatPromptTemplate.from_messages([
        ("system",
         "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n"
         "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.\n"
         "–†–∞–∑–¥–µ–ª–∏ –µ–≥–æ –Ω–∞ –ø–æ–¥–∑–∞–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç —á–∞—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞"
         "–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON –±–µ–∑ —Ç–µ–∫—Å—Ç–∞:\n"
         '{{"queries": ["...","..."]}}\n'
         ),
        ("human", "{text}")
    ])
    raw = _invoke(
        QUERY_REWRITE_PROMPT,
        {"text": text},
        temperature=0.3,
    )
    data = _extract_json(raw) or {}
    queries = data.get("queries") or []

    if not isinstance(queries, list):
        return [text]

    queries = [q.strip() for q in queries if isinstance(q, str) and q.strip()]
    queries = queries[:n]

    # –≤—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    return _dedup([text] + queries)


def _rerank_hits(
        query: str,
        hits: List[dict],
        top_k: int = CROSS_ENCODER_TOP_K,
) -> List[dict]:
    """
    Rerank hits using cross-encoder.
    Each hit must contain 'chunk'.
    """

    if not hits:
        return []

    pairs = []
    valid_hits = []

    for h in hits:
        chunk = (h.get("chunk") or "").strip()
        if not chunk:
            continue
        pairs.append((query, chunk))
        valid_hits.append(h)

    if not pairs:
        return []
    print(pairs)
    try:
        scores = _cross_encoder.predict(pairs, show_progress_bar=True)
    except Exception:
        return hits[:top_k]

    for h, s in zip(valid_hits, scores):
        h["_ce_score"] = float(s)

    valid_hits.sort(key=lambda x: x.get("_ce_score", 0.0), reverse=True)
    print(valid_hits)
    return valid_hits[:top_k]


# MAIN
def agent_main(user_input: Union[str, Dict[str, Any]],
               search_client,
               history: Optional[Dict[str, Any]] = None) -> str:
    if isinstance(user_input, dict):
        user_text = str(user_input.get("text") or user_input.get("query") or user_input.get("message") or "").strip()
    else:
        user_text = str(user_input or "").strip()

    history_str = ""
    if history:
        try:
            history_str = json.dumps(history, ensure_ascii=False, indent=2)
        except Exception:
            history_str = str(history)
    orig_query = user_text
    if history_str:
        user_text = f"–ò—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–ø–∏—Å–∫–∏ (json), –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å:\n{history_str}\n\n–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å:\n{user_text}".strip()

    if not user_text:
        return "–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å. –ù–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Ç–µ–º—É."

    r = _route(user_text)
    route, topic = r["route"], r["topic"]
    context, hits = _rag_context(route, user_text=orig_query, topic=topic, search_client=search_client)

    if RAG_ONLY and not context.strip():
        return "–ù–µ –Ω–∞—à—ë–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –ø–æ —ç—Ç–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."
    if route == "interview":
        draft = _invoke(
            INTERVIEW_PROMPT,
            {"topic": topic or user_text, "n": r["n_questions"], "context": context or "(–ø—É—Å—Ç–æ)"},
            temperature=WORK_TEMP,
        )
    elif route == "course":
        draft = _invoke(
            COURSE_PROMPT,
            {"topic": topic or user_text, "weeks": r["weeks"], "level": r["level"], "context": context or "(–ø—É—Å—Ç–æ)"},
            temperature=WORK_TEMP,
        )
    else:
        draft = _invoke(
            QA_PROMPT,
            {"question": user_text, "context": context or "(–ø—É—Å—Ç–æ)"},
            temperature=WORK_TEMP,
        )

    checked = _invoke(
        VALIDATOR,
        {"user_text": user_text, "context": context or "(–ø—É—Å—Ç–æ)", "draft": draft},
        temperature=VALIDATOR_TEMP,
    )

    final_text = _invoke(FINALIZER, {"text": checked}, temperature=FINAL_TEMP).strip()

    if INCLUDE_SOURCES:
        if hits:
            final_text += "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö):\n" + "\n".join(
                f"{s['document_title']}- {s['url']}" for s in hits)
        elif RAG_ONLY:
            final_text += "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."

    return final_text
